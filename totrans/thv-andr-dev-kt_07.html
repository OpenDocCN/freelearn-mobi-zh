<html><head></head><body>
<div><h1 class="chapter-number" id="_idParaDest-108"><a id="_idTextAnchor109" class="calibre6 pcalibre1 pcalibre"/>5</h1>
<h1 id="_idParaDest-109" class="calibre5"><a id="_idTextAnchor110" class="calibre6 pcalibre1 pcalibre"/>Creating a Photo Editor Using CameraX</h1>
<p class="calibre3">In the smartphone era, taking and sharing photos has become second nature, and platforms such as Instagram have shown us how powerful a single photo can be. For apps like these, it’s not just about snapping a picture; it’s about enhancing and personalizing that image to tell a story. But have you ever wondered what lies behind those in-app camera buttons and filters?</p>
<p class="calibre3">Enter CameraX, Android’s go-to tool for everything camera-related. This tool doesn’t just make capturing photos seamless; it’s also the bridge to editing and refining them. In this chapter, we’ll get hands-on with CameraX, discovering how it can transform the Packtagram photography experience. We’ll also design an interactive space for users to tweak and enhance their shots, adding that personal touch. And for the cherry on top? We’ll dive into a bit of smart tech, teaching our app to recognize photo themes and suggest relevant hashtags.</p>
<p class="calibre3">Building on our prior work – crafting the screens and feed for our Instagram-inspired app – we’re now diving deeper into the app’s features. With CameraX, intuitive editing tools, and some clever features, we’re set to elevate our app’s photo-sharing game.</p>
<p class="calibre3">In this chapter, we will cover the following topics:</p>
<ul class="calibre15">
<li class="calibre14">Getting to know CameraX</li>
<li class="calibre14">Integrating CameraX into our Packtagram app</li>
<li class="calibre14">Adding photo-editing functionalities</li>
<li class="calibre14">Using <strong class="bold">machine learning</strong> (<strong class="bold">ML</strong>) to categorize photos and generate hashtags</li>
</ul>
<h1 id="_idParaDest-110" class="calibre5"><a id="_idTextAnchor111" class="calibre6 pcalibre1 pcalibre"/>Technical requirements</h1>
<p class="calibre3">As in the previous chapter, you will need to have Android Studio (or another editor of your preference) installed.</p>
<p class="calibre3">You can find the complete code that we will be using in this chapter in this book’s GitHub repository: <a href="https://github.com/PacktPublishing/Thriving-in-Android-Development-using-Kotlin/tree/main/Chapter-5" class="calibre6 pcalibre1 pcalibre">https://github.com/PacktPublishing/Thriving-in-Android-Development-using-Kotlin/tree/main/Chapter-5</a>.</p>
<h1 id="_idParaDest-111" class="calibre5"><a id="_idTextAnchor112" class="calibre6 pcalibre1 pcalibre"/>Getting to know CameraX</h1>
<p class="calibre3">Since the inception of the Android<a id="_idIndexMarker526" class="calibre6 pcalibre1 pcalibre"/> platform, cameras have played a pivotal role in defining the feature set of smartphones. From capturing moments to enabling augmented reality experiences, the camera has evolved from a mere hardware component to a powerful tool for developers. This evolution, however, has not been without its complexities.</p>
<h2 id="_idParaDest-112" class="calibre7"><a id="_idTextAnchor113" class="calibre6 pcalibre1 pcalibre"/>The evolution of camera libraries in Android</h2>
<p class="calibre3">Since the first version<a id="_idIndexMarker527" class="calibre6 pcalibre1 pcalibre"/> of Android, developers interacted<a id="_idIndexMarker528" class="calibre6 pcalibre1 pcalibre"/> with the camera hardware through the Camera API; this was Android’s first attempt at giving developers the power to harness the capabilities of onboard cameras.</p>
<p class="calibre3">As devices proliferated and features such as more advanced photo hardware grew, the need for a more robust API became evident. Consequently, Camera2 API was introduced in API level 21 (Lollipop). While this offered more granular control over camera capabilities and supported the expanding features of new hardware, its steep learning curve made camera development challenging for many in terms of complexity and performance overhead.</p>
<p class="calibre3">Given the intricacies of Camera2 and the variances in camera hardware across different devices, developers found it increasingly difficult to provide a consistent camera experience to end users. This fragmentation, alongside the complexity of Camera2, made it imperative for a more streamlined, developer-friendly solution.</p>
<p class="calibre3">Enter CameraX.</p>
<h2 id="_idParaDest-113" class="calibre7"><a id="_idTextAnchor114" class="calibre6 pcalibre1 pcalibre"/>The importance and advantages of CameraX</h2>
<p class="calibre3"><strong class="bold">CameraX</strong> is Android’s modern solution for camera<a id="_idIndexMarker529" class="calibre6 pcalibre1 pcalibre"/> app development that was developed<a id="_idIndexMarker530" class="calibre6 pcalibre1 pcalibre"/> with the primary goal of simplifying the process while reducing the fragmentation between devices. Here’s why it has quickly become indispensable:</p>
<ul class="calibre15">
<li class="calibre14"><strong class="bold">Consistency across devices</strong>: CameraX abstracts the differences between device-specific camera behaviors, ensuring that most features work consistently across a wide range of devices.</li>
<li class="calibre14"><strong class="bold">Life cycle awareness</strong>: Gone are the days of tedious life cycle management. CameraX is integrated with Android’s life cycle libraries, meaning less boilerplate code and more focus on core camera functionality.</li>
<li class="calibre14"><strong class="bold">Use case-based approach</strong>: Instead of dealing with low-level tasks, developers can now focus on specific use cases, such as image preview, image capture, and image analysis. This makes development faster and less error-prone.</li>
<li class="calibre14"><strong class="bold">Extensions for enhanced capabilities</strong>: With the CameraX Extensions API, developers can access device-specific features such as portrait mode, HDR, and more, further enriching the camera experience.</li>
<li class="calibre14"><strong class="bold">Backward compatibility</strong>: CameraX offers compatibility with devices running Android 5.0 (API level 21) and beyond, ensuring a wider reach than Camera2.</li>
<li class="calibre14"><strong class="bold">Performance and quality</strong>: CameraX provides optimized performance out of the box, delivering high-quality images and videos without the need for extra tuning.</li>
</ul>
<p class="calibre3">In summary, CameraX has not only simplified camera app development but also bridged the gap that’s caused by hardware discrepancies. As we delve deeper into this chapter, you’ll come to appreciate the nuances and capabilities that CameraX brings to the table, setting the stage for powerful, consistent, and high-quality camera applications on Android.</p>
<p class="calibre3">Now, let’s start using CameraX and configuring its dependencies in our project.</p>
<h2 id="_idParaDest-114" class="calibre7"><a id="_idTextAnchor115" class="calibre6 pcalibre1 pcalibre"/>Setting up CameraX</h2>
<p class="calibre3">To set up CameraX, we need to add<a id="_idIndexMarker531" class="calibre6 pcalibre1 pcalibre"/> the necessary dependencies to our version catalog file, <code>libs.versions.toml</code>, as follows:</p>
<pre class="source-code">
[versions]
...
camerax = "1.2.1"
accompanist = "0.31.1-alpha"
[libraries]
...
cameraCore = { module = "androidx.camera:camera-core", version.ref = "camerax" }
cameraCamera2 = { module = "androidx.camera:camera-camera2", version.ref = "camerax" }
cameraView = { module = "androidx.camera:camera-view", version.ref = "camerax" }
cameraExtensions = { module = "androidx.camera:camera-extensions", version.ref = "camerax" }
accompanist = { group = "com.google.accompanist", name = "accompanist-permissions", version.ref = "accompanist"}</pre> <p class="calibre3">In this code block, we are adding the dependencies that are needed to use CameraX, plus a library called Accompanist.</p>
<p class="calibre3"><strong class="bold">Accompanist</strong> is a collection of extension<a id="_idIndexMarker532" class="calibre6 pcalibre1 pcalibre"/> libraries that are designed to complement Jetpack Compose. It fills the gaps by offering utilities for specific use cases and easing the integration of Compose with other Android capabilities. The features of Accompanist include image loading integrations, useful components such as ViewPager, tools to manage system UI insets, Compose navigation enhancements, and permissions handling. To learn more and expand on this information, please<a id="_idIndexMarker533" class="calibre6 pcalibre1 pcalibre"/> refer to the official documentation: <a href="https://google.github.io/accompanist/" class="calibre6 pcalibre1 pcalibre">https://google.github.io/accompanist/</a>.</p>
<p class="calibre3">In our case, we are going to use it to simplify the process of checking and asking the user for camera permissions.</p>
<p class="calibre3">Regarding the dependencies to use CameraX, we are adding the following:</p>
<ul class="calibre15">
<li class="calibre14"><strong class="source-inline1">cameraCore</strong>: This dependency provides the core functionality of CameraX, including the ability to manage camera devices, configure capture sessions, and receive frames from the camera. It is the foundation for all other CameraX dependencies.</li>
<li class="calibre14"><strong class="source-inline1">cameraCamera2</strong>: This dependency provides the Camera2 implementation of CameraX, which is the most powerful and flexible way to access the camera on Android devices. It provides low-level access to the camera’s hardware and allows for custom capture configurations and processing pipelines.</li>
<li class="calibre14"><strong class="source-inline1">cameraView</strong>: This dependency provides a pre-built view component that integrates with CameraX to simplify the process of displaying camera preview frames. It takes care of the layout and setup of the view so that you can focus on capturing and processing the camera data.</li>
<li class="calibre14"><strong class="source-inline1">cameraExtensions</strong>: This dependency provides a set of extensions for CameraX that add additional features, such as support for focus peaking, image stabilization, and panorama capture. It also includes extensions for working with ML models on camera frames.</li>
</ul>
<p class="callout-heading">Note</p>
<p class="callout">The versions in the previous code are the latest stable ones at the time of writing this book, but there will likely be new ones by the time you are reading this.</p>
<p class="calibre3">After adding these dependencies<a id="_idIndexMarker534" class="calibre6 pcalibre1 pcalibre"/> to the version catalog, we need to add them to the <code>build.gradle.kts</code> file of the <code>:feature:stories</code> module, as follows:</p>
<pre class="source-code">
    implementation(libs.cameraCore)
    implementation(libs.cameraCamera2)
    implementation(libs.cameraView)
    implementation(libs.cameraExtensions)
    implementation(libs.androidx.camera.lifecycle)
    implementation(libs.accompanist)</pre> <p class="calibre3">Now that our project is ready<a id="_idIndexMarker535" class="calibre6 pcalibre1 pcalibre"/> to use CameraX, let’s learn more about the library.</p>
<h2 id="_idParaDest-115" class="calibre7"><a id="_idTextAnchor116" class="calibre6 pcalibre1 pcalibre"/>Learning about CameraX’s core concepts</h2>
<p class="calibre3">In this section, we’ll learn about some of CameraX’s most important concepts.</p>
<h3 class="calibre9">View life cycle</h3>
<p class="calibre3">CameraX, a Jetpack support library, simplifies<a id="_idIndexMarker536" class="calibre6 pcalibre1 pcalibre"/> camera development<a id="_idIndexMarker537" class="calibre6 pcalibre1 pcalibre"/> across Android devices, and its life-cycle-aware nature seamlessly integrates with Jetpack Compose, empowering developers to create resilient and efficient camera applications. At the core of CameraX’s design philosophy lies its inherent support for Android’s life cycle, which eliminates the complexities of managing camera resources. CameraX automatically handles camera start, stop, and resource release based on life cycle events, streamlining the development process.</p>
<p class="calibre3">Jetpack Compose, the declarative UI toolkit for Android, is also deeply rooted in life cycle concepts. Composables inherently possess life cycle states, such as <code>onActive</code> and <code>onDispose</code>, that get triggered during their existence within the UI hierarchy. Combining the powers of CameraX and Compose offers a harmonized approach to managing the camera’s life cycle within Composable UI components.</p>
<h3 class="calibre9">Image analysis</h3>
<p class="calibre3">CameraX goes beyond<a id="_idIndexMarker538" class="calibre6 pcalibre1 pcalibre"/> just capturing<a id="_idIndexMarker539" class="calibre6 pcalibre1 pcalibre"/> images. With <strong class="bold">image analysis</strong>, developers can process live camera feeds in real time. This is perfect for features such as barcode scanning, face detection, or even applying live filters. Here is an example:</p>
<pre class="source-code">
@Composable
fun CameraPreviewWithImageAnalysis() {
    val cameraProvider = rememberCameraProvider()
    val preview = remember { Preview.Builder().build() }
    val text = remember { mutableStateOf("Analyzing...") }
    val imageAnalyzer = ImageAnalysis.Builder()
        .setAnalyzer { image -&gt;
            // Process the image data here
            text.value = "Detected image to analyze..."
        }
        .build()
    LaunchedEffect(cameraProvider) {
        val useCaseBinding = UseCaseBinding.Builder()
            .addUseCases(preview, imageAnalyzer)
            .build()
        val camera =
            cameraProvider.bindToLifecycle(useCaseBinding)
        camera.close()
    }
    Box(modifier = Modifier.fillMaxSize()) {
        Preview(preview)
        Text(text.value)
    }
}</pre> <p class="calibre3">The preceding code defines a composable function called <code>CameraPreviewWithImageAnalysis</code> that displays a camera preview and analyzes the live camera feed, utilizing Jetpack Compose and CameraX to achieve this.</p>
<p class="calibre3">First, the <code>rememberCameraProvider</code> function is used to retrieve the camera provider instance, which is responsible for managing the camera’s life cycle and providing access to camera controls. Then, a <code>Preview</code> instance is created using <code>Preview.Builder</code> to define the camera preview surface. This preview will display the live camera feed on the screen.</p>
<p class="calibre3">After that, an <code>ImageAnalysis</code> instance is created using <code>ImageAnalysis.Builder</code> to process the live camera feed. The <code>setAnalyzer</code> method is used to specify an analyzer function that will be called whenever a new image frame is available.</p>
<p class="calibre3">A <code>LaunchedEffect</code> block is used to start a coroutine that binds the camera preview and image analyzer to the camera’s life cycle. The <code>bindToLifecycle</code> method is used to connect the use cases to the camera’s life cycle, ensuring that they start and stop automatically when the app starts and stops.</p>
<p class="calibre3">A <code>mutableStateOf</code> variable text is used to store the current state of the analysis. The text variable is updated within the analyzer function to reflect the results of the image analysis.</p>
<p class="calibre3">Finally, the <code>Box</code> composable<a id="_idIndexMarker540" class="calibre6 pcalibre1 pcalibre"/> is used to lay out the camera<a id="_idIndexMarker541" class="calibre6 pcalibre1 pcalibre"/> preview and the text. The <code>fillMaxSize</code> modifier is used to make <code>Box</code> occupy the entire screen. The <code>Preview</code> composable is placed inside <code>Box</code> to display the camera preview. The <code>Text</code> composable is also placed inside <code>Box</code> to display the current state of the analysis.</p>
<p class="calibre3">This is a basic example of how to apply image analysis, but there are some already existing image analyzers, such as <code>BarcodeScanner</code>. The following code is built upon the previous one, adding this analyzer:</p>
<pre class="source-code">
@Composable
fun BarcodeScannerPreview() {
    val cameraProvider = rememberCameraProvider()
    val preview = remember { Preview.Builder().build() }
    val barcodeText = remember { mutableStateOf("") }
    val barcodeScanner = BarcodeScanner.Builder()
        .setBarcodeFormats(BarcodeScannerOptions.
            BarcodeFormat.ALL_FORMATS)
        .build()
    LaunchedEffect(cameraProvider) {
        val imageAnalyzer = ImageAnalysis.Builder()
            .setAnalyzer { image -&gt;
                val rotation =
                    image.imageInfo.rotationDegrees
                val imageProxy =
                    InputImage.fromMediaImage(image.image,
                        rotation)
                barcodeScanner.processImage(imageProxy)
                    .addOnSuccessListener { barcodes -&gt;
                        if (barcodes.isNotEmpty()) {
                            val barcode = barcodes[0]
                            barcodeText.value =
                                barcode.displayValue
                        } else {
                            barcodeText.value = "No barcode
                                detected"
                        }
                    }
                    .addOnFailureListener { e -&gt;
                        barcodeText.value = "Barcode
                            scanning failed: ${e.message}"
                    }
            }
            .build()
        val useCaseBinding = UseCaseBinding.Builder()
            .addUseCases(preview, imageAnalyzer)
            .build()
        val camera =
            cameraProvider.bindToLifecycle(useCaseBinding)
        camera.close()
    }
    Box(modifier = Modifier.fillMaxSize()) {
        Preview(preview)
        Text(barcodeText.value)
    }
}</pre> <p class="calibre3">Similar to the previous<a id="_idIndexMarker542" class="calibre6 pcalibre1 pcalibre"/> example, this code<a id="_idIndexMarker543" class="calibre6 pcalibre1 pcalibre"/> defines a composable function called <code>BarcodeScannerPreview</code> that displays a camera preview and analyzes the live camera feed for barcodes. However, this code specifically focuses on barcode scanning and utilizes the ML Kit <code>BarcodeScanner</code> library to achieve this functionality.</p>
<p class="calibre3">First, the <code>rememberCameraProvider</code> and <code>Preview</code> functions are used in the same way as they were in the previous example to retrieve the camera provider instance and create a preview instance for displaying the live camera feed.</p>
<p class="calibre3">Then, a <code>BarcodeScanner</code> instance is created using <code>BarcodeScanner.Builder</code>, specifying the barcode formats to be detected. In this case, all barcode formats are specified using <code>BarcodeScannerOptions.BarcodeFormat.ALL_FORMATS</code>.</p>
<p class="calibre3">Following this, an <code>ImageAnalysis</code> instance is created using <code>ImageAnalysis.Builder</code>, and the analyzer function is defined to process each image frame. First, the analyzer function retrieves the image rotation from the <code>imageInfo</code> object. Then, it converts the <code>ImageProxy</code> instance into an <code>InputImage</code> format that’s compatible with ML Kit’s <code>BarcodeScanner</code>.</p>
<p class="calibre3">The <code>BarcodeScanner.processImage</code> method is called on the <code>InputImage</code> instance to detect barcodes. Here, <code>OnSuccessListener</code> is used to handle the successful barcode detection, while <code>OnFailureListener</code> is used to handle any errors that occur during barcode scanning.</p>
<p class="calibre3">If barcodes are detected, the <code>displayValue</code> value of the first barcode is extracted and stored in the <code>barcodeText</code> mutable state variable. This variable is used to update the text field with the detected barcode information.</p>
<p class="calibre3">With this, we have<a id="_idIndexMarker544" class="calibre6 pcalibre1 pcalibre"/> created our first image analyzer<a id="_idIndexMarker545" class="calibre6 pcalibre1 pcalibre"/> to get barcode information. Let’s move on to the next feature: <code>CameraSelector</code>.</p>
<h3 class="calibre9">CameraSelector</h3>
<p class="calibre3">When dealing with cameras, it’s not always<a id="_idIndexMarker546" class="calibre6 pcalibre1 pcalibre"/> about just one camera – many modern devices come with multiple camera lenses. This is where <code>CameraSelector</code> comes to the rescue, allowing developers to programmatically choose between, say, the front or rear camera. Whether you’re building a selfie app or a more standard photo application, <code>CameraSelector</code> ensures consistent behavior across the board. Let’s see how we can allow a user to select which camera they want to use:</p>
<pre class="source-code">
@Composable
fun CameraSelectorExample() {
    val cameraProvider = rememberCameraProvider()
    val preview = remember { Preview.Builder().build() }
    val isUsingFrontCamera = remember {
        mutableStateOf(true) }
    val cameraSelector = remember {
        if (isUsingFrontCamera.value) {
            CameraSelector.DEFAULT_FRONT_CAMERA
        } else {
            CameraSelector.DEFAULT_BACK_CAMERA
        }
    }
    val imageAnalyzer = ImageAnalysis.Builder()
        .setAnalyzer { image -&gt;
            // Process the image data here
        }
        .build()
    LaunchedEffect(cameraProvider) {
        val useCaseBinding = UseCaseBinding.Builder()
            .addUseCases(preview, imageAnalyzer)
            .build()
        val camera =
            cameraProvider.bindToLifecycle(useCaseBinding)
        camera.close()
    }
    Box(modifier = Modifier.fillMaxSize()) {
        Preview(preview)
        Column {
            Button(onClick = {
                isUsingFrontCamera.value =
                    !isUsingFrontCamera.value
            }) {
                Text("Switch Camera")
            }
        }
    }
}</pre> <p class="calibre3">The preceding code will display a camera preview and a button. Clicking the button will switch between the front and rear cameras. The <code>isUsingFrontCamera</code> mutable state variable is used to keep track of which camera is currently being used. Then, <code>cameraSelector</code> is updated whenever the <code>isUsingFrontCamera</code> variable changes. The camera preview is automatically updated to reflect the new camera selection.</p>
<p class="calibre3">It’s also possible to provide your users<a id="_idIndexMarker547" class="calibre6 pcalibre1 pcalibre"/> with more control over the camera functionality. So, let’s talk about <code>CameraControls</code>.</p>
<h3 class="calibre9">CameraControls</h3>
<p class="calibre3">A comprehensive camera experience<a id="_idIndexMarker548" class="calibre6 pcalibre1 pcalibre"/> isn’t just about capturing or analyzing an image. It’s also about control. With <code>CameraControls</code>, developers gain access to an array of functions that allow them to manipulate the camera feed. From zooming into a subject and adjusting focus for that crystal-clear shot to toggling the torch for those night-time snaps, <code>CameraControls</code> ensures users always get the perfect shot.</p>
<p class="calibre3">Here is an example of how to use <code>CameraControls</code> to zoom, adjust focus, and toggle the torch, starting with the first part of the code:</p>
<pre class="source-code">
@Composable
fun CameraControlsExample() {
    val cameraProvider = rememberCameraProvider()
    val preview = remember { Preview.Builder().build() }
    val zoomLevel = remember { mutableStateOf(1.0f) }
    val focusPoint = remember { mutableStateOf(0.5f, 0.5f) }
    val isTorchEnabled = remember { mutableStateOf(false) }
    val imageAnalyzer = ImageAnalysis.Builder()
        .setAnalyzer { image -&gt;
            // Process the image data here
        }
        .build()</pre> <p class="calibre3">In the preceding code, we are defining<a id="_idIndexMarker549" class="calibre6 pcalibre1 pcalibre"/> the <code>rememberCameraProvider</code> function, which is used to retrieve the camera provider instance. It manages the camera’s life cycle and provides access to camera controls. Then, <code>Preview.Builder()</code> is used to create a <code>Preview</code> instance, which defines the surface on which the live camera feed will be displayed.</p>
<p class="calibre3">Three <code>mutableStateOf</code> variables are used to store the state of the zoom level, focus point, and torch status:</p>
<ul class="calibre15">
<li class="calibre14"><strong class="source-inline1">zoomLevel</strong>: This stores the current zoom level, ranging from 1.0f (no zoom) to 5.0f (maximum zoom)</li>
<li class="calibre14"><strong class="source-inline1">focusPoint</strong>: This stores the current focus point, represented as a pair of coordinates (<em class="italic">x</em>, <em class="italic">y</em>) within the preview frame</li>
<li class="calibre14"><strong class="source-inline1">isTorchEnabled</strong>: This stores the current torch status, indicating whether the torch is enabled or disabled</li>
</ul>
<p class="calibre3">Let’s continue with the next part of the code:</p>
<pre class="source-code">
    LaunchedEffect(cameraProvider) {
        val cameraControl =
            cameraProvider.getCameraControl(preview)
        cameraControl.setZoomRatio(zoomLevel.value)
        cameraControl.setFocusPoint(focusPoint.value)
        cameraControl.enableTorch(isTorchEnabled.value)
        val useCaseBinding = UseCaseBinding.Builder()
            .addUseCases(preview, imageAnalyzer)
            .build()
        val camera =
            cameraProvider.bindToLifecycle(useCaseBinding)
        camera.close()
    }</pre> <p class="calibre3">Here, the <code>cameraControl.getCameraControl(preview)</code> method<a id="_idIndexMarker550" class="calibre6 pcalibre1 pcalibre"/> retrieves the <code>CameraControl</code> instance associated with the preview. This instance provides access to various camera controls:</p>
<ul class="calibre15">
<li class="calibre14"><strong class="source-inline1">cameraControl.setZoomRatio(zoomLevel.value)</strong>: This control sets the zoom level using the value stored in the <strong class="source-inline1">zoomLevel</strong> variable</li>
<li class="calibre14"><strong class="source-inline1">cameraControl.setFocusPoint(focusPoint.value)</strong>: This control sets the focus point using the coordinates stored in the <strong class="source-inline1">focusPoint</strong> variable</li>
<li class="calibre14"><strong class="source-inline1">cameraControl.enableTorch(isTorchEnabled.value)</strong>: This control enables or disables the torch based on the value stored in the <strong class="source-inline1">isTorchEnabled</strong> variable</li>
</ul>
<p class="calibre3">Now, let’s move<a id="_idIndexMarker551" class="calibre6 pcalibre1 pcalibre"/> on to the last chunk of code:</p>
<pre class="source-code">
    Box(modifier = Modifier.fillMaxSize()) {
        Preview(preview)
        Column {
            Slider(
                value = zoomLevel.value,
                onValueChange = { zoomLevel.value = it },
                valueRange = 1.0f..5.0f,
                steps = 10
            ) {
                Text("Zoom")
            }
            Button(onClick = {
                val newFocusPoint = if (focusPoint.value ==
                0.5f) {
                    0.1f to 0.1f
                } else {
                    0.5f to 0.5f
                }
                focusPoint.value = newFocusPoint
                cameraControl.setFocusPoint(newFocusPoint)
            }) {
                Text("Adjust Focus")
            }
            Button(onClick = {
                isTorchEnabled.value =
                    !isTorchEnabled.value
                cameraControl.enableTorch(
                    isTorchEnabled.value)
            }) {
                Text("Toggle Torch")
            }
        }
    }
}</pre> <p class="calibre3">In this last code block, the controls<a id="_idIndexMarker552" class="calibre6 pcalibre1 pcalibre"/> are configured and used within the <code>Column</code> layout:</p>
<ul class="calibre15">
<li class="calibre14">A <strong class="source-inline1">Slider</strong> component is used to adjust the zoom level. The <strong class="source-inline1">valueRange</strong> property defines the range of zoom levels (1.0f to 5.0f), and the <strong class="source-inline1">onValueChange</strong> callback updates the <strong class="source-inline1">zoomLevel</strong> variable with the selected zoom level.</li>
<li class="calibre14">A <strong class="source-inline1">Button</strong> component triggers a change in the focus point. When clicked, it updates the <strong class="source-inline1">focusPoint</strong> variable between two predefined locations (0.5f to 0.5f and 0.1f to 0.1f).</li>
<li class="calibre14">Another <strong class="source-inline1">Button</strong> component toggles the torch status. When clicked, it updates the <strong class="source-inline1">isTorchEnabled</strong> variable and calls <strong class="source-inline1">cameraControl.enableTorch</strong> to set the torch accordingly.</li>
</ul>
<p class="calibre3">In conclusion, CameraX provides<a id="_idIndexMarker553" class="calibre6 pcalibre1 pcalibre"/> a robust and versatile platform for developing high-quality camera applications on Android. It offers a simplified API, streamlined use cases, and a comprehensive set of features, making it an ideal choice for building modern camera-centric apps. Now, we are ready to use it in our app.</p>
<h1 id="_idParaDest-116" class="calibre5"><a id="_idTextAnchor117" class="calibre6 pcalibre1 pcalibre"/>Integrating CameraX into our Packtagram app</h1>
<p class="calibre3">Now that we know more<a id="_idIndexMarker554" class="calibre6 pcalibre1 pcalibre"/> about CameraX, let’s start integrating<a id="_idIndexMarker555" class="calibre6 pcalibre1 pcalibre"/> it into our app. First, we will need to deal with the camera permissions, providing a way for the user to accept them. Then, we will set up our camera preview and add the camera capture functionality to our code.</p>
<h2 id="_idParaDest-117" class="calibre7"><a id="_idTextAnchor118" class="calibre6 pcalibre1 pcalibre"/>Setting up the permissions checker with Accompanist</h2>
<p class="calibre3">There are several ways to check<a id="_idIndexMarker556" class="calibre6 pcalibre1 pcalibre"/> if the camera permissions<a id="_idIndexMarker557" class="calibre6 pcalibre1 pcalibre"/> have been granted, and if not, to request them: we could do this manually or use a library. In this case, we will use the Accompanist library, as we introduced at the beginning of this chapter.</p>
<p class="calibre3">Before requesting any permission at runtime, it’s fundamental to declare the same permissions in the app’s <code>AndroidManifest.xml</code> file. This declaration informs the Android operating system of the app’s intentions. For the camera permission, you need to add the following line within the <code>&lt;</code><code>manifest&gt;</code> tag:</p>
<pre class="console">
&lt;uses-permission android:name="android.permission.CAMERA" /&gt;</pre> <p class="calibre3">While the manifest informs the system of the app’s needs, runtime permissions are about seeking the user’s explicit consent. Ensure you always have both in place when accessing protected features or user data.</p>
<p class="calibre3">Now, let’s go into the permissions checker code. Our aim here is to create a reusable composable function that can handle the camera permission elegantly. It should be able to request the permission, handle user<a id="_idIndexMarker558" class="calibre6 pcalibre1 pcalibre"/> decisions, and, if necessary, explain<a id="_idIndexMarker559" class="calibre6 pcalibre1 pcalibre"/> why the app needs this permission.</p>
<p class="calibre3">First, we need to import the required libraries:</p>
<pre class="source-code">
import com.google.accompanist.permissions.ExperimentalPermissionsApi
import com.google.accompanist.permissions.PermissionState
import com.google.accompanist.permissions.rememberPermissionState
@OptIn(ExperimentalPermissionsApi::class)
@Composable
fun CameraPermissionRequester(onPermissionGranted: () -&gt; Unit) {
    // ... code ...
}</pre> <p class="calibre3">Here, the <code>@OptIn</code> annotation indicates that we’re using an experimental API from the Accompanist permissions library.</p>
<p class="calibre3">Now, inside <code>CameraPermissionRequester</code>, we need to add the following:</p>
<pre class="source-code">
val cameraPermissionState = rememberPermissionState(Manifest.permission.CAMERA)</pre> <p class="calibre3">Here, <code>rememberPermissionState</code> is a helper function that recalls the current state of the camera permission. It provides information such as whether the permission is granted, if we’ve already asked the user, or if we should show a rationale.</p>
<p class="calibre3">With the permission state in hand, we can create a UI flow that responds to this state:</p>
<ul class="calibre15">
<li class="calibre14"><strong class="bold">Permission granted</strong>: If permission is already granted, the user can directly proceed to use the camera.</li>
<li class="calibre14"><strong class="bold">Show rationale</strong>: Sometimes, if a user denies a certain permission, it’s helpful to explain why the app needs that permission. This is where the rationale comes into play.</li>
<li class="calibre14"><strong class="bold">Permission not yet requested</strong>: If the app hasn’t asked for the permission yet, we want to provide a button to initiate the request.</li>
<li class="calibre14"><strong class="bold">Permission denied without rationale</strong>: In some cases, users deny permissions and opt not to be asked again. It’s good practice to guide them to the app settings if they change their mind.</li>
</ul>
<p class="calibre3">Let’s learn how to handle<a id="_idIndexMarker560" class="calibre6 pcalibre1 pcalibre"/> all these possible flows. First, we will create<a id="_idIndexMarker561" class="calibre6 pcalibre1 pcalibre"/> a new composable called <code>CameraPermissionRequester</code>. The <code>onPermissionGranted</code> callback is provided to handle the scenario when the camera permission has been granted:</p>
<pre class="source-code">
@OptIn(ExperimentalPermissionsApi::class)
@Composable
fun CameraPermissionRequester(onPermissionGranted:
@Composable () -&gt; Unit) {</pre> <p class="calibre3">Next, we will retrieve <code>cameraPermissionState</code>:</p>
<pre class="source-code">
    // Camera permission state
    val cameraPermissionState = rememberPermissionState(
        android.Manifest.permission.CAMERA
    )</pre> <p class="calibre3">The <code>rememberPermissionState(permission)</code> function retrieves the current state of the specified permission. In this case, we’re checking the status of the <code>CAMERA</code> permission, which is necessary for accessing the device’s camera. The result is stored in the <code>cameraPermissionState</code> variable.</p>
<p class="calibre3">Now, let’s evaluate the different values it could have:</p>
<pre class="source-code">
    if (cameraPermissionState.status.isGranted) {
        OnPermissionGranted.invoke()</pre> <p class="calibre3">In the previous code block, we are starting to evaluate the <code>status.isGranted</code> property of the <code>cameraPermissionState</code> object, which indicates whether the permission has been granted. If it’s true, it means the permission is available, and we can call the <code>onPermissionGranted</code> callback to proceed with using the camera features.</p>
<p class="calibre3">If it is false, this means that the permission<a id="_idIndexMarker562" class="calibre6 pcalibre1 pcalibre"/> hasn’t been granted, so we will have to communicate<a id="_idIndexMarker563" class="calibre6 pcalibre1 pcalibre"/> that situation to the user and give them the option to grant it:</p>
<pre class="source-code">
    } else {
                Surface(
                    modifier = Modifier
                        .fillMaxWidth()
                        .padding(16.dp)
                        .padding(top = 24.dp),
                    color =
                      MaterialTheme.colorScheme.background,
        ) {
            Column(
                modifier = Modifier.padding(16.dp),
                verticalArrangement =
                    Arrangement.spacedBy(12.dp),
                horizontalAlignment =
                    Alignment.CenterHorizontally
            ) {
                val textToShow = if
                (cameraPermissionState.shouldShowRationale)
                {
                    "The camera and record audio are
                     important for this app. Please grant
                     the permissions."
                } else {
                    "Camera permission is required for this
                     feature to be available. Please grant
                     the permission."
                }
                Text(
                    text = textToShow,
                    style =
                    MaterialTheme.typography.bodyLarge.copy
                    (
                        fontSize = 16.sp,
                        fontWeight = FontWeight.Medium
                    ),
                    color =
                    MaterialTheme.colorScheme.onBackground
                )
                Button(
                    onClick = { cameraPermissionState
                        .launchMultiplePermissionRequest()
                        },
                    colors = ButtonDefaults.buttonColors(
                        containerColor =
                        MaterialTheme.colorScheme.primary,
                        contentColor =
                        MaterialTheme.colorScheme.onPrimary
                    ),
                    contentPadding = PaddingValues(12.dp)
                ) {
                    Text("Request Permission",
                        fontSize = 14.sp,
                            fontWeight = FontWeight.Bold)
                }
            }
        }
    }
}</pre> <p class="calibre3">In the previous code<a id="_idIndexMarker564" class="calibre6 pcalibre1 pcalibre"/> block, we’re displaying a message<a id="_idIndexMarker565" class="calibre6 pcalibre1 pcalibre"/> explaining the need for the permission and providing a <code>Button</code> component to initiate the permission request process. The <code>onClick</code> handler of the button triggers the <code>launchPermissionRequest()</code> method of the <code>cameraPermissionState</code> object, which prompts the user to grant the permission.</p>
<p class="calibre3">The <code>launchPermissionRequest()</code> method opens a system dialogue requesting the user to grant the <code>CAMERA</code> permission. The dialogue provides clear instructions and explains the reasons why the permission is required.</p>
<p class="calibre3">If we run this code now, we should see the two screens. First, we will see our screen with the message to request the permissions (left). Once we click <strong class="bold">Request permission</strong>, we will see the system<a id="_idIndexMarker566" class="calibre6 pcalibre1 pcalibre"/> prompt to accept<a id="_idIndexMarker567" class="calibre6 pcalibre1 pcalibre"/> the permission (right):</p>
<div><div><img alt="Figure 5.1: Camera permission requested in our app (left) and system prompt to grant capture and record permissions (right)" src="img/B19443_05_001.jpg" class="calibre4"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"> </p>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 5.1: Camera permission requested in our app (left) and system prompt to grant capture and record permissions (right)</p>
<p class="calibre3">Once the permissions have been<a id="_idIndexMarker568" class="calibre6 pcalibre1 pcalibre"/> granted, <code>CameraPreview</code> can start<a id="_idIndexMarker569" class="calibre6 pcalibre1 pcalibre"/> working. We will use the <code>onPermissionGranted</code> callback to show it.</p>
<h2 id="_idParaDest-118" class="calibre7"><a id="_idTextAnchor119" class="calibre6 pcalibre1 pcalibre"/>Creating our own CameraPreview</h2>
<p class="calibre3">The following <code>CameraPreview</code> composable function<a id="_idIndexMarker570" class="calibre6 pcalibre1 pcalibre"/> is designed to elegantly integrate CameraX into the Jetpack Compose ecosystem. At the time of writing, there is not an official composable implementation for the CameraX preview, so we will use <code>AndroidView</code>:</p>
<pre class="source-code">
@Composable
@Composable
fun CameraPreview(cameraController:
LifecycleCameraController, modifier: Modifier = Modifier) {
    AndroidView(
        factory = { context -&gt;
            PreviewView(context).apply {
                implementationMode =
                  PreviewView.ImplementationMode.COMPATIBLE
            }
        },
        modifier = modifier,
        update = { previewView -&gt;
            previewView.controller = cameraController
        }
    )
}</pre> <p class="calibre3">This composable function takes two parameters: <code>cameraController</code>, which is an instance of <code>LifecycleCameraController</code> to control the camera, and an optional modifier, which is used to specify layout options.</p>
<p class="calibre3">Inside the function, an <code>AndroidView</code> composable is used to bridge traditional Android views with the Jetpack Compose UI framework. The factory parameter of <code>AndroidView</code> is a Lambda that provides context and returns a <code>PreviewView</code> object. The <code>PreviewView</code> object is a standard Android view that’s used to display the camera feed. It is configured with <code>implementationMode</code> set to <code>COMPATIBLE</code> to ensure compatibility with different devices and scenarios (one of the most relevant CameraX features).</p>
<p class="calibre3">The modifier parameter of <code>AndroidView</code> is set to the passed modifier to allow the layout to be customized. The <code>update</code> parameter is another Lambda that’s called to perform updates on <code>PreviewView</code>. In this case, it assigns <code>cameraController</code> to the controller property of <code>PreviewView</code>, linking the camera preview to <code>LifecycleCameraController</code>.</p>
<p class="calibre3">Now, let’s integrate the preview into our existing code. In the <code>StoryContent</code> composable, we will include the following code, where we expect to have the camera image:</p>
<pre class="source-code">
    CameraPermissionRequester {
        Box(contentAlignment = Alignment.BottomCenter,
        modifier = Modifier.fillMaxSize()) {
            CameraPreview(
                cameraController = cameraController,
                modifier = Modifier.fillMaxSize()
            )
        }
    }</pre> <p class="calibre3">With that, we should be ready<a id="_idIndexMarker571" class="calibre6 pcalibre1 pcalibre"/> to use the camera! At this point, we’ve learned how to integrate <code>CameraPreview</code>, check the permissions, and show the camera image stream. Now, let’s add the possibility of saving the photos!</p>
<h2 id="_idParaDest-119" class="calibre7"><a id="_idTextAnchor120" class="calibre6 pcalibre1 pcalibre"/>Adding photo-saving functionality</h2>
<p class="calibre3">The capture functionality<a id="_idIndexMarker572" class="calibre6 pcalibre1 pcalibre"/> is a staple for every app using the camera. We will need to add some logic to our existing code to handle the capture storage. Let’s start with a use case (where we are going to put our domain logic) to store the captured image.</p>
<h3 class="calibre9">Creating the SaveCaptureUseCase</h3>
<p class="calibre3">The primary responsibility<a id="_idIndexMarker573" class="calibre6 pcalibre1 pcalibre"/> of <code>SaveCaptureUseCase</code> will be to take<a id="_idIndexMarker574" class="calibre6 pcalibre1 pcalibre"/> a bitmap object (the format we will use for our photos) and save it as an image file in the device’s gallery. Additionally, it will handle the different approaches based on the Android version as how media storage is accessed is different, depending on the version.</p>
<p class="calibre3">For example, we will need to obtain the URI (the route in the storage of the device) where we are going to store the image. If the user has a version of Android more recent than 9.0, the location will be different than in the previous versions. The following code block shows what the check to obtain the corresponding route will look like:</p>
<pre class="source-code">
if (Build.VERSION.SDK_INT &gt;= Build.VERSION_CODES.Q) {
            MediaStore.Images.Media.getContentUri(
                MediaStore.VOLUME_EXTERNAL_PRIMARY)
        } else {
            MediaStore.Images.Media.EXTERNAL_CONTENT_URI
        }
}</pre> <p class="calibre3">Here, we are evaluating if the version is major or equal to Android 9.0 and obtaining the URI using <code>MediaStore.Images.Media.getContentUri(MediaStore.VOLUME_EXTERNAL_PRIMARY)</code>. If the version doesn’t meet those requirements, we obtain the URI from <code>MediaStore.Images.Media.EXTERNAL_CONTENT_URI</code>. We should take all these different cases into account so that our use case handles the different Android versions properly.</p>
<p class="calibre3">Now, let’s create the <code>SaveCaptureUse</code> class:</p>
<pre class="source-code">
class SaveCaptureUseCase(private val context: Context) {
}</pre> <p class="calibre3">Then, we can create the main function<a id="_idIndexMarker575" class="calibre6 pcalibre1 pcalibre"/> of this use<a id="_idIndexMarker576" class="calibre6 pcalibre1 pcalibre"/> case, <code>save()</code>, which will take care of saving the capture:</p>
<pre class="source-code">
    suspend fun save(capturePhotoBitmap: Bitmap):
    Result&lt;Uri&gt; = withContext(Dispatchers.IO) {
        val resolver: ContentResolver =
            context.applicationContext.contentResolver
        val imageCollection = getImageCollectionUri()
        val nowTimestamp = System.currentTimeMillis()
        val imageContentValues =
            createContentValues(nowTimestamp)
        val imageMediaStoreUri: Uri? =
            resolver.insert(imageCollection,
                imageContentValues)
        return@withContext imageMediaStoreUri?.let { uri -&gt;
            saveBitmapToUri(resolver, uri,
                capturePhotoBitmap, imageContentValues)
        } ?: Result.failure(Exception("Couldn't create file
                                       for gallery"))
    }</pre> <p class="calibre3">In this code block, we are starting to create the save function. As it is marked as a <code>suspend</code> function, the save function is designed to be called within a coroutine context. It uses <code>withContext(Dispatchers.IO)</code> to ensure that all I/O operations are performed on a background thread. This is crucial for maintaining UI responsiveness as I/O operations can be time-consuming.</p>
<p class="calibre3">Next, we are declaring <code>ContextResolver</code>. This resolver is used to interact with <code>MediaStore</code>, which is Android’s central repository for media files.</p>
<p class="calibre3">Then, the function will call <code>getImageCollectionUri()</code>, a helper function that provides the appropriate URI for <code>MediaStore</code> based on the Android version. This URI is where the image will be saved. We will implement this function next.</p>
<p class="calibre3">After, the current system<a id="_idIndexMarker577" class="calibre6 pcalibre1 pcalibre"/> time (<code>nowTimestamp</code>) is captured, and <code>createContentValues (nowTimestamp)</code> is invoked<a id="_idIndexMarker578" class="calibre6 pcalibre1 pcalibre"/> to prepare the metadata for the image. This metadata, which is stored in a <code>ContentValues</code> object, includes details such as the image’s display name, <code>MIME</code> type, and timestamps.</p>
<p class="calibre3">The function then attempts to insert a new record into <code>MediaStore</code> using the resolved URI and the prepared metadata. The <code>insert</code> method returns a URI that points to the newly created record. If this operation is successful, a non-null URI is returned, representing the location of the new image record in <code>MediaStore</code>.</p>
<p class="calibre3">Finally, if the URI is not null, the <code>saveBitmapToUri</code> function is called with the resolver, the URI, the bitmap to be saved, and the image metadata. This function handles the actual process of writing the bitmap data to the location pointed to by the URI. We will implement it soon.</p>
<p class="calibre3">Regarding error handling, our <code>save</code> function uses Kotlin’s <code>Result</code> class for structured error handling. If the insertion into the MediaStore is successful and the bitmap is saved correctly, the function returns <code>Result.success(Unit)</code>. If there is a failure at any point (for example, the URI is null, indicating that the insertion failed), the function returns <code>Result.failure</code>, encapsulating an exception with an appropriate error message.</p>
<p class="calibre3">Now, let’s implement the <code>getImageCollectionUri()</code> function, which will return the correct URI based on the Android version:</p>
<pre class="source-code">
    private fun getImageCollectionUri(): Uri =
        if (Build.VERSION.SDK_INT &gt;= Build.VERSION_CODES.Q)
        {
            MediaStore.Images.Media.getContentUri(
                MediaStore.VOLUME_EXTERNAL_PRIMARY)
        } else {
            MediaStore.Images.Media.EXTERNAL_CONTENT_URI
        }</pre> <p class="calibre3">Then, we<a id="_idIndexMarker579" class="calibre6 pcalibre1 pcalibre"/> can create<a id="_idIndexMarker580" class="calibre6 pcalibre1 pcalibre"/> the <code>createContentValues</code> function:</p>
<pre class="source-code">
private fun createContentValues(timestamp: Long):
ContentValues = ContentValues().apply {
        put(MediaStore.Images.Media.DISPLAY_NAME,
            "$FILE_NAME_PREFIX${System.currentTimeMillis()}
                .jpg")
        put(MediaStore.Images.Media.MIME_TYPE, "image/jpg")
        if (Build.VERSION.SDK_INT &gt;= Build.VERSION_CODES.Q)
        {
            put(MediaStore.MediaColumns.DATE_TAKEN,
                timestamp)
            put(MediaStore.MediaColumns.RELATIVE_PATH,
                "${Environment.DIRECTORY_DCIM}/Packtagram")
            put(MediaStore.MediaColumns.IS_PENDING, 1)
        }
        if (Build.VERSION.SDK_INT &gt;= Build.VERSION_CODES.R)
        {
            put(MediaStore.Images.Media.DATE_ADDED,
                timestamp)
            put(MediaStore.Images.Media.DATE_MODIFIED,
                timestamp)
            put(MediaStore.Images.Media.AUTHOR,
                AUTHOR_NAME)
            put(MediaStore.Images.Media.DESCRIPTION,
                DESCRIPTION)
        }
    }</pre> <p class="calibre3">The <code>createContentValues</code> function<a id="_idIndexMarker581" class="calibre6 pcalibre1 pcalibre"/> is designed to prepare<a id="_idIndexMarker582" class="calibre6 pcalibre1 pcalibre"/> the metadata for an image file before it is saved to the device’s gallery via <code>MediaStore</code>. This method is pivotal in ensuring that the saved image has the correct and necessary information associated with it. So, let’s break down its functionality:</p>
<ul class="calibre15">
<li class="calibre14">First, the function initiates a <strong class="source-inline1">ContentValues</strong> object. Here, <strong class="source-inline1">ContentValues</strong> is a key-value pair that’s used in Android to store a set of values that <strong class="source-inline1">ContentResolver</strong> can process. It is commonly used for passing data to Android’s content providers</li>
<li class="calibre14">Next, the display name of the image in <strong class="source-inline1">MediaStore</strong> is set. We will use a predefined <strong class="source-inline1">FILE_NAME_PREFIX</strong> constant and append the current timestamp to it, followed by the <strong class="source-inline1">.jpg</strong> extension, ensuring each saved image has a unique name.</li>
<li class="calibre14">Then, the <strong class="source-inline1">MIME</strong> type of the image is set to <strong class="source-inline1">image/jpg</strong>. This information is used by <strong class="source-inline1">MediaStore</strong> and other apps to understand the file format of the image.</li>
<li class="calibre14">We have to store it differently, depending on the Android version of the device:<ul class="calibre16"><li class="calibre14">For Android Q (API Level 29) and above, we must do the following:<ul class="calibre16"><li class="calibre14">We need to add the timestamp of when the image is being stored and use the <strong class="source-inline1">MediaStore.MediaColumns.DATE_TAKEN</strong> key.</li><li class="calibre14">We must use the <strong class="source-inline1">createContentValues</strong> function to specify a relative path for the image file, pointing<a id="_idIndexMarker583" class="calibre6 pcalibre1 pcalibre"/> to a directory within the <strong class="bold">Digital Camera Images</strong> (<strong class="bold">DCIM</strong>) folder using <strong class="source-inline1">put(MediaStore.MediaColumns.RELATIVE_PATH, "${Environment.DIRECTORY_DCIM}/Packtagram")</strong>. This helps in organizing the saved images in a specific subdirectory, making them easier to locate.</li><li class="calibre14">We need to update the <strong class="source-inline1">ContentValues</strong> instance and set <strong class="source-inline1">IS_PENDING</strong> to <strong class="source-inline1">1</strong> (true), indicating that file creation is in progress. This is a way to inform the system and other apps that the file is not yet fully written and should not be accessed until the status is reverted.</li></ul></li><li class="calibre14">For Android R (API Level 30) and above, our function should add more metadata, including the date added, date modified, author name, and a description. This is part of the enhanced metadata management in newer Android versions, allowing for more detailed information to be stored with media files.</li></ul></li>
</ul>
<p class="calibre3">Now that we are handling<a id="_idIndexMarker584" class="calibre6 pcalibre1 pcalibre"/> the URI that’s needed<a id="_idIndexMarker585" class="calibre6 pcalibre1 pcalibre"/> to store the file, as well as the values and metadata needed to create the file, let’s proceed to do the saving itself. To do so, we will create a new private function called <code>saveBitmapToUri</code>, as follows:</p>
<pre class="source-code">
    private fun saveBitmapToUri(
        resolver: ContentResolver,
        uri: Uri,
        bitmap: Bitmap,
        contentValues: ContentValues
    ): Result&lt;Uri&gt; = kotlin.runCatching {
       resolver.openOutputStream(uri).use { outputStream -&gt;
           checkNotNull(outputStream) { "Couldn't create
               file for gallery, MediaStore output stream
                   is null»}`
           bitmap.compress(Bitmap.CompressFormat.JPEG,
               IMAGE_QUALITY, outputStream)
        }</pre> <p class="calibre3">The function starts by attempting to open <code>OutputStream</code> for the given URI. This stream is where the bitmap data will be written. Here, <code>Resolver.openOutputStream(uri)</code> is used to obtain the stream, and the <code>use</code> block ensures that this stream is closed properly after its operations, following the best practices in resource management.</p>
<p class="calibre3">Inside the <code>use</code> block, the function<a id="_idIndexMarker586" class="calibre6 pcalibre1 pcalibre"/> checks if <code>outputStream</code> is not <code>null</code>, throwing<a id="_idIndexMarker587" class="calibre6 pcalibre1 pcalibre"/> an exception with a descriptive message if it is. If the stream is valid, the bitmap is compressed and written to this stream. The compression format is set to JPEG, and the quality is determined by the <code>IMAGE_QUALITY</code> constant.</p>
<p class="calibre3">Now, if the image is saved successfully, we have to update and return the result. If something has failed, we have to return an error:</p>
<pre class="source-code">
        if (Build.VERSION.SDK_INT &gt;= Build.VERSION_CODES.Q)
        {
            contentValues.clear()
            contentValues.put(
                MediaStore.MediaColumns.IS_PENDING, 0)
            resolver.update(uri, contentValues, null, null)
        }
        return Result.success(Unit)
    }.getOrElse { exception -&gt;
        exception.message?.let(::println)
        resolver.delete(uri, null, null)
        return Result.failure(exception)
    }
}</pre> <p class="calibre3">For devices running Android Q (API level 29) or higher, after the image is saved, the function updates the <code>MediaStore</code> entry to indicate that the image is no longer pending. This is done by clearing the existing <code>contentValues</code>, setting <code>IS_PENDING</code> to <code>0</code> (false), and then updating the <code>MediaStore</code> entry with these new values. This step is crucial for making the image available to the user and other applications.</p>
<p class="calibre3">The entire operation is wrapped in a <code>runCatching</code> block, which is a Kotlin construct that’s used for simplified exception handling. This block captures any exceptions that occur during the <code>OutputStream</code> operation or <code>MediaStore</code> update. If an exception occurs, it is logged, and the function attempts to delete the possibly corrupted or incomplete file from <code>MediaStore</code>. This cleanup is essential to prevent cluttering the storage with unusable files.</p>
<p class="calibre3">The function returns <code>Result&lt;Uri&gt;</code>, indicating the success or failure of the operation. In case of success, <code>Result.success(uri)</code> is returned. In case of an exception, <code>Result.failure(exception)</code> is returned, encapsulating the exception details.</p>
<p class="calibre3">The only thing left will be to add<a id="_idIndexMarker588" class="calibre6 pcalibre1 pcalibre"/> the parameters that<a id="_idIndexMarker589" class="calibre6 pcalibre1 pcalibre"/> will be used during the development of these classes. For simplicity, we will add them as constants, but they could also be provided to the class:</p>
<pre class="source-code">
companion object {
    private const val IMAGE_QUALITY = 100
    private const val FILE_NAME_PREFIX = "YourImageName"
    private const val AUTHOR_NAME = "Your Name"
    private const val DESCRIPTION = "Your description"
}</pre> <p class="calibre3">The next step is to integrate this use case in <code>StoryEditorViewModel</code>.</p>
<h3 class="calibre9">Integrating SaveCaptureUseCase in StoryEditorViewModel</h3>
<p class="calibre3">Here, we need to create<a id="_idIndexMarker590" class="calibre6 pcalibre1 pcalibre"/> a new property <a id="_idIndexMarker591" class="calibre6 pcalibre1 pcalibre"/>and function in <code>StoryEditorViewModel</code> to store the captured image:</p>
<pre class="source-code">
class StoryEditorViewModel(
    private val saveCaptureUseCase: SaveCaptureUseCase
): ViewModel() {
    private val _isEditing = MutableStateFlow(false)
    val isEditing: StateFlow&lt;Boolean&gt; = _isEditing
    private val _imageCaptured: MutableStateFlow&lt;Uri&gt; =
        MutableStateFlow(Uri.EMPTY)
    val imageCaptured: StateFlow&lt;Uri&gt; = _imageCaptured
    fun storePhotoInGallery(bitmap: Bitmap) {
        viewModelScope.launch {
            val imageUri =
                saveCaptureUseCase.save(bitmap).getOrNull()
            if (imageUri != null) {
                _imageCaptured.value = imageUri
                _isEditing.value = true
            }
    }
}</pre> <p class="calibre3">In this <code>storePhotoInGallery</code> function, we are just launching a coroutine to call the <code>saveCaptureUseCase.save</code> method. Then, once we’ve obtained<a id="_idIndexMarker592" class="calibre6 pcalibre1 pcalibre"/> the URI, we check if it is not <code>null</code> and update<a id="_idIndexMarker593" class="calibre6 pcalibre1 pcalibre"/> the <code>imageCaptured</code> property.</p>
<p class="calibre3">Finally, we are ready to add this functionality to the UI.</p>
<h3 class="calibre9">Adding the capture functionality to StoryContent</h3>
<p class="calibre3">To add the capture functionality<a id="_idIndexMarker594" class="calibre6 pcalibre1 pcalibre"/> to <code>StoryContent</code>, we need to add<a id="_idIndexMarker595" class="calibre6 pcalibre1 pcalibre"/> a Lambda to the <code>StoryContent</code> composable so that whenever we use <code>StoryContent</code>, capture handling will be delegated. For example, in our case, we will call the already implemented <code>storePhotoInGallery</code> function from <code>StoryEditorViewModel</code>:</p>
<pre class="source-code">
@Composable
fun StoryContent(
    isEditing: Boolean = false,
    onImageCaptured: (Bitmap) -&gt; Any,
    modifier: Modifier = Modifier,
) { ... }</pre> <p class="calibre3">Next, let’s integrate the code that’s needed to take the capture from our camera:</p>
<pre class="source-code">
fun capturePhoto(
        context: Context,
        cameraController: LifecycleCameraController,
        onPhotoCaptured: (Bitmap) -&gt; Unit,
        onError: (Exception) -&gt; Unit
    ) {</pre> <p class="calibre3">The parameters we are using in the previous code block are as follows:</p>
<ul class="calibre15">
<li class="calibre14"><strong class="source-inline1">context</strong>: The Android context that we will use to obtain <strong class="source-inline1">MainExecutor</strong>.</li>
<li class="calibre14"><strong class="source-inline1">cameraController</strong>: A <strong class="source-inline1">LifecycleCameraController</strong> object from <strong class="source-inline1">CameraX</strong>, which controls the camera’s life cycle and operations.</li>
<li class="calibre14"><strong class="source-inline1">onPhotoCaptured</strong>: The callback function that will be invoked when a photo is successfully captured and processed. It accepts a <strong class="source-inline1">Bitmap</strong> as its parameter.</li>
<li class="calibre14"><strong class="source-inline1">onError</strong>: A callback function to handle any errors that occur during the photo capture process.</li>
</ul>
<p class="calibre3">Let’s continue by defining the necessary properties:</p>
<pre class="source-code">
val mainExecutor: Executor =
ContextCompat.getMainExecutor(context)</pre> <p class="calibre3">Here, we will retrieve <code>MainExecutor</code>. This executor<a id="_idIndexMarker596" class="calibre6 pcalibre1 pcalibre"/> is used to run tasks<a id="_idIndexMarker597" class="calibre6 pcalibre1 pcalibre"/> on the Android main thread, which is essential for UI updates and certain CameraX operations. It is needed for <code>CameraController</code>.</p>
<p class="calibre3">Next, we will execute the take picture action:</p>
<pre class="source-code">
        cameraController.takePicture(mainExecutor,
        @ExperimentalGetImage object :
        ImageCapture.OnImageCapturedCallback() {
            override fun onCaptureSuccess(image:
            ImageProxy) {
                try {
                    CoroutineScope(Dispatchers.IO).launch {
                        val correctedBitmap: Bitmap? =
                            image
                                ?.image
                                ?.toBitmap()
                                ?.rotateBitmap(image
                                    .imageInfo
                                    .rotationDegrees)
                        correctedBitmap?.let {
                            withContext(Dispatchers.Main) {
                                onPhotoCaptured(
                                    correctedBitmap)
                            }
                        }
                        image.close()
                    }
                } catch (e: Exception) {
                    onError(e)
                } finally {
                    image.close()
                }
            }
            override fun onError(exception:
            ImageCaptureException) {
                Log.e("CameraContent", "Error capturing
                    image", exception)
                onError(exception)
            }
        })
    }</pre> <p class="calibre3">Here, we call the <code>cameraController.takePicture</code> method. We will need to provide it with the executor and an <code>ImageCapture.OnImageCapturedCallback</code> class. This class provides callback methods for when an image is successfully captured or when an error occurs.</p>
<p class="calibre3">In the case of <a id="_idIndexMarker598" class="calibre6 pcalibre1 pcalibre"/>success, we will switch to the <code>onPhotoCaptured</code> Lambda from the main dispatcher. Alternatively, if there is any error, we will receive them via the <code>onError(exception: ImageCaptureException)</code> callback. Then, we will pass the error to the <code>onError</code> callback function, which we received as the parameter of the <code>capturePhoto()</code> function.</p>
<p class="calibre3">Now, let’s link the capture functionality<a id="_idIndexMarker599" class="calibre6 pcalibre1 pcalibre"/> with our UI. We already have<a id="_idIndexMarker600" class="calibre6 pcalibre1 pcalibre"/> a button for doing the capture in our <code>StoryContent</code> composable, <code>OutlinedButton</code>, so let’s see how we can call this capture function from it:</p>
<pre class="source-code">
OutlinedButton(
                    onClick = { capturePhoto(
                        context = localContext,
                        cameraController =
                            cameraController,
                        onPhotoCaptured = {
                            onImageCaptured(it) },
                        onError = { /* Show error */ }
                            )
                    },
                    modifier = Modifier.size(50.dp),
                    shape = CircleShape,
                    border = BorderStroke(4.dp,
                        MaterialTheme.colorScheme.primary),
                    contentPadding = PaddingValues(0.dp),
                    colors =
                        ButtonDefaults.outlinedButtonColors
                            (contentColor =
                                MaterialTheme.colorScheme
                                    .primary)
                ) {
                }</pre> <p class="calibre3">As we can see, we are calling<a id="_idIndexMarker601" class="calibre6 pcalibre1 pcalibre"/> the <code>capturePhoto</code> function<a id="_idIndexMarker602" class="calibre6 pcalibre1 pcalibre"/> from the <code>onClick</code> button.</p>
<p class="calibre3">With this, we are ready to capture our photos:</p>
<div><div><img alt="Figure 5.2: Image preview with the capture button" src="img/B19443_05_002.jpg" class="calibre4"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 5.2: Image preview with the capture button</p>
<p class="calibre3">With that, we have created<a id="_idIndexMarker603" class="calibre6 pcalibre1 pcalibre"/> a use case so that we can store<a id="_idIndexMarker604" class="calibre6 pcalibre1 pcalibre"/> our photos and link the functionality with our already existing UI. Our users can also capture and store their photos. Next, let’s see if we can enable them so that we can edit some aspects of them.</p>
<h1 id="_idParaDest-120" class="calibre5"><a id="_idTextAnchor121" class="calibre6 pcalibre1 pcalibre"/>Adding photo-editing functionalities</h1>
<p class="calibre3">There are multiple operations<a id="_idIndexMarker605" class="calibre6 pcalibre1 pcalibre"/> that we can enable for the user to edit and modify their images: we can allow them to crop, resize, and rotate the image, as well as adjust<a id="_idIndexMarker606" class="calibre6 pcalibre1 pcalibre"/> the brightness and contrast, apply filters, or add text overlays.</p>
<p class="calibre3">As part of this chapter, we are going to implement two operations: a black-and-white filter and a text overlay.</p>
<h2 id="_idParaDest-121" class="calibre7"><a id="_idTextAnchor122" class="calibre6 pcalibre1 pcalibre"/>Adding filters</h2>
<p class="calibre3">Creating filters over an existing image<a id="_idIndexMarker607" class="calibre6 pcalibre1 pcalibre"/> is as easy as modifying the values<a id="_idIndexMarker608" class="calibre6 pcalibre1 pcalibre"/> of the bitmap that contains the image. There are several well-known filters, such as sepia, vintage, and black and white. As an example, we are going to implement the black and white filter, like so:</p>
<pre class="source-code">
@Composable
fun BlackAndWhiteFilter(
    imageUri: Uri,
    modifier: Modifier = Modifier
) {
    var isBlackAndWhiteEnabled by remember {
    mutableStateOf(false) }
    val localContext = LocalContext.current
    Box(modifier = modifier.fillMaxSize()) {
        Canvas(modifier = Modifier.fillMaxSize()) {
            getBitmapFromUri(localContext, imageUri)?.let {
                val imageBitMap = it.asImageBitmap()
                val colorFilter = if
                (isBlackAndWhiteEnabled) {
                    val colorMatrix = ColorMatrix().apply {
                        setToSaturation(0f) }
                    ColorFilter.colorMatrix(colorMatrix)
                } else {
                    null
                }
                val (offsetX, offsetY) =
                    getCanvasImageOffset(imageBitMap)
                val scaleFactor =
                    getCanvasImageScale(imageBitMap)
                with(drawContext.canvas) {
                    save()
                    translate(offsetX, offsetY)
                    scale(scaleFactor, scaleFactor)
                    drawImage(
                        image = imageBitMap,
                        topLeft =
                            androidx.compose.ui.geometry
                                .Offset.Zero,
                        colorFilter = colorFilter
                    )
                    restore()
                }
            }
        }
        Button(
            onClick = { isBlackAndWhiteEnabled =
                !isBlackAndWhiteEnabled },
            modifier = Modifier.padding(16.dp)
        ) {
            Text("Apply Black and White Filter")
        }
    }
}</pre> <p class="calibre3">This function starts<a id="_idIndexMarker609" class="calibre6 pcalibre1 pcalibre"/> by accepting <code>imageUri</code>, which is the URI representing the image<a id="_idIndexMarker610" class="calibre6 pcalibre1 pcalibre"/> to be displayed, and an optional modifier parameter to customize the layout.</p>
<p class="calibre3">Within the function, a state variable called <code>isBlackAndWhiteEnabled</code> is declared using <code>remember</code> and <code>mutableStateOf</code>, which tracks whether the black-and-white filter is applied. Here, <code>LocalContext.current</code> provides the context needed to load the image from the URI.</p>
<p class="calibre3">A <code>Box</code> composable is used to contain the entire layout, ensuring that the content fills the available space. Inside <code>Box</code>, a <code>Canvas</code> composable is used to draw the image. The <code>Canvas</code> modifier is set to fill the available size.</p>
<p class="calibre3">The <code>Canvas</code> composable uses the <code>getBitmapFromUri</code> function to load the image as a <code>Bitmap</code>, which is then converted into <code>ImageBitmap</code> using the <code>asImageBitmap</code> extension function. If the <code>isBlackAndWhiteEnabled</code> state is true, a <code>ColorMatrix</code> value with zero saturation is applied to create a black-and-white <code>ColorFilter</code>. Otherwise, no color filter is applied.</p>
<p class="calibre3">The <code>getCanvasImageOffset</code> and <code>getCanvasImageScale</code> functions are used to calculate the offset and scale factor needed to center and scale the image within the canvas. The <code>with(drawContext.canvas)</code> block is used to draw the image. Within this block, <code>save</code> and <code>restore</code> are called to save and restore the canvas state, ensuring that transformations do not affect subsequent drawing operations. The <code>translate</code> function applies the calculated offsets, and the <code>scale</code> function applies the scale factor, to fill the entire <code>Canvas</code> with the image. Finally, the <code>drawImage</code> function draws the image on the canvas with the optional color filter.</p>
<p class="calibre3">Below <code>Canvas</code>, a <code>Button</code> composable is placed within <code>Box</code>. This button is used to toggle the <code>isBlackAndWhiteEnabled</code> state when clicked. The button’s <code>onClick</code> Lambda updates the state variable, and the button’s text is set to <strong class="bold">Apply Black and White Filter</strong>. The modifier parameter<a id="_idIndexMarker611" class="calibre6 pcalibre1 pcalibre"/> for the button includes padding<a id="_idIndexMarker612" class="calibre6 pcalibre1 pcalibre"/> to ensure it is not placed at the edge of the screen.</p>
<p class="calibre3">Now that we have built our first filter, let’s learn how to implement text overlays.</p>
<h2 id="_idParaDest-122" class="calibre7"><a id="_idTextAnchor123" class="calibre6 pcalibre1 pcalibre"/>Adding a text overlay</h2>
<p class="calibre3">Adding a text overlay<a id="_idIndexMarker613" class="calibre6 pcalibre1 pcalibre"/> is a typical image editing<a id="_idIndexMarker614" class="calibre6 pcalibre1 pcalibre"/> functionality that allows us to tag other people, add a hashtag to an image, or add an accompanying written message. Let’s see how we can offer our users this functionality.</p>
<p class="calibre3">First, we are going to create a composable that contains the state of the <code>Text</code> and <code>Image</code> components. This state will update as the user updates the text. Here’s the code:</p>
<pre class="source-code">
@Composable
fun ImageWithTextOverlay(capturedBitmap: Bitmap) {
    var textOverlay = remember { mutableStateOf("Add your
        text here") }
    var showTextField = remember { mutableStateOf(false) }
    Box(modifier = Modifier.fillMaxSize()) {
        Image(
            bitmap = capturedBitmap.asImageBitmap(),
            contentDescription = "Captured Image",
            modifier = Modifier.matchParentSize()
        )
        if (showTextField) {
            TextField(
                value = textOverlay,
                onValueChange = { textOverlay = it },
                modifier = Modifier
                    .align(Alignment.Center)
                    .padding(16.dp)
            )
        }
        Text(
            text = textOverlay,
            color = Color.White,
            fontSize = 24.sp,
            modifier = Modifier.align(Alignment.Center)
        )
        FloatingActionButton(
            onClick = { showTextField = !showTextField },
            modifier = Modifier
                .align(Alignment.BottomEnd)
                .padding(16.dp)
        ) {
            Icon(Icons.Default.Edit, contentDescription =
                "Edit Text")
        }
    }
}</pre> <p class="calibre3">This example defines<a id="_idIndexMarker615" class="calibre6 pcalibre1 pcalibre"/> a composable function<a id="_idIndexMarker616" class="calibre6 pcalibre1 pcalibre"/> called <code>ImageWithTextOverlay</code>. It accepts a bitmap object named <code>capturedBitmap</code>, which represents the captured image that will be displayed with a text overlay.</p>
<p class="calibre3">The function starts by defining two pieces of state:</p>
<ul class="calibre15">
<li class="calibre14">First, we have <strong class="source-inline1">textOverlay</strong>, which holds the text that will be displayed over the image. It’s initially set to a default value of <strong class="bold">Add your </strong><strong class="bold">text here</strong>.</li>
<li class="calibre14">Then, we have a <strong class="source-inline1">showTextField</strong> Boolean, which determines whether the text editing field (<strong class="source-inline1">TextField</strong>) is visible or not. It’s initially set to <strong class="source-inline1">false</strong>.</li>
</ul>
<p class="calibre3">Within the function, we use a <code>Box</code> composable as a container. The <code>Box</code> composable allows us to layer its child components, and we set its size to fill the maximum available space. This creates an area where we can overlay text on top of an image.</p>
<p class="calibre3">The first child of the <code>Box</code> composable is an <code>Image</code> composable, which is responsible for displaying the captured photo. The photo is passed to this function as a bitmap, and we ensure that it fills the entire parent container, ensuring that the image takes up the whole screen space available.</p>
<p class="calibre3">Next, we check the state of <code>showTextField</code>. If it’s <code>true</code>, we display <code>TextField</code> in the center of the screen. This <code>TextField</code> allows the user to input or edit the text that will be overlaid on the image. As the user types, the text in <code>textOverlay</code> is updated in real time thanks to the two-way binding provided by Jetpack Compose.</p>
<p class="calibre3">Regardless of the state of <code>showTextField</code>, we always display a <code>Text</code> composable. This component is responsible for rendering the overlay text on top of the image. We style this text to be white and of a reasonable font size, ensuring it’s visible against a variety of backgrounds.</p>
<p class="calibre3">Finally, at the bottom corner of the <code>Box</code> composable, we place <code>FloatingActionButton</code>. This button, when clicked, toggles the visibility of <code>TextField</code>, allowing the user to switch between viewing the overlaid text and editing it. The button is intuitively designed with an edit icon, signaling its purpose to the user.</p>
<p class="calibre3">Now, imagine that we want to allow<a id="_idIndexMarker617" class="calibre6 pcalibre1 pcalibre"/> the user to move the text whenever<a id="_idIndexMarker618" class="calibre6 pcalibre1 pcalibre"/> they want in the image. Let’s implement some drag-and-drop magic. We will start by updating the <code>ImageWithTextOverlay</code> composable function:</p>
<pre class="source-code">
@Composable
fun ImageWithTextOverlay(capturedBitmap: Bitmap) {
    var textOverlay = remember { mutableStateOf("Your text
        here") }
    var showTextField = remember { mutableStateOf(false) }
    var textPosition by remember {
        mutableStateOf(Offset.Zero) }</pre> <p class="calibre3">In this updated version of the <code>ImageWithTextOverlay</code> composable function, we’ve introduced an interactive feature that allows users to drag and position the text overlay anywhere on the image. To achieve this, we added a new state variable, <code>textPosition</code>, initialized to <code>Offset.Zero</code>. This state holds the current position of the text overlay on the screen. Now, we must create a new composable function, <code>DraggableText</code>, to handle the text display and its draggable functionality.</p>
<p class="calibre3">Let’s add this <code>DraggableText</code> to our existing code:</p>
<pre class="source-code">
    val imageModifier = Modifier.fillMaxSize()
    Box(modifier = Modifier.fillMaxSize()) {
        Image(
            bitmap = capturedBitmap.asImageBitmap(),
            contentDescription = "Captured Image",
            modifier = imageModifier
        )
        if (showTextField) {
            TextField(
                value = textOverlay,
                onValueChange = { textOverlay = it },
                modifier = Modifier
                    .align(Alignment.Center)
                    .padding(16.dp)
            )
        }
        DraggableText(
            text = textOverlay,
            position = textPosition,
            onPositionChange = { newPosition -&gt;
                textPosition = newPosition },
            modifier = Modifier
                .offset { IntOffset(textPosition.x.toInt(),
                    textPosition.y.toInt()) }
                .align(Alignment.Center)
        )
        FloatingActionButton(
            onClick = { showTextField = !showTextField },
            modifier = Modifier
                .align(Alignment.BottomEnd)
                .padding(16.dp)
        ) {
            Icon(Icons.Default.Edit, contentDescription =
                "Edit Text")
        }
    }
}</pre> <p class="calibre3">Here, the existing functionality<a id="_idIndexMarker619" class="calibre6 pcalibre1 pcalibre"/> for editing the text<a id="_idIndexMarker620" class="calibre6 pcalibre1 pcalibre"/> through <code>TextField</code> is the same. The <code>TextField</code> field appears when the user wishes to edit the text, facilitated by a floating action button. This button toggles the visibility of <code>TextField</code>, allowing users to switch seamlessly between editing the text and adjusting its position.</p>
<p class="calibre3">Now, we are ready to create the <code>DraggableText</code> composable:</p>
<pre class="source-code">
@Composable
fun DraggableText(
    text: String,
    position: Offset,
    onPositionChange: (Offset) -&gt; Unit,
    modifier: Modifier = Modifier
) {</pre> <p class="calibre3">The <code>DraggableText</code> composable takes several parameters, including the text to display, its current position, and a callback function, <code>onPositionChange</code>, which updates this position. Within <code>DraggableText</code>, we utilize the draggable modifier on the <code>Text</code> composable. This modifier is pivotal as it allows the text to be moved across the screen. As the user drags the text, the drag offset is updated, which, in turn, updates the <code>textPosition</code> state in the main <code>ImageWithTextOverlay</code> function.</p>
<p class="calibre3">Finally, define  the variables<a id="_idIndexMarker621" class="calibre6 pcalibre1 pcalibre"/> that are needed<a id="_idIndexMarker622" class="calibre6 pcalibre1 pcalibre"/> and the <code>Text</code> composable to show the text:</p>
<pre class="source-code">
    var dragOffset = remember { mutableStateOf(position) }
    Text(
        text = text,
        color = Color.White,
        fontSize = 24.sp,
        modifier = modifier
            .offset {
                IntOffset(dragOffset.value.x.roundToInt(),
                    dragOffset.value.y.roundToInt()) }
            .pointerInput(Unit) {
                detectDragGestures { change, dragAmount -&gt;
                    change.consume()
                    dragOffset.value =
                        Offset((dragOffset.value.x +
                            dragAmount.x),
                                (dragOffset.value.y +
                                    dragAmount.y))
                    onPositionChange(dragOffset.value)
                }
            }
            .background(
                color = Color.Black.copy(alpha = 0.5f),
                shape = RoundedCornerShape(8.dp)
            )
    )</pre> <p class="calibre3">We begin by initializing a state to hold the current drag offset. This state will track the position of the text as it is dragged.</p>
<p class="calibre3">Next, we define the <code>Text</code> composable to display our draggable text. To control the positioning of the text, we use the offset modifier, which positions the text based on the current drag offset.</p>
<p class="calibre3">The <code>pointerInput</code> modifier<a id="_idIndexMarker623" class="calibre6 pcalibre1 pcalibre"/> allows us to handle drag gestures<a id="_idIndexMarker624" class="calibre6 pcalibre1 pcalibre"/> on the text element. Within the <code>detectDragGestures</code> block, we update the drag offset by adding the drag amount to the current offset each time the user drags the text. The gesture change is consumed to indicate that the drag event has been handled, and we call a function to handle any additional actions that are needed when the position changes.</p>
<p class="calibre3">And with that, here are the two filters we have created:</p>
<div><div><img alt="Figure 5.3: The black and white filter composable (left) and text overlay (right)" src="img/B19443_05_003.jpg" class="calibre4"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 5.3: The black and white filter composable (left) and text overlay (right)</p>
<p class="calibre3">At this point, we have already<a id="_idIndexMarker625" class="calibre6 pcalibre1 pcalibre"/> implemented some cool<a id="_idIndexMarker626" class="calibre6 pcalibre1 pcalibre"/> features for our users, such as a black-and-white filter and the possibility to add a caption. So, why don’t leverage the use of ML to build outstanding features? We’ll look at this in the next section.</p>
<h1 id="_idParaDest-123" class="calibre5"><a id="_idTextAnchor124" class="calibre6 pcalibre1 pcalibre"/>Using ML to categorize photos and generate hashtags</h1>
<p class="calibre3">ML is a branch of <strong class="bold">artificial intelligence</strong> (<strong class="bold">AI</strong>) that focuses on building systems<a id="_idIndexMarker627" class="calibre6 pcalibre1 pcalibre"/> that can learn<a id="_idIndexMarker628" class="calibre6 pcalibre1 pcalibre"/> from and make decisions<a id="_idIndexMarker629" class="calibre6 pcalibre1 pcalibre"/> based on data. Unlike<a id="_idIndexMarker630" class="calibre6 pcalibre1 pcalibre"/> traditional software, which follows explicitly programmed instructions, ML algorithms use statistical techniques to enable computers to improve at tasks with experience. The fundamental premise of ML is to develop algorithms that can receive input data and use statistical analysis to predict or make decisions about some aspect of the data.</p>
<p class="calibre3">ML is a huge field that is outside the scope of this book, but we still can do interesting things using already-built libraries. For example, <strong class="bold">ML Kit</strong> is a powerful ML solution<a id="_idIndexMarker631" class="calibre6 pcalibre1 pcalibre"/> offered by Google for mobile developers that provides a suite of ready-to-use APIs for various ML tasks, both on-device and cloud-based. These functionalities are designed to be easily integrated into mobile applications, facilitating the use of ML without requiring deep expertise in the field. Here’s an overview of the key functionalities<a id="_idIndexMarker632" class="calibre6 pcalibre1 pcalibre"/> offered by ML Kit:</p>
<ul class="calibre15">
<li class="calibre14"><strong class="bold">Image labeling</strong>: Identifies objects, locations, activities, animal species, products, and more within an image.</li>
<li class="calibre14"><strong class="bold">Text recognition</strong>: Extracts text from images. This can be useful for <strong class="bold">optical character recognition</strong> (<strong class="bold">OCR</strong>) applications, such as scanning<a id="_idIndexMarker633" class="calibre6 pcalibre1 pcalibre"/> documents, business cards, or any printed or handwritten text.</li>
<li class="calibre14"><strong class="bold">Face detection</strong>: Detects faces in an image, including key facial features such as eyes and nose, and characteristics such as smiles or head tilt. This is useful in applications such as photo tagging and facial recognition.</li>
<li class="calibre14"><strong class="bold">Barcode scanning</strong>: Reads and scans barcodes and QR codes. It supports various formats, including UPC, EAN, Code 39, and others.</li>
<li class="calibre14"><strong class="bold">Object detection and tracking</strong>: Identifies and tracks objects in an image or video stream. This feature is useful in scenarios such as real-time video analysis.</li>
</ul>
<p class="calibre3">You can learn more<a id="_idIndexMarker634" class="calibre6 pcalibre1 pcalibre"/> about ML Kit’s features at <a href="https://developers.google.com/ml-kit" class="calibre6 pcalibre1 pcalibre">https://developers.google.com/ml-kit</a>.</p>
<p class="calibre3">As an example, we are going<a id="_idIndexMarker635" class="calibre6 pcalibre1 pcalibre"/> to create the logic to identify and label elements<a id="_idIndexMarker636" class="calibre6 pcalibre1 pcalibre"/> in the photo that could be used in the future to categorize the images or create automatic hashtags. We will start by adding the corresponding dependencies to <code>libs.versions.toml</code>:</p>
<pre class="source-code">
[versions]
...
ml-labeling = "17.0.5"
[libraries]
...
mlKitLabeling= { group = "com.google.mlkit", name = "image-labeling", version.ref="ml-labeling"}</pre> <p class="calibre3">Then, we will add these dependencies to the <code>build.gradle</code> file of the module. This is where we are creating this functionality (<code>feature:stories</code>):</p>
<pre class="source-code">
    implementation(libs.mlKitLabeling)</pre> <p class="calibre3">Now, we can create<a id="_idIndexMarker637" class="calibre6 pcalibre1 pcalibre"/> the actual code. We are going<a id="_idIndexMarker638" class="calibre6 pcalibre1 pcalibre"/> to leverage the image analysis feature from CameraX and analyze the preview using MLKitLabeling before using the results to write them in over the image. To do this, we will create a new preview composable just for this feature:</p>
<pre class="source-code">
@Composable
fun CameraPreviewWithImageLabeler(cameraController: LifecycleCameraController, modifier: Modifier = Modifier) {
    val context = LocalContext.current
    var labels by remember {
        mutableStateOf&lt;List&lt;String&gt;&gt;(emptyList()) }
    val cameraProviderFuture = remember {
        ProcessCameraProvider.getInstance(context) }
    val previewView = remember { PreviewView(context) }
    val imageAnalysis = remember {
        ImageAnalysis.Builder()
            .setTargetResolution(Size(1280, 720))
            .setBackpressureStrategy(
                ImageAnalysis.STRATEGY_KEEP_ONLY_LATEST)
            .build()
    }
    DisposableEffect(Unit) {
        val cameraProvider = cameraProviderFuture.get()
        val preview = Preview.Builder().build().also {
            it.setSurfaceProvider(
                previewView.surfaceProvider)
        }
        val cameraSelector =
            CameraSelector.DEFAULT_BACK_CAMERA
        cameraProvider.bindToLifecycle(
            context as LifecycleOwner, cameraSelector,
                preview, imageAnalysis)
        onDispose {
            cameraProvider.unbindAll()
        }
    }
    imageAnalysis.setAnalyzer(ContextCompat.getMainExecutor
    (context)) { imageProxy -&gt;
        processImageProxyForLabeling(imageProxy) {
        detectedLabels -&gt;
            labels = detectedLabels
        }
    }
    Box(modifier = modifier) {
        AndroidView(
            factory = { previewView },
            modifier = modifier
        )
        Canvas(modifier = Modifier.fillMaxSize()) {
            drawIntoCanvas { canvas -&gt;
                val paint = android.graphics.Paint().apply
                {
                    color = android.graphics.Color.RED
                    textSize = 60f
                }
                labels.forEachIndexed { index, label -&gt;
                    canvas.nativeCanvas.drawText(label,
                        10f, 100f + index * 70f, paint)
                }
            }
        }
    }
}</pre> <p class="calibre3">The start of this function<a id="_idIndexMarker639" class="calibre6 pcalibre1 pcalibre"/> is pretty similar to our already<a id="_idIndexMarker640" class="calibre6 pcalibre1 pcalibre"/> existing <code>CameraPreview</code> composable. After<a id="_idIndexMarker641" class="calibre6 pcalibre1 pcalibre"/> the camera provider<a id="_idIndexMarker642" class="calibre6 pcalibre1 pcalibre"/> is defined, an <code>ImageAnalysis</code> instance is configured with a target resolution of 1,280x720 pixels and a backpressure strategy set to <code>STRATEGY_KEEP_ONLY_LATEST</code> to process the latest image frame.</p>
<p class="calibre3">The <code>imageAnalysis.setAnalyzer</code> method sets an analyzer to process image frames using ML Kit’s Image Labeler. The <code>processImageProxyForLabeling</code> function is called to process each image frame. The detected labels are passed to a Lambda function that updates the <code>labels</code> state variable. We will see how to implement this function shortly.</p>
<p class="calibre3">In the end, the <code>Box</code> composable is used to overlay <code>PreviewView</code> and a <code>Canvas</code> composable. The <code>Canvas</code> composable is used to draw the detected labels on top of the camera preview. The <code>drawIntoCanvas</code> method accesses the native <code>canvas</code> for drawing. A <code>Paint</code> object is configured with a red color and a text size of 60 pixels. The <code>forEachIndexed</code> method iterates over the labels list, drawing each label at a specified position on the canvas.</p>
<p class="calibre3">Now, let’s learn how we can implement the image analyzer:</p>
<pre class="source-code">
@OptIn(ExperimentalGetImage::class)
private fun processImageProxyForLabeling(imageProxy:
ImageProxy, onLabelsDetected: (List&lt;String&gt;) -&gt; Unit) {
    val mediaImage = imageProxy.image
    if (mediaImage != null) {
        val image = InputImage.fromMediaImage(mediaImage,
            imageProxy.imageInfo.rotationDegrees)
        val labeler =
        ImageLabeling.getClient(
            ImageLabelerOptions.DEFAULT_OPTIONS)
        labeler.process(image)
            .addOnSuccessListener { labels -&gt;
                val labelNames = labels.map { it.text }
                onLabelsDetected(labelNames)
            }
            .addOnFailureListener { e -&gt;
                e.printStackTrace()
            }
            .addOnCompleteListener {
                imageProxy.close()
            }
    }
}</pre> <p class="calibre3">This function takes<a id="_idIndexMarker643" class="calibre6 pcalibre1 pcalibre"/> the <code>ImageProxy</code> object and a callback<a id="_idIndexMarker644" class="calibre6 pcalibre1 pcalibre"/> function, <code>onLabelsDetected</code>, as parameters, where<a id="_idIndexMarker645" class="calibre6 pcalibre1 pcalibre"/> the callback<a id="_idIndexMarker646" class="calibre6 pcalibre1 pcalibre"/> function is invoked with a list of detected labels.</p>
<p class="calibre3">Within the function, <code>mediaImage</code> is extracted from the <code>ImageProxy</code> object. If <code>mediaImage</code> is not <code>null</code>, it is converted into <code>InputImage</code> using the <code>InputImage.fromMediaImage</code> method, which requires the media image and the rotation degrees from <code>imageProxy</code>.</p>
<p class="calibre3">An instance of the image labeler is obtained by calling <code>ImageLabeling.getClient</code> with <code>ImageLabelerOptions.DEFAULT_OPTIONS</code>. This sets up the labeler with default configuration options suitable for general-purpose image labeling.</p>
<p class="calibre3">The <code>labeler.process</code> method<a id="_idIndexMarker647" class="calibre6 pcalibre1 pcalibre"/> processes <code>InputImage</code> asynchronously. After, the processing<a id="_idIndexMarker648" class="calibre6 pcalibre1 pcalibre"/> outcome<a id="_idIndexMarker649" class="calibre6 pcalibre1 pcalibre"/> is handled by two<a id="_idIndexMarker650" class="calibre6 pcalibre1 pcalibre"/> listeners:</p>
<ul class="calibre15">
<li class="calibre14">In <strong class="source-inline1">addOnSuccessListener</strong>, the function receives a list of labels if the processing is successful. Each label in this list represents an element identified in the image, accompanied by a confidence score. The function iterates through these labels, logging the identified element (<strong class="source-inline1">label.text</strong>) and its confidence score (<strong class="source-inline1">label.confidence)</strong>. In future iterations, we could use this information to auto-create automatic overlays over the image or to inform the user of which could be the best hashtags for the image.</li>
<li class="calibre14">In case of any failure during image processing, <strong class="source-inline1">addOnFailureListener</strong> is invoked, which logs the error. This error handling is crucial for diagnosing issues that might occur during the ML process, such as problems with the input image or internal errors in the ML Kit processing pipeline.</li>
</ul>
<p class="calibre3">Now, if we replace our <code>CameraPreview</code> composable with the <code>CameraPreviewImageLabeler</code> composable, we should see the results of the image analysis taking place:</p>
<div><div><img alt="Figure 5.4: ML labeling taking place in the live preview" src="img/B19443_05_004.jpg" class="calibre4"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 5.4: ML <a href="https://developer.android.com/ml" class="calibre6 pcalibre1 pcalibre">labeling taking place in the liv</a>e preview</p>
<p class="calibre3">If you want<a id="_idIndexMarker651" class="calibre6 pcalibre1 pcalibre"/> to know<a id="_idIndexMarker652" class="calibre6 pcalibre1 pcalibre"/> more<a id="_idIndexMarker653" class="calibre6 pcalibre1 pcalibre"/> about what<a id="_idIndexMarker654" class="calibre6 pcalibre1 pcalibre"/> can be done<a id="_idIndexMarker655" class="calibre6 pcalibre1 pcalibre"/> with the ML Kit library, check out <a href="https://developer.android.com/ml" class="calibre6 pcalibre1 pcalibre">https://developer.android.com/ml</a>.</p>
<h1 id="_idParaDest-124" class="calibre5"><a id="_idTextAnchor125" class="calibre6 pcalibre1 pcalibre"/>Summary</h1>
<p class="calibre3">In this chapter, we started by familiarizing ourselves with CameraX, a key component of the Android Jetpack suite. We learned how to set up CameraX in our applications while enabling features such as live camera preview and image capture.</p>
<p class="calibre3">Moving on, we delved into the practical implementation of capturing images using CameraX. Additionally, we introduced basic image editing functionalities, guiding you through the process of creating a filter and adding a text overlay. These skills are pivotal in enhancing the interactivity and user experience of photography apps.</p>
<p class="calibre3">Finally, we unveiled the integration of Google’s ML Kit, demonstrating how to add advanced ML capabilities to the app. We explored how to use ML Kit to identify elements in images, such as objects. This experience highlighted the practical application of these technologies in enhancing the functionality of photography apps.</p>
<p class="calibre3">At this point, you should have gained valuable insights and practical skills in building feature-rich photography apps using CameraX and ML Kit.</p>
<p class="calibre3">In the next chapter, we will give life to those images by learning how to capture and edit video for our Packtagram app.</p>
</div>
</body></html>