<html><head></head><body><div><div><div><div><h1 class="title"><a id="ch14"/>Chapter 14. Concurrency and Parallelism in Swift</h1></div></div></div><p>When I first started learning Objective-C, I already had a good understanding of concurrency and multitasking with my background in other languages such as C and Java. This background made it very easy for me to create multithreaded applications using threads in Objective-C. Then, Apple changed everything for me when they released <strong>Grand Central Dispatch</strong> (<strong>GCD</strong>) with OS X 10.6 and iOS 4. At first, I went into denial; there was no way GCD could manage my application's threads better than I could. Then I entered the anger phase, GCD was hard to use and understand. Next was the bargaining phase, maybe I can use GCD with my threading code, so I could still control how the threading worked. Then there was the depression phase, maybe GCD does handle the threading better than I can. Finally, I entered the wow phase; this <a class="indexterm" id="id571"/>GCD thing is really easy to use and works amazingly well. After using Grand Central Dispatch and Operation Queues with Objective-C, I do not see a reason for using manual threads with Swift.</p><p>In this chapter, we will learn the following topics:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Basics of concurrency and parallelism</li><li class="listitem" style="list-style-type: disc">How to use GCD to create and manage concurrent dispatch queues</li><li class="listitem" style="list-style-type: disc">How to use GCD to create and manage serial dispatch queues</li><li class="listitem" style="list-style-type: disc">How to use various GCD functions to add tasks to the dispatch queues</li><li class="listitem" style="list-style-type: disc">How to use <code class="literal">NSOperation</code> and <code class="literal">NSOperationQueues</code> to add concurrency to our applications</li></ul></div><div><div><div><div><h1 class="title"><a id="ch14lvl1sec88"/>Concurrency and parallelism</h1></div></div></div><p>Concurrency is the<a class="indexterm" id="id572"/> concept of multiple tasks starting, running, and <a class="indexterm" id="id573"/>completing within the same time period. This does not necessarily mean that the tasks are executing simultaneously. In order for tasks to be run simultaneously, our application needs to be running on a multicore or multiprocessor system. Concurrency allows us to share the processor or cores with multiple tasks; however, a single core can only execute one task at a given time.</p><p>Parallelism is the concept of two or more tasks running simultaneously. Since each core of our processor can <a class="indexterm" id="id574"/>only execute one task at a time, the number of tasks<a class="indexterm" id="id575"/> executing simultaneously is limited to the number of cores within our processors. Therefore, if we have, for example, a four-core processor, then we are limited to only four tasks running simultaneously. Today's processors can execute tasks so quickly that it may appear that larger tasks are executing simultaneously. However, within the system, the larger tasks are actually taking turns executing subtasks on the cores.</p><p>In order to understand the<a class="indexterm" id="id576"/> difference between concurrency and parallelism, let's look at how a juggler juggles balls. If you watch a juggler, it seems they are catching and throwing multiple balls at any given time; however, a closer look reveals that they are, in fact, only catching and throwing one ball at a time. The other balls are in the air waiting to be caught and thrown. If we want to be able to catch and throw multiple balls simultaneously, we need to add multiple jugglers.</p><p>This example is really good because we can think of jugglers as the cores of a processer. A system with a single core processor (one juggler), regardless of how it seems, can only execute one task (catch and throw one ball) at a time. If we want to execute more than one task at a time, we need to use a multicore processor (more than one juggler).</p><p>Back in the old days when all the processors were single core, the only way to have a system that executed tasks simultaneously was to have multiple processors in the system. This also required specialized software to take advantage of the multiple processors. In today's world, just about every device has a processor that has multiple cores, and both the iOS and OS X operating systems are designed to take advantage of the multiple cores to run tasks simultaneously.</p><p>Traditionally, the way applications added concurrency was to create multiple threads; however, this model does not scale well to an arbitrary number of cores. The biggest problem with using threads was that our applications ran on a variety of systems (and processors), and in order to optimize our code, we needed to know how many cores/processors could be efficiently used at a given time, which is sometimes not known at the time of development.</p><p>In order to solve this problem, many operating systems, including iOS and OS X, started relying on asynchronous functions. These functions are often used to initiate tasks that could possibly take a long time to complete, such as making an HTTP request or writing data to disk. An asynchronous function typically starts the long running task and then returns prior to the task completion. Usually, this task runs in the background and uses a callback function (such as closure in Swift) when the task completes.</p><p>These asynchronous functions work great for the tasks that the OS provides them for, but what if we needed to<a class="indexterm" id="id577"/> create our own asynchronous functions and do not want<a class="indexterm" id="id578"/> to manage the threads ourselves? For this, Apple provides a couple of technologies. In this chapter, we will be covering two of these technologies. These are GCD and operation queues.</p><p>GCD is a low-level<a class="indexterm" id="id579"/> C-based API that allows specific tasks to be queued up for execution and schedules the execution on any of the available processor cores. Operation queues are similar to GCD; however, they are Cocoa objects and are internally implemented using GCD.</p><p>Let's begin by looking at GCD.</p><div><div><div><div><h2 class="title"><a id="ch14lvl2sec126"/>Grand Central Dispatch</h2></div></div></div><p>Grand Central Dispatch provides <a class="indexterm" id="id580"/>what is known as dispatch queues to manage submitted tasks. The queues manage these submitted tasks and execute<a class="indexterm" id="id581"/> them in a <strong>first-in, first-out</strong> (<strong>FIFO</strong>) order. This ensures that the tasks are started in the order they were submitted.</p><p>A task is simply some work that our application needs to perform. As examples, we can create tasks that perform simple calculations, read/write data to disk, make an HTTP request, or anything else that our application needs to do. We define these tasks by placing the code inside <a class="indexterm" id="id582"/>either a function or a closure and adding it to a dispatch queue.</p><p>GCD provides three<a class="indexterm" id="id583"/> types of queues:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><strong>Serial queues</strong>: Tasks in a <a class="indexterm" id="id584"/>serial queue (also known as a <strong>private queue</strong>) are executed one at a time in the order they were submitted. Each<a class="indexterm" id="id585"/> task is started only after the preceding task is completed. Serial queues are often used to synchronize access to specific resources because we are guaranteed that no two tasks in a serial queue will ever run simultaneously. Therefore, if the only way to access the specific resource is through the tasks in the serial queue, then no two tasks will attempt to access the resource at the same time or be out of order.</li><li class="listitem" style="list-style-type: disc"><strong>Concurrent queues</strong>: Tasks in <a class="indexterm" id="id586"/>a concurrent queue (also known as a <strong>global dispatch queue</strong>) execute concurrently; however, the<a class="indexterm" id="id587"/> tasks are still started in the order that they were added to the queue. The exact number of tasks that can be executing at any given instance is variable and is dependent on the system's current conditions and resources. The decision on when to start a task is up to GCD and is not something that <a class="indexterm" id="id588"/>we can control within our application.</li><li class="listitem" style="list-style-type: disc"><strong>Main dispatch queue</strong>: The main dispatch queue is a globally available serial queue that executes tasks on the application's main thread. Since tasks put into the main dispatch<a class="indexterm" id="id589"/> queue run on the main thread, it is usually called from a background queue when some background processing has finished and the user interface needs to be updated.</li></ul></div><p>Dispatch queues offer a number of advantages over traditional threads. The first and foremost advantage is, with dispatch queues, the system handles the creation and management <a class="indexterm" id="id590"/>of threads rather than the application itself. The system can scale the number of threads, dynamically based on the overall available resources of the system and the current system conditions. This means that dispatch queues can manage the threads with greater efficiency than we could.</p><p>Another advantage of dispatch queues is we are able to control the order that our tasks are started. With serial queues, not only do we control the order in which tasks are started, but also ensure that one task does not start before the preceding one is complete. With traditional threads, this can be very cumbersome and brittle to implement, but with dispatch queues, as we will see later in this chapter, it is quite easy.</p></div><div><div><div><div><h2 class="title"><a id="ch14lvl2sec127"/>Creating and managing dispatch queues</h2></div></div></div><p>Let's look at how to<a class="indexterm" id="id591"/> create and use a dispatch queue. The following<a class="indexterm" id="id592"/> three functions are used to <a class="indexterm" id="id593"/>create or retrieve queues. These functions are as follows:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><code class="literal">dispatch_queue_create</code>: This creates a <a class="indexterm" id="id594"/>dispatch queue of either the<a class="indexterm" id="id595"/> concurrent or serial type</li><li class="listitem" style="list-style-type: disc"><code class="literal">dispatch_get_global_queue</code>: This returns a<a class="indexterm" id="id596"/> system-defined global concurrent queue with a specified quality of service</li><li class="listitem" style="list-style-type: disc"><code class="literal">dispatch_get_main_queue</code>: This returns<a class="indexterm" id="id597"/> the serial dispatch queue associated with the application's main thread</li></ul></div><p>We will also be looking at several functions that submit tasks to a queue for execution. These functions are as follows:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><code class="literal">dispatch_async</code>: This <a class="indexterm" id="id598"/>submits a task for asynchronous execution and returns immediately.</li><li class="listitem" style="list-style-type: disc"><code class="literal">dispatch_sync</code>: This submits a task for synchronous execution and waits until it is complete before it<a class="indexterm" id="id599"/> returns.</li><li class="listitem" style="list-style-type: disc"><code class="literal">dispatch_after</code>: This <a class="indexterm" id="id600"/>submits a task for execution at a specified time.</li><li class="listitem" style="list-style-type: disc"><code class="literal">dispatch_once</code>: This submits<a class="indexterm" id="id601"/> a task to be executed once and only once while this application is running. It will execute the task again if the application restarts.</li></ul></div><p>Before we look at how<a class="indexterm" id="id602"/> to use the dispatch queues, we need to create a class that will help us demonstrate how the various types of queues work. This class will contain two<a class="indexterm" id="id603"/> basic functions. The first function will simply perform some basic calculations and then return a value. Here is the code for this function, which is named <code class="literal">doCalc()</code>:</p><div><pre class="programlisting">func doCalc() {
  var x=100
  var y = x*x
  _ = y/x
}</pre></div><p>The other function, which is named <code class="literal">performCalculation()</code>, accepts two parameters. One is an integer named <code class="literal">iterations</code>, and the other is a string named <code class="literal">tag</code>. The <code class="literal">performCalculation()</code> function calls the <code class="literal">doCalc()</code> function repeatedly until it calls the function the same number of times as defined by the iterations parameter. We also use the <code class="literal">CFAbsoluteTimeGetCurrent()</code> function to calculate the elapsed time it took to perform all of the iterations and then print the elapse time with the <code class="literal">tag</code> string to the console. This will let us know when the function completes and how long it took to complete it. The code for this function looks similar to this:</p><div><pre class="programlisting">func performCalculation(iterations: Int, tag: String) {
  let start = CFAbsoluteTimeGetCurrent()
  for var i=0; i&lt;iterations; i++ {
    self.doCalc()
  }
  let end = CFAbsoluteTimeGetCurrent()
  print("time for \(tag):  \(end-start)")
}</pre></div><p>These functions will be used together to keep our queues busy, so we can see how they work. Let's begin by looking at the GCD functions by using the <code class="literal">dispatch_queue_create()</code> function to create both concurrent and serial queues.</p><div><div><div><div><h3 class="title"><a id="ch14lvl3sec21"/>Creating queues with the dispatch_queue_create() function</h3></div></div></div><p>The <code class="literal">dispatch_queue_create()</code> function is used to create both concurrent and serial queues. The syntax<a class="indexterm" id="id604"/> of the<a class="indexterm" id="id605"/> <code class="literal">dispatch_queue_create()</code> function looks similar to this:</p><div><pre class="programlisting">func dispatch_queue_t dispatch_queue_create(label: UnsafePointer&lt;Int8&gt;, attr: dispatch_queue_attr_t!) -&gt; dispatch_queue_t!</pre></div><p>It takes the following parameters:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><code class="literal">label</code>: This is a <a class="indexterm" id="id606"/>string label that is attached to the queue to uniquely identify it in debugging tools, such as Instruments and crash reports. It is recommended that we use a reverse DNS naming convention. This parameter is optional and can be nil.</li><li class="listitem" style="list-style-type: disc"><code class="literal">attr</code>: This specifies<a class="indexterm" id="id607"/> the type of queue to make. This can be <code class="literal">DISPATCH_QUEUE_SERIAL, DISPATCH_QUEUE_CONCURRENT</code> or nil. If this parameter is nil, a serial queue is created.</li></ul></div><p>The return value for this function is the newly created dispatch queue. Let's see how to use the <code class="literal">dispatch_queue_create()</code> function by creating a concurrent queue and seeing how it works.</p><div><div><h3 class="title"><a id="note23"/>Note</h3><p>Some programming languages use the reverse DNS naming convention to name certain components. This convention is based on a registered domain name that is reversed. As an example, if we worked for company that had a domain name <code class="literal">mycompany.com</code> with a product called <code class="literal">widget</code>, the reverse DNS name will be <code class="literal">com.mycompany.widget</code>.</p></div></div><div><div><div><div><h4 class="title"><a id="ch14lvl4sec01"/>Creating concurrent dispatch queues with the dispatch_queue_create() function</h4></div></div></div><p>The following line creates a<a class="indexterm" id="id608"/> concurrent<a class="indexterm" id="id609"/> dispatch queue with the label of <code class="literal">cqueue.hoffman.jon</code>:</p><div><pre class="programlisting">let queue = dispatch_queue_create("cqueue.hoffman.jon", DISPATCH_QUEUE_CONCURRENT)</pre></div><p>As we saw in the beginning of this section, there are several functions that we can use to submit tasks to a dispatch queue. When we work with queues, we generally want to use the <code class="literal">dispatch_async()</code> function to submit tasks because when we submit a task to a queue, we usually do not want to wait for a<a class="indexterm" id="id610"/> response. The <code class="literal">dispatch_async()</code> function has the following signature:</p><div><pre class="programlisting">func dispatch_async(queue: dispatch_queue_t!, block: dispatch_queue_block!)</pre></div><p>The following example shows how to use the <code class="literal">dispatch_async()</code> function with the concurrent queue we just created:</p><div><pre class="programlisting">let c = { performCalculation(1000, tag: "async0") }
dispatch_async(queue, c)</pre></div><p>In the preceding code, we created a closure, which represents our task, that simply calls the <code class="literal">performCalculation()</code> function of the <code class="literal">DoCalculation</code> instance requesting that it runs through 1000 iterations<a class="indexterm" id="id611"/> of the <code class="literal">doCalc()</code> function. Finally, we use the <code class="literal">dispatch_async()</code> function to submit the task to the concurrent dispatch queue. This code will execute the task in a concurrent dispatch queue, which is separate from the main thread.</p><p>While the preceding example works perfectly, we can actually shorten the code a little bit. The next example shows that we do not need to create a separate closure as we did in the preceding example; we can also submit the task to execute like this:</p><div><pre class="programlisting">dispatch_async(queue) {
  calculation.performCalculation(10000000, tag: "async1")
}</pre></div><p>This shorthand version is how we usually submit small code blocks to our queues. If we have larger tasks, or tasks that we need to submit multiple times, we will generally want to create a closure<a class="indexterm" id="id612"/> and submit the closure to the queue as we showed originally.</p><p>Let's see how the concurrent queue actually works by adding several items to the queue and looking at the order and time that they return. The following code will add three tasks to the queue. Each task will call the <code class="literal">performCalculation()</code> function with various iteration counts. Remember that the <code class="literal">performCalculation()</code> function will execute the calculation routine continuously until it is executed the number of times as defined by the iteration count passed in. Therefore, the larger the iteration count we pass into the <code class="literal">performCalculation()</code> function, the longer it should take to execute. Let's take a look at the following code:</p><div><pre class="programlisting">dispatch_async(queue) {
  calculation.performCalculation(10000000, tag: "async1")
}

dispatch_async(queue) {
  calculation.performCalculation(1000, tag: "async2")
}

dispatch_async(queue) {
  calculation.performCalculation(100000, tag: "async3")
}</pre></div><p>Notice that each of the functions is called with a different value in the <code class="literal">tag</code> parameter. Since the <code class="literal">performCalculation()</code> function prints out the <code class="literal">tag</code> variable with the elapsed time, we can see the order in which the tasks complete and the time it took to execute. If we execute the <a class="indexterm" id="id613"/>preceding code, we<a class="indexterm" id="id614"/> should see the following results:</p><div><pre class="programlisting">time for async2:  0.000200986862182617
time for async3:  0.00800204277038574
time for async1:  0.461670994758606</pre></div><div><div><h3 class="title"><a id="note24"/>Note</h3><p>The elapse time will vary from one run to the next and from system to system.</p></div></div><p>Since the queues function in a FIFO order, the task that had the tag of <code class="literal">async1</code> was executed first. However, as we can see from the results, it was the last task to finish. Since this is a concurrent queue, if it is possible (if the system has available resources), the blocks of code will execute concurrently. This is why the tasks with the tags of <code class="literal">async2</code> and <code class="literal">async3</code> completed prior to the task that had the <code class="literal">async1</code> tag, even though the execution of the <code class="literal">async1</code> task began before the other two.</p><p>Now, let's see how a serial queue executes tasks.</p></div><div><div><div><div><h4 class="title"><a id="ch14lvl4sec02"/>Creating a serial dispatch queue with the dispatch_queue_create() function</h4></div></div></div><p>A serial queue<a class="indexterm" id="id615"/> functions is a little different than a concurrent queue. A serial queue will only execute one task at a<a class="indexterm" id="id616"/> time and will wait for one task to complete before starting the next task. This queue, like the concurrent dispatch queue, follows a first-in first-out order. The following line of code will create a serial queue with the label of <code class="literal">squeue.hoffman.jon</code>:</p><div><pre class="programlisting">let queue2 = dispatch_queue_create("squeue.hoffman.jon", DISPATCH_QUEUE_SERIAL)</pre></div><p>Notice that we create the serial queue with the <code class="literal">DISPATCH_QUEUE_SERIAL</code> attribute. If you recall, when we created the concurrent queue, we created it with the <code class="literal">DISPATCH_QUEUE_CONCURRENT</code> attribute. We can also set this attribute to <code class="literal">nil</code>, which will create a serial queue by default. However, it is recommended to always set the attribute to either <code class="literal">DISPATCH_QUEUE_SERIAL</code> or <code class="literal">DISPATCH_QUEUE_CONCURRENT</code> to make it easier to identify which type of queue we are creating.</p><p>As we saw with the concurrent dispatch queues, we generally want to use the <code class="literal">dispatch_async()</code> function to submit tasks because when we submit a task to a queue, we usually do not want to wait for a response. If, however, we did want to wait for a response, we would use the <code class="literal">dispatch_synch()</code> function.</p><div><pre class="programlisting">var calculation = DoCalculations()
let c = { calculation.performCalculation(1000, tag: "sync0") }
dispatch_async(queue2, c)</pre></div><p>Just like with<a class="indexterm" id="id617"/> the concurrent queues, we do not need to create a closure to submit a task to the queue. We can also submit the task like this:</p><div><pre class="programlisting">dispatch_async(queue2) {
    calculation.performCalculation(100000, tag: "sync1")
}</pre></div><p>Let's see how the serial queues works by adding several items to the queue and looking at the order and time that they complete. The following code will add three tasks, which will call the <code class="literal">performCalculation()</code> function with various iteration counts, to the queue:</p><div><pre class="programlisting">dispatch_async(queue2) {
    calculation.performCalculation(100000, tag: "sync1")
}

dispatch_async(queue2) {
    calculation.performCalculation(1000, tag: "sync2")
}

dispatch_async(queue2) {
    calculation.performCalculation(100000, tag: "sync3")
}</pre></div><p>Just like with<a class="indexterm" id="id618"/> the concurrent queue example, we call the <code class="literal">performCalculation()</code> function with various iteration counts and different values in the <code class="literal">tag</code> parameter. Since the <code class="literal">performCalculation()</code> function prints out the <code class="literal">tag</code> string with the elapsed time, we can see the order that the tasks complete in and the time it takes to execute. If we execute this code, we should see the following results:</p><div><pre class="programlisting">time for sync1:  0.00648999214172363
time for sync2:  0.00009602308273315
time for sync3:  0.00515800714492798</pre></div><div><div><h3 class="title"><a id="note25"/>Note</h3><p>The elapse time will vary from one run to the next and from system to system.</p></div></div><p>Unlike the concurrent queues, we can see that the tasks completed in the same order that they were submitted, even though the <code class="literal">sync2</code> and <code class="literal">sync3</code> tasks took considerably less time to complete. This demonstrates that a serial queue only executes one task at a time and that the queue waits for each task to complete before starting the next one.</p><p>Now that we have seen how to use the <code class="literal">dispatch_queue_create()</code> function to create both concurrent and <a class="indexterm" id="id619"/>serial queues, let's look at how we can get one of the four system-defined, global<a class="indexterm" id="id620"/> concurrent queues using the <code class="literal">dispatch_get_global_queue()</code> function.</p></div></div><div><div><div><div><h3 class="title"><a id="ch14lvl3sec22"/>Requesting concurrent queues with the dispatch_get_global_queue() function</h3></div></div></div><p>The system provides <a class="indexterm" id="id621"/>each application with four concurrent global dispatch queues of different priority levels. The different priority levels are what distinguish these<a class="indexterm" id="id622"/> queues. The four priorities are:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><code class="literal">DISPATCH_QUEUE_PRIORITY_HIGH</code>: The items<a class="indexterm" id="id623"/> in this queue run with the highest priority and are scheduled before items in the default and low priority queues</li><li class="listitem" style="list-style-type: disc"><code class="literal">DISPATCH_QUEUE_PRIORITY_DEFAULT</code>: The items in this queue run at the default priority and are <a class="indexterm" id="id624"/>scheduled before items in the low priority queue but after items in the high priority queue</li><li class="listitem" style="list-style-type: disc"><code class="literal">DISPATCH_QUEUE_PRIORITY_LOW</code>: The items in this queue run with a low priority and are schedule<a class="indexterm" id="id625"/> only after items in the high and default queues</li><li class="listitem" style="list-style-type: disc"><code class="literal">DISPATCH_QUEUE_PRIORITY_BACKGROUND</code>: The items in this queue run with a background <a class="indexterm" id="id626"/>priority, which has the lowest priority</li></ul></div><p>Since these are global queues, we do not need to actually create them; instead, we ask for a reference to the queue with the priority level needed. To request a global queue, we use the <code class="literal">dispatch_get_global_queue()</code> function. This function has the following syntax:</p><div><pre class="programlisting">func dispatch_get_global_queue(identifier: Int, flags: UInt) -&gt; dispatch_queue_t!</pre></div><p>Here, the following parameters are defined:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><code class="literal">identifier</code>: This is the priority of the queue we are requesting</li><li class="listitem" style="list-style-type: disc"><code class="literal">flags</code>: This is reserved for future expansion and should be set to zero at this time</li></ul></div><p>We request a queue using the <code class="literal">dispatch_get_global_queue()</code> function, as shown in the following example:</p><div><pre class="programlisting">let queue = dispatch_get_global_queue(DISPATCH_QUEUE_PRIORITY_DEFAULT, 0)</pre></div><p>In this example, we are<a class="indexterm" id="id627"/> requesting the global queue with the default priority. We can then use this queue exactly as we used the concurrent queues that we created with the <code class="literal">dispatch_queue_create()</code> function. The difference between the queues returned with the <code class="literal">dispatch_get_global_queue()</code> function and the ones created with the <code class="literal">dispatch_create_queue()</code> function is that with the <code class="literal">dispatch_create_queue()</code> function, we <a class="indexterm" id="id628"/>are actually creating a new queue. The queues that are returned with the <code class="literal">dispatch_get_global_queue()</code> function are global queues that are created when our application first starts; therefore, we are requesting a queue rather than creating a new one.</p><p>When we use the <code class="literal">dispatch_get_global_queue()</code> function, we avoid the overhead of creating the queue; therefore, I recommend using the <code class="literal">dispatch_get_global_queue()</code> function unless you have a specific reason to create a queue.</p></div><div><div><div><div><h3 class="title"><a id="ch14lvl3sec23"/>Requesting the main queue with the dispatch_get_main_queue() function</h3></div></div></div><p>The <code class="literal">dispatch_get_main_queue()</code> function returns the main queue for our application. The main queue is<a class="indexterm" id="id629"/> automatically created for the main thread when the application starts. This main queue is a serial queue; therefore, items in this queue are executed one at a time, in the order that they were submitted. We will generally want to avoid using this queue<a class="indexterm" id="id630"/> unless we have a need to update the user interface from a background thread.</p><p>The <code class="literal">dispatch_get_main_queue()</code> function has the following syntax:</p><div><pre class="programlisting">func dispatch_get_main_queue() -&gt; dispatch_queue_t!</pre></div><p>The following code example shows how to request the main queue:</p><div><pre class="programlisting">let mainQueue = dispatch_get_main_queue();</pre></div><p>We will then submit tasks to the main queue exactly as we would any other serial queue. Just remember that anything submitted to this queue will run on the main thread, which is the thread that all the user interface updates run on; therefore, if we submitted a long running task, the user interface will freeze until that task is completed.</p><p>In the previous sections, we saw how the <code class="literal">dispatch_async()</code> functions submit tasks to concurrent and serial queues. Now, let's look at two additional functions that we can use to submit tasks to our<a class="indexterm" id="id631"/> queues. The first function we will look at is the <code class="literal">dispatch_after()</code> function.</p></div><div><div><div><div><h3 class="title"><a id="ch14lvl3sec24"/>Using the dispatch_after() function</h3></div></div></div><p>There will be times that we need to execute tasks after a delay. If we were using a threading model, we<a class="indexterm" id="id632"/> would need to create a new thread, perform some sort of delay or sleep function, and execute our task. With GCD, we can use the <code class="literal">dispatch_after()</code> function. The <code class="literal">dispatch_after()</code> function takes the<a class="indexterm" id="id633"/> following syntax:</p><div><pre class="programlisting">func dispatch_after(when: dispatch_time_t, queue: dispatch_queue_t, block: dispatch_block_t)</pre></div><p>Here, the <code class="literal">dispatch_after()</code> function takes the following parameters:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><code class="literal">when</code>: This is the time that we wish the queue to execute our task in</li><li class="listitem" style="list-style-type: disc"><code class="literal">queue</code>: This is the queue that we want to execute our task in</li><li class="listitem" style="list-style-type: disc"><code class="literal">block</code>: This is the task to execute</li></ul></div><p>As with the <code class="literal">dispatch_async()</code> and <code class="literal">dispatch_synch()</code> functions, we do not need to include our task as a parameter. We can include our task to execute between two curly brackets exactly as we did previously with the <code class="literal">dispatch_async()</code> and <code class="literal">dispatch_synch()</code> functions.</p><p>As we can see from the <code class="literal">dispatch_after()</code> function, we use the <code class="literal">dispatch_time_t</code> type to define the time to execute the task. We use the <code class="literal">dispatch_time()</code> function to create the <code class="literal">dispatch_time_t</code> type. The <code class="literal">dispatch_time()</code> function has the following syntax:</p><div><pre class="programlisting">func dispatch_time(when: dispatch_time_t, delta:Int64) -&gt; dispatch_time_t</pre></div><p>Here, the <code class="literal">dispatch_time()</code> function takes the following parameter:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><code class="literal">when</code>: This value is used as the basis for the time to execute the task. We generally pass the <code class="literal">DISPATCH_TIME_NOW</code> value to create the time, based on the current time.</li><li class="listitem" style="list-style-type: disc"><code class="literal">delta</code>: This is the number of nanoseconds to add to the <code class="literal">when</code> parameter to get our time.</li></ul></div><p>We will use the <code class="literal">dispatch_time()</code> and <code class="literal">dispatch_after()</code> functions like this:</p><div><pre class="programlisting">var delayInSeconds = 2.0
let eTime = dispatch_time(DISPATCH_TIME_NOW, Int64(delayInSeconds * Double(NSEC_PER_SEC)))
dispatch_after(eTime, queue2) {
  print("Times Up")
}</pre></div><p>The preceding code will execute the task after a two-second delay. In the <code class="literal">dispatch_ time()</code> function, we create a <code class="literal">dispatch_time_t</code> type that is two seconds in the future. The <code class="literal">NSEC_PER_SEC</code> constant is use to calculate the nanoseconds from seconds. After the two-second delay, we <a class="indexterm" id="id634"/>print the message, <code class="literal">Times Up</code>, to the console.</p><p>There is one thing to watch out for with the <code class="literal">dispatch_after()</code> function. Let's take a look at the<a class="indexterm" id="id635"/> following code:</p><div><pre class="programlisting">let queue2 = dispatch_queue_create("squeue.hoffman.jon", DISPATCH_QUEUE_SERIAL)

var delayInSeconds = 2.0
let pTime = dispatch_time(DISPATCH_TIME_NOW,Int64(delayInSeconds * Double(NSEC_PER_SEC)))
dispatch_after(pTime, queue2) {
  print("Times Up")
}
  
dispatch_sync(queue2) {
  calculation.performCalculation(100000, tag: "sync1")
}</pre></div><p>In this code, we begin by creating a serial queue and then adding two tasks to the queue. The first task uses the <code class="literal">dispatch_after()</code> function, and the second task uses the <code class="literal">dispatch_sync()</code> function. Our initial thought would be that when we executed this code within the serial queue, the first task would execute after a two-second delay and then the second task would execute; however, this would not be correct. The first task is submitted to the queue and executed immediately. It also returns immediately, which lets the queue execute the next task while it waits for the correct time to execute the first task. Therefore, even though we are running the tasks in a serial queue, the second task completes before the first task. The following is an example of the output if we run the preceding code:</p><div><pre class="programlisting">time for sync1:  0.00407701730728149
Times Up</pre></div><p>The final GCD function that we are going to look at is <code class="literal">dispatch_once()</code>.</p></div><div><div><div><div><h3 class="title"><a id="ch14lvl3sec25"/>Using the dispatch_once() function</h3></div></div></div><p>The <code class="literal">dispatch_once()</code> function <a class="indexterm" id="id636"/>will execute a task once, and only once, for the lifetime of the application. What this <a class="indexterm" id="id637"/>means is that the task will be executed and marked as executed, then that task will not be executed again unless the application restarts. While the <code class="literal">dispatch_once()</code> function can be and has been used to implement the singleton pattern, there are other easier ways to do this. Refer to <a class="link" href="ch17.html" title="Chapter 17. Adopting Design Patterns in Swift">Chapter 17</a>, <em>Adopting Design Patterns in Swift</em>, for examples on how to implement the singleton design pattern.</p><p>The <code class="literal">dispatch_once()</code> function is great for executing initialization tasks that need to run when our application initially <a class="indexterm" id="id638"/>starts. These initialization tasks can consist of initializing our data store or variables and objects. The following code shows the syntax for the <code class="literal">dispatch_once()</code> function:</p><div><pre class="programlisting">func dispatch_once(predicate: UnsafeMutablePointer&lt;dispatch_once_t&gt;,block: dispatch_block_t!)</pre></div><p>Let's look at how<a class="indexterm" id="id639"/> to use the <code class="literal">dispatch_once()</code> function:</p><div><pre class="programlisting">var token: dispatch_once_t = 0
func example() {
    dispatch_once(&amp;token) {
        print("Printed only on the first call")
    }
    print("Printed for each call")
}</pre></div><p>In this example, the line that prints the message, <code class="literal">Printed only on the first call</code>, will be executed only once, no matter how many times the function is called. However, the line that prints the <code class="literal">Printed for each call</code> message will be executed each time the function is called. Let's see this in action by calling this function four times, like this:</p><div><pre class="programlisting">for i in 0..&lt;4 {
   example()
}</pre></div><p>If we execute this example, we should see the following output:</p><div><pre class="programlisting">Printed only on the first call
Printed for each call
Printed for each call
Printed for each call
Printed for each call</pre></div><p>Notice, in this example, that we only see the <code class="literal">Printed only on the first call</code> message once whereas we see the <code class="literal">Printed for each call</code> message all the four times that we call the function.</p><p>Now that we have looked at GCD, let's take a look at operation queues.</p></div></div><div><div><div><div><h2 class="title"><a id="ch14lvl2sec128"/>Using NSOperation and NSOperationQueue types</h2></div></div></div><p>The <code class="literal">NSOperation</code> and <code class="literal">NSOperationQueues</code> types, working together, provide us with an alternative to <a class="indexterm" id="id640"/>GCD for adding concurrency to our applications. Operation queues are Cocoa objects that function like dispatch queues and internally, operation queues are implemented using GCD. We define the tasks (<code class="literal">NSOperations</code>) that we <a class="indexterm" id="id641"/>wish to execute and then add the task to the operation queue (<code class="literal">NSOperationQueue</code>). The operation queue will then handle the scheduling and execution of tasks. Operation queues are instances of the <code class="literal">NSOperationQueue</code> class and operations are instances of the <code class="literal">NSOperation</code> class.</p><p>The operation represents a single unit of work or task. The <code class="literal">NSOperation</code> type is an abstract class that provides a thread-safe structure for modeling the state, priority, and dependencies. This class must be subclassed in order to perform any useful work.</p><p>Apple does provide two concrete implementations of the <code class="literal">NSOperation</code> type that we can use as-is for situations where it does not make sense to build a custom subclass. These subclasses are <code class="literal">NSBlockOperation</code> and <code class="literal">NSInvocationOperation</code>.</p><p>More than one operation queue can exist at the same time, and actually, there is always at least one operation queue running. This operation queue is known <a class="indexterm" id="id642"/>as the <strong>main queue</strong>. The main queue is automatically created for the main thread when the application starts and is where all the UI operations are performed.</p><p>There are several ways that we can use the <code class="literal">NSOperation</code> and <code class="literal">NSOperationQueues</code> classes to add concurrency to our application. In this chapter, we will look at three different ways. The first one we will look at is using the <code class="literal">NSBlockOperation</code> implementation of the <code class="literal">NSOperation</code> abstract class.</p><div><div><div><div><h3 class="title"><a id="ch14lvl3sec26"/>Using the NSBlockOperation implementation of NSOperation</h3></div></div></div><p>In this section, we will be<a class="indexterm" id="id643"/> using the same <code class="literal">DoCalculation</code> class that we used in the <em>Grand Central Dispatch</em> section to keep our queues busy with work so that we can see how the <code class="literal">NSOpererationQueues</code> class work.</p><p>The <code class="literal">NSBlockOperation</code> class is a <a class="indexterm" id="id644"/>concrete implementation of the <code class="literal">NSOperation</code> type that can manage the execution of one or more blocks. This class can be used to execute several tasks at once without the need to create separate operations for each task.</p><p>Let's see how to use the <code class="literal">NSBlockOperation</code> class to add concurrency to our application. The following code shows how to add three tasks to an operation queue using a single <code class="literal">NSBlockOperation</code> instance:</p><div><pre class="programlisting">let calculation = DoCalculations()
let operationQueue = NSOperationQueue()
       
let blockOperation1: NSBlockOperation = NSBlockOperation.init(block: {
  calculation.performCalculation(10000000, tag: "Operation 1")
})
       
blockOperation1.addExecutionBlock(
  {
    calculation.performCalculation(10000, tag: "Operation 2")
  }
)
       
blockOperation1.addExecutionBlock(
  {
    calculation.performCalculation(1000000, tag: "Operation 3")
  }
)
       
operationQueue.addOperation(blockOperation1)</pre></div><p>In this code, we begin by creating an instance of the <code class="literal">DoCalculation</code> class and an instance of the <code class="literal">NSOperationQueue</code> class. Next, we created an instance of the <code class="literal">NSBlockOperation</code> <a class="indexterm" id="id645"/>class using the <code class="literal">init</code> constructor. This constructor takes a single parameter, which is a block of code that represents one of the tasks we want to execute in the queue. Next, we add two additional tasks to the <code class="literal">NSBlockOperation</code> instance using the <code class="literal">addExecutionBlock()</code> method.</p><p>This is one of the<a class="indexterm" id="id646"/> differences between dispatch queues and operations. With dispatch queues, if resources are available, the tasks are executed as they are added to the queue. With operations, the individual tasks are not executed until the operation itself is submitted to an operation queue.</p><p>Once we add all of the tasks to the <code class="literal">NSBlockOperation</code> instance, we then add the operation to the <code class="literal">NSOperationQueue</code> instance that we created at the beginning of the code. At this point, the individual tasks within the operation start to execute.</p><p>This example shows how to use <code class="literal">NSBlockOperation</code> to queue up multiple tasks and then pass the tasks to the operation queue. The tasks are executed in a FIFO order; therefore, the first task that is added to the <code class="literal">NSBlockOperation</code> instance will be the first task executed. However, since the tasks can be executed concurrently if we have the available resources, the output from this code should look similar to this:</p><div><pre class="programlisting">time for Operation 2:  0.00546294450759888
time for Operation 3:  0.0800899863243103
time for Operation 1:  0.484337985515594</pre></div><p>What if we do not want our tasks to run concurrently? What if we wanted them to run serially like the serial dispatch queue? We can set a property in our operation queue that defines the number of tasks that can be run concurrently in the queue. The property is called <code class="literal">maxConcurrentOperationCount</code> and is used like this:</p><div><pre class="programlisting">operationQueue.maxConcurrentOperationCount = 1</pre></div><p>However, if we added this line to our previous example, it will not work as expected. To see why this is, we need to understand what the property actually defines. If we look at Apple's <code class="literal">NSOperationQueue</code> class reference, the definition of the property says, "The maximum number <a class="indexterm" id="id647"/>of queued operations that can execute at the same time."</p><p>What this tells us is that the <code class="literal">maxConcurrentOperationCount</code> property defines the number of operations (this is the key word) that can be executed at the same time. The <code class="literal">NSBlockOperation</code> instance, which we added all of our tasks to, represents a single operation; therefore, no other <code class="literal">NSBlockOperation</code> added to the queue will execute until the first one is complete, but the individual tasks within the operation will execute concurrently. To run the tasks serially, we would need to create a separate instance of the <code class="literal">NSBlockOperations</code> for each task.</p><p>Using an instance of the <code class="literal">NSBlockOperation</code> class good if we have a number of tasks that we want to execute concurrently, but they will not start executing until we add the operation to an operation queue. Let's look at a simpler way of adding tasks to an operation queue using the queues <code class="literal">addOperationWithBlock()</code> methods.</p></div><div><div><div><div><h3 class="title"><a id="ch14lvl3sec27"/>Using the addOperationWithBlock() method of the operation queue</h3></div></div></div><p>The <code class="literal">NSOperationQueue</code> class has a method named <code class="literal">addOperationWithBlock()</code> that makes it easy to add a<a class="indexterm" id="id648"/> block of code to the queue. This method automatically wraps the block of code in an operation object and then passes that operation to the queue itself. Let's see how to use this method to add tasks to a queue:</p><div><pre class="programlisting">let operationQueue = NSOperationQueue()
let calculation = DoCalculations()
       
operationQueue.addOperationWithBlock() {
  calculation.performCalculation(10000000, tag: "Operation1")
}
       
operationQueue.addOperationWithBlock() {
  calculation.performCalculation(10000, tag: "Operation2")
}
       
operationQueue.addOperationWithBlock() {
  calculation.performCalculation(1000000, tag: "Operation3")
}</pre></div><p>In the <code class="literal">NSBlockOperation</code> example, earlier in this chapter, we added the tasks that we wished to execute into an <code class="literal">NSBlockOperation</code> instance. In this example, we are adding the tasks directly to the operation queue, and each task represents one complete operation. Once we create the instance of the operation queue, we then use the <code class="literal">addOperationWithBlock()</code> method to add the tasks to the queue.</p><p>Also, in the <code class="literal">NSBlockOperation</code> example, the individual tasks did not execute until all of the tasks were added to the <code class="literal">NSBlockOperation</code> object and then that operation was added to the queue. This <code class="literal">addOperationWithBlock()</code> example is similar to the GCD example where the tasks begin executing as soon as they are added to the operation queue.</p><p>If we run the <a class="indexterm" id="id649"/>preceding code, the output should be similar to this:</p><div><pre class="programlisting">time for Operation2:  0.0115870237350464
time for Operation3:  0.0790849924087524
time for Operation1:  0.520610988140106</pre></div><p>You will notice that the operations are executed concurrently. With this example, we can execute the tasks serially by using the <code class="literal">maxConcurrentOperationCount</code> property that we mentioned earlier. Let's try this by initializing the <code class="literal">NSOperationQueue</code> instance like this:</p><div><pre class="programlisting">var operationQueue = NSOperationQueue()
operationQueue.maxConcurrentOperationCount = 1</pre></div><p>Now, if we run the example, the output should be similar to this:</p><div><pre class="programlisting">time for Operation1:  0.418763995170593
time for Operation2:  0.000427007675170898
time for Operation3:  0.0441589951515198</pre></div><p>In this example, we can see that each task waited for the previous task to complete prior to starting.</p><p>Using the <code class="literal">addOperationWithBlock()</code> method to add tasks, the operation queue is generally easier than using the <code class="literal">NSBlockOperation</code> method; however, the tasks will begin as soon as they are added to the queue, which is usually the desired behavior.</p><p>Now, let's look at how we can subclass the <code class="literal">NSOperation</code> class to create an operation that we can add directly to an operation queue.</p></div><div><div><div><div><h3 class="title"><a id="ch14lvl3sec28"/>Subclassing the NSOperation class</h3></div></div></div><p>The previous two<a class="indexterm" id="id650"/> examples showed how to add small blocks of code to our operation queues. In these examples, we called the <code class="literal">performCalculations</code> method in the <code class="literal">DoCalculation</code> class to perform our tasks. These examples illustrate two really good ways to add concurrency for functionally that is already written, but what if, at design time, we want to design our <code class="literal">DoCalculation</code> class for concurrency? For this, we can subclass the <code class="literal">NSOperation</code> class.</p><p>The <code class="literal">NSOperation</code> abstract class provides a significant amount of infrastructure. This allows us to very easily create a subclass without a lot of work. We should at least provide an <code class="literal">initialization</code> method and a <code class="literal">main</code> method. The <code class="literal">main</code> method will be called when the queue begins executing the operation:</p><p>Let's see how<a class="indexterm" id="id651"/> to implement the <code class="literal">DoCalculation</code> class as a subclass of the <code class="literal">NSOperation</code> class; we will call this new class <code class="literal">MyOperation</code>:</p><div><pre class="programlisting">class MyOperation: NSOperation {
  let iterations: Int
  let tag: String
  
  init(iterations: Int, tag: String) {
    self.iterations = iterations
    self.tag = tag
  }
  
  override func main() {
    performCalculation()
  }
  
  func performCalculation() {
    let start = CFAbsoluteTimeGetCurrent()
    for var i=0; i&lt;iterations; i++ {
      self.doCalc()
    }
    let end = CFAbsoluteTimeGetCurrent()
    print("time for \(tag):  \(end-start)")
  }
   
  func doCalc() {
    let x=100
    let y = x*x
    _ = y/x
  }
}</pre></div><p>We begin by defining that the <code class="literal">MyOperation</code> class is a subclass of the <code class="literal">NSOperation</code> class. Within the implementation of the class, we define two class constants, which represent the iteration count and the tag that the <code class="literal">performCalculations()</code> method uses. Keep in mind that when the operation queue begins executing the operation, it will call the <code class="literal">main()</code> method with no parameters; therefore, any parameters that we need to pass in must be passed in through the initializer.</p><p>In this example, our initializer takes two parameters that are used to set the <code class="literal">iterations</code> and <code class="literal">tag</code> classes constants. Then the <code class="literal">main()</code> method, that the operation queue is going to call to begin<a class="indexterm" id="id652"/> execution of the operation, simply calls the <code class="literal">performCalculation()</code> method.</p><p>We can now very easily add instances of our <code class="literal">MyOperation</code> class to an operation queue, like this:</p><div><pre class="programlisting">var operationQueue = NSOperationQueue()
operationQueue.addOperation(MyOperation(iterations: 10000000, tag: "Operation 1"))
operationQueue.addOperation(MyOperation(iterations: 10000, tag: "Operation 2"))
operationQueue.addOperation(MyOperation(iterations: 1000000, tag: "Operation 3"))</pre></div><p>If we run this code, we will see the following results:</p><div><pre class="programlisting">time for Operation 2:  0.00187397003173828
time for Operation 3:  0.104826986789703
time for Operation 1:  0.866684019565582</pre></div><p>As we saw earlier, we can also execute the tasks serially by adding the following line, which sets the <code class="literal">maxConcurrentOperationCount</code> property of the operation queue:</p><div><pre class="programlisting">operationQueue.maxConcurrentOperationCount = 1</pre></div><p>If we know that we need to execute some functionality concurrently prior to writing the code, I will recommend subclassing the <code class="literal">NSOperation</code> class, as shown in this example, rather than using the previous examples. This gives us the cleanest implementation; however, there is nothing wrong with using the <code class="literal">NSBlockOperation</code> class or the <code class="literal">addOperationWithBlock()</code> methods described earlier in this section.</p></div></div></div></div>
<div><div><div><div><h1 class="title"><a id="ch14lvl1sec89"/>Summary</h1></div></div></div><p>Before we consider adding concurrency to our application, we should make sure that we understand why we are adding it and ask ourselves whether it is necessary. While concurrency can make our application more responsive by offloading work from our main application thread to a background thread, it also adds extra complexity to our code and overhead to our application. I have even seen numerous applications, in various languages, which actually run better after we pulled out some of the concurrency code. This is because the concurrency was not well thought out or planned. With this in mind, it is always a good idea to think and talk about concurrency while we are discussing the application's expected behavior.</p><p>At the start of this chapter, we had a discussion about running tasks concurrently compared to running tasks in parallel. We also discussed the hardware limitation that limits how many tasks can run in parallel on a given device. Having a good understanding of those concepts is very important to understanding how and when to add concurrency to our projects.</p><p>While GCD is not limited to system-level applications, before we use it in our application, we should consider whether operation queues would be easier and more appropriate for our needs. In general, we should use the highest level of abstraction that meets our needs. This will usually point us to using operation queues; however, there really is nothing preventing us from using GCD, and it may be more appropriate for our needs.</p><p>One thing to keep in mind with operation queues is that they do add additional overhead because they are Cocoa objects. For the large majority of applications, this little extra overhead should not be an issue or even noticed; however, for some projects, such as games that need every last resource that they can get, this extra overhead might very well be an issue.</p></div></body></html>