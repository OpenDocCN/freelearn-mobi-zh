- en: Light Estimation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Magicians spend hours in front of a mirror, watching and studying every angle
    of their performance in order to get it just right. They realize that every detail
    needs to be perfect in order for the audience to believe in the illusion. Even
    a single mistake can ruin not only the illusion, but the entire performance and
    credibility of the magician. As harsh as it is, this is no different to what it's
    like building an AR app. If your app will immerse a user in your world, you need
    to make it as believable as possible. This includes ensuring that all the virtual
    objects in a scene look like they belong. Magicians use lighting and perspective
    tricks to fool the user into believing that something is real. We have already
    seen how we use perspective, so now we need to cover and enhance our use of lighting.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover how ARCore uses light estimation techniques
    to make the AR experience more believable to the user. We will then go on to extend
    some of those basic techniques in order to improve our future AR apps. Here are
    the main topics we will cover in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: 3D rendering
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 3D lighting
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Light estimation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cg/HLSL shaders
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Estimating light direction
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will use Unity in this chapter because it provides an easier platform for
    learning about the rendering process, lighting, and more about shader programs.
    The shader programs in Unity are a different variety and are definitely worth
    taking a look at.
  prefs: []
  type: TYPE_NORMAL
- en: 'While this chapter is less than halfway through the book, a reader should consider
    this as an advanced chapter. We will again be covering more about shader programs
    and 3D math concepts. Here''s a good site for those of you who want to review
    or just get a basic understanding of 3D math, through this tutorial, *3D Math:
    Vector Math for 3D Computer Graphics* at [http://chortle.ccsu.edu/vectorlessons/vectorindex.html](http://chortle.ccsu.edu/vectorlessons/vectorindex.html).
    This is an excellent site licensed by *Bradley Kjell*.'
  prefs: []
  type: TYPE_NORMAL
- en: 3D rendering
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Before we get into talking about light estimation for AR, let''s step back
    and review the rendering process of a 3D model. Take a look at the following diagram
    that explains the rendering process at a high level:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/06d37bf8-5c90-4970-8064-be27a97eceaf.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Typical rendering process for a 3D model
  prefs: []
  type: TYPE_NORMAL
- en: Now, the diagram only visually demonstrates the rendering process. Geometry
    and vertex shaders never actually render a wireframe model. Rather, they only
    position and color vertices and surfaces, which are then fed into the pixel/fragment
    and lighting shaders. This last step is called **rasterization** and represents
    the final step when the 2D image is generated or rasterized.
  prefs: []
  type: TYPE_NORMAL
- en: The rendering process we are talking about here is for standard real-time rendering
    on a device's GPU using DirectX or OpenGL. Keep in mind that there are other rendering
    processes used for real-time (voxel) and non real-time (ray tracing) rendering.
  prefs: []
  type: TYPE_NORMAL
- en: 'Euclideon have developed a voxel-like rendering technology, which they are
    claiming to be, in their words, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '"The First Truly Applicable Hologram Tech is Here."'
  prefs: []
  type: TYPE_NORMAL
- en: '- Euclideon'
  prefs: []
  type: TYPE_NORMAL
- en: This sounds very promising and a game changer for AR and VR. However, this technology
    has come under incredible scrutiny for making, what some feel are outlandish claims
    of rendering trillions of points without frame rate loss.
  prefs: []
  type: TYPE_NORMAL
- en: Building a test scene
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As always, let''s take a look at how this looks in our tools. Open up Unity
    with the sample ARCore project we have already installed, and perform the following
    steps:'
  prefs: []
  type: TYPE_NORMAL
- en: From the menu, select File | New Scene. This will create a new empty scene for
    us in Unity.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'From the Project window, drag the Andy prefab from the `Assets/GoogleARCore/HelloARExample/Prefabs`
    folder into the Hierarchy window, as shown in the following screen excerpt:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/64458ed3-7272-431f-b1b5-866bfd43649f.png)'
  prefs: []
  type: TYPE_IMG
- en: Unity interface showing Andy prefab dragged onto the scene
  prefs: []
  type: TYPE_NORMAL
- en: 'Andy is quite small, so we will adjust his size and the camera so that he fits
    in the Scene and Game windows better. Select Andy and modify Transform Scale to
    X as `25`, Y as `25`, and Z as `25`. Then, select Main Camera and modify its Transform
    Position to Y as `4`. This is shown in the following screen excerpt:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/7a24a2fb-c4f9-4cab-bd23-fc151ae513ea.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Setting the Transform of Andy and the Main Camera
  prefs: []
  type: TYPE_NORMAL
- en: Click on the Game and Scene tabs to switch views and see how the Andy model
    looks in each view.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Scene window in Unity is for composing your scene objects. This is where
    you will generally do most of your work in Unity. The Game window represents the
    view, as close as possible, as it is rendered in game. Unfortunately, for ARCore
    apps, we are limited to testing on a device and thus unable to generate an accurate
    game view. This is why, for now anyway, we will work in a separate scene for discovery
    purposes.
  prefs: []
  type: TYPE_NORMAL
- en: From the menu, select GameObject | 3D Object | Plane. This will add a new plane
    to the scene. Ensure that the plane is positioned at `0`,`0`,`0` by clicking on
    the Gear icon beside the Transform component in the Inspector window and selecting
    Reset Position from the menu. After you do that, Andy will be casting a shadow
    on the plane.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Switch between views again. Expand the Shaded dropdown just under the Scene
    tab, as shown in the following excerpt:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/6fe07cca-f11f-4345-bef0-b1a41714e3f0.png)'
  prefs: []
  type: TYPE_IMG
- en: The Draw Mode menu
  prefs: []
  type: TYPE_NORMAL
- en: This menu represents the various Draw Modes Unity can support. Some of these
    may make sense, such as Wireframe, while others less so. In any case, run through
    the list of each option to see what they do.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Materials, shaders, and textures
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Okay, now we have seen how Unity renders a scene and the various draw modes
    available. However, we still need to go over how an object is colored or textured.
    In Unity, we typically use materials, shaders, and textures to render 3D objects.
    A material is essentially an encapsulation of a shader, its dependent textures,
    and other settings. Let''s see what AndyMaterial looks like in Unity by following
    the given steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Open the `Assets/GoogleARCore/HelloARExample/Materials/Andy` folder in the Project
    window and select AndyMaterial. Look at the Inspector window and note the name
    of the Shader (`ARCoreDiffuseWithLightEstimation`) at the top. The current Shader
    uses a simple lighting model and has been optimized for mobile AR, which we don't
    currently need, so we will change it.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Expand the Shader dropdown in AndyMaterial and select Standard. This will switch
    the material to using the Standard Shader, as shown in the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/2a606dce-ceea-4292-8a90-48daba9241f9.png)'
  prefs: []
  type: TYPE_IMG
- en: Switching Andy to use the Standard Unity shader
  prefs: []
  type: TYPE_NORMAL
- en: The first thing you will immediately note is that Andy gets very dark. This
    is because the Metallic and Smoothness are turned way up. Use your mouse to adjust
    the various values to something more pleasant, as shown by the red arrows in the
    preceding screenshot. Perhaps a metallic shiny Andy?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: One thing to note when adjusting materials is that any changes you make to a
    material will be automatically saved and persisted even when running in the play
    or demo mode. Sometimes, it is useful to have backups of settings, especially
    if you found them difficult to achieve.
  prefs: []
  type: TYPE_NORMAL
- en: Make a copy of AndyMaterial by selecting it in the Project window and typing
    *Ctrl* + *D* or *command* + *D* on Mac. Rename the new material StandardAndyMaterial.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select AndyMaterial again. Change Shader back to `ARCore/DiffuseWithLightEstimation`.
    Note how the look of Andy quickly changes.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: From the menu, select File | Save Scenes. Save the scene to the `Assets/GoogleARCore/HelloARExample/Scenes`
    folder as `RenderingTest.scene`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: As you can see, there are plenty of options and settings that can go into rendering
    a 3D object. Feel free to explore on your own what each of the material settings
    are on the Standard Shader. In the next section, we will expand our understanding
    of rendering by discussing lighting.
  prefs: []
  type: TYPE_NORMAL
- en: 3D lighting
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'So far, we have looked at the basics of the rendering process and how a 3D
    model is rendered. What we omitted in the first section, however, is how lighting
    plays into this. In order to get a sense of the importance of lights in a 3D scene,
    how about we go ahead and turn out the lights. Open up Unity to where we left
    off in the first section and follow along:'
  prefs: []
  type: TYPE_NORMAL
- en: Select the Directional Light object in the Hierarchy window.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Disable the Light in the Inspector window by unchecking the box beside the object's
    name. This will turn off or disable the light. You will note that not all the
    lights go off, however. This is because we have an ambient or global light that
    is used to account for general light scattering.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'You are now left with a dark object with no lights and shadows. Turn back on
    the Directional Light by clicking on the checkbox. Take a look at the properties
    of the Light in the **Inspector** window, as shown:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/8ba30c1d-96a4-4608-a149-0560247d2fa9.png)'
  prefs: []
  type: TYPE_IMG
- en: Directional Light properties in the Inspector window
  prefs: []
  type: TYPE_NORMAL
- en: Play with the Type, Color, **Mode**, and Shadow Type properties in the Inspector
    window. There are four different types of lights you can work with. The Directional
    type represents a light source such as the sun, and as such, we only need to identify
    the direction the light is pointing. For the other light types, such as **point**
    and **spot**, you will need to position the light in the scene correctly in order
    to see any effects.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We can calculate simple 3D diffuse lighting with the following equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9e407203-35eb-49da-8758-82d70b640467.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/dee632b5-0408-475d-ae58-5ff5d8339424.png) is the direction of the light'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ec79985f-08b2-431b-b4e5-ce76d43d63c7.png) is the normal to the surface'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6a2d28c1-8564-4d7b-9564-2c7ace5febf8.png) is the intensity of light
    [0 to 1]'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0edecbb9-9645-4bc9-bd5e-7613ef9651a7.png) is then multiplied by the
    color in order to determine the resulting lit color.'
  prefs: []
  type: TYPE_NORMAL
- en: The **Standard** Shader we looked at earlier uses **Physically-Based Rendering **(**PBR**)
    or a lighting model, which is quite sophisticated. Unfortunately, PBR shaders
    are currently limited for mobile platforms and often don't work or have poor performance.
    Often, the devices' GPU cannot support the additional instructions required for
    a PBR shader. Therefore, we will be limited to writing our own custom lighting
    shaders.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Let's explore switching shaders on our AndyMaterial so that we can see what
    effect different lighting models have. Locate AndyMaterial in the `Assets/GoogleARCore/HelloARExample/Materials/Andy`
    folder and select it.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Switch between `ARCore/DiffuseWithLightEstimation`, **Mobile Diffuse**, and
    the **Standard** shaders to see the effects or the different lighting models,
    as illustrated:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/d41cd325-4480-4822-9f63-a8878a28646f.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Comparison of lighting models from three different shaders
  prefs: []
  type: TYPE_NORMAL
- en: Obviously, the Standard shader looks the most natural, but as we learned, PBR
    shaders are currently not supported on mobile platforms. Another option would
    be the Mobile Diffuse shader; let's see how that shader looks in our AR sample
    app.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Switch the shader to the Mobile Diffuse one and then save the project (File | Save
    Project).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Connect your device and type *Ctrl *+ *B*, *command *+ *B* on Mac. This will
    build and run the app on your device. Play with the app and wait for a surface
    to be visible and then tap and place Andy.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note anything different about our friend? That's right, he appears to stick
    out like a hot day in Canada. The reason for this is that the Mobile Diffuse shader
    is assuming a consistent light source, which means our model is always getting
    the same light (direction and intensity), except that in the real world, as the
    user moves, light direction and intensity can change dramatically. Your device's
    camera will try and compensate for this, but you can still see perceptible changes
    in lighting, especially if the lighting around the user changes dramatically.
    You can see this by running the app again, and this time, take a closer look at
    how the lighting looks different on and around our model. ARCore solves this issue
    of inconsistent lighting by performing a process called light estimation. We will
    cover light estimation in detail in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Light estimation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Light estimation is a technique for replicating the lighting conditions of
    the real world and applying it to our 3D virtual objects. Ideally, we would like
    to be able to replicate the exact lighting conditions, but of course, we''re not
    there yet. ARCore currently uses an image analysis algorithm to determine light
    intensity based on the current image from the device. This is then applied as
    global light to the 3D objects in the scene. Open up Unity again and let''s see
    how this is done by following along the given steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Locate the AndyMaterial again and revert its shader to `ARCore/DiffuseWithLightEstimation`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Save the project (File | Save Project).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Connect your device and type *Ctrl* + *B* (*command* + *B* on Mac) to build
    and run the app on your device. Place a couple of Andy models and alter the lighting
    conditions. Note how our objects respond to the changes in lighting.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Go back to Unity and double-click on the `HelloAR` scene in the `Assets/GoogleARCore/HelloARExample/Scenes`
    folder to open the scene. Feel free to save your `RenderingTest` scene.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Direct your attention to the Hierarchy window and double-click on Directional
    Lightto focus and highlight it in the Scene window. Note how the light is pointing
    straight down in the Scene window. In the **Inspector** window, you will see that
    the Shadow Type is set to No Shadows, and the Intensity is turned down to `0.7`,
    which essentially turns the light into a directional ambient or global light.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Direct your attention back to the Hierarchy window and select **Environmental
    Light**. Go to the **Inspector** window and click on the Gear icon beside the
    **Environmental Light (Script)** component. Then, select the **Edit Script** option
    from the context menu, as shown:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/6c61f973-382a-41ad-a138-9848114b4bd5.png)'
  prefs: []
  type: TYPE_IMG
- en: Editing the Environmental Light script
  prefs: []
  type: TYPE_NORMAL
- en: 'This will open up the script in your script editor. By default, Unity installs
    **MonoDevelop**, which will open the script if you have not installed and set
    a different editor. Scroll down to the `Update` method, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The `#if UNITY_EDITOR` is a compiler directive that checks whether the code
    is running in the editor. The reason we do this is so that when the code runs
    in the Unity editor, we want it to ignore any light estimation calculations. When
    the code is running in the editor, it will execute the next line; the `_GlobalLightEstimation`
    shader variable is set to `1`. This means that when the code is running in the
    editor, all it does is set our light to `1.0`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You will come across the `#if UNITY_EDITOR` directive quite frequently when
    doing mobile development. This directive allows you to write test code that only
    executes when the code is running in the editor. This allows us to simulate the
    object running in the editor without the need to worry about ARCore services or
    device restrictions.
  prefs: []
  type: TYPE_NORMAL
- en: Direct your attention to the `#else` block of code. This is code that is executed
    on the device and first checks whether the `Frame` is tracking. We have already
    seen this check in Android. The rest of the code is essentially just math, but
    if you look at the last highlighted line, you will see a call to `Frame.LightEstimate.PixelIntensity`.
    This is the call where ARCore reads the image from the camera and determines the
    current pixel intensity; a float value from 0 for a totally black image to `1`
    that is fully white. The intensity is normalized based on a constant called `MiddleGray`.
    The `MiddleGray` color or light intensity of `0.18f` corresponds roughly to the
    point where we humans stop recognizing colors.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We then use the `normalizedIntensity` to determine whether we want a linear
    change in lighting, when `normalizedIntensity` is less than `1.0`, or more gradually,
    when the intensity is greater than `1.0`. That's all that the rest of the math
    is doing, just making the lighting change more gradually after a certain threshold.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Change the `MiddleGray` constant to match the following line:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: This will convert our light estimation to now use a linear model. Save the code
    change and return to Unity. Unity will automatically recompile the code and inform
    you of any errors in the status bar at the bottom of the editor.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Connect your device and build and run. Place an Andy on a surface. Note how
    dark the figure is; this is because the lighting model is too abrupt.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We are using a single channel of color or what you may also call gray scale.
    This is why we refer to values as a color but it is in fact just a single float.
    A gray scale color of `0.18f` is equivalent to the RGB color (`0.18f`, `0.18f`,
    `0.18f`) or what ARCore calls `MiddleGray`.
  prefs: []
  type: TYPE_NORMAL
- en: Change the `MiddleGray` constant back to `0.18f`, save the project, and run
    the app. Note the difference in lighting.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This covers how ARCore uses image analysis techniques to read the light intensity
    from the camera's image and converts that value into a global light intensity
    or color. The lighting value is set on a shader, and we will follow how that value
    is used in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Cg/HLSL shaders
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The shading language used in Unity is a variety of HLSL, or sometimes referred
    to as Cg. This shading variant provides two different forms of shaders: **surface**
    and **vertex**/**fragment** shaders. Now, coming from Android, this may sound
    confusing, since GLSL treats vertex and fragment shaders differently. However,
    variety of HLSL in Unity treats vertex and fragment shaders as the same, since
    they reside in the same file and are in the same workflow. A surface shader, which
    handles the lighting of our model, can be simple or quite complex. The Standard
    Unity surface shader uses a PBR lighting model, which is quite advanced and not
    supported on most mobile devices. This issue, combined with our limited ability
    to track scene lights, limits us to writing our own shaders in order to get our
    object lighting correct. ARCore provides us with a very simple surface shader
    that is used in the sample to light the Andy model. Let''s open up Unity and take
    a look at what that shader looks like by following the given steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Load up the `HelloAR` sample project and scene.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select the AndyMaterial in the `Assets/GoogleARCore/HelloARExample/Materials/Andy`
    folder. Ensure that the Shader is set to `ARCore/DiffuseWithLightEstimation`.
    Switch it back if you changed it.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Click on the Gear icon and from the context menu, select Edit Shader. This
    will open the shader in your code editor, and it is also shown here for reference:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'This is a fairly simple diffuse lighting shader that uses the global light
    estimate we calculated earlier. It starts by defining itself with this line:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Next, it defines `Properties` in the next code block, where `_MainTex` represents
    the base texture, is called `"Base (RGB)"`, and is set to `2D`. If you quickly
    look back at Unity, you can see this property in the **Inspector** window.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The block of code that starts with `SubShader` is where the action happens.
    We first define `Tags`, which are sets of key/value pairs that set the rendering
    order and type parameters. In our example, we set this to `Opaque`. Then, we have
    the following line:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'This determines the **level of detail** of the shader. The `LOD` directive
    is used to determine the complexity or performance requirements of the shader.
    You can set the value to anything, but typical values are shown in the following
    list:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: VertexLit kind of shaders = `100`
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Decal, Reflective VertexLit = `150`
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Diffuse = `200`
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Diffuse Detail, Reflective Bumped Unlit, Reflective Bumped VertexLit = `250`
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Bumped, Specular = `300`
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Bumped Specular = `400`
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Parallax = `500`
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Parallax Specular = `600`
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: As you can see from the list, the simple shader represents a low level of detail.
    This means that lower-level hardware should be able to run this shader without
    any issue. You can set the maximum shader LOD per shader or globally; check the
    Unity documentation for further details.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We start our actual shader code with `CGPROGRAM` and then define the form of
    surface shader with the `#pragma` directive, as shown in the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: The first part of the directive, `surface`, defines this as a surface shader.
    Then, we see that the `surf` function name refers to the main surface function.
    Then comes the lighting model, `Lambert` in this case. After that, the options
    are set to `noforwardadd`, which is just a simple way to limit the number of lights
    to one. Finally, we use a custom modification function called `lightEstimation`
    that is set with `finalcolor:lightEstimation`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This shader uses the Lambert lighting model. You can find plenty of examples
    of what lighting models Unity supports or how to write your own model at [https://docs.unity3d.com/Manual/SL-SurfaceShaderLightingExamples.html](https://docs.unity3d.com/Manual/SL-SurfaceShaderLightingExamples.html).
  prefs: []
  type: TYPE_NORMAL
- en: 'Just inside the `#pragma` directive, we see the definition of the shader inputs:
    `_MainTex`, `_GlobalLightEstimation`, and `struct Input`. If you recall, `_GlobalLightEstimation`
    is the variable we set inside the `EnvironmentalLight` script to represent our
    global light.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Next, we will jump down a few lines to the `surf` function, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: This function simply samples the color from our `_MainTex` using `tex2D` and
    the input `uv` coordinates. Then, it sets the color (`Albedo`) and `Alpha` from
    the lookup. This function is called first to determine the color of the surface,
    and then, its output is passed to the Lambert lighting model, after which the
    final color is set by the `lightEstimation` function.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: An input marked as `inout` represents a value that can be modified and will
    automatically be returned.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Scroll up a bit to the `lightEstimation` function. Inside this function, the
    code, shown as follows, modifies the color based on the value that was set for
    `_GlobalLightEstimation`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Multiplying the color by the global light estimation is the same as adjusting
    the brightness with a dimmer switch.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Finally, we complete the shader with `Fallback` and the name of another shader.
    This sets the fall back or backup shader if the current shader is unable to run.
    A shader can fail due to compilation errors or hardware limitations.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now that we have a clear understanding of how the light estimation value we
    saw generated earlier is used in the shader, we can move to perhaps enhancing
    our lighting. If you recall, our current light just points straight down, but
    ideally, we would like to position the light to match the strongest light source.
    We will look at a simple but effective technique to track and position a light
    in AR in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Estimating light direction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Google provides us with a robust solution for estimating the amount of light
    in an AR scene with ARCore. As we learned, light direction is an equally important
    part of scene lighting. Google didn''t intentionally ignore estimating light direction
    with ARCore; it''s just that that problem is really difficult to do right. However,
    Google did provide us with just enough tools in ARCore to be able to estimate
    light direction, providing some simple assumptions. First, we need to assume that
    our user, for now anyway, will remain in the same room or area. Second, our user
    will need to look in at least an 180 degree arc across their vision, or more simply
    put, the user just needs to look around. Third, it works best if the real-world
    environment is lit from a distant single bright source, such as the sun. Based
    on those assumptions, we can simply store the direction the user saw the brightest
    image in and use that to reverse calculate our light direction. This may sound
    more complex than it is, so hopefully, the following diagram can explain this
    further:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6845f85e-4266-4ec6-8a32-f96f0d76bdc2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Calculating light direction from camera pixel intensity
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, this technique may sound quite complicated, but it isn''t. We can actually
    accomplish this with just a few lines of code. Open up Unity and follow along
    to write our directional light detector:'
  prefs: []
  type: TYPE_NORMAL
- en: Ensure that the `HelloAR` scene of the sample app is loaded.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select the Environmental Light object in the Hierarchy window.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click on the Gear icon beside the Environmental Light (Script) component in
    the **Inspector** window and select Edit Script from the context menu.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Just beneath the class declaration, add the following lines to declare new
    variables:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: These variables will hold a reference to the scene camera, light, the max global
    intensity we find, and the direction we find it.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Scroll down in the code until you see the identified line in the `Update` method,
    and add the following lines:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: All this code does is use `Frame.LightEstimate.PixelIntensity` to read the light
    intensity for the current camera direction. Then, we check whether this value
    is higher than any previous seen value (`maxGlobal`). If it is, we set a new maximum
    value and rotate the light (`SceneLight`) in the opposite direction of the camera,
    which means that the light will face toward the camera.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Be careful when you edit code outside of the `#if UNITY_EDITOR` directive. This
    code won't be compiled until a build is run for the platform, which means that
    any errors in the code will be identified as build errors. This can be confusing,
    so be careful to avoid syntax errors when coding these sections.
  prefs: []
  type: TYPE_NORMAL
- en: Save the file; that's all the code we need to write in order to adjust the light
    direction. If you recall from the last section, the diffuse shader we are using
    doesn't account for light direction. However, ARCore has provided us with another
    shader that does.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Return to the editor to find and select the AndyMaterial in the Assets/GoogleARCore/HelloARExample/Materials/Andy
    folder.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Change the material to use the `ARCore/SpecularWithLightEstimation` shader.
    This material shows the direction of light better.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select the Environmental Light object in the Hierarchy window. Note how we have
    two new properties added to the Environmental Light (Script) component. These
    new properties (Scene Camera and Scene Light) were added because we declared them
    as **public** fields in the class.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Click on the icon that resembles a bullseye next to the Scene Camera property.
    Then, as shown in the following excerpt, select the First Person Camera object
    from the Select GameObject dialog:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/5bf994ec-eaf5-4f99-9495-9f55657f92d8.png)'
  prefs: []
  type: TYPE_IMG
- en: Setting the Scene Camera and Scene Light properties of the component
  prefs: []
  type: TYPE_NORMAL
- en: Close the **Select GameObject** dialog.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Repeat the same process for setting the **Directional Light** as the **Scene
    Light**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Connect your device and build and run. Run the app in an area with a single
    bright light source and see how Andy looks after you place it.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Updating the environmental lighting
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now Andy should be lit from what looks like the brightest light source in the
    area. However, because we don''t currently track changes in light direction, if
    you change rooms or the lighting changes, then the illusion is broken. Light tracking
    is difficult, and it''s more difficult than tracking a user, except that we can
    put a simple hack in place to not track the lighting for as long as we do, which
    is currently forever, if you weren''t paying attention. Follow along to put this
    simple hack in the code we just wrote:'
  prefs: []
  type: TYPE_NORMAL
- en: Open up the `EnvrionmentalLight.cs` script in your text editor of choice. If
    you forgot how to do this, just look back a few pages.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Add the following line right after and before the lines identified:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: That single line is a degrade function on the `maxGlobal` variable. Remember
    that `maxGlobal` is the value we identify as the strongest light source. This
    simple function, yep function, degrades this value over time. The value of `.98f` sets
    the speed of decay. A value of `.98f` represents a fairly quick decay rate, whereas
    a value of `.9999f` would represent a slow decay.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Save the file, and yep, that's it.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Go back to Unity. Connect and build and run the app. Now when you place an Andy,
    you should quickly see changes in what the app identifies as the strongest light
    source. Feel free to go back and change the decay rate or alter the function and
    use your own method; experiment.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What we put together is a simple way to track and estimate light direction.
    As we mentioned, this method works, but it's certainly not without its limitations.
    In any case, this should give the curious reader enough to continue and extend
    this further. We also completely avoided a proper discussion of shadows. Fortunately,
    we will have plenty of time to do that in [Chapter 9](843257a4-843b-4278-99df-fec1e2bd996b.xhtml), *Blending
    Light for Architectural Design*, where we will allow the user to transform their
    own living space.
  prefs: []
  type: TYPE_NORMAL
- en: Exercises
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Complete the following exercises on your own**:'
  prefs: []
  type: TYPE_NORMAL
- en: Change the `maxGlobal` rate of decay. You decide whether to make it faster or
    slower.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Increase or decrease the `maxGlobal` rate of decay based on the user's amount
    of movement. Hint—recall how we tracked the user, and use that to determine how
    far they have gone or how fast. Use that information to set the rate of decay.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Write your own custom lighting surface shader. This one's difficult, but it's
    worth the effort.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Certainly, as you become more of an expert in AR, you realize how important
    lighting is to augmented reality. It's so important that Google developed ARCore
    with light estimation built in, which is why we spent this entire chapter on the
    subject. First, we learned about the rendering process in a bit more depth; then,
    we covered 3D lighting, an essential bit of knowledge that we will need in order
    to understand the added complexity of lighting in AR. This led us to look at the
    way ARCore estimates the light levels or global light in an area by taking a closer
    look at Unity Cg/HLSL shaders and, more specifically, surface shaders. Finally,
    we implemented a simple but effective hack to track and estimate light direct
    in a scene, which we left the reader with to improve on in their own time.
  prefs: []
  type: TYPE_NORMAL
- en: Estimating the actual lighting conditions of the environment will be a major
    hurdle for AR to overcome. However, with the incredible advances in AI and Machine
    Learning, we will likely see some better solutions come out soon. We will take
    a closer look at how Machine Learning can assist AR in the next chapter.
  prefs: []
  type: TYPE_NORMAL
