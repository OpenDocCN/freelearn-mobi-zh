<html><head></head><body>
<div><h1 class="chapter-number" id="_idParaDest-125"><a id="_idTextAnchor126" class="calibre6 pcalibre1 pcalibre"/>6</h1>
<h1 id="_idParaDest-126" class="calibre5"><a id="_idTextAnchor127" class="calibre6 pcalibre1 pcalibre"/>Adding Video and Editing Functionality to Packtagram</h1>
<p class="calibre3">Having already mastered the art of capturing stunning photographs and applying mesmerizing filters with CameraX, it’s time to elevate our Packtagram app to new heights. Now, we will embark on an exciting new venture: diving into the world of video.</p>
<p class="calibre3">Videos are not just moving pictures; they are powerful storytelling tools that breathe life into our apps. They create dynamic interactions, keeping users engaged and offering them a canvas to express creativity. In this chapter, we’ll guide you through the process of integrating video capabilities into your app, akin to adding a new dimension to the Instagram-like experience we have been crafting.</p>
<p class="calibre3">We will start by exploring how to capture high-quality videos using the CameraX library, an extension of the skills you’ve already honed for photo capture. Then, we’ll delve<a id="_idIndexMarker656" class="calibre6 pcalibre1 pcalibre"/> into the world of <strong class="bold">Fast Forward Moving Picture Expert Group</strong> (<strong class="bold">Ffmpeg</strong>), a robust library for video processing, to add layers of creativity to your videos – from simple captions that convey messages to sophisticated filters that transform the visual mood.</p>
<p class="calibre3">You’ll learn to not only capture and edit videos but also to efficiently upload them to Firebase Storage, ensuring that your app can handle large files seamlessly and provide a smooth user experience.</p>
<p class="calibre3">By the end of this chapter, you will have added a significant feature to your app, making it not just a photo-sharing platform but a comprehensive multimedia experience.</p>
<p class="calibre3">To accomplish that, in this chapter, we will cover the following topics:</p>
<ul class="calibre15">
<li class="calibre14">Adding video functionality to our app</li>
<li class="calibre14">Getting to know FFmpeg</li>
<li class="calibre14">Adding a caption to a video with FFmpeg</li>
<li class="calibre14">Adding a filter to a video with FFmpeg</li>
<li class="calibre14">Uploading the video</li>
</ul>
<h1 id="_idParaDest-127" class="calibre5"><a id="_idTextAnchor128" class="calibre6 pcalibre1 pcalibre"/>Technical requirements</h1>
<p class="calibre3">As in the previous chapter, you will need to have installed Android Studio (or another editor of your preference).</p>
<p class="calibre3">You can find the complete code that we will be using in this chapter in this book’s GitHub repository: <a href="https://github.com/PacktPublishing/Thriving-in-Android-Development-using-Kotlin/tree/main/Chapter-6" class="calibre6 pcalibre1 pcalibre">https://github.com/PacktPublishing/Thriving-in-Android-Development-using-Kotlin/tree/main/Chapter-6</a>.</p>
<h1 id="_idParaDest-128" class="calibre5"><a id="_idTextAnchor129" class="calibre6 pcalibre1 pcalibre"/>Adding video functionality to our app</h1>
<p class="calibre3">In this section, we will extend<a id="_idIndexMarker657" class="calibre6 pcalibre1 pcalibre"/> the functionality<a id="_idIndexMarker658" class="calibre6 pcalibre1 pcalibre"/> of our Android app so that it includes video-capturing capabilities through CameraX. This powerful library not only simplifies the process of capturing photos but also provides an efficient way to record videos. We’ll start by adapting our existing CameraX setup, which is designed for capturing photos, to also handle video recording. The aim is to provide a seamless integration, maintaining the simplicity and robustness of CameraX.</p>
<p class="calibre3">First, we need to set up the preview for the video recording. In the previous chapter, we created a <code>CameraPreview</code> composable. We’ll reuse the same composable here:</p>
<pre class="source-code">
@Composable
fun CameraPreview(cameraController:
LifecycleCameraController, modifier: Modifier = Modifier) {
    AndroidView(
        factory = { context -&gt;
            PreviewView(context).apply {
                implementationMode =
                  PreviewView.ImplementationMode.COMPATIBLE
            }
        },
        modifier = modifier,
        update = { previewView -&gt;
            previewView.controller = cameraController
        }
    )
}</pre> <p class="calibre3">Now, we need to create<a id="_idIndexMarker659" class="calibre6 pcalibre1 pcalibre"/> a new button composable to record images<a id="_idIndexMarker660" class="calibre6 pcalibre1 pcalibre"/> and sound from the preview (instead of just capturing the image):</p>
<pre class="source-code">
@Composable
fun CaptureVideoButton(
    cameraController: LifecycleCameraController,
    onRecordingFinished: (String) -&gt; Unit,
) {
    val context = LocalContext.current
    val recording = remember {
        mutableStateOf&lt;Recording?&gt;(null) }
    IconButton(
        onClick = {
            cameraController.setEnabledUseCases(
                LifecycleCameraController.VIDEO_CAPTURE)
            if (recording.value == null) {
                recording.value =
                    startRecording(cameraController,
                        context, onRecordingFinished)
            } else {
                stopRecording(recording.value)
                recording.value = null
            }
        },
        modifier = Modifier
            .size(60.dp)
            .padding(8.dp),
    ) {
        Icon(
            painter = if (recording.value == null)
                painterResource(id =
                    R.drawable.ic_videocam) else
                        painterResource(id =
                            R.drawable.ic_stop),
            contentDescription = "Capture video",
            tint = MaterialTheme.colorScheme.onPrimary
        )
    }
}</pre> <p class="calibre3">Here, we are creating a new composable called <code>CaptureVideoButton</code>. It is similar to the <code>CaptureButton</code> composable but with some modifications. For example, now, we’ll need to create a variable recording. The <code>Recording</code> class in CameraX is responsible for managing an active video recording session. It encapsulates the state and operations needed to start, pause, resume, and stop the recording. In our code, the <code>recording</code> variable will be used to manage the current recording session.</p>
<p class="calibre3">Once the user clicks the button, we’ll configure the video capture use case, <code>cameraController.setEnabledUseCases(LifecycleCameraController.VIDEO_CAPTURE)</code>, so that <code>cameraController</code> can start and manage the video recording process, ensuring that the camera is correctly set up for capturing high-quality video and enabling the necessary configurations and resources for the recording session to proceed smoothly. Then, if a recording hasn’t been already initiated, we’ll start a new recording. If it has already been initiated, we’ll stop it.</p>
<p class="calibre3">The icon of the button<a id="_idIndexMarker661" class="calibre6 pcalibre1 pcalibre"/> will show a camera prior to the recording<a id="_idIndexMarker662" class="calibre6 pcalibre1 pcalibre"/> being initiated and a stop button if the recording is already in progress, to indicate to the user that they should click it to stop the recording.</p>
<p class="calibre3">To finish this recording functionality, we need to implement the <code>startRecording</code> function:</p>
<pre class="source-code">
@SuppressLint("MissingPermission")
private fun startRecording(
    cameraController: LifecycleCameraController,
    context: Context,
    onRecordingFinished: (String) -&gt; Unit
): Recording {
    val videoFile = File(context.filesDir,
        "video_${System.currentTimeMillis()}.mp4")
    val outputOptions =
        FileOutputOptions.Builder(videoFile).build()
    val audioConfig = AudioConfig.create(true)
    val executor = Executors.newSingleThreadExecutor()
    return cameraController.startRecording(
        outputOptions,
        audioConfig,
        executor
    ) { recordEvent -&gt;
        when (recordEvent) {
            is VideoRecordEvent.Finalize -&gt; {
                if (recordEvent.hasError()) {
                    Log.e("CaptureVideoButton",
                        "Video recording error:
                            ${recordEvent.error}")
                } else {
                    onRecordingFinished(
                        videoFile.absolutePath)
                }
            }
        }
    }
}</pre> <p class="calibre3">This function is marked<a id="_idIndexMarker663" class="calibre6 pcalibre1 pcalibre"/> with the <code>@SuppressLint("MissingPermission")</code> annotation, indicating<a id="_idIndexMarker664" class="calibre6 pcalibre1 pcalibre"/> an assumption that the necessary runtime permissions, such as access to the camera and microphone, have already been granted. We will handle these permissions the same way we did with the photo capture, so the annotation is safe to use here as the permissions would have already been granted.</p>
<p class="calibre3">The function begins by defining the location and filename for the video recording. It uses the <code>File</code> class to create a reference to a <code>video_${System.currentTimeMillis()}.mp4</code> file, which is stored in the app-specific directory on the external storage. This approach to file storage is advantageous as it does not require additional permissions and ensures that the stored data is private to the application.</p>
<p class="calibre3">Next, the code sets up <code>FileOutputOptions</code> using the previously defined file. This step is crucial as it configures how the recorded video data will be written to the filesystem. The <code>FileOutputOptions</code> class, part of the CameraX library, offers an intuitive API to set these parameters efficiently – for example, it allows us to specify the video location using <code>ContentResolver</code> (you can find additional information about <code>FileOutputOptions</code> here: <a href="https://developer.android.com/reference/androidx/camera/video/FileOutputOptions" class="calibre6 pcalibre1 pcalibre">https://developer.android.com/reference/androidx/camera/video/FileOutputOptions</a>). Next, the audio configuration<a id="_idIndexMarker665" class="calibre6 pcalibre1 pcalibre"/> is created, in this case to allow audio using <code>AudioConfig.create(true)</code>.</p>
<p class="calibre3">Then, an executor is created using <code>Executors.newSingleThreadExecutor()</code>, which facilitates the execution of tasks in a background thread, thereby keeping the UI thread unblocked and responsive. With these parameters defined (<code>fileOutputOptions</code>, <code>AudioConfig</code>, and <code>Executor</code>), we can execute the <code>cameraController.startRecording</code> function, which will initiate the recording.</p>
<p class="calibre3">Additionally, an event listener is defined using the <code>Consumer&lt;VideoRecordEvent&gt;</code> interface. This listener uses a <code>when</code> statement to handle different types of <code>VideoRecordEvent</code>, such as <code>VideoRecordEvent.Finalize</code>, which indicates the completion of the recording. The event listener also checks for errors during the recording process, ensuring robust error handling.</p>
<p class="calibre3">Then, a <code>Recording</code> object<a id="_idIndexMarker666" class="calibre6 pcalibre1 pcalibre"/> is returned, representing the ongoing<a id="_idIndexMarker667" class="calibre6 pcalibre1 pcalibre"/> recording session. This recording object is crucial for the next step.</p>
<p class="calibre3">Now, let’s implement the <code>stopRecording</code> function:</p>
<pre class="source-code">
fun stopRecording(recording: Recording?) {
    recording?.stop()
}</pre> <p class="calibre3">In this concise and straightforward function, we only have one line of code, but it does something essential. The function takes a single parameter, <code>recording</code>, which is our instance of the <code>Recording</code> class from the CameraX library.</p>
<p class="calibre3">The core action in this function is to invocate <code>stop()</code> on the <code>recording</code> object. When this method is called, it tells the <code>recording</code> instance to terminate the current video recording session. This involves stopping video frames from being captured and finalizing the video file that’s being recorded. The video file is then saved to the location that’s specified when the recording has finished.</p>
<p class="calibre3">Now, we will include<a id="_idIndexMarker668" class="calibre6 pcalibre1 pcalibre"/> the new button in <code>CaptureModeContent</code>, which we built<a id="_idIndexMarker669" class="calibre6 pcalibre1 pcalibre"/> previously for the capture feature:</p>
<pre class="source-code">
@Composable
private fun CaptureModeContent(
    cameraController: LifecycleCameraController,
    onImageCaptured: (Bitmap) -&gt; Any,
    onVideoCaptured: (String) -&gt; Any
) {
    Box(modifier = Modifier.fillMaxSize()) {
        CameraPermissionRequester {
            Box(
                contentAlignment = Alignment.BottomCenter,
                modifier = Modifier.fillMaxSize()
            ) {
                CameraPreview(...)
                Row {
                    CaptureButton(...)
                    CaptureVideoButton(
                       cameraController =
                           cameraController,
                       onRecordingFinished = { videoPath -&gt;
                           onVideoCaptured(videoPath)
                       }
                    )
                }
            }
        }
    }
}</pre> <p class="calibre3">Here, we have added<a id="_idIndexMarker670" class="calibre6 pcalibre1 pcalibre"/> a <code>Row</code> composable to show both buttons horizontally<a id="_idIndexMarker671" class="calibre6 pcalibre1 pcalibre"/> side by side. We have also added a new Lambda (<code>onVideoCaptured</code>) that we will use to pass the video file path when the recording has finished.</p>
<p class="calibre3">With these changes, we should be able to see the newly implemented button:</p>
<div><div><img alt="Figure 6.1: The video capture button already integrated into the StoryContent screen when the video is not being recorded" src="img/B19443_06_01.jpg" class="calibre4"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 6.1: The video capture button already integrated into the StoryContent screen when the video is not being recorded</p>
<p class="calibre3">When we click the video capture button, we should see its icon change to the stop symbol:</p>
<div><div><img alt="Figure 6.2: Video recording in progress" src="img/B19443_06_02.jpg" class="calibre4"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 6.2: Video recording in progress</p>
<p class="calibre3">And with this, we are ready <a id="_idIndexMarker672" class="calibre6 pcalibre1 pcalibre"/>to record<a id="_idIndexMarker673" class="calibre6 pcalibre1 pcalibre"/> our videos using CameraX! Now, it is time for us to learn how to modify or edit the recorded videos. With these aspects in mind, let me introduce you to the FFmpeg library.</p>
<h1 id="_idParaDest-129" class="calibre5"><a id="_idTextAnchor130" class="calibre6 pcalibre1 pcalibre"/>Getting to know FFmpeg</h1>
<p class="calibre3"><strong class="bold">FFmpeg</strong> is an open-source multimedia framework<a id="_idIndexMarker674" class="calibre6 pcalibre1 pcalibre"/> that has become a cornerstone in the world of audio and video processing. Renowned for its versatility and power, FFmpeg offers a comprehensive suite of libraries and tools to handle video, audio, and other multimedia files and streams. At its core, FFmpeg is a command-line tool, enabling users to convert media files from one format into another, manipulate video and audio recordings, and perform a wide array of other multimedia processing tasks.</p>
<p class="callout-heading">Note</p>
<p class="callout">You can find<a id="_idIndexMarker675" class="calibre6 pcalibre1 pcalibre"/> the official FFmpeg documentation here: <a href="https://ffmpeg.org/" class="calibre6 pcalibre1 pcalibre">https://ffmpeg.org/</a>.</p>
<p class="calibre3">Through the following subsections, we will learn what components are part of FFmpeg, its key features, and how to integrate this powerful library in our Android apps.</p>
<h2 id="_idParaDest-130" class="calibre7"><a id="_idTextAnchor131" class="calibre6 pcalibre1 pcalibre"/>The components of FFmpeg</h2>
<p class="calibre3">The FFmpeg project is composed<a id="_idIndexMarker676" class="calibre6 pcalibre1 pcalibre"/> of several components, each serving a specific role in multimedia processing:</p>
<ul class="calibre15">
<li class="calibre14"><strong class="source-inline1">libavcodec</strong>: A library containing decoders and encoders for audio/video codecs</li>
<li class="calibre14"><strong class="source-inline1">libavformat</strong>: This library deals with the container formats, managing the multiplexing and demultiplexing aspects of multimedia streams</li>
<li class="calibre14"><strong class="source-inline1">libavutil</strong>: A utility library that provides a range of helper functions and data structures</li>
<li class="calibre14"><strong class="source-inline1">libavfilter</strong>: Used for applying various audio and video filters</li>
<li class="calibre14"><strong class="source-inline1">libswscale</strong>: Dedicated to handling<a id="_idIndexMarker677" class="calibre6 pcalibre1 pcalibre"/> image scaling and color format conversions</li>
</ul>
<p class="calibre3">Together, these components provide a robust foundation for handling a wide array of multimedia processing tasks.</p>
<h2 id="_idParaDest-131" class="calibre7"><a id="_idTextAnchor132" class="calibre6 pcalibre1 pcalibre"/>Key features of FFmpeg</h2>
<p class="calibre3">FFmpeg stands out for its extensive<a id="_idIndexMarker678" class="calibre6 pcalibre1 pcalibre"/> range of capabilities. Some of its key features include the following:</p>
<ul class="calibre15">
<li class="calibre14"><strong class="bold">Format support</strong>: FFmpeg supports a vast number of audio and video formats, both in terms of encoding and decoding, making it incredibly versatile for multimedia processing</li>
<li class="calibre14"><strong class="bold">Conversion</strong>: It can convert media files between various formats with high efficiency, a feature that’s widely used in various applications and services</li>
<li class="calibre14"><strong class="bold">Streaming</strong>: FFmpeg excels in streaming capabilities, allowing for audio and video to be captured, encoded, and streamed in real time</li>
<li class="calibre14"><strong class="bold">Filtering</strong>: With its powerful filtering capabilities, users can apply various transformations, overlays, and effects to their media</li>
</ul>
<h2 id="_idParaDest-132" class="calibre7"><a id="_idTextAnchor133" class="calibre6 pcalibre1 pcalibre"/>Integrating mobile-ffmpeg into our project</h2>
<p class="calibre3">In the context of Android<a id="_idIndexMarker679" class="calibre6 pcalibre1 pcalibre"/> development, FFmpeg can be used as a powerful<a id="_idIndexMarker680" class="calibre6 pcalibre1 pcalibre"/> tool for video editing functionalities, such as applying filters, transcoding, or even adding subtitles. However, integrating FFmpeg into Android applications<a id="_idIndexMarker681" class="calibre6 pcalibre1 pcalibre"/> while using C++ code requires using <code>mobile-ffmpeg</code>.</p>
<p class="calibre3"><code>mobile-ffmpeg</code> is a specialized port of Ffmpeg that’s designed for mobile platforms such as Android and iOS. It provides pre-built binaries, mobile-specific APIs, and optimizations tailored to the constraints of mobile hardware. This makes it easier to integrate FFmpeg’s powerful capabilities into mobile applications, allowing developers to leverage advanced multimedia processing features with less complexity.</p>
<p class="calibre3">To integrate the <code>mobile-ffmpeg</code> library into our project, we will start by opening our <code>libs.versions.toml</code> file. There, we will add the version and the library group and name:</p>
<pre class="source-code">
[versions]
...
mobileffmpeg = "4.4"
[libraries]
...
mobileffmpeg = { group = "com.arthenica", name = "mobile-ffmpeg-full", version.ref = "mobileffmpeg" }</pre> <p class="calibre3">Here, we have just added the latest <code>mobile-ffmpeg</code> version and the library reference to our version catalog.</p>
<p class="calibre3">As always, to use it in any of our modules, we will have to add the dependency in the <code>build.gradle.kts</code> file:</p>
<pre class="source-code">
dependencies {
    ....
    implementation(libs.mobileffmpeg)
}</pre> <p class="calibre3">Once it’s added to our<a id="_idIndexMarker682" class="calibre6 pcalibre1 pcalibre"/> dependencies, we will have to sync our Gradle<a id="_idIndexMarker683" class="calibre6 pcalibre1 pcalibre"/> files so that it’s ready to be used in our code. But first, let’s learn how FFmpeg works and can be used.</p>
<h2 id="_idParaDest-133" class="calibre7"><a id="_idTextAnchor134" class="calibre6 pcalibre1 pcalibre"/>Understanding the FFmpeg command-line syntax</h2>
<p class="calibre3">As we have seen, FFmpeg<a id="_idIndexMarker684" class="calibre6 pcalibre1 pcalibre"/> is a powerful multimedia framework that’s capable of decoding, encoding, transcoding, multiplexing (joining, for example, audio and video in a single file), demultiplexing (separating audio and video in different files), streaming, filtering, and playing almost any type of media file. Understanding its command-line syntax is crucial for effective video processing, especially in Android environments.</p>
<p class="calibre3">Keep in mind that we will not be executing these commands in a terminal, but the <code>mobile-ffmpeg</code> library uses the same syntax to allow us to execute them using a function called <code>FFmpeg.execute()</code>, as we will see now.</p>
<p class="calibre3">At its core, an FFmpeg command follows a basic structure:</p>
<pre class="source-code">
FFmpeg.execute("[global_options] {[input_file_options] [flags] input_url} ... {[output_file_options] output_url} ...")</pre> <p class="calibre3">Let’s take a closer look<a id="_idIndexMarker685" class="calibre6 pcalibre1 pcalibre"/> at the components of this syntax:</p>
<ul class="calibre15">
<li class="calibre14"><strong class="source-inline1">global_options</strong>: These are settings that can be applied throughout the command, such as configuring logging levels or overriding default configurations.</li>
<li class="calibre14"><strong class="source-inline1">input_file_options</strong>: These are options that specifically affect the input file, such as the format, codec, or frame rate.</li>
<li class="calibre14"><strong class="source-inline1">input_url</strong>: The path to the input file.</li>
<li class="calibre14"><strong class="source-inline1">output_file_options</strong>: These are similar to input file options but they affect the output file, such as the format, codec, or bitrate.</li>
<li class="calibre14"><strong class="source-inline1">output_url</strong>: The path for the output file.</li>
<li class="calibre14"><strong class="source-inline1">options</strong>/<strong class="source-inline1">flags</strong>: These start with a dash (<strong class="source-inline1">-</strong>) and modify how FFmpeg processes files. The most used options and flags are as follows:<ul class="calibre16"><li class="calibre14"><strong class="source-inline1">-i</strong>: Specifies the input file</li><li class="calibre14"><strong class="source-inline1">-c</strong>: Indicates the codec; use <strong class="source-inline1">-c:v</strong> for video and <strong class="source-inline1">-c:a</strong> for audio</li><li class="calibre14"><strong class="source-inline1">-b</strong>: Sets the bitrate; <strong class="source-inline1">-b:v</strong> for video and <strong class="source-inline1">-b:a</strong> for audio</li><li class="calibre14"><strong class="source-inline1">-s</strong>: Defines the frame size (resolution)</li><li class="calibre14"><strong class="source-inline1">-r</strong>: Sets the frame rate</li><li class="calibre14"><strong class="source-inline1">-f</strong>: Indicates<a id="_idIndexMarker686" class="calibre6 pcalibre1 pcalibre"/> the format</li></ul></li>
</ul>
<p class="calibre3"> Let’s see how we can use this syntax to complete some basic operations.</p>
<h3 class="calibre9">Basic conversion</h3>
<p class="calibre3">Converting a video file<a id="_idIndexMarker687" class="calibre6 pcalibre1 pcalibre"/> from one format into another is a fundamental task in video editing. For example, converting an MP4 file into an AVI file can be done like so:</p>
<pre class="source-code">
FFmpeg.execute("-i input.mp4 output.avi")</pre> <p class="calibre3">This command tells FFmpeg to take <code>input.mp4</code> and convert it into <code>output.avi</code> using the default settings for codecs and quality (the default values are used here because we didn’t specify any settings).</p>
<h3 class="calibre9">Specifying codecs</h3>
<p class="calibre3"><strong class="bold">Codecs</strong> are algorithms that<a id="_idIndexMarker688" class="calibre6 pcalibre1 pcalibre"/> are used<a id="_idIndexMarker689" class="calibre6 pcalibre1 pcalibre"/> for encoding (compressing) or decoding (decompressing) video and audio streams. In FFmpeg, you can specify different codecs for the video and audio components of a file:</p>
<ul class="calibre15">
<li class="calibre14"><strong class="bold">Video codec</strong>: A video codec processes<a id="_idIndexMarker690" class="calibre6 pcalibre1 pcalibre"/> the visual data in the file. Choosing the right video codec affects the video’s quality, size, and compatibility with different players and devices.</li>
<li class="calibre14"><strong class="bold">Audio codec</strong>: An audio codec deals with the sound<a id="_idIndexMarker691" class="calibre6 pcalibre1 pcalibre"/> component. It determines the audio quality, file size, and compatibility with audio playback systems.</li>
</ul>
<p class="calibre3">To specify codecs in FFmpeg, use the <code>-c</code> flag followed by a colon, then either <code>v</code> for video or <code>a</code> for audio, and then specify the codec’s name:</p>
<pre class="source-code">
ffmpeg -i input.file -c:v [video_codec] -c:a [audio_codec] output.file</pre> <p class="calibre3">So, for example, to specify the H.264 and AAC codecs, you can run the following command:</p>
<pre class="source-code">
ffmpeg -i input.mp4 -c:v libx264 -c:a aac output.mp4</pre> <p class="calibre3">Let’s understand what the values of this command mean:</p>
<ul class="calibre15">
<li class="calibre14"><strong class="source-inline1">-i</strong>: This indicates that the next parameter is going to be the input file.</li>
<li class="calibre14"><strong class="source-inline1">input.mp4</strong>: This is the route to the input file.</li>
<li class="calibre14"><strong class="source-inline1">-c:v libx264</strong>: This value sets the video codec to <strong class="source-inline1">libx264</strong>, a popular codec for H.264 video encoding. It’s known for its efficiency and compatibility with most video platforms.</li>
<li class="calibre14"><strong class="source-inline1">-c:a aac</strong>: This value sets the audio codec to <strong class="source-inline1">aac</strong> (which stands for Advanced Audio Coded), known for good quality audio at lower bitrates, making it ideal for web videos.</li>
<li class="calibre14"><strong class="source-inline1">output.mp4</strong>: This indicates the route to the output file.</li>
</ul>
<p class="calibre3">Note that higher-quality codecs often result in larger file sizes – the balance between quality and file size can be key, depending on the use case.</p>
<p class="calibre3">Also, it is important to know<a id="_idIndexMarker692" class="calibre6 pcalibre1 pcalibre"/> that some codecs require licensing<a id="_idIndexMarker693" class="calibre6 pcalibre1 pcalibre"/> for commercial use (for example, H.264), whereas others are open source and free (for example, VP9 and Opus).</p>
<h3 class="calibre9">Adjusting video quality</h3>
<p class="calibre3">In video processing, one of the most<a id="_idIndexMarker694" class="calibre6 pcalibre1 pcalibre"/> crucial aspects<a id="_idIndexMarker695" class="calibre6 pcalibre1 pcalibre"/> to manage is the quality of the output video. The quality is often directly influenced by the bitrate. The <strong class="bold">bitrate</strong> is measured in <strong class="bold">bits per second</strong> (<strong class="bold">bps</strong>) and represents the amount<a id="_idIndexMarker696" class="calibre6 pcalibre1 pcalibre"/> of video or audio<a id="_idIndexMarker697" class="calibre6 pcalibre1 pcalibre"/> data that’s encoded for 1 second of playback. Higher bitrates generally mean better quality but also larger file sizes.</p>
<p class="calibre3">There are two types of bitrate:</p>
<ul class="calibre15">
<li class="calibre14"><strong class="bold">Constant bitrate</strong> (<strong class="bold">CBR</strong>): This encodes the file<a id="_idIndexMarker698" class="calibre6 pcalibre1 pcalibre"/> at a consistent bitrate throughout, leading to predictable file sizes but potentially varying quality</li>
<li class="calibre14"><strong class="bold">Variable bitrate</strong> (<strong class="bold">VBR</strong>): This adjusts the bitrate<a id="_idIndexMarker699" class="calibre6 pcalibre1 pcalibre"/> according to the complexity of each part of the video, balancing quality and file size more effectively</li>
</ul>
<p class="calibre3">To adjust the bitrate in FFmpeg, we can use the <code>-b:v</code> flag for video bitrate and <code>-b:a</code> for audio bitrate:</p>
<pre class="source-code">
ffmpeg -i input.file -b:v [video_bitrate] -b:a [audio_bitrate] output.file</pre> <p class="calibre3">For example, to set standard definition video with moderate quality, we can run the following command:</p>
<pre class="source-code">
ffmpeg -i input.mp4 -b:v 1500k -b:a 128k output.mp4</pre> <p class="calibre3">Let’s see what the values of this command mean:</p>
<ul class="calibre15">
<li class="calibre14"><strong class="source-inline1">-i</strong>: This indicates that the next parameter is going to be the input file</li>
<li class="calibre14"><strong class="source-inline1">input.mp4</strong>: This is the route to the input file</li>
<li class="calibre14"><strong class="source-inline1">-b:v 1500k</strong>: Sets the video bitrate to 1,500 kbps, which is suitable for standard-definition content</li>
<li class="calibre14"><strong class="source-inline1">-b:a 128k</strong>: Sets the audio bitrate to 128 kbps, providing decent audio quality without excessive file size</li>
<li class="calibre14"><strong class="source-inline1">output.mp4</strong>: Indicates the route to the output file</li>
</ul>
<p class="calibre3">It’s worth noting that lower bitrates may lead to noticeable compression artifacts, especially in fast-moving or complex scenes. On the other hand, higher bitrates offer better quality but at the expense of larger<a id="_idIndexMarker700" class="calibre6 pcalibre1 pcalibre"/> file sizes, which might be an issue for online streaming<a id="_idIndexMarker701" class="calibre6 pcalibre1 pcalibre"/> or limited storage.</p>
<h3 class="calibre9">Resizing video</h3>
<p class="calibre3">Resizing or scaling videos<a id="_idIndexMarker702" class="calibre6 pcalibre1 pcalibre"/> is a common task<a id="_idIndexMarker703" class="calibre6 pcalibre1 pcalibre"/> in video editing, whether it’s to fit different screen sizes, reduce file size, or conform to specific resolution requirements. FFmpeg offers powerful tools to resize videos with ease, but understanding the impact of these changes is crucial for maintaining quality.</p>
<p class="calibre3">But what are video resolution and aspect ratio?</p>
<ul class="calibre15">
<li class="calibre14"><strong class="bold">Resolution</strong>: The resolution of a video<a id="_idIndexMarker704" class="calibre6 pcalibre1 pcalibre"/> is the dimension in pixels, given as width x height. Standard resolutions include 480p (SD), 720p (HD), 1080p (Full HD), and 4K (Ultra HD).</li>
<li class="calibre14"><strong class="bold">Aspect ratio</strong>: This is the ratio of the width<a id="_idIndexMarker705" class="calibre6 pcalibre1 pcalibre"/> to the height of the video. Common aspect ratios are 16:9 (widescreen) and 4:3 (traditional).</li>
</ul>
<p class="calibre3">To resize videos in FFmpeg, the <code>-s</code> (size) flag is used. It sets the resolution:</p>
<pre class="source-code">
ffmpeg -i input.file -s [width]x[height] output.file</pre> <p class="calibre3">For example, to resize to 1080p, the command will be as follows:</p>
<pre class="source-code">
ffmpeg -i input.mp4 -s 1920x1080 output.mp4</pre> <p class="calibre3">Let’s see what the values of this command mean:</p>
<ul class="calibre15">
<li class="calibre14"><strong class="source-inline1">-i</strong>: Indicates that the next parameter is going to be the input file</li>
<li class="calibre14"><strong class="source-inline1">input.mp4</strong>: The route to the input file</li>
<li class="calibre14"><strong class="source-inline1">-s 1920x1080</strong>: Resizes the video to full HD (1080p), which is suitable for high-quality presentations and large displays</li>
<li class="calibre14"><strong class="source-inline1">output.mp4</strong>: Indicates the route to the output file</li>
</ul>
<p class="calibre3">There are some things to consider when resizing videos:</p>
<ul class="calibre15">
<li class="calibre14">Choose the resolution based on where and how the video will be viewed. For instance, you should choose a high resolution for TV broadcasts and something lower for web or mobile use.</li>
<li class="calibre14">Higher resolutions lead to larger files, which can be a concern for storage and streaming.</li>
<li class="calibre14">Always consider the quality<a id="_idIndexMarker706" class="calibre6 pcalibre1 pcalibre"/> of the source video. Upscaling low-quality footage might not yield<a id="_idIndexMarker707" class="calibre6 pcalibre1 pcalibre"/> desirable results.</li>
</ul>
<p class="calibre3">Now that we are familiar with the basic features of FFmpeg, we will learn about the advanced ones.</p>
<h2 id="_idParaDest-134" class="calibre7"><a id="_idTextAnchor135" class="calibre6 pcalibre1 pcalibre"/>Advanced syntax and options in FFmpeg</h2>
<p class="calibre3">FFmpeg’s true power lies<a id="_idIndexMarker708" class="calibre6 pcalibre1 pcalibre"/> in its advanced options, allowing for sophisticated manipulation and processing of audio and video files. This section delves deeper into these advanced features, providing insights into how they can be leveraged for complex tasks.</p>
<h3 class="calibre9">Using filters for enhanced video and audio manipulation</h3>
<p class="calibre3">FFmpeg comes equipped<a id="_idIndexMarker709" class="calibre6 pcalibre1 pcalibre"/> with an extensive range of filters<a id="_idIndexMarker710" class="calibre6 pcalibre1 pcalibre"/> for both video and audio. These can be applied to tasks such as cropping, rotating, adding watermarks, and adjusting brightness or contrast.</p>
<p class="calibre3">To apply filters, you can use the <code>-vf</code> (video filters) or <code>-af</code> (audio filters) option. Here is the schema of how the filter syntax would work:</p>
<pre class="source-code">
ffmpeg -i input.file -vf "[filter1],[filter2]" output.file</pre> <p class="calibre3">For example, imagine a scenario where you need to crop a video and adjust its color properties. You can do this by running the following command:</p>
<pre class="source-code">
ffmpeg -i input.mp4 -vf "crop=640:480:0:0, hue=h=60:s=1" -c:a copy output.mp4</pre> <p class="calibre3">Let’s take a closer look at the values of this command:</p>
<ul class="calibre15">
<li class="calibre14"><strong class="source-inline1">-i</strong>: Indicates that the next parameter is going to be the input file.</li>
<li class="calibre14"><strong class="source-inline1">input.mp4</strong>: This is the route to the input file.</li>
<li class="calibre14"><strong class="source-inline1">-vf</strong>: This stands for video filters, and allows you to apply one or more filters to the video stream.</li>
<li class="calibre14"><strong class="source-inline1">crop=640:480:0:0</strong>: This is the crop filter. It crops the video to a width of <strong class="source-inline1">640</strong> pixels and a height of <strong class="source-inline1">480</strong> pixels. The <strong class="source-inline1">0:0</strong> value at the end specifies the <em class="italic">x</em> and <em class="italic">y</em> coordinates of the top-left corner of the crop area. In this case, it’s set to the top-left corner of the original video. So, this filter effectively crops the video to a 640x480 rectangle starting from the top-left corner.</li>
<li class="calibre14"><strong class="source-inline1">hue=h=60:s=1</strong>: There are two parts to this code:<ul class="calibre16"><li class="calibre14"><strong class="source-inline1">h=60</strong> adjusts the hue of the video. Hue is a color component that allows us to shift colors on a 360-degree color wheel. A value of 60 shifts the colors by 60 degrees. For example, blue might become green, red might become yellow, and so on.</li><li class="calibre14"><strong class="source-inline1">s=1</strong> sets the saturation level. A saturation of <strong class="source-inline1">1</strong> means that the colors are left as-is in terms of intensity. Decreasing this value would desaturate the colors, leading to a more grayscale image.</li></ul></li>
<li class="calibre14"><strong class="source-inline1">-c:a</strong>: Resizes the video to full HD (1080p).</li>
<li class="calibre14"><strong class="source-inline1">output.mp4</strong>: Indicates the route to the output file.</li>
</ul>
<p class="calibre3">In summary, this FFmpeg<a id="_idIndexMarker711" class="calibre6 pcalibre1 pcalibre"/> command reads <code>input.mp4</code>, crops the video<a id="_idIndexMarker712" class="calibre6 pcalibre1 pcalibre"/> to a 640x480 resolution starting from the top-left corner, shifts the hue of the video colors by 60 degrees on the color wheel, maintains the original saturation, copies the audio without re-encoding, and saves all these changes in <code>output.mp4</code>.</p>
<h3 class="calibre9">Using an overlay video filter</h3>
<p class="calibre3">The overlay filter in FFmpeg<a id="_idIndexMarker713" class="calibre6 pcalibre1 pcalibre"/> is a versatile feature that allows users to superimpose one video or image over another. This is particularly useful for adding logos, watermarks, subtitles, picture-in-picture effects, or any additional visual elements to a video.</p>
<p class="calibre3">The overlay filter can be applied with the <code>-filter_complex</code> option in FFmpeg, which is used for more complex filtering that involves multiple input streams (such as combining two videos or adding an image to a video).</p>
<p class="calibre3">The basic syntax for the overlay filter is as follows:</p>
<pre class="source-code">
ffmpeg -i main_video.mp4 -i overlay.mp4 -filter_complex "overlay=x:y" output.mp4</pre> <p class="calibre3">Here, <code>main_video.mp4</code> is our primary video, and <code>overlay.mp4</code> is the video or image we want to overlay. The <code>x</code> and <code>y</code> values in the overlay filter specify the position of the overlay image/video on the main video.</p>
<p class="calibre3">As an example, let’s say we want to add a company logo to the bottom-right corner of a video. First, we must prepare the files. In this case, we have the following:</p>
<ul class="calibre15">
<li class="calibre14">The main video file will be <strong class="source-inline1">video.mp4</strong></li>
<li class="calibre14">The logo image will be <strong class="source-inline1">logo.png</strong> (preferably with a transparent background)</li>
</ul>
<p class="calibre3">Then, we will determine the logo’s position. The logo’s position will depend on the resolution of the main video. For example, if the video is 1920x1080 (full HD), and you want to place the logo 10 pixels from the bottom and right edges, the coordinates would be (x=1900, y=1060).</p>
<p class="calibre3">With this in mind, we will have to execute the following command:</p>
<pre class="source-code">
ffmpeg -i video.mp4 -i logo.png -filter_complex "overlay=1900:1060" -codec:a copy output.mp4</pre> <p class="calibre3">In this command, we have the following:</p>
<ul class="calibre15">
<li class="calibre14"><strong class="source-inline1">-i video.mp4</strong>: Specifies the main video file.</li>
<li class="calibre14"><strong class="source-inline1">-i logo.png</strong>: Specifies the overlay file (logo).</li>
<li class="calibre14"><strong class="source-inline1">-filter_complex "overlay=1900:1060"</strong>: Applies the overlay filter. The logo is positioned at (1900,1060), which is near the bottom-right corner.</li>
<li class="calibre14"><strong class="source-inline1">-codec:a copy</strong>: Copies the audio from the main video without re-encoding.</li>
<li class="calibre14"><strong class="source-inline1">output.mp4</strong>: The output file with the logo overlaid on the video.</li>
</ul>
<p class="calibre3">Is this all we can do with the overlay<a id="_idIndexMarker714" class="calibre6 pcalibre1 pcalibre"/> filter? No, there’s much more! For example, we can move this overlay dynamically.</p>
<h3 class="calibre9">Dynamic positioning with the overlay filter in FFmpeg</h3>
<p class="calibre3">The overlay filter in FFmpeg<a id="_idIndexMarker715" class="calibre6 pcalibre1 pcalibre"/> not only allows<a id="_idIndexMarker716" class="calibre6 pcalibre1 pcalibre"/> static placement of images or videos over a main video but also offers dynamic positioning capabilities. This advanced feature enables the overlay to move across the screen or change its appearance over time, adding a dynamic element to your videos.</p>
<p class="calibre3">First, let’s explore how to create the effect of moving an overlay across the screen. This technique is particularly effective for adding motion to logos, text, or other graphical elements.</p>
<p class="calibre3">Before we dive into the command, it’s important to understand how FFmpeg processes expressions for movement. These expressions allow the position of the overlay to change frame by frame, creating the illusion of motion.</p>
<p class="calibre3">The command for moving an overlay is as follows:</p>
<pre class="source-code">
ffmpeg -i main_video.mp4 -i logo.png -filter_complex "overlay=x='t*100':y=50" output.mp4</pre> <p class="calibre3">In this command, we have the following:</p>
<ul class="calibre15">
<li class="calibre14"><strong class="source-inline1">x='t*100'</strong>: The horizontal position (<strong class="source-inline1">x</strong>) of the overlay starts at 0 and increases by 100 pixels every second. The <strong class="source-inline1">t</strong> variable represents the current time in seconds.</li>
<li class="calibre14"><strong class="source-inline1">y=50</strong>: The vertical position (<strong class="source-inline1">y</strong>) is fixed at <strong class="source-inline1">50</strong> pixels from the top of the frame.</li>
</ul>
<p class="calibre3">We can play with these values to introduce different effects in our video overlay. For example, if we create a complete video editor, we could allow the users to move an element over the video and change its position during the video playback. Then, we could map those different positions<a id="_idIndexMarker717" class="calibre6 pcalibre1 pcalibre"/> to the seconds where we want it to be moved using FFmpeg. However, we won’t be doing<a id="_idIndexMarker718" class="calibre6 pcalibre1 pcalibre"/> this as it would take another book entirely!</p>
<p class="calibre3">If you are curious about this, here<a id="_idIndexMarker719" class="calibre6 pcalibre1 pcalibre"/> is the documentation for the <code>overlay</code> parameter: <a href="https://ffmpeg.org/ffmpeg-filters.html#overlay-1" class="calibre6 pcalibre1 pcalibre">https://ffmpeg.org/ffmpeg-filters.html#overlay-1</a>.</p>
<p class="calibre3">Another feature we can use is fade-in and fade-out effects, which we can apply to our overlay. Let’s see how it works.</p>
<h3 class="calibre9">Introducing the fade-in/out command</h3>
<p class="calibre3">To achieve a fade-in/out effect, we combine<a id="_idIndexMarker720" class="calibre6 pcalibre1 pcalibre"/> the overlay filter with the fade filter. Let’s break down the command to understand how it’s structured:</p>
<pre class="source-code">
ffmpeg -i main_video.mp4 -i logo.png -filter_complex "[1:v]fade=t=in:st=0:d=1,fade=t=out:st=3:d=1[logo];[0:v][logo]overlay=10:10" output.mp4</pre> <p class="calibre3">Let’s understand how this command is configured:</p>
<ul class="calibre15">
<li class="calibre14"><strong class="source-inline1">[1:v]fade=t=in:st=0:d=1</strong>: Applies a fade-in effect to the overlay, starting at <strong class="source-inline1">0</strong> seconds and lasting for <strong class="source-inline1">1</strong> second</li>
<li class="calibre14"><strong class="source-inline1">fade=t=out:st=3:d=1[logo]</strong>: Subsequently, a fade-out effect starts at <strong class="source-inline1">3</strong> seconds and also lasts for <strong class="source-inline1">1</strong> second</li>
<li class="calibre14"><strong class="source-inline1">overlay=10:10</strong>: The overlay is placed at the coordinates (10,10) on the main video</li>
</ul>
<p class="calibre3">But there is more that we can<a id="_idIndexMarker721" class="calibre6 pcalibre1 pcalibre"/> do with FFmpeg, apart from using exposed filters. Let’s see how we can use the <code>mobile-ffmpeg</code> library that we’ve already integrated into our project to improve the videos we are already recording.</p>
<h2 id="_idParaDest-135" class="calibre7"><a id="_idTextAnchor136" class="calibre6 pcalibre1 pcalibre"/>Using mobile-ffmpeg to execute FFmpeg commands</h2>
<p class="calibre3">With <code>mobile-ffmpeg</code> integrated, executing <a id="_idIndexMarker722" class="calibre6 pcalibre1 pcalibre"/>FFmpeg commands<a id="_idIndexMarker723" class="calibre6 pcalibre1 pcalibre"/> in Android becomes a streamlined process.</p>
<p class="calibre3">The library’s <code>FFmpeg.execute()</code> method is the gateway to running FFmpeg commands. For instance, a command such as <code>-i input.mp4 -c:v libx264 output.mp4</code>, which converts an input video so that it uses the H.264 codec, is seamlessly executed within the Android environment. This function mirrors the command-line syntax of FFmpeg, maintaining familiarity for those accustomed to FFmpeg’s command-line interface.</p>
<p class="calibre3">Here’s how it would work:</p>
<pre class="source-code">
val command = "-i input.mp4 -c:v libx264 output.mp4"
val returnCode = FFmpeg.execute(command)</pre> <p class="calibre3">In the previous code block, we are building a string with the <code>command</code> instruction and storing it in the <code>command</code> variable. Then, we are using the <code>FFmpeg.execute()</code> method to execute the command. Note that this execution will happen in the current thread, which could be undesirable performance-wise.</p>
<p class="calibre3">Managing performance<a id="_idIndexMarker724" class="calibre6 pcalibre1 pcalibre"/> and user experience<a id="_idIndexMarker725" class="calibre6 pcalibre1 pcalibre"/> is crucial in Android, especially for resource-intensive tasks such as video processing. <code>mobile-ffmpeg</code> accommodates this by offering asynchronous execution of commands. Utilizing <code>FFmpeg.executeAsync()</code> ensures that longer operations do not block the main thread, thus maintaining the application’s responsiveness. This method becomes instrumental when handling complex transformations or filters, such as scaling a video.</p>
<p class="calibre3">Here’s how we can use the <code>executeAsync</code> function:</p>
<pre class="source-code">
FFmpeg.executeAsync(command) { executionId, returnCode -&gt;
    when (returnCode) {
        Config.RETURN_CODE_SUCCESS -&gt; {
            // Processing was successful
        }
        Config.RETURN_CODE_CANCEL -&gt; {
            // Command execution was cancelled
        }
        else -&gt; {
            // Command execution failed
        }
    }
}</pre> <p class="calibre3">In this example, the <code>executeAsync()</code> method is called with the <code>FFmpeg</code> command in string format. This command is what we intend FFmpeg to execute, such as converting a video file, applying filters, or any other media processing task supported by FFmpeg. The execution of this command occurs in a separate thread, preventing any blocking of the main UI thread of the application.</p>
<p class="calibre3">When the command has finished executing, a Lambda function is triggered. This function is structured to receive two parameters: <code>executionId</code> and <code>returnCode</code>. The <code>executionId</code> parameter is a unique identifier for this particular execution instance of the <code>FFmpeg</code> command and can be useful for tracking or managing this specific operation, especially<a id="_idIndexMarker726" class="calibre6 pcalibre1 pcalibre"/> if our application handles<a id="_idIndexMarker727" class="calibre6 pcalibre1 pcalibre"/> multiple FFmpeg processes concurrently.</p>
<p class="calibre3">The <code>returnCode</code> parameter is crucial as it indicates the outcome of the executed <code>FFmpeg</code> command. The different return codes and their implications are as follows:</p>
<ul class="calibre15">
<li class="calibre14"><strong class="source-inline1">Config.RETURN_CODE_SUCCESS</strong>: This code signifies that the <strong class="source-inline1">FFmpeg</strong> command was executed successfully without any errors. In the corresponding block of the <strong class="source-inline1">when</strong> statement, you might want to implement functionality that deals with the successful completion of the media processing task. This could include updating the user interface, processing or displaying the output file, or triggering subsequent application logic.</li>
<li class="calibre14"><strong class="source-inline1">Config.RETURN_CODE_CANCEL</strong>: This return code indicates that the execution of the <strong class="source-inline1">FFmpeg</strong> command was canceled. This can occur if the execution is programmatically aborted or if certain external conditions pre-emptively stop the command. The handling code block for this return code could involve notifying the user of the cancellation, cleaning up resources, or setting the stage for a potential retry of the operation.</li>
<li class="calibre14"><strong class="source-inline1">else</strong>: This block catches all other cases, which generally suggests that an error occurred during the execution of the <strong class="source-inline1">FFmpeg</strong> command. Here, error-handling strategies come into play, such as logging the error for diagnostic purposes, informing the user of the failure, or attempting to retry the operation under certain conditions.</li>
</ul>
<p class="calibre3">To further refine the integration, <code>mobile-ffmpeg</code> allows us to handle progress and log outputs. This is essential for debugging and enhancing the user experience. Here’s how it works:</p>
<pre class="source-code">
FFmpeg.executeAsync(command, ExecuteCallback { executionId,
returnCode -&gt;
    // Handle execution result
}, LogCallback { logMessage -&gt;
    // Handle log message
}, StatisticsCallback { statistics -&gt;
    // Handle progress updates
})</pre> <p class="calibre3">Here, <code>LogCallback</code> complements the execution callback that we described before. FFmpeg is known for its verbose logging, providing a wealth of information about the ongoing operation. The <code>logMessage</code> parameter in this callback gives you access to these logs, enabling you to handle them as per your application’s needs. Whether it’s displaying these logs for debugging purposes, analyzing them for detailed error reporting, or simply directing them to a file for record-keeping, this callback plays a pivotal role in understanding and managing the intricacies of FFmpeg’s operations.</p>
<p class="calibre3">Last but not least, <code>StatisticsCallback</code> opens the door to real-time monitoring of the FFmpeg process. This callback, through the <code>statistics</code> parameter, provides live data, such as the frame currently being processed, elapsed time, and bitrate, among others. Utilizing this data can significantly enhance the user experience, enabling you to implement dynamic features such as progress bars, estimated-time-to-completion indicators, or even detailed<a id="_idIndexMarker728" class="calibre6 pcalibre1 pcalibre"/> reports of the ongoing<a id="_idIndexMarker729" class="calibre6 pcalibre1 pcalibre"/> operation’s status.</p>
<p class="calibre3">Now that we know how to execute our FFmpeg commands in Android, let’s build something. We will start by adding a caption to the video.</p>
<h1 id="_idParaDest-136" class="calibre5"><a id="_idTextAnchor137" class="calibre6 pcalibre1 pcalibre"/>Adding a caption to the video with FFmpeg</h1>
<p class="calibre3">In this section, we will create<a id="_idIndexMarker730" class="calibre6 pcalibre1 pcalibre"/> all the components we’ll need<a id="_idIndexMarker731" class="calibre6 pcalibre1 pcalibre"/> to add a caption to a video using FFmpeg. We’ll start this new feature by creating a use case where the business logic of adding the caption to the video will be defined. We will call it <code>AddCaptionToVideoUseCase</code>, and its responsibility will be to add the caption to the video and return the new video file once it has been added.</p>
<p class="calibre3">This is how<a id="_idIndexMarker732" class="calibre6 pcalibre1 pcalibre"/> we can <a id="_idIndexMarker733" class="calibre6 pcalibre1 pcalibre"/>build <code>AddCaptionToVideoUseCase</code>:</p>
<pre class="source-code">
class AddCaptionToVideoUseCase() {
    suspend fun addCaption(videoFile: File, captionText:
    String): Result&lt;File&gt; = withContext(Dispatchers.IO) {
        val outputFile = File(
            videoFile.parent,
                "${videoFile.nameWithoutExtension}
                    _captioned.mp4")
        val fontFilePath =
            "/system/fonts/Roboto-Regular.ttf"
        val ffmpegCommand = arrayOf(
            "-i", videoFile.absolutePath,
            "-vf", "drawtext=fontfile=$fontFilePath:
                text='$captionText':
                    fontcolor=white:
                        fontsize=24:x=(w-text_w)/2:
                            y=(h-text_h)-10",
            "-c:a", "aac",
            "-b:a", "192k",
            outputFile.absolutePath
        )
        try {
            val executionId =
            FFmpeg.executeAsync(ffmpegCommand)
            { _, returnCode -&gt;
                if (returnCode !=
                Config.RETURN_CODE_SUCCESS) {
                    Result.failure&lt;AddCaptionToVideoError&gt;(
                        AddCaptionToVideoError)
                }
            }
            // Optionally handle the executionId, e.g., for
               cancellation
            Result.success(outputFile)
        } catch (e: Exception) {
            Result.failure(e)
        }
    }
}
object AddCaptionToVideoError: Throwable("There was an
error adding the caption to the video") {
    private fun readResolve(): Any = AddCaptionToVideoError
}</pre> <p class="calibre3">In the preceding code, we start by creating a suspend function, <code>addCaption</code>, which is specifically designed to facilitate asynchronous execution via coroutines. As the action of adding a caption involves intensive tasks such as video processing, we should avoid executing this kind of logic in the main thread to prevent any lag or unresponsiveness in the application. The function takes two parameters: a <code>File</code> object representing the video file and a <code>String</code> containing the caption text to be added.</p>
<p class="calibre3">Inside the <code>addCaption</code> function, the execution context is switched to the I/O dispatcher. This is done to optimize for I/O operations, ensuring that the file processing workload is handled appropriately without straining the main thread. The function proceeds to create an <code>outputFile</code> object. This object represents the new video file that will be generated post-captioning.</p>
<p class="calibre3">The next segment<a id="_idIndexMarker734" class="calibre6 pcalibre1 pcalibre"/> in the function involves constructing a command<a id="_idIndexMarker735" class="calibre6 pcalibre1 pcalibre"/> string for FFmpeg. This command is carefully crafted to utilize FFmpeg’s <code>drawtext</code> filter, enabling the provided caption text to be overlaid on the video. Let’s analyze the command that we used in the previous code block:</p>
<pre class="source-code">
val command = "-i ${videoFile.absolutePath} -vf drawtext=text='$captionText':fontcolor=white:fontsize=24:x=(w-text_w)/2:y=(h-text_h)/2 -codec:a copy ${outputFile.absolutePath}"</pre> <p class="calibre3">Let’s break this command down:</p>
<ul class="calibre15">
<li class="calibre14"><strong class="source-inline1">-i ${videoFile.absolutePath}</strong>: This part of the command specifies the input file for FFmpeg to process. The <strong class="source-inline1">-i</strong> flag is used for input files in FFmpeg and <strong class="source-inline1">${videoFile.absolutePath}</strong> dynamically inserts the absolute path of the video file you’re processing.</li>
<li class="calibre14"><strong class="source-inline1">-vf drawtext=text='$captionText':...</strong>: The <strong class="source-inline1">-vf</strong> (video filter) flag is used to apply filters to the video. Here, the <strong class="source-inline1">drawtext</strong> filter is used to add text to the video.</li>
<li class="calibre14"><strong class="source-inline1">text='$captionText'</strong>: This specifies the text to be drawn. Here, <strong class="source-inline1">$captionText</strong> is the variable holding the caption text, which is dynamically inserted into the command.</li>
<li class="calibre14"><strong class="source-inline1">fontcolor=white</strong>: Sets the font color of the text to white.</li>
<li class="calibre14"><strong class="source-inline1">fontsize=24</strong>: Defines the size of the font used for the text.</li>
<li class="calibre14"><strong class="source-inline1">x=(w-text_w)/2</strong>: This sets the horizontal position of the text. Here, <strong class="source-inline1">w</strong> represents the width of the video, and <strong class="source-inline1">text_w</strong> is the width of the text. By setting <strong class="source-inline1">x to (w-text_w)/2</strong>, the text is horizontally centered.</li>
<li class="calibre14"><strong class="source-inline1">y=(h-text_h)/2</strong>: Similarly, this sets the vertical position of the text. Here, <strong class="source-inline1">h</strong> is the height of the video, and <strong class="source-inline1">text_h</strong> is the height of the text. This formula vertically centers the text within the video.</li>
<li class="calibre14"><strong class="source-inline1">-codec:a acc</strong>: This part of the command instructs FFmpeg to use <strong class="source-inline1">acc</strong> as the codec for audio streaming.</li>
<li class="calibre14"><strong class="source-inline1">-b:a=192k</strong>: This part of the command sets the bitrate to 192k.</li>
<li class="calibre14"><strong class="source-inline1">${outputFile.absolutePath}</strong>: The last part of the command specifies the output file’s path, where the processed video (with the caption added) will be saved.</li>
</ul>
<p class="calibre3">Executing this FFmpeg command is handled asynchronously with <code>FFmpeg.executeAsync()</code>. This method is pivotal for running the command in a non-blocking manner and is accompanied by a Lambda function for handling the execution result. The Lambda function evaluates <code>returnCode</code> from the FFmpeg execution. In the case of a non-successful execution (indicated by any return code other than <code>RETURN_CODE_SUCCESS</code>), the function constructs <code>Result.failure</code>, wrapping a custom <code>AddCaptionToVideoError</code> object. This custom error object, defined as a singleton, provides a specific error message indicating an issue with the captioning process.</p>
<p class="calibre3">On the flip side, successful command<a id="_idIndexMarker736" class="calibre6 pcalibre1 pcalibre"/> execution results in <code>Result.success</code>, passing<a id="_idIndexMarker737" class="calibre6 pcalibre1 pcalibre"/> along <code>outputFile</code>. This bifurcation in handling success and failure scenarios ensures robust error management and clear feedback regarding the outcome of the captioning process.</p>
<p class="calibre3">Now, we can use <code>AddCaptionToVideoUseCase</code> in <code>StoryEditorViewModel</code>:</p>
<pre class="source-code">
class StoryEditorViewModel(
    private val saveCaptureUseCase: SaveCaptureUseCase,
    private val addCaptionToVideoUseCase:
    AddCaptionToVideoUseCase
): ViewModel() {
  // Other variables we defined for the photo feature
    var videoFile: File? = null
  // Other code we already added for the photo feature
    fun addCaptionToVideo(captionText: String) {
        videoFile?.let { file -&gt;
            viewModelScope.launch {
                val result =
                    addCaptionToVideoUseCase.addCaption(
                        file, captionText)
                // Handle the result of the captioning
                   process
            }
        }
    }
}</pre> <p class="calibre3">We start by injecting <code>AddCaptionToVideoUseCase</code> into <code>StoryEditorViewModel</code> using<a id="_idIndexMarker738" class="calibre6 pcalibre1 pcalibre"/> its constructor. Then, we declare<a id="_idIndexMarker739" class="calibre6 pcalibre1 pcalibre"/> a <code>videoFile</code> variable in <code>ViewModel</code>, which holds the video we’re working with – it’s nullable because there might be times when we don’t have a video to display or edit. In <code>videoFile</code>, we should have stored the view we have already recorded.</p>
<p class="calibre3">Next, the core function in this <code>ViewModel</code> is <code>addCaptionToVideo</code>. This function takes the caption text as input and uses the video file we have. First, it checks if <code>videoFile</code> isn’t <code>null</code>. If we have a video, it proceeds; if not, nothing happens.</p>
<p class="calibre3">Inside <code>addCaptionToVideo</code>, by launching a coroutine within <code>viewModelScope</code>, we ensure that our caption-adding process doesn’t freeze the UI. This is crucial for maintaining a smooth user experience.</p>
<p class="calibre3">The <code>addCaption</code> method of our use case is then called with the video file and caption text. Whatever comes back from this operation – success or failure – is stored in the result.</p>
<p class="calibre3">The <code>// Handle the result of the captioning process</code> comment is where you’d put our code to update the UI based on the result. This could mean displaying the captioned video, showing an error message, or whatever else makes sense for our app. For simplicity, we won’t be adding it here just yet, but we will learn more about video playback in the last three chapters of this book when we create a Netflix-esque app.</p>
<p class="calibre3">But we can still test the effect<a id="_idIndexMarker740" class="calibre6 pcalibre1 pcalibre"/> in our video. We just have to look at the internal app<a id="_idIndexMarker741" class="calibre6 pcalibre1 pcalibre"/> files using Device Explorer in Android Studio. There, we’ll see two files – one of the original video, and the other a modified one with the <code>_captioned</code> suffix:</p>
<div><div><img alt="Figure 6.3: Device Explorer with video files in Android Studio" src="img/B19443_06_03.jpg" class="calibre4"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 6.3: Device Explorer with video files in Android Studio</p>
<p class="calibre3">If we download the captioned<a id="_idIndexMarker742" class="calibre6 pcalibre1 pcalibre"/> file video and play it, we should see that a caption<a id="_idIndexMarker743" class="calibre6 pcalibre1 pcalibre"/> has been added to the video:</p>
<div><div><img alt="Figure 6.4: A video with caption text stating, “This is the caption text”" src="img/B19443_06_04.jpg" class="calibre4"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 6.4: A video with caption text stating, “This is the caption text”</p>
<p class="calibre3">Now that we know how to apply a caption to our video, let’s see how we can apply a filter.</p>
<h1 id="_idParaDest-137" class="calibre5"><a id="_idTextAnchor138" class="calibre6 pcalibre1 pcalibre"/>Adding a filter to a video with FFmpeg</h1>
<p class="calibre3">In this section, we will learn<a id="_idIndexMarker744" class="calibre6 pcalibre1 pcalibre"/> how to add a filter<a id="_idIndexMarker745" class="calibre6 pcalibre1 pcalibre"/> to our video. A popular filter that is visually impactful is the “vignette” effect – this effect typically darkens the edges of the frame, drawing the viewer’s attention toward the center of the image or video, and can add a dramatic or cinematic quality to the footage. FFmpeg has the capability to apply this artistic filter to videos, so let’s try it out!</p>
<p class="calibre3">As we did with the caption, we will start by creating the use case: <code>AddVignetteEffectUseCase</code>. The primary role of <code>AddVignetteEffectUseCase</code> is to execute the business logic for applying the vignette effect to a given video file by using <code>mobile-ffmpeg</code>. We will use a specific <code>FFmpeg</code> command, as follows:</p>
<pre class="source-code">
class AddVignetteEffectUseCase() {
    suspend fun addVignetteEffect(videoFile: File):
    Result&lt;File&gt; = withContext(Dispatchers.IO) {
        val outputFile = File(videoFile.parent,
            "${videoFile.nameWithoutExtension}
                _vignetted.mp4")
        val command = "-i ${videoFile.absolutePath} -vf
            vignette=angle=PI/4 ${outputFile.absolutePath}"
        try {
            val executionId = FFmpeg.executeAsync(command)
            { _, returnCode -&gt;
                if (returnCode !=
                Config.RETURN_CODE_SUCCESS) {
                    Result.failure&lt;AddVignetteEffectError&gt;(
                        AddVignetteEffectError)
                }
            }
            // Optionally handle the executionId, e.g., for
               cancellation
            Result.success(outputFile)
        } catch (e: Exception) {
            Result.failure(e)
        }
    }
}
object AddVignetteEffectError : Throwable("There was an
error adding the vignette effect to the video") {
    private fun readResolve(): Any = AddVignetteEffectError
}</pre> <p class="calibre3">Let’s walk through <a id="_idIndexMarker746" class="calibre6 pcalibre1 pcalibre"/>the code in <code>AddVignetteEffectUseCase</code>. Here, <code>addVignetteEffect</code> is a suspend<a id="_idIndexMarker747" class="calibre6 pcalibre1 pcalibre"/> function, meaning it’s designed to run asynchronously with Kotlin’s coroutines. In this function, we take the video file that needs the vignette effect and start by defining where to save the processed video. We keep the original video intact and create a new file for the output. The output’s filename keeps the original name but with <code>_vignetted</code> added to it so that it’s easy to track.</p>
<p class="calibre3">Next up, we build our FFmpeg command. This command tells FFmpeg to apply the vignette effect. Let’s see how this command (already present in the previous code block) works in detail:</p>
<pre class="source-code">
val command = "-i ${videoFile.absolutePath} -vf vignette=angle=PI/4 ${outputFile.absolutePath}"</pre> <p class="calibre3">This command is composed of the following segments:</p>
<ul class="calibre15">
<li class="calibre14"><strong class="source-inline1">-i ${videoFile.absolutePath}</strong>: This part of the command specifies the input file for FFmpeg to process. The <strong class="source-inline1">-i</strong> flag is used for input files in FFmpeg and <strong class="source-inline1">${videoFile.absolutePath}</strong> dynamically inserts the absolute path of the video file you want to process. In simple terms, it tells FFmpeg, “Here’s the video I want you to work on.”</li>
<li class="calibre14"><strong class="source-inline1">-vf vignette=angle=PI/4</strong>: This segment is where the vignette effect is applied.</li>
<li class="calibre14"><strong class="source-inline1">-vf</strong> stands for video filters and is a powerful feature in FFmpeg that allows you to apply various transformations or effects to your video.</li>
<li class="calibre14"><strong class="source-inline1">vignette=angle=PI/4</strong>: This is the specific filter and setting for the vignette effect. The vignette filter in FFmpeg is used to apply the vignette effect, which typically darkens the edges of the video to focus attention on the center. The <strong class="source-inline1">angle=PI/4</strong> part is a parameter of the vignette filter that controls the angle of the effect. This specific setting, <strong class="source-inline1">PI/4</strong>, is chosen to give a visually pleasing vignette. It’s a bit of a creative choice, balancing subtlety and impact.</li>
<li class="calibre14"><strong class="source-inline1">${outputFile.absolutePath}</strong>: The last part of the command specifies where to save the processed video. It takes the path where you want the new video (with the vignette effect applied) to be saved. By placing it here in the command, you’re telling FFmpeg, “Once you’re done adding the effect, save the new video here.”</li>
</ul>
<p class="calibre3">When it comes to running<a id="_idIndexMarker748" class="calibre6 pcalibre1 pcalibre"/> this command, we<a id="_idIndexMarker749" class="calibre6 pcalibre1 pcalibre"/> use <code>FFmpeg.executeAsync</code>. This method is great because it runs our command without blocking the app. The method also has a way to check if everything went as planned. If the command runs successfully, we return the path of our new vignette video. But if something goes wrong, we catch it and return an error. Here, <code>AddVignetteEffectError</code> is a custom error message we throw if the FFmpeg command doesn’t execute properly. It’s a simple way to know exactly what went wrong when we add<a id="_idIndexMarker750" class="calibre6 pcalibre1 pcalibre"/> our vignette<a id="_idIndexMarker751" class="calibre6 pcalibre1 pcalibre"/> effect. And with this, <code>AddVignetteUseCase</code> is ready.</p>
<p class="calibre3">Now, we can integrate this use case into <code>StoryEditorViewModel</code>:</p>
<pre class="source-code">
class StoryEditorViewModel(
    private val saveCaptureUseCase: SaveCaptureUseCase,
    private val addCaptionToVideoUseCase:
        AddCaptionToVideoUseCase,
    private val addVignetteEffectUseCase:
        AddVignetteEffectUseCase
): ViewModel() {
...
    var videoFile: File? = null
...
    fun addVignetteFilterToVideo() {
        videoFile?.let { file -&gt;
            viewModelScope.launch {
                val result =
                    addVignetteEffectUseCase
                        .addVignetteEffect(file)
                // Handle the result of the filter process
            }
        }
    }
}</pre> <p class="calibre3">Here, <code>StoryEditorViewModel</code> is structured to receive <code>AddVignetteEffectUseCase</code> as a dependency.</p>
<p class="calibre3">Within this ViewModel, we maintain a <code>videoFile</code> property, which holds a reference to the video file that the vignette effect will be applied to. The nullable nature of this property allows for scenarios where a video file may not be immediately available.</p>
<p class="calibre3">The function to execute this functionality is <code>addVignetteEffectToVideo</code>. When invoked, this function checks whether <code>videoFile</code> is not null, ensuring that there is a valid file to process. If a video file is available, the function proceeds to launch a coroutine within <code>viewModelScope</code>.</p>
<p class="calibre3">Inside the coroutine, the <code>addVignetteEffectUseCase.addVignetteEffect</code> method is called<a id="_idIndexMarker752" class="calibre6 pcalibre1 pcalibre"/> with the video file<a id="_idIndexMarker753" class="calibre6 pcalibre1 pcalibre"/> as its argument. This is where the vignette effect is applied to the video. The result of this operation is captured in a variable named <code>result</code>. This result could indicate either a successful application of the effect or a failure due to some error.</p>
<p class="calibre3">The commented section within the function, <code>// Handle the result of the vignette effect process</code>, is where we would typically handle the outcome of the operation. Depending on whether the vignette effect was successfully applied or not, this section could include code for updating the UI to display the processed video or handling any errors that might have occurred during the process.</p>
<p class="calibre3">As we mentioned when we discussed adding captions, we haven’t implemented video playback yet, but we can still test the effect in our video. Just like back in <em class="italic">Figure 6</em><em class="italic">.3</em>, we can see two files, but this time one of them has a <code>_vignetted</code> suffix to indicate it has been modified:</p>
<div><div><img alt="Figure 6.5: Device Explorer in Android Studio" src="img/B19443_06_05.jpg" class="calibre4"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 6.5: Device Explorer in Android Studio</p>
<p class="calibre3">We can download<a id="_idIndexMarker754" class="calibre6 pcalibre1 pcalibre"/> and reproduce both videos<a id="_idIndexMarker755" class="calibre6 pcalibre1 pcalibre"/> to check and test the filter:</p>
<div><div><img alt="Figure 6.6: Video without (left) and with (right) the vignette filter effect applied" src="img/B19443_06_06.jpg" class="calibre4"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 6.6: Video without (left) and with (right) the vignette filter effect applied</p>
<p class="calibre3">Now that we know<a id="_idIndexMarker756" class="calibre6 pcalibre1 pcalibre"/> how to integrate FFmpeg<a id="_idIndexMarker757" class="calibre6 pcalibre1 pcalibre"/> and use its commands to edit the user’s videos, it is time to upload those videos so that they can be shared between their contacts.</p>
<h1 id="_idParaDest-138" class="calibre5"><a id="_idTextAnchor139" class="calibre6 pcalibre1 pcalibre"/>Uploading the video</h1>
<p class="calibre3">Now that our video<a id="_idIndexMarker758" class="calibre6 pcalibre1 pcalibre"/> is ready, it’s time to upload it to any service, from where it can be shared with the user contacts. We’re going to use Firebase Storage for this (to learn how to set up Firebase Storage, please refer to <a href="B19443_03.xhtml#_idTextAnchor060" class="calibre6 pcalibre1 pcalibre"><em class="italic">Chapter 3</em></a>).</p>
<p class="calibre3">We’ll start by creating a data source that will be responsible for uploading the video to Firebase Storage. We will call it <code>VideoStorageDataSource</code>:</p>
<pre class="source-code">
class VideoStorageDataSource {
    fun uploadVideo(videoFile: File, onSuccess: (String) -&gt;
    Unit, onError: (Exception) -&gt; Unit) {
        val storageReference =
            FirebaseStorage.getInstance().reference
        val videoRef = storageReference.child(
            "videos/${videoFile.name}")
        val uploadTask =
            videoRef.putFile(Uri.fromFile(videoFile))
        uploadTask.addOnSuccessListener {
        videoRef.downloadUrl.addOnSuccessListener { uri -&gt;
            onSuccess(uri.toString())
        }
        }.addOnFailureListener { exception -&gt;
            onError(exception)
        }
    }
}</pre> <p class="calibre3">Inside the <code>uploadVideo</code> function, we start indicating that we’ll execute the logic in the I/O dispatcher.</p>
<p class="calibre3">Then, the heart of the function<a id="_idIndexMarker759" class="calibre6 pcalibre1 pcalibre"/> is where we use Firebase Storage. First, we obtain the reference of the storage using <code>FirebaseStorage.getInstance().reference</code>, after which we set up a reference to where we want our video to be stored in Firebase using <code>storageReference.child("videos/${videoFile.name}")</code>.</p>
<p class="calibre3">Next, we start the upload itself. The <code>putFile</code> method is used to upload the video file. This is where <code>await()</code> comes into play. This <code>await()</code> is a suspending function that patiently waits for the upload to complete without blocking the thread. It’s part of Kotlin’s coroutines magic and is a game-changer for async operations.</p>
<p class="calibre3">Once the upload is done, we need to grab the URL of our video. So, we call <code>downloadUrl.await()</code>. Just like with the upload, <code>await()</code>suspends the operation until Firebase gives us the video’s URL.</p>
<p class="calibre3">We’ve also got our error handling covered. The upload and URL retrieval process is wrapped in a <code>try-catch</code> block. If anything goes sideways during the upload or while fetching the URL, we catch the exception and wrap it up in <code>Result.failure(e)</code>. On the other hand, if all goes well, we return <code>Result.success(downloadUrl.toString())</code>, handing over the URL of the newly uploaded video.</p>
<p class="calibre3">Next, we will implement the repository that will be responsible for managing and connecting the data sources to the domain layer. We will call its interface <code>VideoRepository</code> and the implementation <code>VideoRepositoryImpl</code>:</p>
<pre class="source-code">
interface VideoRepository {
    suspend fun uploadVideo(videoFile: File):
        Result&lt;String&gt;
}
class VideoRepositoryImpl(private val
videoStorageDataSource: VideoStorageDataSource) :
VideoRepository {
    override suspend fun uploadVideo(videoFile: File):
    Result&lt;String&gt; {
        return try {
            var uploadResult: Result&lt;String&gt; =
                Result.failure(RuntimeException("Upload
                    failed"))
            firebaseStorageDataSource.uploadVideo(
            videoFile, { url -&gt;
                uploadResult = Result.success(url)
            }, { exception -&gt;
                uploadResult = Result.failure(exception)
            })
            uploadResult
        } catch (e: Exception) {
            Result.failure(e)
        }
    }
}</pre> <p class="calibre3">First up, we have our <code>VideoRepository</code> interface. This is a straightforward Kotlin interface with one key function: <code>uploadVideo</code>.</p>
<p class="calibre3">Next, we have the <code>VideoRepositoryImpl</code> class, which implements<a id="_idIndexMarker760" class="calibre6 pcalibre1 pcalibre"/> the <code>VideoRepository</code> interface. This class is where the action happens. It’s initialized with an instance of <code>VideoStorageDataSource</code>.</p>
<p class="calibre3">Then, the <code>uploadVideo</code> function follows a <code>try-catch</code> pattern for robust error handling. Initially, it sets up a default <code>uploadResult</code> as a failure. This is a cautious approach, assuming things might go wrong, and we’ll update this only if the upload succeeds.</p>
<p class="calibre3">Then, we call <code>uploadVideo</code> on <code>videoStorageDataSource</code>, passing the video file along with two Lambda functions for handling success and failure. If the upload is successful, the success Lambda updates <code>uploadResult</code> with the URL of the uploaded video. If there’s a failure, the failure Lambda updates <code>uploadResult</code> with the encountered exception.</p>
<p class="calibre3">Finally, we return <code>uploadResult</code>. If all goes well, we’ll see the URL<a id="_idIndexMarker761" class="calibre6 pcalibre1 pcalibre"/> of the uploaded video. If not, we’ll see the error that occurred during the process. The <code>try-catch</code> block ensures that if there’s an unexpected exception anywhere in this process, we catch it and return it as a failure.</p>
<p class="calibre3">Now, it’s time for us to implement <code>UploadVideoUseCase</code>:</p>
<pre class="source-code">
class UploadVideoUseCase(private val videoRepository:
VideoRepository) {
    suspend fun uploadVideo(videoFile: File):
    Result&lt;String&gt; {
        return videoRepository.uploadVideo(videoFile)
    }
}</pre> <p class="calibre3">Here, we are injecting <code>VideoRepository</code>. In the <code>uploadVideo</code> function, we call <code>videoRepository</code> and pass <code>videoFile</code> as a parameter.</p>
<p class="calibre3">Finally, we will include <code>UploadVideoUseCase</code> in <code>StoryEditorViewModel</code> and use it from there:</p>
<pre class="source-code">
class StoryEditorViewModel(
private val saveCaptureUseCase: SaveCaptureUseCase,
private val addCaptionToVideoUseCase:
    AddCaptionToVideoUseCase,
private val addVignetteEffectUseCase:
    AddVignetteEffectUseCase,
private val uploadVideoUseCase: UploadVideoUseCase
) : ViewModel() {
...
    fun uploadVideo(videoFile: File) {
        viewModelScope.launch {
            val result =
                uploadVideoUseCase.uploadVideo(videoFile)
            // Handle the result of the upload process
        }
    }
}</pre> <p class="calibre3">In <code>StoryEditorViewModel</code>, we add a function called <code>uploadVideo</code> that takes the video file and uses <code>uploadVideoUseCase</code> to upload it. The operation is performed within a coroutine to ensure it doesn’t block the UI thread.</p>
<p class="calibre3">The <code>// Handle the result of the upload process</code> comment is where we would implement the logic based on the outcome of the upload. If the upload is successful, we might update the UI to show that the video has been uploaded or display the video URL. In case of failure, we would handle the error, perhaps by showing an error message to the user.</p>
<p class="calibre3">And with this change, we are ready to upload<a id="_idIndexMarker762" class="calibre6 pcalibre1 pcalibre"/> the video from our ViewModel. By doing this, we have completed this chapter, as well as our work on Packtagram!</p>
<h1 id="_idParaDest-139" class="calibre5"><a id="_idTextAnchor140" class="calibre6 pcalibre1 pcalibre"/>Summary</h1>
<p class="calibre3">Wrapping up this chapter, you’ve significantly leveled up your Packtagram app’s video capabilities.</p>
<p class="calibre3">Starting with CameraX, we expanded its use from snapping photos to capturing high-quality videos, but this was just the beginning. Then, we dived into FFmpeg, an incredibly versatile tool for video editing. Here, you learned how to add a creative touch to videos, be it through captions that tell a story or filters that change the entire look and feel.</p>
<p class="calibre3">But what’s a great video if it can’t be shared? We tackled that too by integrating Firebase Storage for seamless video uploads. This means your app is now adept at handling large files smoothly, ensuring users enjoy a hiccup-free experience.</p>
<p class="calibre3">With this chapter, we have finished our work on Packtagram. Now, it’s time to learn about the project that will be implemented in the last three chapters: a video playback app so that you can view your favorite series and films!</p>
</div>
</body></html>