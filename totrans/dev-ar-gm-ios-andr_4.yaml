- en: Chapter 4. Trackables and Tracking
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Trackables are an integral part of an AR experience. It is the foundation on
    which the whole world we are building literally rests. We can have the best AR
    content in the world, but if the trackable is not suitable, the experience will
    degrade considerably. In this chapter we will try to understand the details of
    how to create and use suitable trackables. We will also explore how to modify
    a trackable to increase its trackability in the app.
  prefs: []
  type: TYPE_NORMAL
- en: What are trackables for image targets?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Trackables are a collection of features that the AR app can track. This can
    be anything from the traditional QR code, where a collection of black and white
    binary code determines the object detected, to the image targets we experienced
    in the previous chapter where the trackable is just an image.
  prefs: []
  type: TYPE_NORMAL
- en: For image targets, only the natural features of the image itself is used as
    a way of detecting the image in the real, and its perspective to calculate where
    the AR camera should be. Natural features are analyzed, stored in a database,
    and then used to compare with the camera input feed. This naturally makes how
    effectively the image can be tracked, based on its features.
  prefs: []
  type: TYPE_NORMAL
- en: Creating image targets
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The process is made simple using Vuforia's **Target Manager**. The target manager
    is an online tool provided by Qualcomm that automatically analyzes and creates
    image target databases to be deployed in apps. It can also manage multiple datasets
    with multiple targets.
  prefs: []
  type: TYPE_NORMAL
- en: 'To reach this target manager, simply go to the following URL: [https://developer.vuforia.com/target-manager](https://developer.vuforia.com/target-manager).'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following screenshot shows **Target Manager**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Creating image targets](img/0032_4_1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: You should be greeted with a view similar to the one above. This is the target
    manager—the tool that we will use to create all of our targets and maintain them.
    The target manager can be used for both local target datasets and cloud-based
    ones. In this book, we will focus on **Device Databases**.
  prefs: []
  type: TYPE_NORMAL
- en: 'To start, let''s create a database that we will use to see how the process
    of creating targets works. Click on the **Create Database** button and name the
    database Chapter 4\. The following image shows a created dataset in **Target Manager**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Creating image targets](img/0032_4_2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Now we have a dataset. Currently our dataset is empty, but we can add multiple
    image targets to a dataset for the AR app to track all of them. We can even create
    multiple datasets in this view, each with its own set of targets.
  prefs: []
  type: TYPE_NORMAL
- en: Now what we need to do is to create our first image target. First, we will use
    the stones image from Vuforia's sample project we did earlier. It will give us
    an idea of how the image targets for the sample project were created.
  prefs: []
  type: TYPE_NORMAL
- en: 'Click on the database to open it. We will find an add a target button on the
    right; click on it. The following image shows target creation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Creating image targets](img/0032_4_3.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The parameters for creating a target are very simple. For the name, we will
    pick Stones, like it was in the sample app. For target type, we will leave it
    at Single Image. The other two types are used for MultiTarget prefab in Vuforia
    for detecting 3D objects in the world.
  prefs: []
  type: TYPE_NORMAL
- en: The last parameter, Target Dimension, is an important parameter. This number
    is the representation of the image target in the scene. It governs how objects
    that appear on top of it are scaled, and how much space it occupies of the virtual
    space in the scene. That said, it is a value easily ignorable in Unity 3D environment.
    This is due to the scaling property that is easily editable in Unity. This value
    is very important in OpenGL environment however. For now, we can leave it at 5
    units. This is a 5 units distance in the Unity 3D scene.
  prefs: []
  type: TYPE_NORMAL
- en: 'Click on the **Add** button, and let the image be uploaded. The target will
    have processing tag on it; processing takes a few minutes to happen. Give it some
    time, and then click on the target to see its details window. The following image
    shows Stones target details window:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Creating image targets](img/0032_4_4.jpg)'
  prefs: []
  type: TYPE_IMG
- en: This is the details window of the target we just added to the database. To the
    right, we will find all the details about the target. It starts with a unique
    ID of the target across all databases, cloud-based and local. This is useful for
    global identification of the target.
  prefs: []
  type: TYPE_NORMAL
- en: Below the **Target ID**, we will find the augmentable score. This is the most
    important feature of the target. It demonstrates how well the target can be tracked
    in the app. This target has 5 stars out of 5; this is because the features in
    image are great for tracking.
  prefs: []
  type: TYPE_NORMAL
- en: Trackable score
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Several factors affect the trackable score, but first we need to understand
    how the score affects the trackability for the image.
  prefs: []
  type: TYPE_NORMAL
- en: 'The augmentable score is based on 5 stars. It represents augmentability as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Between 4 to 5 stars**: The trackable is very suitable for AR apps. It can
    handle part of the image to be occluded, and still the app will be able to track
    it. It can also be tracked in low light and other environment noise.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Between 2 to 3 stars**: The trackable is augmentable. It will work fine under
    ideal conditions. It may not be very good with part of the images occluded. This
    is the least score to aim for that will not affect the user''s experience.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**1 star**: This is the bare minimum score for trackability. It means that
    the image will be recognizable by the app, but the experience will be affected.
    Avoid attaining this score at all costs.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**0 stars**: The image is not suitable for trackability at all; there are not
    enough recognizable features in the image for the app to recognize. This image
    will not be recognized at all by the app.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In situations where the content of the trackable is restricted, and we know
    that the usage conditions will be idle in good lighting with no occlusion, we
    can aim for 2 to 3 stars. Otherwise, it is preferable to get 4 to 5 stars for
    optimal usage by the user. Anything below 2 stars should be avoided completely.
  prefs: []
  type: TYPE_NORMAL
- en: What decides trackable score?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Trackables are the foundation of the AR experience using Vuforia. It is paramount
    to understand and create a suitable trackable for the experience to be robust
    and useful. The score attributed to the trackable in the target manager is our
    indication of how robust the target image is going to perform, but what decides
    that score?
  prefs: []
  type: TYPE_NORMAL
- en: The best way of understanding this, is by understanding how Vuforia tracks the
    images. The idea is simple; it looks for position of contrasting edges in clusters
    all around the image. Those edges are tracked, and based on the map of positions
    that are stored in the dataset, Vuforia can tell the relative position of the
    trackable in the real world, and accordingly render the 3D content on top of it.
    This particularly means that tracking the image is not a function of its color
    or what really is in it, as much as how many contrasting edges are there in the
    image, and how well they are distributed on the image.
  prefs: []
  type: TYPE_NORMAL
- en: 'To better understand this, we can look on the current edges that are recognizable
    in the image we have just uploaded. To do that, simply click on the **Show Features**
    link on the top left of the webpage. The following image shows features in image
    target stones:'
  prefs: []
  type: TYPE_NORMAL
- en: '![What decides trackable score?](img/0032_4_5.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Once the **Show Features** link has been clicked, the image target manager layers
    over the target image an overlay of where it detects a recognizable edge that
    it can track in a Vuforia image target. Notice that it is only tracking the dark
    edges between the `Stones` and nothing else in the image. It is even tracking
    only the high contrast edges between the `Stones`, while ignoring some of the
    lighter ones.
  prefs: []
  type: TYPE_NORMAL
- en: Also notice that the number of edges found in the image is large, and evenly
    distributed all around the image. This is a great factor in what made this image
    suitable for tracking.
  prefs: []
  type: TYPE_NORMAL
- en: 'To contrast this image''s result, lets try an image that will yield a 1-star
    score when tried on the target manager. The following image shows landscape image
    added to target image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![What decides trackable score?](img/0032_4_6.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Before adding this image, intuitively, we might think that this image is suitable
    for tracking. It certainly has a lot of details of a wide-angle landscape. But
    this image yielded a shocking 1-star result when added to the **Target Manager**.
  prefs: []
  type: TYPE_NORMAL
- en: The main reason for the low score for this image is the fact that the entire
    image is a shade of green. This greatly diminishes contrasting edges in the image.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we are to click on the **Show Features** link on the top, we will be able
    to see what the target manager detected from the image. The following image shows
    features in the mountain landscape image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![What decides trackable score?](img/0032_4_7.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Immediately, we notice the considerably lower number of features detected in
    the image compared to the stones one. It only detected the edges created by the
    shadows of the objects in the image, which is clearly not enough to award it any
    score above 1 star.
  prefs: []
  type: TYPE_NORMAL
- en: Features definition
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To help us get a higher score, we must understand what are the features that
    the target manager is looking for. We do know now that the main thing that the
    target manager is looking for in an image is edges, but what kind of edges specifically?
    To understand that, we need the definition of features.
  prefs: []
  type: TYPE_NORMAL
- en: 'A feature is a sharp and spiked detail in the image, like the corner of an
    edge. Features must be very contrasting to be found and it has to be distributed
    evenly across the image and in a random manner. The following image shows shapes
    and features recognized in them:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Features definition](img/0032_4_8.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'In the shapes illustrated above, we can see the yellow crosses representation
    of the features recognizable in the shape. The representation is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Shape 1**: It is a perfect circle without any corners at all, and as such,
    no features are recognizable in it.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Shape 2**: It has an edge to the left with two recognizable corners. That
    yields two features recognizable in the shape.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Shape 3**: It is a square with four edges and four corners. This yields four
    recognizable features in the shape.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This means that any curved object yields little to none features at all. Primarily,
    humans and animals make very poor trackables due to their curved nature.
  prefs: []
  type: TYPE_NORMAL
- en: Enhancing score by enhancing contrast
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'One of the easiest ways of enhancing an image''s score is by simply enhancing
    the image''s contrast. Feature detection looks for sharp edges like above; it
    is very hard to do so when the image''s contrast is low. Like the landscape image
    we used before, the main reason the image resulted in a low score was because
    of the low contrast in the image. Then what happens when we increase the image''s
    contrast and light levels in a photo editing application like Photoshop or Gimp?
    The following image shows the figure with enhanced contrast in landscape image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Enhancing score by enhancing contrast](img/0032_4_9.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The score makes a giant leap from 1-star score to 4-star score. As you can
    see, if you compare the image used now to the one we used earlier, the image''s
    contrast is greatly enhanced, and the target manager easily detects such shadows
    and edges now. Lets look at the features detected by the target manager. The following
    image shows features in the high contrast image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Enhancing score by enhancing contrast](img/0032_4_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The features detected in the image are way more than what the target manager
    found in the previous image. Mostly, the features are located around the mountain
    and tree shadows. Notice how the green field is still yielding little features,
    but the features from the mountain and trees are enough to yield a high score
    of 4 stars.
  prefs: []
  type: TYPE_NORMAL
- en: It is highly recommend to enhance the contrast in all targets used for AR apps.
    It is greatly beneficial for the experience to have the best trackable possible.
  prefs: []
  type: TYPE_NORMAL
- en: Feature distribution on image targets
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Having recognizable features on the image is important, but how they are distributed
    is also very important. We can have all the features recognized on only one part
    of the image and nothing on another. This kind of imbalance lowers the score greatly,
    because it hinders the detection of the relative position of the image in the
    world for the AR app. For example, examine the image target below. The following
    image shows the lake target:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Feature distribution on image targets](img/0032_4_11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: This is a lake image target that was added to the image target manager. It has
    a fair bit of details, but the left side of the image is mostly empty but for
    the lake. This image yielded 2 stars, and that is after enhancing the image's
    contrast.
  prefs: []
  type: TYPE_NORMAL
- en: 'To understand the reason for the low score, lets look at the features detected.
    The following image shows features in the lake house target:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Feature distribution on image targets](img/0032_4_12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: As expected, all the features detected are on the right side of the image, leaving
    the left side completely empty. This is very bad for occlusion management and
    relative position detection by the AR app. It will track, but it will be a very
    poor target.
  prefs: []
  type: TYPE_NORMAL
- en: How to enhance distribution of features
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Enhancing distribution of features can be done by the obvious method, which
    is adding objects to the empty space of the image. If we are to add textured objects
    to the empty side of the image above, it will naturally enhance its score after
    the new object yields new detectable features. But changing the target's composition
    might not always be a viable option in practice if there is a restriction on what
    the target can be. For example, if the target is part of a magazine or a brochure,
    and we do not have control on what we can add to the image. However, we will always
    have control on what we can subtract from the target.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we manage to subtract the empty space from the image target and take a subset
    of the target that is rich in details and well-distributed features, we can circumvent
    the problem. The interesting part is that the AR app will trigger on the large
    image just fine, even if we only give data of the subset. For example, examine
    this subset target of the lake target we added earlier. The following figure shows
    a subset of the lake image target:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How to enhance distribution of features](img/0032_4_13.jpg)'
  prefs: []
  type: TYPE_IMG
- en: As we can see, the above image is only a subset of the lake image, with just
    the lake house visible in it. Immediately, more features are recognizable now
    that target manager can focus on a smaller area. It also enhanced the feature
    distribution on the image. This enhanced the score to 3 stars for this trackable.
  prefs: []
  type: TYPE_NORMAL
- en: The AR app will trigger to this image, regardless if it's in this subset form,
    or if it was subjected to the original image before cropping the lake house from
    it. This is a very useful feature to keep in mind when trying to achieve a higher
    score for a target.
  prefs: []
  type: TYPE_NORMAL
- en: The position of the AR content will need to be adjusted according to appear
    relative the original lake image and not the subset. This can be achieved easily
    with an offset to the position applied to the AR content in Unity.
  prefs: []
  type: TYPE_NORMAL
- en: Patterns in image targets
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We now understand the need for a good distribution of features on the image,
    but there is one thing to keep in mind: having repeated patterns on the image
    is only counted once, meaning if we have a repeated pattern all across the image
    target, the score will be very bad. Examine the following image target. The following
    figure shows a snowflake pattern image target:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Patterns in image targets](img/0032_4_14.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The above image when used yields a staggering 0 star. This image is mainly
    a repeated pattern of a snowflake. If we examine the features detected, we will
    see something like the following image. The following figure shows features in
    snowflake pattern:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Patterns in image targets](img/0032_4_15.jpg)'
  prefs: []
  type: TYPE_IMG
- en: As we can see, there are enough features detected in the image to effectively
    be augmentable, but yet the target manager gives it a 0 star. It will not be detectable
    at all from the app's perspective.
  prefs: []
  type: TYPE_NORMAL
- en: 'To understand why that happens, we need to ask ourselves the following question:
    if we take a subset of the image at the center, would it be distinguishable from
    the larger image? The answer is no, the pattern repeats itself symmetrically around
    the image. The app will not be able to find the relative position of the target
    in the real world if it compares the features detected with that in the dataset.'
  prefs: []
  type: TYPE_NORMAL
- en: Exporting datasets to Unity
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that we know how to select and create our trackables, exporting them to
    Unity is a much easier task. The following figure shows highlighted targets to
    be exported:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Exporting datasets to Unity](img/0032_4_16.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'From the dataset''s view, we can select what targets we want to export. Simply
    select any number of targets for deployment. Once the targets are selected, we
    can click on **Download Selected Targets** on the top left. The following image
    shows **Download Selected Targets**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Exporting datasets to Unity](img/0032_4_17.jpg)'
  prefs: []
  type: TYPE_IMG
- en: From the list of development option, select **Unity Editor** as the option.
    It is recommended to leave the database name the same name in the target manager.
    This makes it easier to update the dataset later. This will download a Unity package
    file that we can import easily into a project like we did in the sample project.
  prefs: []
  type: TYPE_NORMAL
- en: As we have seen, the create of a dataset in the target manager is quite easy,
    and makes creating a project more fluid.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we understood the process of creating our own trackables and
    datasets using the target manager from Qualcomm. We also explored how to design
    and use a trackable that will yield the best trackability in our apps. We have
    seen what makes a trackable bad, such as patterns and feature distribution, and
    what makes it good, such as contrast, and edges. We learned a couple of tricks
    to enhance the trackability score of our trackable, such as taking a subset of
    the original image or by increasing the contrast in Photoshop or apps like it.
    With this knowledge, we easily optimize the most important foundation of AR, which
    is our trackable.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will create a project from the scratch that will be
    an AR game. Techniques and code will be of a higher level than previously explored
    in the book so far, and will get us closer to the full potential of Unity and
    Vuforia.
  prefs: []
  type: TYPE_NORMAL
