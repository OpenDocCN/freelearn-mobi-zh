- en: '9'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Event Sourcing and CQRS
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The previous chapter, on **Domain-Driven Design** (**DDD**), laid the foundation
    for us to dive into two powerful architectural patterns that answer to the demand
    for scalable, responsive, and maintainable applications: **Event Sourcing** and
    **Command-Query Responsibility** **Segregation** (**CQRS**).'
  prefs: []
  type: TYPE_NORMAL
- en: Firstly, we will explore the foundation of Event Sourcing. We will discuss how
    we can use Event Sourcing to model our domain, how to persist the state of your
    domain, and how to reconstruct the current state from the persisted events. We
    will explore the benefits of this approach.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we will turn our attention to CQRS, examining how it separates the responsibilities
    of commands (write) and queries (read). We will discuss the key components of
    a CQRS architecture, including the command and query handlers, the domain model,
    and the event store. We will delve into the benefits of this separation.
  prefs: []
  type: TYPE_NORMAL
- en: As we delve deeper, we will examine the practical considerations of implementing
    CQRS and Event Sourcing together, including data modeling, event schema design,
    and handling eventual consistency. We will also discuss strategies for integrating
    these patterns into your existing software ecosystem, ensuring a seamless and
    scalable transition.
  prefs: []
  type: TYPE_NORMAL
- en: Through real-world examples and best practices, you will gain a comprehensive
    understanding of how CQRS and Event Sourcing can transform the way you approach
    software design and development. By the end of this chapter, you will be equipped
    with the knowledge and tools to harness the power of these patterns and unlock
    the full potential of your applications.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will go through the main topics in the following order:'
  prefs: []
  type: TYPE_NORMAL
- en: Event Sourcing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Command-Query Responsibility Segregation (CQRS)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Combining CQRS and Event Sourcing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'You can find all the code files used in this chapter on GitHub: [https://github.com/PacktPublishing/Software-Architecture-with-Kotlin/tree/main/chapter-9](https://github.com/PacktPublishing/Software-Architecture-with-Kotlin/tree/main/chapter-9)'
  prefs: []
  type: TYPE_NORMAL
- en: Event Sourcing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Event Sourcing** is a data management pattern, and its origin can be traced
    back to the 1990s, when engineers recognized the limitations of traditional data
    storage **Create, Read, Update, and Delete** (**CRUD**), particularly in the context
    of building complex and event-driven systems.'
  prefs: []
  type: TYPE_NORMAL
- en: Event Sourcing has its roots in the principles of **Domain-Driven Design** (**DDD**),
    as covered in [*Chapter 8*](B21737_08.xhtml#_idTextAnchor289). DDD introduced
    the concept of an **Aggregate** as a fundamental building block of the domain
    model, and Aggregates usually need to be persisted in data storage.
  prefs: []
  type: TYPE_NORMAL
- en: The classic CRUD approach and its limitations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The classic CRUD approach is sufficient for capturing the latest snapshot of
    an Aggregate by CRUD operations, usually with the use of a relational database.
    There are, however, limitations to this approach:'
  prefs: []
  type: TYPE_NORMAL
- en: '**History, auditability, and traceability**: While the CRUD approach can capture
    the current snapshot of an Aggregate, its ability to keep audit trails of all
    changes made to the Aggregate over time is limited.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This is usually overcome by custom data persistence code to keep historical
    records, or with the assistance of database update triggers. This can make it
    challenging to track the history of changes, understand how the system reached
    a particular state, and comply with regulatory requirements.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Modeling complex domains**: CRUD-based systems work well with simple and
    straightforward data models, but they can struggle to effectively represent and
    manage the evolution of complex domain models over time.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Traditionally, with the use of relational databases, a complex Aggregate object
    results in convoluted database schemas, complex data persistence operations, and
    difficulties in maintaining and evolving the system.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Event-driven capabilities**: The CRUD approach has no support for event-driven
    architectures, where the system needs to react to and propagate changes in a decoupled,
    scalable manner.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Concurrency and consistency**: CRUD-based systems often rely on traditional
    locking mechanisms to ensure data consistency, which often leads to performance
    bottlenecks in distributed, concurrent, and high-load environments.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Maintaining strong consistency in the face of concurrent updates can be a significant
    challenge in CRUD systems.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Versioning and evolution**: Updating and evolving CRUD-based systems can
    be problematic, as changes to the data model or business logic may require complex
    migrations and data transformations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Versioning and handling historical data can also be more complicated in a CRUD-centric
    approach.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Analytics and reporting**: CRUD systems focus on the current snapshot of
    Aggregates, which can make it challenging to analyze, generate reports, or derive
    insights from the historical data of Aggregates.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the face of these challenges, the idea of capturing the full history of Aggregate
    changes began to gain traction.
  prefs: []
  type: TYPE_NORMAL
- en: Events as first-class citizens
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Event Sourcing aims to solve these challenges by making events first-class citizens.
    The term *event* here entails the same concept as the *event* in DDD mentioned
    in [*Chapter 8*](B21737_08.xhtml#_idTextAnchor289). An event captures the change
    in an aggregate, making it a key element in this framework.
  prefs: []
  type: TYPE_NORMAL
- en: Event Sourcing persists all the events of aggregates in an event store. There
    are no update or delete operations to an event because an event represents a change
    that has already happened to an aggregate. In other words, events are immutable
    and are stored as a journal in chronological order. Event stores are often not
    relational databases; they can be NoSQL databases or persistent queues.
  prefs: []
  type: TYPE_NORMAL
- en: In contrast to CRUD, in which the latest snapshot of an aggregate is a first-class
    citizen, Event Sourcing derives the latest snapshot of an aggregate by replaying
    the events from the aggregate from the first to the last event. As a result, the
    full history of an aggregate is preserved and no custom code is required to provide
    an audit trail of the aggregate.
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, the history of an aggregate is captured as a linear timeline and naturally
    eliminates the challenge of keeping strong consistency with concurrent updates.
    There should be, however, version validation before a request to mutate an aggregate
    is accepted and eventually generates an event. This is to prevent the **Lost Update**
    problem, where concurrent updates of the same aggregate overwrite each other unknowingly.
  prefs: []
  type: TYPE_NORMAL
- en: Functional representations of Event Sourcing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The idea of representing the state of a system as a sequence of immutable events
    aligns well with the functional programming paradigm. Aggregates and events are
    immutable. Each change is performed by creating a new version of an aggregate
    from an event through stateless functions. This can be expressed through two basic
    functions written as Kotlin lambdas:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The first function creates an initial aggregate. Subsequently, the update functions
    take the current version of the aggregate and create a new version.
  prefs: []
  type: TYPE_NORMAL
- en: An example of how a request is handled with Event Sourcing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Suppose there is a request to update an existing aggregate. The service that
    receives the request would need to get the latest version of the aggregate to
    validate the request. So, the service gets all the events for the aggregate from
    the event store.
  prefs: []
  type: TYPE_NORMAL
- en: All the events are replayed to recreate the latest snapshot of the aggregate.
    Assuming the request is all good, the service creates a new event. The service
    then plays this event on the current aggregate and creates an updated version
    of the aggregate.
  prefs: []
  type: TYPE_NORMAL
- en: The transaction is committed by appending the new event in the event store.
    The updated version of the aggregate can be used as a response to the original
    requester.
  prefs: []
  type: TYPE_NORMAL
- en: 'The whole interaction is illustrated as a sequence diagram, as shown in *Figure
    9**.1*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.1 – An example of Event Sourcing](img/B21737_09_1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.1 – An example of Event Sourcing
  prefs: []
  type: TYPE_NORMAL
- en: It is important to point out that the aggregate is not directly updated by the
    service. It is achieved by the handling of the new event. Also, the event store
    is responsible for distributing the new event to subscribers that are interested
    in these events.
  prefs: []
  type: TYPE_NORMAL
- en: Benefits of Event Sourcing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The benefits of Event Sourcing come from the persistence of full audit trails
    of an Aggregate:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Full audit trails with intents**: Not only are the full audit trails of an
    aggregate preserved, but also the intent of each change is captured. The name
    of each event of the aggregate ideally should come from the ubiquitous language
    so it becomes a business-aware and user-friendly history.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Time travel**: With the full history captured as a linear sequence of events,
    it is possible to travel back in time to construct a historical representation
    of the aggregate. It helps engineers to reproduce a scenario that happened in
    the past for investigation and troubleshooting purposes. It also enables users
    to see the historical aggregate as a feature.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Creation of read models**: Having multiple consumers of the same event of
    an Aggregate opens the door to multiple read models. Each read model consumes
    the same event but transforms it to meet its specific requirements. This approach
    provides diverse views tailored for particular business purposes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deciding whether Event Sourcing should be used
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Choosing Event Sourcing as the way to store aggregates and their audit trails
    should not be taken lightly. It is a fundamental shift in how we reason about
    data, and it requires noticeable effort to make it work.
  prefs: []
  type: TYPE_NORMAL
- en: From the *YAGNI* principle we covered in [*Chapter 1*](B21737_01.xhtml#_idTextAnchor013),
    engineers should build the simplest things that work. When there is more than
    one solution, the simplest solution should be chosen.
  prefs: []
  type: TYPE_NORMAL
- en: A simple solution is different from an easy solution
  prefs: []
  type: TYPE_NORMAL
- en: Simple solutions are not complicated or are straightforward to reason about.
    Easy solutions require less effort to make. Take the example of capturing a new
    field. If we believe that the field should belong to a new entity, then creating
    a new entity that has the field is the most intuitive and straightforward approach.
    However, a new entity may mean adding new database tables, new validations, and
    new exposed APIs. On the other hand, if we attach the new field to an existing
    entity, we only need to enhance the existing entity, database table, and APIs.
    There is less effort involved in coding and testing, even though the field does
    not belong to the existing entity. This is an easy solution as less effort is
    required, but it is not simple because it is not intuitive and is instead confusing
    to see the field in an entity to which it does not belong.
  prefs: []
  type: TYPE_NORMAL
- en: 'An decision tree to determine if an aggregate should use Event Sourcing is
    shown in *Figure 9**.2*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.2 – A decision tree whether to use Event Sourcing](img/B21737_09_2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.2 – A decision tree whether to use Event Sourcing
  prefs: []
  type: TYPE_NORMAL
- en: The most decisive factor is whether the aggregate being considered to use Event
    Sourcing belongs to a Generic subdomain or not. In [*Chapter 8*](B21737_08.xhtml#_idTextAnchor289),
    we identified Core domains, Supporting subdomains, and Generic subdomains. A Generic
    subdomain has a high likelihood of being fully replaced by off-the-shelf software
    products, which makes the benefits of using Event Sourcing not significant.
  prefs: []
  type: TYPE_NORMAL
- en: If the aggregate involved belongs to either a Core domain or a Supporting subdomain,
    the next step in the consideration is whether it is required to keep the full
    audit trails of the aggregate. Full audit trails can be used for regulatory reporting,
    replaying events to get a particular historical state of the aggregate, or performing
    time-series data analysis. It is a powerful feature of Event Sourcing, but not
    all aggregates need such power.
  prefs: []
  type: TYPE_NORMAL
- en: Another hint that helps when considering Event Sourcing is if there are multiple
    read models for the Aggregate. The definition of a read model here is the same
    as the read models that can be discovered during **Event Storming**, which was
    also covered in [*Chapter 8*](B21737_08.xhtml#_idTextAnchor289).
  prefs: []
  type: TYPE_NORMAL
- en: An aggregate that requires multiple read models can benefit from Event Sourcing.
    Each read model can consume the same event of the aggregate, but it transforms
    the data to its unique representation of the aggregate as a materialized view.
    Sometimes, a read model might even combine data from other aggregates or entities.
  prefs: []
  type: TYPE_NORMAL
- en: Event Sourcing uses events extensively for each change in an aggregate, and
    events are often processed asynchronously. If the operations for the aggregate
    are predominately synchronous, it imposes challenges in implementing Event Sourcing
    for the aggregate. There are techniques to synchronously process events to update
    aggregates, and the implementation has a cost.
  prefs: []
  type: TYPE_NORMAL
- en: It is important to reiterate that this is just an example decision tree. Each
    organization may have other factors in its decision-making. Sometimes, it may
    even make a different decision given the same question.
  prefs: []
  type: TYPE_NORMAL
- en: Usage of Event Sourcing with a real-life example
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let’s revisit the real-life example of villagers exchanging services, with
    the three bounded contexts identified in [*Chapter 8*](B21737_08.xhtml#_idTextAnchor289):'
  prefs: []
  type: TYPE_NORMAL
- en: 'Core domains: **Contract Service**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Supporting subdomain: **Household Service**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Generic subdomain: **Notification Service**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Walking through the decision tree (see *Figure 9**.2*) mentioned in the previous
    section, Notification Service, as a Generic subdomain, can be safely ruled out
    from using Event Sourcing.
  prefs: []
  type: TYPE_NORMAL
- en: Household as an aggregate in Household Service does not need to keep full audit
    trails because only the latest states of households are needed for business cases.
    The CRUD approach is sufficient.
  prefs: []
  type: TYPE_NORMAL
- en: Contract as an aggregate in Contract Service may need to keep full audit trails
    because disputes are likely to arise between households on the agreements in the
    contract.
  prefs: []
  type: TYPE_NORMAL
- en: There are also multiple read models involving contracts. The primary read model
    of a contract is the one that specifies the details of the contract between two
    households.
  prefs: []
  type: TYPE_NORMAL
- en: There can also be a unilateral read model for each household. It contains a
    list of services that the household should provide and to which household. There
    is another list of services that the household expects to receive and from which
    household.
  prefs: []
  type: TYPE_NORMAL
- en: In addition, there is potential read model that aims to highlight the most wanted
    services in the village and the most active households in exchanging services.
  prefs: []
  type: TYPE_NORMAL
- en: The negotiation process of a contract involves multiple rounds of amendments
    until both households agree. When a contract is drafted by one household, an email
    is sent to another household asynchronously. During the negotiation process, any
    change made by one household results in an email notification to the other household
    involved. There are also multiple messages between two households in providing
    the services as per the contract. This asynchronous nature of communication suggests
    that a contract is a suitable candidate for using Event Sourcing in the Contract
    Service.
  prefs: []
  type: TYPE_NORMAL
- en: In this example, we are going to focus on using Event Sourcing to capture the
    full history of the aggregate contract in Contract Service.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s revisit the aggregate contract as a data class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: The `Contract` data class contains an `id` field, which uniquely identifies
    this aggregate. There is also a field named `version`, which is a monotonic increasing
    integer that shows how many events have been played for this aggregate.
  prefs: []
  type: TYPE_NORMAL
- en: 'The basic construct of a `ContractEvent` should have the unique identifier
    of the aggregate and the time when the event happened:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: It also has a target version, which is the version of the aggregate after the
    event is applied.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this example, we are using a simple in-memory event store. It has two basic
    functions. The `append` function adds a new event at the tail of the sequence
    by the aggregate ID, and the `get` function returns a chronological sequence of
    events given the aggregate ID:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: If this is a real system, reputable event store middleware should be used to
    make it durable, highly available, and resilient.
  prefs: []
  type: TYPE_NORMAL
- en: 'The creation of the aggregate contract starts with a household that has drafted
    a contract, and it should contain all the information required to create the first
    version of the aggregate:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'The `Contract Drafted Event` class should provide a function to create the
    aggregate. It is a simple function that puts the values into the appropriate structure:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Any subsequent event must take a parameter of the current version of the aggregate
    to generate a new version. For instance, an event that captures when a household
    amends and agrees to a drafted contract could look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that this event does not necessarily follow the data structure of the
    aggregate. The key point is to keep the event lean and simple. So, this event
    only mentions one household, and it relies on the corresponding `play` function
    to apply the change correctly. Note that the `play` function takes a parameter
    of the current aggregate:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'You will notice there is a `validate` function, which is important for ensuring
    data integrity:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: This `validate` function asserts that the event refers to the aggregate in the
    parameter. Then, it asserts that the current aggregate is one version lower than
    the target version of the event. Finally, it asserts that the involved household
    is mentioned in the aggregate contract.
  prefs: []
  type: TYPE_NORMAL
- en: 'There should be an iterative function that takes a list of `Contract Events`
    and eventually returns a `Contract` object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'The function uses a `List` of contract events as the receiver. The return type
    is nullable in the case of an empty list. It assumes the first event is `ContractCreatedEvent`,
    which sets up the initial snapshot of the `Contract`. It loops from the second
    event to the last, generates a new version of the `Contract`, sets it as `current`
    to pass to the next event, and at the end returns the `Contract` object. An example
    of its usage is as follows. A list of events of the same aggregate is ordered
    and is played sequentially:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'The code does not directly update the aggregate. Instead, it creates a few
    events and lets them play through. Eventually, the version should be `3` because
    the first version is `0`. The following should be printed to the console when
    the previous code is executed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: This example illustrates a simple form of Event Sourcing where each event generates
    a new version of the aggregate. These events should be persisted to an event store
    as permanent storage and be received by subscribers so other read models can be
    built upon.
  prefs: []
  type: TYPE_NORMAL
- en: In complex systems, processing an event could produce a list of events as reactions,
    and that would require a recursive function to walk through the processing. It
    may also require grouping related events as one transaction due to the chained
    reactions.
  prefs: []
  type: TYPE_NORMAL
- en: Although the example here is simple, there are many ways Event Sourcing can
    go wrong. We are going to discuss some best practices that should be considered
    in the implementation.
  prefs: []
  type: TYPE_NORMAL
- en: Event Sourcing best practices
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Event Sourcing is a different way to reason about an aggregate in a domain from
    the classic CRUD approach. It only works if we design and architect our system
    with the mindset of events being first-class citizens. Otherwise, it could become
    an anti-pattern and undo all the benefits that it brings. Here are some of the
    fundamental best practices.
  prefs: []
  type: TYPE_NORMAL
- en: Randomization and idempotence
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'It is important that replaying the same sequence of events for an aggregate
    generates the same snapshot of the aggregate every time. In other words, the processing
    of events must be idempotent. There are two major factors that could violate this
    behavior: time and randomization.'
  prefs: []
  type: TYPE_NORMAL
- en: 'If the event processing contains logic that makes use of the time the event
    is processed, then it will generate different results depending on the time of
    processing. For example, the following `expire` variable would have different
    Boolean values based on the system clock:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Any information related to the system clock should be stamped on the event instead.
    In this way, the result has been determined and will not change over time. Any
    time-based trigger or schedule job should obtain the system time and have the
    value captured in the events.
  prefs: []
  type: TYPE_NORMAL
- en: 'Any randomization at the time of event processing will also generate different
    outcomes for each iteration. Values generated from randomization should be captured
    in the event payload, and there is no randomization involved in the event processing.
    If identifiers must be generated during the processing, they can be unique values
    within the scope of the event. Externally, they are used together with the event
    identifiers as composite keys. Here is an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: The value inside the event can be identified externally by concatenation of
    the event ID and the value ID inside the event, delimited by a hyphen.
  prefs: []
  type: TYPE_NORMAL
- en: Event design
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: An event should have one and only one aggregate. Mixing multiple aggregates,
    whether they are of the same or different types, results in unnecessary coupling
    between aggregates. The coupling created by mixed aggregates in one event makes
    it difficult to scale events and their topics.
  prefs: []
  type: TYPE_NORMAL
- en: There could be business cases where multiple aggregates are affected. In this
    scenario, multiple events should be created as a result, and each event describes
    what happened to each aggregate.
  prefs: []
  type: TYPE_NORMAL
- en: Each event should capture the intent of the change in an aggregate. For example,
    `ContractCreatedEvent` is a bad name because it does not describe why the aggregate
    contract is created. A better name would be in line with ubiquitous language,
    such as `ContractDraftedEvent`.
  prefs: []
  type: TYPE_NORMAL
- en: Event topologies
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Events are published for subscribers to receive and can be logically grouped
    as **topics**. A topic here is not to be mistaken for the topic in traditional
    pub-sub messaging, in which messages are no longer in a topic once all subscribers
    acknowledge receipt. In Event Sourcing, events are meant to be kept permanently
    as an append-only and sequential log of events. For example, a Kafka topic with
    an infinite retention period can be used to keep events, and each topic represents
    a logical grouping of events.
  prefs: []
  type: TYPE_NORMAL
- en: All events of one aggregate should only go to one topic only. This is to simplify
    creating and reading the linear history of an aggregate.
  prefs: []
  type: TYPE_NORMAL
- en: Spreading the events of an aggregate to multiple topics imposes difficulties
    in recreating the full history of an aggregate. It is also more difficult to scale
    performance and increase throughput, which are separate concerns from the event
    design.
  prefs: []
  type: TYPE_NORMAL
- en: Event schema compatibility
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As Event Sourcing intends to keep all historical events, it is important that
    all events are backward compatible; in other words, old events can still be read
    and processed when the event schema evolves.
  prefs: []
  type: TYPE_NORMAL
- en: 'Maintaining backward compatibility is a big topic in itself. There are many
    things that can keep or break backward compatibility. Here are some examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Keep**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Adding an optional field
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Adding more enum values to a type
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Reducing the constraints of a field
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Break**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Adding a mandatory field
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Renaming a field
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Changing the data type of a field
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Removing a field
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Increasing the constraints of a field
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: In the context of Event Sourcing, a backward-compatible event schema ensures
    that the system can always read the full history of an aggregate to re-create
    the latest snapshot of the aggregate.
  prefs: []
  type: TYPE_NORMAL
- en: Forward and full compatibility
  prefs: []
  type: TYPE_NORMAL
- en: Forward compatibility means that an old consumer can read and process events
    of a new schema. A fully compatible schema means it is both backward and forward
    compatible.
  prefs: []
  type: TYPE_NORMAL
- en: Performance and Memento
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: While the current version of an aggregate can always be derived from all the
    events of that aggregate from the beginning of time, it is not always ideal to
    have to play these events if a current snapshot is requested.
  prefs: []
  type: TYPE_NORMAL
- en: A performance optimization is to persist the latest version of the aggregate
    as a derived record. This pattern is called **Memento**. The usage of this pattern
    can be justified if current snapshots are frequently requested.
  prefs: []
  type: TYPE_NORMAL
- en: In the case of using events to recover the latest state of an aggregate, it
    may also be justified to use the Memento pattern. The reason for this is that
    the number of events will keep growing, and therefore the total time to replay
    all events will become longer and longer. Applying the Memento pattern changes
    the total time used for recovery versus number of events from linear to constant
    for a given aggregate.
  prefs: []
  type: TYPE_NORMAL
- en: Migration from CRUD
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Migrating an aggregate from CRUD to Event Sourcing is interesting in that usually,
    CRUD does not have full audit trails to allow a complete history to be rebuilt
    as events. Instead, the latest snapshots of aggregates are treated as the first
    versions, and then subsequent events are persisted.
  prefs: []
  type: TYPE_NORMAL
- en: In this case, something like `ContractMigratedEvent` would be the first event.
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, the mutation of an aggregate will be done through the playing of events,
    not a direct update to the aggregate. As a result, any code that directly updates
    the aggregate will need to be deprecated.
  prefs: []
  type: TYPE_NORMAL
- en: We have covered the basics of Event Sourcing with a real-life example and source
    code. There is another architectural pattern that works with Event Sourcing and
    is also based on DDD. We are going to cover this pattern now.
  prefs: []
  type: TYPE_NORMAL
- en: Command-Query Responsibility Segregation (CQRS)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The origin of CQRS can be traced back to another design pattern called **Command
    Query Separation** (**CQS**). CQS is the core concept that defines two types of
    operations handled in a system: a command that executes a task, and a query that
    returns information, and there should never be one function that does both jobs.'
  prefs: []
  type: TYPE_NORMAL
- en: The term CQS was created by Bertrand Meyer in his book *Object-Oriented Software
    Construction* in 1988\. He created it as part of his work on the Eiffel programming
    language.
  prefs: []
  type: TYPE_NORMAL
- en: CQRS takes the defining principle of CQS and extends it to specific objects
    within a system, one retrieving data and one modifying data. CQRS is a broader
    architectural pattern, and CQS is the general principle of behavior.
  prefs: []
  type: TYPE_NORMAL
- en: The term CQRS was coined by Greg Young in 2010\. Since then, CQRS has gained
    traction, and various frameworks and libraries have been developed to support
    the pattern’s implementation in popular languages such as Java and .NET.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are four basic elements in CQRS: **aggregate**, **query**, **command**,
    and **event**.'
  prefs: []
  type: TYPE_NORMAL
- en: Aggregate
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Aggregate in CQRS has the same meaning as in Event Sourcing and DDD. It is an
    aggregated entity that represents the current state of the domain model. The aggregate
    contains a basket of other entities and value objects to represent a domain concept
    as defined in ubiquitous language.
  prefs: []
  type: TYPE_NORMAL
- en: Query
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A query is a request from clients to retrieve a representation of the state
    of the domain model. Handling queries is a read-only operation and does not change
    the state of any aggregate. However, queries may be targeted to a certain read
    model related to an aggregate.
  prefs: []
  type: TYPE_NORMAL
- en: Command
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A command is a request from clients intending to change the state of an aggregate
    in the domain model. The intention is handled to determine whether the state should
    be changed and how. A command may only contain the necessary information for the
    change, and not the whole aggregate in the request.
  prefs: []
  type: TYPE_NORMAL
- en: Event
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: An event is a confirmed and immutable change of the state of an aggregate. An
    event can be created because of a command, or because of the handling of another
    event. This is the same as the concept of events in DDD and Event Sourcing.
  prefs: []
  type: TYPE_NORMAL
- en: How CQRS breaks down CRUD
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: CQRS has broken down the classic CRUD into many small queries, commands, and
    events. Each of them carries a precise meaning of what is happening, to the point
    that it matches the ubiquitous language.
  prefs: []
  type: TYPE_NORMAL
- en: Take the real-life example of the negotiation process of a service contract
    between two households. Both households can amend the contract and eventually
    agree to it.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.3 – CRUD versus CQRS – update versus command](img/B21737_09_3.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.3 – CRUD versus CQRS – update versus command
  prefs: []
  type: TYPE_NORMAL
- en: In CRUD style, both amendments to and agreement of a contract result in a request
    to update the contract, and the difference is the content of the contract. In
    CQRS style, amendments and agreements have dedicated commands to capture not only
    what needs to be updated, but also the intent and business context of the update.
  prefs: []
  type: TYPE_NORMAL
- en: The CQRS style results in the amendment and agreement operations being separated.
    This leads to a cleaner and more modular design. The separation also allows independent
    scaling and the optimization of commands.
  prefs: []
  type: TYPE_NORMAL
- en: On the query side, as shown in the following figure, households A and B can
    get the contract between them by using a CRUD read request, and the responses
    will be the same for both households. However, the CQRS query allows multiple
    read models, and in this case, it can return a custom read model depending on
    which household makes the query.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.4 – CRUD versus CQRS – read versus query](img/B21737_09_4.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.4 – CRUD versus CQRS – read versus query
  prefs: []
  type: TYPE_NORMAL
- en: The CQRS style can build a materialized view for each household as a read model
    by consuming the events produced when a command is accepted. In CRUD style, these
    custom views are typically implemented using SQL commands and the custom views
    do not materialize.
  prefs: []
  type: TYPE_NORMAL
- en: A materialized read model can scale independently without concerns for commands.
    For example, if the read-write ratio of the aggregate contract heavily tilts towards
    reading, then it is sensible to consider materializing the corresponding read
    model in a separate data store infrastructure, so the writing is not affected
    even under a heavy load of query operations.
  prefs: []
  type: TYPE_NORMAL
- en: As read models are materialized by consuming events via asynchronous messaging,
    changes in the aggregates may not be immediately reflected in the read models
    but will eventually be synchronized.
  prefs: []
  type: TYPE_NORMAL
- en: It is important to point out that handling commands does need some existing
    information for validation, integrity checks, and concurrency control. These read
    operations are necessary for handling commands, but not for serving requests.
  prefs: []
  type: TYPE_NORMAL
- en: When should CQRS be considered?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Like Event Sourcing, CQRS should be considered when a couple of prerequisites
    are met and there are legitimate problems that can be solved by CQRS. CQRS is
    a paradigm shift in how we reason about a system, and significant effort is required
    to implement it correctly. Applying CQRS to the wrong system increases the complexity
    with no benefits.
  prefs: []
  type: TYPE_NORMAL
- en: CQRS is an architectural pattern built upon DDD. If the current system has no
    concept of DDD, bounded contexts, or aggregates, then it is a non-starter. Even
    if the system includes bounded contexts, using CQRS may not be necessary for generic
    subdomains due to their limited complexity. CQRS is most likely beneficial only
    for core domains, where the domain itself is complex enough to warrant its use.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are, however, a few signs that CQRS can be considered in the domain:'
  prefs: []
  type: TYPE_NORMAL
- en: Multiple actors working on the same aggregate. This usually means not all actors
    are concerned with everything in an aggregate. Some actors may work on a part
    of an aggregate but not all of it.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Multiple use cases of updating the aggregate. There are specific use cases in
    which only a part of the aggregate should be updated.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Multiple views of the same aggregate. There are alternate views of the same
    aggregate, and sometimes there may even be a view combining multiple entities
    that deviate from the aggregate.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Imbalanced read-write ratio. If either read or write operations are significantly
    more frequent than the other, read and write would need to be scaled differently
    as their needs are different.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Benefits and costs of CQRS
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: CQRS separates the concerns of read (query) and write (command) operations so
    their requirements can be met in isolation. This leads to smaller code footprints
    per function or per class, but there will be more functions or classes due to
    the separation.
  prefs: []
  type: TYPE_NORMAL
- en: This separation drives the code toward the **Single Responsibility Principle**
    (**SRP**), as mentioned in [*Chapter 2*](B21737_02.xhtml#_idTextAnchor045), where
    there should be one and only one reason to change a class. Each use case for each
    actor has its own class, either as a query or as a command.
  prefs: []
  type: TYPE_NORMAL
- en: The separation of queries and commands enables independent performance optimization,
    resulting in improved system performance and scalability overall. For example,
    queries can be optimized for faster execution due to the dedicated read models,
    and commands can be optimized for high throughput and consistency. However, this
    also results in more moving parts in the system and thus increases its complexity.
  prefs: []
  type: TYPE_NORMAL
- en: Queries and commands are broken down into their own functions or classes. This
    means that extending functionality is unlikely to need to change existing queries
    and commands, and therefore it is easier than in CRUD, where there is a big repository
    class that contains all the CRUD operations.
  prefs: []
  type: TYPE_NORMAL
- en: Dedicated queries and commands for each business case eliminate the need for
    clients to deal with unrelated fields and details about an aggregate, or to create
    a CRUD-style update or read request. This is in line with the **Interface Segregation
    Principle** (**ISP**), as mentioned in [*Chapter 2*](B21737_02.xhtml#_idTextAnchor045),
    where a client is not forced to depend on fields and functions it does not use.
  prefs: []
  type: TYPE_NORMAL
- en: Supporting multiple read models using CRUD is challenging. It often requires
    complicated SQL statements to join relevant data together. Moreover, it is difficult
    to optimize performance as different read models have different needs. Quite often,
    compromises are made so that different read models have reasonably acceptable
    performance.
  prefs: []
  type: TYPE_NORMAL
- en: Using CQRS, read models are materialized by consuming the events of aggregates.
    They have their own storage so they can scale and optimize performance that is
    unique to the non-functional requirements. This comes at the cost of the replication
    of data in various forms, and more storage is needed to keep these read models.
    Also, each read model requires its own code to transform the event and persist
    data that’s relevant to its data structure.
  prefs: []
  type: TYPE_NORMAL
- en: You may recognize the synergy between CQRS and Event Sourcing at this point.
    We are going to illustrate how they work together with a concrete example.
  prefs: []
  type: TYPE_NORMAL
- en: Combining CQRS and Event Sourcing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: CQRS and Event Sourcing are complementary patterns that work well together in
    building robust, scalable, and maintainable distributed systems.
  prefs: []
  type: TYPE_NORMAL
- en: 'The **command handler** in the CQRS architecture is responsible for validating
    write requests. If a command is valid, an event is persisted to an event store,
    which is the core of the Event Sourcing pattern. An example of how the CQRS command
    and Event Sourcing integrate is shown in *Figure 9**.5*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.5 – CQRS command and Event Sourcing](img/B21737_09_5.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.5 – CQRS command and Event Sourcing
  prefs: []
  type: TYPE_NORMAL
- en: The **service** receives a command from the **requester**. The **service** requires
    the current state of the aggregate, which is rebuilt by replaying events retrieved
    from the **Event Store**. The **command** passes the validation, so a new event
    is generated. The new event is played on the aggregate to generate a new state.
    The new event is appended to the **Event Store** and the updated aggregate is
    returned to the **requester**.
  prefs: []
  type: TYPE_NORMAL
- en: Event Sourcing answered the question from CQRS of how to update an aggregate
    and inform subscribers of the changes to an aggregate. CQRS answered the question
    from Event Sourcing of how an event was created.
  prefs: []
  type: TYPE_NORMAL
- en: 'The query, in turn, rebuilds the current state of the application by replaying
    the events stored in the event store. Also, multiple read models are rebuilt by
    transforming the event payloads to build their unique data structures. An example
    of how CQRS query and Event Sourcing integrate is shown in *Figure 9**.6*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.6 – CQRS query and Event Sourcing](img/B21737_09_6.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.6 – CQRS query and Event Sourcing
  prefs: []
  type: TYPE_NORMAL
- en: Event Sourcing provides a way for a CQRS query to rebuild a snapshot of a given
    aggregate. It enables the query to build any given read model as per the request.
    It also permits building a historical view of the aggregate from a given timestamp.
  prefs: []
  type: TYPE_NORMAL
- en: This separation of concerns between the command and query models, combined with
    the event-driven nature of Event Sourcing, allows highly scalable, flexible, and
    maintainable systems that can easily adapt to changing business requirements.
  prefs: []
  type: TYPE_NORMAL
- en: Using CQRS and Event Sourcing together
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Extending from the previous example of Event Sourcing, adding CQRS would require
    a couple of command and query classes to be created. We will need a class to capture
    the query of the current state of a contract among households and a class to capture
    the command for drafting a contract. The corresponding code is shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'You will find these command classes look quite like the event classes. The
    differences are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: The command that creates the aggregate does not contain the aggregate ID
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The command does not contain the aggregate version or the timestamp
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This is because the aggregate ID, version, and timestamp are populated when
    handling the commands. In this example, command handling is not idempotent. It
    uses randomization for aggregate IDs and a system clock to stamp timestamps.
  prefs: []
  type: TYPE_NORMAL
- en: There could be various implementations that supply random values and system
    timestamps to make command handling idempotent. Both approaches can be justified
    if they are consistent and well understood.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this example, the handling of every command has two potential outcomes.
    A successful outcome creates an event, and this event needs to be persisted. A
    failure outcome will inform the callers of the cause, and no event will be created.
    It is necessary to have a class to encapsulate the information for a failure outcome:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: The `Failure` class contains the original request, an optional message, and
    an optional `Throwable` object.
  prefs: []
  type: TYPE_NORMAL
- en: 'Each query and command requires a handler. Taking advantage of the `EventStore`
    class in the example of Event Sourcing, the query handler is straightforward with
    the use of Kotlin extensions and the event store as a parameter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: The query handler simply gets all the events for the given `contractId` and
    then plays all events to re-create the latest version of `Contract` as the return
    value.
  prefs: []
  type: TYPE_NORMAL
- en: 'The command handler has two main styles: creating and updating. The handler
    for the creation command generates a random **Universally unique identifier**
    (**UUID**) and the timestamp. These fields are captured in the creation event:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: The command handler requires two callback functions, one for success and one
    for failure. Only one of the callback functions is invoked during the execution.
    If the command fails validation (in this case, when the same household is used
    for the draft contract), no event is created and the failure callback function
    is invoked. Otherwise, an event is created to capture the randomized contract
    ID, the time of the event, and the rest of the fields. The event is persisted
    to the event store. The event is then passed to the success callback function.
  prefs: []
  type: TYPE_NORMAL
- en: 'The handler for the update command requires validation of whether the aggregate
    exists, and whether the same aggregate ID is retained. The rest of the implementation
    is the handler for the create command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'There is a `validate` function that is meant to be shared with other update
    command handlers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: The success callback function will have the `Contract` passed in because the
    latest version of the aggregate has been found and re-created. The failure callback
    function will have the `Failure` object passed in for delegation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, when using this example of CQRS and Event Sourcing, the client only
    needs to create a command and pass it in the event store to start with. Then,
    the extension `handle` function is invoked:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'The success callback function captures `contractId` for future updates. To
    update the aggregate, an update command needs to be created and the contract ID
    needs to be specified. Afterwards, the `handle` extension function is invoked:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'After all these updates, we can query the latest `Contract` and see if all
    these updates have accumulated. A query is created with the captured contract
    ID. The `handle` extension function is invoked, and the event store is passed
    in:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Because the event store keeps on capturing events as commands are handled,
    it already has the full history of the aggregate. This is the console output you
    get after executing all the commands and queries:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: This example has illustrated the powerful combination of CQRS and Event Sourcing
    at work. They complement each other and work together seamlessly. It has also
    demonstrated that each command and query has its own class and functions. This
    breaks down the traditional CRUD approach, where there are usually repository
    classes that contain all four types of operations in a big file.
  prefs: []
  type: TYPE_NORMAL
- en: Outbox pattern
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: It is worth pointing out that in real systems, there is a trend to also apply
    the **Outbox** pattern to manage the delivery of events in a reliable and fault-tolerant
    manner. This is implemented by having an outbox of messages in persistent storage,
    such as a relational database table.
  prefs: []
  type: TYPE_NORMAL
- en: There is a separate process that reads the unsent outbox messages and delivers
    them to the target destinations. If a message is delivered, the corresponding
    record is considered sent and will be deleted.
  prefs: []
  type: TYPE_NORMAL
- en: If the event store is unavailable, this delivery process will retry delivery
    automatically until the event store is operational again. The delivery process
    can also scale independently and potentially deliver messages to different destinations
    in parallel.
  prefs: []
  type: TYPE_NORMAL
- en: A similar pattern to the Outbox pattern is the **Change Data Capture** (**CDC**)
    pattern. CDC detects changes to records by database triggers, transaction logs,
    or change trackers and creates an event. The created event eventually goes into
    the event stream or topic. While events are created before the Outbox process,
    events are retrospectively created in CDC. That means that CDC is less intuitive
    in capturing the intent of the event.
  prefs: []
  type: TYPE_NORMAL
- en: Traditional relational databases provide strong consistency and transactional
    guarantees. This means we can have one transaction for normal database operations
    and event delivery as database records for either Outbox or CDC, achieving the
    all-or-none transactional behavior.
  prefs: []
  type: TYPE_NORMAL
- en: By storing the Outbox messages in relational databases, the reliability, fault
    tolerance, consistency, and scalability of event sending are also improved.
  prefs: []
  type: TYPE_NORMAL
- en: Popular frameworks and infrastructure for CQRS and Event Sourcing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: CQRS and Event Sourcing are architecture concepts that do not rely on a particular
    technology or framework. They are also agnostic to programming languages. However,
    there are frameworks and infrastructure that aim to support CQRS or Event Sourcing.
  prefs: []
  type: TYPE_NORMAL
- en: 'CQRS / Event Sourcing frameworks:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Axon framework ([https://www.axoniq.io/products/axon-framework](https://www.axoniq.io/products/axon-framework))
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Akka ([https://akka.io/](https://akka.io/))
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Event stores:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: EventStore ([https://www.eventstore.com/](https://www.eventstore.com/))
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Apache Cassandra ([https://cassandra.apache.org/](https://cassandra.apache.org/))
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: MongoDB ([https://www.mongodb.com/](https://www.mongodb.com/))
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Messaging infrastructure:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: RabbitMQ streams ([https://www.rabbitmq.com/docs/streams](https://www.rabbitmq.com/docs/streams))
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Apache Kafka ([https://kafka.apache.org/](https://kafka.apache.org/))
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: It is important to mention that using these tools does not automatically make
    CQRS or Event Sourcing work in your system. Your current framework and infrastructure
    may already be ready for these architecture styles, as long as the team implements
    the system using the semantics of CQRS and Event Sourcing.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We began by covering the classic CRUD architecture and its limitations. Then,
    we introduced Event Sourcing as an alternative approach to managing data and explored
    its history. We delved into how a team can decide whether Event Sourcing should
    be considered in their systems.
  prefs: []
  type: TYPE_NORMAL
- en: We used the real-life example of villagers exchanging services to demonstrate
    how Event Sourcing can be implemented. We also briefly laid out a plan for how
    a CRUD system can migrate to Event Sourcing.
  prefs: []
  type: TYPE_NORMAL
- en: Afterward, we moved to the topic of CQRS architecture. We discussed using commands
    as write operations and queries as read operations. We mentioned the basic constructs
    of CQRS and how they relate to the DDD and Event Sourcing architectures. We saw
    a side-by-side comparison of CRUD and CQRS in breaking down multiple update operations.
  prefs: []
  type: TYPE_NORMAL
- en: We then discussed using both CQRS and Event Sourcing. We described how these
    two architectures complement each other with the extension of the real-life example.
  prefs: []
  type: TYPE_NORMAL
- en: Lastly, we briefly covered using the Outbox pattern with CQRS and Event Sourcing.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we are going to discuss the idempotence, replication, and
    recovery aspects of distributed systems.
  prefs: []
  type: TYPE_NORMAL
