- en: <st c="0">12</st>
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: <st c="3">Being Smart with Apple Intelligence and ML</st>
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: <st c="46">The launch of ChatGPT in November 2022 wasn’t the first appearance
    of an</st> **<st c="120">Artificial Intelligence</st>** <st c="143">(</st>**<st
    c="145">AI</st>**<st c="147">) tool, but it was the one that put the AI in</st>
    <st c="194">the spotlight.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="208">Some may argue that Apple entered the AI world later than others.</st>
    <st c="275">Perhaps, but what’s certain is that iOS has machine-learning capabilities
    for both users</st> <st c="364">and developers.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="379">Machine learning opens up new capabilities in almost every area
    we can think of – from search, statistics, and insights to understanding images
    and sounds.</st> <st c="536">There are even apps that are based on AI and machine</st>
    <st c="589">learning capabilities.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="611">Currently, most of these capabilities are server-based.</st> <st
    c="668">Still, the ongoing improvements in mobile phones’</st> **<st c="718">System
    On Chip</st>** <st c="732">(</st>**<st c="734">SoC</st>**<st c="737">) performance
    allow them to perform predictions on-device, which opens up</st> <st c="812">new
    opportunities.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="830">In this chapter, we will do</st> <st c="859">the following:</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="873">Cover the basics of AI and machine learning, learn the different
    terms, how machine learning works, and what it means to train</st> <st c="1001">a
    model</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="1008">Explore built-in machine learning frameworks such as</st> **<st
    c="1062">Natural Language Processing</st>** <st c="1089">(</st>**<st c="1091">NLP</st>**<st
    c="1094">), vision, and</st> <st c="1110">sound analysis</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="1124">Add a semantic search to our Core</st> <st c="1159">Spotlight implementation</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="1183">Build and integrate a custom machine learning model using the Create</st>
    **<st c="1253">Machine Learning</st>** <st c="1269">(</st>**<st c="1271">ML</st>**<st
    c="1273">) application and the Core</st> <st c="1301">ML framework</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="1313">Machine learning is a vast topic, and we’ve got much to cover,
    so let’s jump right in to understand</st> <st c="1414">the basics.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="1425">Technical requirements</st>
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: <st c="1448">You must download Xcode version 16.0 or above for this chapter
    from Apple’s</st> <st c="1525">App Store.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="1535">You’ll also need to run the latest version of macOS (Ventura or
    above).</st> <st c="1608">Search for</st> `<st c="1619">Xcode</st>` <st c="1624">in
    the App Store and select and download the latest version.</st> <st c="1686">Launch
    Xcode and follow any additional installation instructions that your system may
    prompt you with.</st> <st c="1789">Once Xcode has fully launched, you’re ready</st>
    <st c="1833">to go.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="1839">This chapter includes many code examples, some of which can be
    found in the following GitHub</st> <st c="1933">repository:</st> [<st c="1945">https://github.com/PacktPublishing/Mastering-iOS-18-Development/tree/main/Chapter12</st>](https://github.com/PacktPublishing/Mastering-iOS-18-Development/tree/main/Chapter12)<st
    c="2028">.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="2029">Note that some examples in this chapter need to be run on a device,
    not</st> <st c="2102">the simulator.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="2116">Going over the basics of AI and machine learning</st>
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: <st c="2165">Before we dive in, let’s acknowledge the complexity – AI and machine
    learning are two huge topics that are impossible to cover in one chapter or even</st>
    <st c="2316">one book.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="2325">However, it is recommended that we</st> <st c="2360">understand
    the basics if we want to implement some machine-learning</st> <st c="2429">capabilities
    in</st> <st c="2445">our projects.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="2458">So, let’s start with understanding the difference between machine
    learning</st> <st c="2534">and AI.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="2541">Learning the differences between AI and machine learning</st>
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: <st c="2598">AI is considered a rising topic in computer</st> <st c="2642">science,
    and this trend has been accelerated</st> <st c="2687">since the launch</st> <st
    c="2705">of</st> **<st c="2708">ChatGPT</st>**<st c="2715">.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="2716">Even though ML is not a new technology, many</st> <st c="2761">people
    still need clarification about the difference between ML and AI.</st> <st c="2834">It’s
    not that they are not related –they are.</st> <st c="2880">Still, as iOS professional
    developers, it is essential to have a clear overview of the differences now that
    Apple has integrated AI deeply into</st> <st c="3024">its system.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="3035">So, what is ML?</st> <st c="3052">ML technology focuses on developing
    algorithms and statistical models to help computers perform tasks such as prediction
    and classification.</st> <st c="3193">For example, a model can receive an image
    and reply whether it contains a cat, or a model can take some text and locate
    the verbs and</st> <st c="3327">the nouns.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="3337">The ML model is an algorithm that performs its predictions and
    classifications.</st> <st c="3418">In fact, a model can use several algorithms
    to perform its calculations.</st> <st c="3491">For example, a vision model can
    use neural networks to</st> <st c="3545">perform its image classification and
    a</st> **<st c="3585">YOLO</st>** <st c="3589">(</st>**<st c="3591">You Only Look
    Once</st>**<st c="3609">) algorithm to perform</st> <st c="3633">real-time object
    detection.</st> <st c="3661">Each algorithm has its strengths and weaknesses.</st>
    <st c="3710">For</st> <st c="3714">example, the decision tree algorithm is easy
    to interpret but is prone to overfitting, while</st> **<st c="3807">KNN</st>**
    <st c="3810">(</st>**<st c="3812">K-Nearest Neighbors</st>**<st c="3831">) is
    simple and intuitive but</st> <st c="3862">computationally intensive.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="3888">Conversely, AI is an array of technologies and methods that create
    a system capable of performing tasks similar to what humans</st> <st c="4016">usually
    do.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="4027">One great</st> <st c="4038">example is</st> **<st c="4049">LLM</st>**
    <st c="4052">(</st>**<st c="4054">Large Language Model</st>**<st c="4074">) services
    such as</st> **<st c="4094">ChatGPT</st>** <st c="4101">or</st> **<st c="4105">Gemini</st>**<st
    c="4111">. Another example is the autonomous car driving projects that involve
    many</st> <st c="4185">ML models, such as object detection</st> <st c="4222">and
    decision-making.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="4242">We now understand that the ML model is one building block in AI.</st>
    <st c="4308">Next, let’s dive into the ML model to understand how</st> <st c="4361">it
    works.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="4370">Delving into the ML model</st>
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: <st c="4396">The</st> **<st c="4401">ML model</st>** <st c="4409">contains data
    to generate a prediction, classification, or decision.</st> <st c="4479">The ML
    models we want to store on a device are relatively small.</st> <st c="4544">However,
    models such as GPT can be hundreds</st> <st c="4588">of gigabytes.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="4601">But what does</st> *<st c="4616">data</st>* <st c="4620">mean here?</st>
    <st c="4632">How is it</st> <st c="4642">structured?</st> <st c="4654">The answer
    to that question depends on a model’s algorithms.</st> <st c="4715">For example,
    if the model uses a linear regression algorithm, the data structure is a 2D array,
    where the rows represent samples and the columns represent features.</st> <st
    c="4880">A model with a</st> **<st c="4895">decision tree algorithm</st>** <st
    c="4918">contains a tree, where the leaves</st> <st c="4952">represent the different
    decisions</st> <st c="4987">or predictions.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="5002">Going forward in this chapter, we will refer to building and creating
    a model’s data as training.</st> <st c="5101">Let’s discuss that</st> <st c="5120">important
    topic.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="5136">Traini</st><st c="5143">ng the model</st>
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: <st c="5156">Two distinct ML models can have the same algorithms and structures,
    but the data can differ because of the training</st> <st c="5273">process.</st>
    <st c="5282">Using the training process, we teach a model to make accurate predictions
    and decisions based on the input data.</st> <st c="5395">This process involves
    optimizing the model’s data (parameters) to accurately perform predictions on</st>
    <st c="5495">unseen data.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="5507">There are several steps we need to do to train</st> <st c="5555">a
    model:</st>
  prefs: []
  type: TYPE_NORMAL
- en: '**<st c="5563">Data collection</st>**<st c="5579">: We need to prepare a relatively
    large dataset to train our model.</st> <st c="5648">We must also preprocess the
    data by handling missing values, cleaning unrelated data items, and</st> <st c="5744">normalizing
    values.</st>'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**<st c="5763">Split the data collection</st>**<st c="5789">: Now that we have
    the dataset, we must divide it into training data, validation, and test sets.</st>
    <st c="5887">We use each of these sets in a different</st> <st c="5928">training
    stage.</st>'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**<st c="5943">Pick our ML algorithm</st>**<st c="5965">: Each algorithm aims
    to solve a different problem.</st> <st c="6018">For example, the logistic regression
    algorithm solves classification problems, and the linear regression algorithm
    solves</st> <st c="6140">regression problems.</st>'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**<st c="6160">Forward pass</st>**<st c="6173">: We pass the training data
    through the model to</st> <st c="6223">make predictions.</st>'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**<st c="6240">Validation</st>**<st c="6251">: We use validation datasets to
    assess the model’s performance and adjust the model based on</st> <st c="6345">the
    results.</st>'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**<st c="6357">Testing</st>**<st c="6365">: We use the test data to evaluate
    our model’s performance in real-time use cases with unseen</st> <st c="6460">input
    data.</st>'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: <st c="6471">That was a schematic overview of the training process.</st> <st
    c="6527">In practice, the process contains even more steps, such as calculating
    loss and optimizations.</st> <st c="6622">However, the goal is to give you a glimpse
    into training so that you can understand the following topics.</st> <st c="6728">And
    don’t worry – we will build and train an ML model</st> <st c="6782">together soon!</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="6796">Now that we know what an ML model is, let’s try to understand how
    it relates</st> <st c="6874">to iOS.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="6881">Apple intelligence and ML</st>
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: <st c="6907">When ChatGPT gained popularity, many felt Apple had fallen behind
    in AI and ML.</st> <st c="6988">This book is not the place to discuss that</st>
    <st c="7030">question; suffice it to say that ML has since been</st> <st c="7081">an
    integral part of iOS for years.</st> <st c="7117">iOS uses ML to optimize our
    photos according to their content.</st> <st c="7180">Keyboard predictions involve
    ML models, and even the way iOS preserves a battery is based</st> <st c="7270">on
    ML.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="7276">All these features and capabilities are transparent to users and
    performed under the hood.</st> <st c="7368">However, iOS 18 brought AI into the
    spotlight with many features, such as an improved Siri, an image playground, and</st>
    <st c="7485">writing tools.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="7499">iOS 18 also provided some neat capabilities for us developers,
    but it especially brought the areas of ML and AI to our attention.</st> <st c="7630">For
    example, semantic search is one of the new capabilities available to</st> <st
    c="7702">developers using iOS</st> <st c="7724">ML features.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="7736">Before we dive into</st> <st c="7757">Core ML and learn how to
    train our models, let’s start with the models that come with the iOS SDK, as there
    is a good chance that that is where we’ll find what we need quickly without training
    a</st> <st c="7952">new model.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="7962">Exploring built-in ML frameworks</st>
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: <st c="7995">When we reviewed the</st> <st c="8016">basics of AI and ML, we
    saw what it means to train a model – it’s a long and complex process.</st> <st
    c="8111">This process requires us to prepare relatively big datasets, including
    the validation and test datasets.</st> <st c="8216">Even after that, we have an
    ML model we need to fine-tune and include in our app while trying to reduce</st>
    <st c="8320">its size.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="8329">However, don’t get me wrong.</st> <st c="8359">There are cases
    where training our ML model is essential, but before we start the training process,
    it’s important to be familiar with what</st> <st c="8499">iOS offers.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="8510">Working with ML frameworks in iOS isn’t new.</st> <st c="8556">These
    frameworks were introduced years ago, some even in iOS 10 (2016).</st> <st c="8628">However,
    few developers use them, perhaps because they believe they are complex</st> <st
    c="8708">to integrate.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="8721">We’ll start with one of the most practical frameworks in the</st>
    <st c="8782">ML toolset –</st> <st c="8796">NLP.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="8800">Interpreting text using NLP</st>
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: <st c="8828">Interpreting and understanding texts can</st> <st c="8870">provide
    significant value to many</st> <st c="8904">apps.</st> <st c="8910">For example,
    NLP can help us understand strings such as search phrases, text inputs, or extracting
    information from an</st> <st c="9029">imported text.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="9043">The iOS SDK has a built-in NLP framework</st> <st c="9085">called</st>
    `<st c="9092">NaturalLanguage</st>`<st c="9107">:</st>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: <st c="9132">The</st> `<st c="9137">NaturalLanguage</st>` <st c="9152">framework
    helps us interpret text efficiently on</st> <st c="9202">a device.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="9211">We must first know how NLP works under the hood and its basic terms
    to understand how</st> <st c="9298">it works.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="9307">The NLP model works</st> <st c="9328">by finding relationships</st>
    <st c="9352">between different parts of texts.</st> <st c="9387">Even though this
    task is complex, it’s interesting to see how</st> <st c="9449">it works.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="9458">Understanding how NLP works</st>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: <st c="9486">The NLP process involves text</st> <st c="9517">processing and
    several algorithms to extract the necessary information.</st> <st c="9589">There
    are three basic steps –</st> **<st c="9619">preprocessing</st>**<st c="9632">,</st>
    **<st c="9634">feature extraction</st>**<st c="9652">, and</st> **<st c="9658">modeling</st>**<st
    c="9666">. Let’s go over them one</st> <st c="9690">by one.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="9698">Preprocessing</st>
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: <st c="9712">In this step, the NLP model starts by</st> <st c="9751">cleaning
    the input, such as removing duplicates, splitting texts into words and sentences,
    converting text to lowercase, and performing stemming and lemmatization.</st>
    <st c="9915">Take the following text as</st> <st c="9942">an example:</st>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: <st c="9986">This will be preprocessed to someth</st><st c="10022">ing like</st>
    <st c="10032">the following:</st>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: <st c="10066">In this example, the NLP removed stop words (such as</st> `<st
    c="10120">is</st>`<st c="10122">) and lowercased the</st> <st c="10144">whole
    string.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="10157">Feature extraction</st>
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: <st c="10176">After the string has been preprocessed, we transform it into a
    feature set that we can use with the ML algorithm.</st> <st c="10291">In most</st>
    <st c="10299">cases, this involves capturing different patterns and word frequencies.</st>
    <st c="10371">For example, the string from the previous step,</st> `<st c="10419">run
    fun love run</st>`<st c="10435">, can be transformed into</st> <st c="10461">the
    following:</st>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: <st c="10509">In this example, the NLP model takes the input string and analyzes
    the frequency of each word.</st> <st c="10605">This technique is called</st> **<st
    c="10630">Bag of Words</st>** <st c="10642">(</st>**<st c="10644">BoW</st>**<st
    c="10647">), and the model uses it to determine the importance of the different</st>
    <st c="10718">words in the string.</st> <st c="10739">Note there are many feature
    extraction techniques, and BoW is just an example.</st> <st c="10818">We can select
    the model now that we have the feature</st> <st c="10871">extraction data.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="10887">Modeling</st>
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: <st c="10896">In the modeling step, we use string and</st> <st c="10937">feature
    extraction as input to the model algorithm.</st> <st c="10989">NLP uses several
    algorithms to analyze the string – logistic regression, naïve Bayes, and a neural
    network.</st> <st c="11097">The algorithm that the model selects depends on the
    task it needs</st> <st c="11163">to achieve.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="11174">For example, if the NLP framework needs to perform sentiment analysis,
    it would use a neural network-based model.</st> <st c="11289">Simple text processing
    tasks would use a rule-based</st> <st c="11341">system model.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="11354">These three steps demonstrate how complex it is to interpret a
    simple text.</st> <st c="11431">Fortunately, the</st> `<st c="11448">NaturalLanguage</st>`
    <st c="11463">framework performs all of these steps</st> <st c="11502">for us.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="11509">Let’s see how to use the</st> `<st c="11535">NaturalLanguage</st>`
    <st c="11550">framework API.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="11565">Using the NaturalLanguage API</st>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: <st c="11595">Finally, we are going to write some code!</st> <st c="11638">The</st>
    `<st c="11642">NaturalLanguage</st>` <st c="11657">framework has two primary uses
    – classification</st> <st c="11706">and word tagging.</st> <st c="11724">Let’s
    start</st> <st c="11736">with classification.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="11756">Text classification</st>
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: <st c="11776">Using</st> **<st c="11783">text classification</st>**<st c="11802">,
    we can analyze the</st> <st c="11822">text sentiment to determine whether it is
    positive</st> <st c="11874">or negative.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="11886">For example, let’s take</st> <st c="11911">a look at the</st>
    <st c="11925">following text:</st>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: <st c="12001">To analyze the sentiment of this sentence using the</st> `<st
    c="12054">NaturalLanguage</st>` <st c="12069">framework, we’ll use the</st> `<st
    c="12095">NLTagger</st>` <st c="12103">class:</st>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '`<st c="12483">NLTagger</st>` <st c="12492">is the primary class we use to
    process texts in NLP.</st> <st c="12546">When we initialize it, we pass the information
    we are interested in.</st> <st c="12615">In our example, we passed</st> `<st c="12641">sentimentScore</st>`
    <st c="12655">– a scheme that helps us determine the</st> <st c="12695">text sentiment.</st>'
  prefs: []
  type: TYPE_NORMAL
- en: <st c="12710">Our next step is to set the text input and call the tag function
    while passing relevant parameters, such as range, unit type, and scheme we want
    it</st> <st c="12859">to analyze.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="12870">The tag function performs the text analysis and returns a score
    between -1 and 1, where a negative score indicates a negative sentiment and a
    positive score indicates a</st> <st c="13040">positive sentiment.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="13059">If we run this code on</st> <st c="13082">our example sentence
    before the code example, we’ll get a score of 1.0 – an extremely</st> <st c="13169">positive
    text!</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="13183">Even though text classification is very easy to use, it is also
    very powerful.</st> <st c="13263">We can use this capability to analyze user feedback/reviews,
    chatbots, and surveys and even adapt an interface, based on the user’s sentiments</st>
    <st c="13406">and emotions.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="13419">We mentioned that text classification is all about understanding
    the text sentiment.</st> <st c="13505">However, we can use NLP to analyze text
    using</st> <st c="13551">word tagging.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="13564">Word tagging</st>
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '**<st c="13577">Word tagging</st>** <st c="13590">is the process of breaking
    a text into components and assigning tags to each phrase in the text, indicating
    its</st> <st c="13702">grammatical category.</st>'
  prefs: []
  type: TYPE_NORMAL
- en: <st c="13724">Let’s take the</st> <st c="13739">example of the</st> <st c="13755">following
    text:</st>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: <st c="13810">If we try to break this sentence into grammatical categories,
    it will be something like</st> *<st c="13898">She</st>* <st c="13902">(pronoun),</st>
    *<st c="13914">enjoys</st>* <st c="13920">(verb),</st> *<st c="13929">reading</st>*
    <st c="13936">(verb),</st> *<st c="13945">books</st>* <st c="13950">(noun),</st>
    *<st c="13959">in</st>* <st c="13961">(preposition),</st> *<st c="13977">the</st>*
    <st c="13980">(determiner), and</st> *<st c="13999">library</st>* <st c="14006">(noun).</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="14014">The different parts of the</st> <st c="14041">text are called</st>
    **<st c="14058">tokens</st>**<st c="14064">, and their grammatical category is</st>
    <st c="14100">called</st> <st c="14107">a</st> **<st c="14109">tag</st>**<st c="14112">.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="14113">The</st> `<st c="14118">NaturalLanguage</st>` <st c="14133">framework
    helps us perform tokenization and tag</st> <st c="14182">its tokens.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="14193">Let’s look at the</st> <st c="14212">following code:</st>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: <st c="14657">The preceding code example takes the same sentence as earlier,
    tokenizes it, and locates the first verb</st> <st c="14762">it finds.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="14771">We start by initializing</st> `<st c="14797">NLTagger</st>`<st
    c="14805">, similar to what we did in text classification.</st> <st c="14854">However,
    we do that this time by passing</st> `<st c="14895">lexicalClass</st>` <st c="14907">as</st>
    <st c="14911">its scheme.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="14922">Then, we provide the input</st> <st c="14949">text and omit punctuation
    and whitespaces.</st> <st c="14993">We do this because we want our text to be
    as clean as possible.</st> `<st c="15057">NLTagger</st>` <st c="15065">can catch
    extra whitespace characters and punctuation as</st> <st c="15123">additional tags.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="15139">After we clean our text, we call the</st> `<st c="15177">enumerateTags</st>`
    <st c="15190">function.</st> <st c="15201">This function iterates the words in
    the text within a given range and extracts the different tags.</st> <st c="15300">We
    compare the tag type inside the passed closure and store it in an</st> <st c="15369">instance
    variable.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="15387">In our example, we locate the first verb, which</st> <st c="15436">is</st>
    `<st c="15439">enjoys</st>`<st c="15445">.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="15446">Although word tagging and text classification are</st> `<st c="15497">NLTagger</st>`<st
    c="15505">’s two primary use cases, they can also be used for additional cases,
    such as to identify a</st> <st c="15598">text’s language:</st>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: <st c="15875">In the preceding example, the</st> `<st c="15906">NLTagger</st>`
    <st c="15914">receives input text and extracts its language.</st> <st c="15962">It
    can identify 50 different languages – impressive for an on-device</st> <st c="16031">NLP
    model!</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="16041">We can use language identification</st> <st c="16076">to identify
    the user locale and offer to change an app’s preferred language, or we can send
    that information as analytics data to</st> <st c="16207">our servers.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="16219">Another great example of NLP is</st> **<st c="16252">word embedding</st>**<st
    c="16266">. This feature can help our application</st> <st c="16306">become smarter.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="16321">Each word in the dictionary is related to other</st> <st c="16369">words.</st>
    <st c="16377">For example,</st> *<st c="16390">house</st>* <st c="16395">is related
    to</st> *<st c="16410">building</st>* <st c="16418">and</st> *<st c="16423">apartment</st>*<st
    c="16432">, and</st> *<st c="16438">cat</st>* <st c="16441">is associated</st>
    <st c="16456">with</st> *<st c="16461">dog</st>*<st c="16464">.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="16465">We can easily find related words, using a class</st> <st c="16514">called</st>
    `<st c="16521">NLEmbedding</st>`<st c="16532">:</st>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: <st c="16930">In the preceding example,</st> `<st c="16957">NLEmbedding</st>`
    <st c="16968">receives an input test, calculates its vector, and finds its closed
    neighbors.</st> <st c="17048">If you ask yourself why this is practical, think
    of a search engine that can find related content even if it isn’t exactly what
    the user</st> <st c="17185">searched for.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="17198">In this section, we analyzed text using the</st> `<st c="17243">NaturalLanguage</st>`
    <st c="17258">framework.</st> <st c="17270">We’ve learned how NLP works, how to
    classify text, and extract additional information such as word tagging and even</st>
    <st c="17385">word embedding.</st> <st c="17402">However, iOS apps contain more
    than just text; they also include images.</st> <st c="17475">Can we analyze images</st>
    <st c="17497">as well?</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="17505">Analyzing images using the Vision framework</st>
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: <st c="17549">Analyzing images is a fundamental</st> <st c="17584">topic in
    iOS apps.</st> <st c="17603">There are many use cases for analyzing images, such
    as detecting barcodes, scanning documents, or</st> <st c="17701">image editing.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="17715">To analyze images in iOS, we need to</st> <st c="17753">use Apple’s
    Vision framework.</st> <st c="17783">Introduced in 2017 with the release of iOS
    11, the Vision framework provides</st> <st c="17860">high-level functionality
    to perform various image</st> <st c="17910">analysis tasks.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="17925">Understanding how image analysis works</st>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: <st c="17964">In a way, image analysis works similarly to text analysis, working
    with different steps that clean and prepare</st> <st c="18076">data before inserting
    it into</st> <st c="18106">a model.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="18114">The image analysis works with a</st> **<st c="18147">CNN</st>**
    <st c="18150">(</st>**<st c="18152">Convolutional Neural Network</st>**<st c="18180">),
    a neural network designed for</st> <st c="18214">visual data.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="18226">Consider CNN as a series of filters that can help a model better
    understand an image.</st> <st c="18313">CNN will perform a similar process if
    the</st> `<st c="18355">NaturalLanguage</st>` <st c="18370">model preprocessed
    the text, removing whitespace and</st> <st c="18424">duplicate words.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="18440">First, the CNN scans an image to detect similar patterns, such
    as lines, edges, and textures.</st> <st c="18535">It then filters out what it
    thinks are non-important features and shrinks the image to contain the most</st>
    <st c="18639">essential information.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="18661">Now that we have a smaller and cleaner image, the CNN tries to
    decide what the image is – for example, “</st>*<st c="18766">It’s</st>* *<st c="18772">a
    cat.</st>*<st c="18778">”</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="18780">Detecting patterns and edges, filtering them, and analyzing an
    image are complex techniques that require</st> <st c="18884">extensive training.</st>
    <st c="18905">Luckily, the Vision framework performs all the heavy lifting</st>
    <st c="18966">for us.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="18973">Let’s see what it can do</st> <st c="18999">for us.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="19006">Exploring the Vision Framework’s capabilities</st>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: <st c="19052">Since starting iOS 18, the</st> **<st c="19080">Vision framework
    API</st>** <st c="19100">has become extremely simple yet even</st> <st c="19138">more
    powerful.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="19152">To understand how the</st> <st c="19174">Vision framework API
    works, we need to remember that it is based on two types – request</st> <st c="19263">and
    observation.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="19279">To perform an image analysis, we first create a</st> **<st c="19328">request</st>**<st
    c="19335">. Then, we request the specific image and receive an</st> **<st c="19388">observation</st>**
    <st c="19399">containing the result (if we</st> <st c="19429">have any).</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="19439">Let’s take two popular use cases – detecting barcodes</st> <st
    c="19494">and faces.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="19504">Detecting barcodes</st>
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: <st c="19523">Look at the following code to</st> <st c="19553">see barcode detecting</st>
    <st c="19576">in action:</st>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: <st c="19875">The preceding code block performs</st> <st c="19909">barcode detection
    using the Vision framework.</st> <st c="19956">First, we create</st> `<st c="19973">DetectBarcodesRequest</st>`<st
    c="19994">, which represents a request to scan barcodes in a given</st> <st c="20051">image
    URL.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="20061">Then, we call the request’s</st> `<st c="20090">perform</st>`
    <st c="20097">function, which returns an array of observations in the case of</st>
    <st c="20162">several barcodes.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="20179">Next, we take the first observation payload and store it in a
    variable.</st> <st c="20252">That payload represents the</st> <st c="20280">barcode
    identifier.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="20299">Note that the scanning operation can be a heavy task, which is
    why it is an</st> <st c="20376">asynchronous function.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="20398">Another interesting example of a Vision framework usage is detecting
    faces in an image – let’s see</st> <st c="20498">an example.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="20509">Detecting faces</st>
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: <st c="20525">Detecting faces works similarly to</st> <st c="20561">detecting
    barcodes.</st> <st c="20581">Let’s see a</st> <st c="20593">code example:</st>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: <st c="20881">The preceding code example looks almost identical to the previous
    barcode example.</st> <st c="20965">First, we create the request.</st> <st c="20995">However,
    this time, the request is from type</st> `<st c="21040">DetectFaceRectanglesRequest</st>`<st
    c="21067">. Next, we perform the detection operation on the given image URL and
    retrieve an array of observations.</st> <st c="21172">Each observation instance
    contains a rectangle of one</st> <st c="21225">of the faces in the image.</st>
    <st c="21253">If the image contains multiple faces, we’ll get one observation
    for</st> <st c="21321">each face.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="21331">Face detection and barcodes are two common examples of Vision
    framework use cases.</st> <st c="21415">However, the Vision framework is full
    of surprises and detection capabilities.</st> <st c="21494">Let’s see what else
    we can do</st> <st c="21524">with it.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="21532">Exploring more detection capabilities</st>
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: <st c="21570">As mentioned, the Vision framework is full of machine-learning
    models capable of detecting almost anything we want.</st> <st c="21687">Barcodes</st>
    <st c="21696">and faces are just the tip of</st> <st c="21726">the iceberg.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="21738">Here’s a list of</st> <st c="21756">additional detectors:</st>
  prefs: []
  type: TYPE_NORMAL
- en: '**<st c="21777">Image aesthetics analysis</st>**<st c="21803">: For analyzing
    an image from an</st> <st c="21837">aesthetic viewpoint</st>'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**<st c="21856">Saliency analysis</st>**<st c="21874">: For finding the most
    important object in</st> <st c="21918">an image</st>'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**<st c="21926">Object tracking</st>**<st c="21942">: For tracking an object’s
    movement across a sequence</st> <st c="21997">of images</st>'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**<st c="22006">Body detection</st>**<st c="22021">: Similar to face detection,
    for locating arms, humans, eyes, a mouth, and a nose</st> <st c="22104">in images</st>'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**<st c="22113">Body and hand pose</st>**<st c="22132">: For locating arms
    in an image as well as detecting</st> <st c="22186">their pose.</st>'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**<st c="22197">Text detection</st>**<st c="22212">: For detecting text in</st>
    <st c="22237">an image</st>'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**<st c="22245">Animal detection</st>**<st c="22262">: For detecting cats and
    dogs in an image as well as</st> <st c="22316">their pose</st>'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**<st c="22326">Background removal and object extraction</st>**<st c="22367">:
    For removing the background and extracting objects</st> <st c="22421">from images</st>'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="22432">The list of the different request types looks impressive, which
    it is.</st> <st c="22504">Reviewing the requests reflects how powerful the Vision
    framework has become.</st> <st c="22582">We can see capabilities usually reserved
    for</st> <st c="22627">high-end image editing applications, such as background
    removal or object extraction, now available with just three lines</st> <st c="22749">of
    code.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="22757">This opens up new possibilities for unique features in our apps,
    such as working with a camera or prioritizing images based on</st> <st c="22885">their
    information.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="22903">We’ve discussed analyzing text and images, which are considered
    the most common data sources we usually use.</st> <st c="23013">The text and image
    analysis techniques are different but straightforward</st> <st c="23086">to implement.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="23099">Now, let’s turn to a different type of source we can analyze –</st>
    <st c="23163">sound.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="23169">Classifying audio using the Sound Analysis framework</st>
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: <st c="23222">Working with audio is not a popular</st> <st c="23259">expertise
    for many developers.</st> <st c="23290">In fact, audio is considered to be a complex
    and unique</st> <st c="23346">world compared to what we developers are</st> <st
    c="23387">used to.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="23395">To mitigate this, the iOS SDK also includes an analysis framework
    that can classify audio using</st> <st c="23492">ML models.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="23502">Working with the</st> **<st c="23520">Sound Analysis framework</st>**
    <st c="23544">differs from the simplicity we are used to with the Vision framework.</st>
    <st c="23615">But don’t worry – it is still simple</st> <st c="23652">to use.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="23659">The Sound Analysis framework contains three</st> <st c="23704">different
    components:</st>
  prefs: []
  type: TYPE_NORMAL
- en: '**<st c="23725">SNAudioFileAnalyzer</st>**<st c="23745">: The main class that
    coordinates the</st> <st c="23784">analysis work</st>'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**<st c="23797">SNClassifySoundRequest</st>**<st c="23820">: The sound</st>
    <st c="23833">detection request</st>'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**<st c="23850">SNResultsObserving</st>**<st c="23869">: A protocol we need
    to implement to observe the results from</st> <st c="23932">the analyzer</st>'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="23944">To see these three components in action, take a look at the</st>
    <st c="24005">following code:</st>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: <st c="24396">In this example, we first</st> <st c="24422">create the</st> `<st
    c="24434">SNAudioFileAnalyzer</st>` <st c="24453">instance and initialize it with
    a URL to the audio file.</st> <st c="24511">Then, we create a request for a classification
    sound request, passing</st> `<st c="24581">version1</st>` <st c="24589">as a</st>
    <st c="24595">parameter.</st> <st c="24606">The</st> `<st c="24610">version1</st>`
    <st c="24618">parameter specifies the pre-trained classification version of the
    model.</st> <st c="24692">At the time of writing, no additional versions</st>
    <st c="24739">are available.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="24753">Then, we create the</st> `<st c="24774">resultsObserver</st>`
    <st c="24789">instance (which we’ll discuss briefly) and coordinate everything
    together, using the analyzer we</st> <st c="24887">created earlier.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="24903">How do we get the results?</st> <st c="24931">Unlike the Vision</st>
    <st c="24948">framework, receiving the results can be streamlined.</st> <st c="25002">The</st>
    `<st c="25006">ClassificationResultsObserver</st>` <st c="25035">is a custom class
    that conforms to</st> `<st c="25071">SNResultsObserving</st>`<st c="25089">. Let’s
    look at the</st> <st c="25109">class implementation:</st>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: <st c="25552">The</st> `<st c="25557">SNResultsObserving</st>` <st c="25575">protocol
    has three essential request methods –</st> `<st c="25623">didProduce</st>`<st
    c="25633">,</st> `<st c="25635">didFailWithError</st>`<st c="25651">,</st> <st
    c="25653">and</st> `<st c="25657">requestDidComplete</st>`<st c="25675">.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="25676">Great!</st> <st c="25684">However, unfortunately, in this case,
    it seems like we need to go back in time and use the delegate pattern to</st>
    <st c="25795">observe results from the Sound</st> <st c="25826">Analysis framework.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="25845">The result is a string describing the sound we passed to the analyzer.</st>
    <st c="25917">The code example in this book’s GitHub</st> <st c="25956">repository
    shows a sound file with a baby crying.</st> <st c="26006">In this case, the result
    would</st> <st c="26037">be</st> `<st c="26040">baby_crying</st>`<st c="26051">.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="26052">Apple has yet to officially publish the number of sound classes
    that the Sound Analysis framework can recognize.</st> <st c="26166">However, in
    most cases, this should be enough for</st> <st c="26216">day-to-day usage.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="26233">The Sound Analysis framework can be great for monitoring apps,
    adding</st> **<st c="26304">SDH</st>** <st c="26307">(</st>**<st c="26309">subtitles
    for the deaf or hard of hearing</st>**<st c="26350">) to video captions, and</st>
    <st c="26376">analyzing videos.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="26393">So far, we have discussed how to analyze</st> <st c="26435">different
    types of data – sound, images, and text.</st> <st c="26486">However, ML is valuable
    in other areas, such as</st> <st c="26534">app search.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="26545">Performing a semantic search with Core Spotlight</st>
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: <st c="26594">When we discussed NLP in the</st> *<st c="26624">Interpreting
    text using NLP</st>* <st c="26651">section, we said that one of the most common
    NLP</st> <st c="26701">use cases is analyzing a search</st> <st c="26732">phrase
    to build intelligent</st> <st c="26761">search queries.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="26776">Even though the</st> `<st c="26793">NaturalLanguage</st>` <st
    c="26808">Framework API is robust and straightforward, performing a semantic search
    is</st> <st c="26885">considered a</st> <st c="26899">complex task.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="26912">Starting iOS 18, the Core Spotlight framework supports a semantic
    search.</st> <st c="26987">Before we dive into the details, let’s clarify the
    term</st> **<st c="27043">semantic search</st>**<st c="27058">.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="27059">Understanding what semantic search is</st>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: <st c="27097">Let’s think together about how</st> <st c="27128">search queries
    work in a standard app, and we’ll do that using</st> <st c="27192">an example.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="27203">Imagine that we have a course catalog app where a user can search
    for a particular course, and let’s say we have the following list of courses in
    our local</st> <st c="27360">data store:</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="27371">Management</st> <st c="27383">for employees</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="27396">Data science</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="27409">Digital marketing</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="27427">ML</st> <st c="27431">and AI</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="27437">Our user wants to improve their leadership skills, so they search
    for a management course within this list</st> <st c="27545">of courses.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="27556">The search query’s basic form is to match a specific phrase.</st>
    <st c="27618">For example, if the user searches for</st> `<st c="27656">management</st>`<st
    c="27666">, we filter only courses containing</st> *<st c="27702">management</st>*<st
    c="27712">. We also need to ensure that the output query</st> <st c="27759">is
    case-insensitive.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="27779">However, what if the user searches for</st> `<st c="27819">manager</st>`<st
    c="27826">? In this case, our query returns no results, even though a typical
    user can search for</st> *<st c="27914">manager</st>* <st c="27921">if they want
    a course</st> <st c="27944">about management.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="27961">In this case, we can use the</st> `<st c="27991">NaturalLanguage</st>`
    <st c="28006">framework to try and perform lemmatization of the search phrase.</st>
    **<st c="28072">Lemmatization</st>** <st c="28085">is a technique that reduces
    words to their basic form.</st> <st c="28141">So, the basic</st> <st c="28155">form
    of</st> *<st c="28163">manager</st>* <st c="28170">is</st> *<st c="28174">manage</st>*<st
    c="28180">.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="28181">However, if we want to match the search phrase</st> *<st c="28229">manage</st>*<st
    c="28235">, we also need all our records with the word</st> *<st c="28280">management</st>*
    <st c="28290">to contain the word</st> *<st c="28311">manage</st>* <st c="28317">so
    that we can filter the results accordingly.</st> <st c="28365">It means we must
    maintain the basic form for each word in</st> <st c="28423">each record.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="28435">But things can get</st> <st c="28455">even more complex than that.</st>
    <st c="28484">What if the user searches for a management course using the phrase</st>
    *<st c="28551">leadership</st>*<st c="28561">? In this case, we will have to index
    our records with embedded words, as we learned in the</st> *<st c="28653">Word
    tagging</st>* <st c="28665">section of</st> <st c="28677">this chapter.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="28690">The conclusion is that basic search is easy.</st> <st c="28736">However,
    semantic search, which is much more effective, is also much</st> <st c="28805">more
    complex.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="28818">As mentioned, semantic search is built on top of the</st> **<st
    c="28872">Core Spotlight framework</st>**<st c="28896">, starting with iOS 18\.</st>
    <st c="28920">The Core Spotlight</st> <st c="28938">framework is not new – it
    was introduced in 2015 as part of iOS 9 and helps developers index app content
    and make it searchable, using the Spotlight feature</st> <st c="29096">in iOS.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="29103">This chapter does not cover using the Core Spotlight framework.</st>
    <st c="29168">However, we will briefly review the Core Spotlight principles to
    understand how to enable semantic search.</st> <st c="29275">Let’s begin.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="29287">Exploring the Core Spotlight framework</st>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: <st c="29326">The Spotlight framework</st> <st c="29350">indexes local data
    and retrieves it by</st> <st c="29390">performing queries.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="29409">The Core Spotlight framework has three primary parts – creating
    searchable items, indexing, and querying.</st> <st c="29516">Let’s go through
    the parts one</st> <st c="29547">by one.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="29554">Creating searchable items</st>
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: <st c="29580">Let’s say we have instances of a</st> <st c="29614">book structure
    in our local storage and want to implement Core Spotlight to allow users to search</st>
    <st c="29712">for books.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="29722">First, we need to map all our</st> `<st c="29753">Book</st>` <st
    c="29757">instances</st> <st c="29768">to</st> `<st c="29771">CSSearchableItem</st>`<st
    c="29787">:</st>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: <st c="30123">In the preceding code example, we</st> <st c="30157">took an array
    of</st> `<st c="30175">Book</st>` <st c="30179">and mapped it to an array of</st>
    `<st c="30209">CSSearchableItem</st>`<st c="30225">. We do that by creating a</st>
    `<st c="30252">CSSearchableItemAttributeSet</st>` <st c="30280">– an item that
    contains general information about the searchable item.</st> <st c="30352">Then,
    we initialize a new</st> `<st c="30378">CSSearchableItem</st>`<st c="30394">,
    passing our</st> `<st c="30408">CSSearchableItemAttributeSet</st>` <st c="30436">and
    providing a unique identifier that can help us retrieve the</st> `<st c="30501">Book</st>`
    <st c="30505">record</st> <st c="30513">when needed.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="30525">Indexing</st>
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: <st c="30534">Now that we have an</st> <st c="30555">array of</st> `<st c="30564">CSSearchableItem</st>`<st
    c="30580">, we need to index the array items for the Core Spotlight framework.</st>
    <st c="30649">We do that by</st> <st c="30663">creating</st> `<st c="30672">CSSearchableIndex</st>`<st
    c="30689">:</st>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: <st c="30937">In the preceding example, we created a new</st> `<st c="30981">CSSearchableIndex</st>`
    <st c="30998">and called the</st> `<st c="31014">indexSearchableItems</st>` <st
    c="31034">function, with the array of</st> `<st c="31063">CSSearchableItem</st>`
    <st c="31079">that we made in the previous step.</st> <st c="31115">Note that</st>
    <st c="31124">this is an asynchronous operation and is considered to be</st> <st
    c="31183">quite intensive.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="31199">Querying</st>
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: <st c="31208">Now that we have an index, we</st> <st c="31239">can perform a
    query to retrieve data based on a</st> <st c="31287">search phrase:</st>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: <st c="31833">In the preceding example, we create a search context containing
    various query information.</st> <st c="31925">Based on the</st> <st c="31937">search
    context and the search phrase, we initialize an item of</st> `<st c="32001">CSUserQuery</st>`
    <st c="32012">and fetch the search results by calling its</st> `<st c="32057">responses</st>`
    <st c="32066">getter.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="32074">The results are an array of</st> `<st c="32103">CSSearchableItem</st>`<st
    c="32119">, and we can retrieve the original item by using the unique identifier
    for</st> <st c="32194">each record.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="32206">Now that we know how to implement search using the Core Spotlight
    framework, let’s see how to implement a</st> <st c="32313">semantic search.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="32329">Implementing semantic search</st>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: <st c="32358">Adding semantic search</st> <st c="32382">capabilities to an existing
    Core Spotlight search is simple.</st> <st c="32443">All we need to do is load
    the ML model once using the following</st> <st c="32507">static function:</st>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: <st c="32545">The</st> `<st c="32550">prepare</st>` <st c="32557">function prepares
    the Core Spotlight framework to load its ML models for</st> <st c="32631">semantic
    search.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="32647">If the search index has a protection level due to privacy concerns,
    we also need to call the</st> `<st c="32741">prepreProtectionClasses</st>` <st
    c="32764">function:</st>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: <st c="32834">This function prepares the search for indexes marked with the</st>
    `<st c="32897">completeUnlessOpen</st>` <st c="32915">protection level.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="32933">What are protection levels?</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="32961">The term</st> **<st c="32971">protection level</st>** <st c="32987">refers
    to the</st> <st c="33002">accessibility level where users have specific resources,
    considering the device’s</st> <st c="33084">security conditions.</st> <st c="33105">There
    are three primary</st> <st c="33129">protection levels:</st>
  prefs: []
  type: TYPE_NORMAL
- en: '<st c="33147">-</st> `<st c="33150">NSFileProtectionNone</st>`<st c="33170">:
    The index is always accessible, even when the device</st> <st c="33226">is locked</st>'
  prefs: []
  type: TYPE_NORMAL
- en: '<st c="33235">-</st> `<st c="33238">NSFileProtectionCompleteUntilFirstUserAuthentication</st>`<st
    c="33290">: Once the user is authenticated for the first time after a device restart,
    the index</st> <st c="33377">is accessible</st>'
  prefs: []
  type: TYPE_NORMAL
- en: '<st c="33390">-</st> `<st c="33393">NSFileProtectionComplete</st>`<st c="33417">:
    The index is accessible only when the device</st> <st c="33465">is unlocked</st>'
  prefs: []
  type: TYPE_NORMAL
- en: <st c="33476">Remember that preparing the ML models costs time and memory, so
    it’s better to call the</st> `<st c="33565">prepare</st>` <st c="33572">function
    only immediately before the search</st> <st c="33617">user interface.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="33632">We have discussed various</st> <st c="33659">built-in ML models,
    and we can see that they cover many use cases where we can use ML capabilities
    with our projects.</st> <st c="33777">However, there are cases where the iOS SDK
    doesn’t provide the exact ML solution we need.</st> <st c="33867">Luckily, we
    can integrate our models using the</st> <st c="33914">CoreML framework.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="33931">Integrating custom models using CoreML</st>
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: <st c="33970">Generally, ML models are trained to perform a specific task –
    recognizing a sentence’s sentiment, detecting humans, or analyzing sounds are
    all examples of different tasks done using various models.</st> <st c="34170">This</st>
    <st c="34175">means that even though the potential of the existing models is enormous,
    we are still limited in what we</st> <st c="34280">can do.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="34287">This is where the</st> **<st c="34306">CoreML framework</st>**
    <st c="34322">enters the</st> <st c="34334">picture.</st> <st c="34343">Using
    CoreML, we can integrate ML models that are not part</st> <st c="34402">of the
    iOS SDK, and we can even train our own models and add more</st> <st c="34468">intelligent
    capabilities.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="34493">It’s best to explain how to do this by using an example, such
    as detecting</st> <st c="34569">spam messages.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="34583">Imaging we are developing a messaging app.</st> <st c="34627">One
    of the most popular messaging app features is the ability to detect spam to improve
    the user experience and</st> <st c="34739">increase retention.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="34758">We must create an ML model to classify messages as spam to implement
    a</st> <st c="34830">spam detector.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="34844">To achieve this, we can use a desktop application called Create
    ML, which is part of the Xcode suite.</st> <st c="34947">Let’s begin by learning
    more about</st> <st c="34982">Create ML!</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="34992">Getting to know the Create ML application</st>
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**<st c="35034">Create ML</st>** <st c="35044">was introduced in 2018 as</st>
    <st c="35071">part of Apple’s ongoing effort to make ML more accessible to developers.</st>
    <st c="35144">We can build, train, and deploy ML models in various areas using</st>
    <st c="35209">Create ML.</st>'
  prefs: []
  type: TYPE_NORMAL
- en: <st c="35219">To open Create ML, follow</st> <st c="35246">these steps:</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="35258">Open Xcode.</st>
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: <st c="35270">Right-click on the Xcode icon on</st> <st c="35304">the dock.</st>
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: <st c="35313">Select</st> **<st c="35321">Open Developer Tool</st>** <st c="35340">|</st>
    **<st c="35343">Create ML</st>**<st c="35352">.</st>
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: <st c="35353">Another way to open</st> `<st c="35374">Create ML</st>` <st c="35383">is
    by searching for it in Spotlight on your Mac and</st> <st c="35436">selecting
    it.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="35449">After opening it and clicking on the</st> **<st c="35487">New
    Document</st>** <st c="35499">button, we get the following screen (</st>*<st c="35537">Figure
    12</st>**<st c="35547">.1</st>*<st c="35549">):</st>
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.1: The Create ML template picker](img/B21795_12_1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '<st c="36033">Figure 12.1: The Create ML template picker</st>'
  prefs: []
  type: TYPE_NORMAL
- en: '*<st c="36075">Figure 12</st>**<st c="36085">.1</st>* <st c="36087">shows the
    Create ML template picker screen.</st> <st c="36132">Each template represents
    a different configuration for our model, and each is designed to handle a different
    type of data.</st> <st c="36255">For example, the</st> **<st c="36272">Image Classification</st>**
    <st c="36292">template is designed to handle images.</st> <st c="36332">Since
    we want to classify</st> <st c="36358">text messages, we will pick the</st> **<st
    c="36390">Text Classification</st>** <st c="36409">template and click the</st>
    **<st c="36433">Next</st>** <st c="36437">button.</st>'
  prefs: []
  type: TYPE_NORMAL
- en: <st c="36445">This will take us to the project details screen (</st>*<st c="36495">Figure
    12</st>**<st c="36505">.2</st>*<st c="36507">):</st>
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.2: The project details form](img/B21795_12_2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '<st c="36940">Figure 12.2: The project details form</st>'
  prefs: []
  type: TYPE_NORMAL
- en: <st c="36977">In the project details form, we will fill in some general information
    about our ML model, such as the name, author, license, and description, and then</st>
    <st c="37129">click</st> **<st c="37135">Next</st>**<st c="37139">.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="37140">Our next screen is the project window (</st>*<st c="37180">Figure
    12</st>**<st c="37190">.3</st>*<st c="37192">):</st>
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.3: The SpamClassifier project window](img/B21795_12_3.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '<st c="37585">Figure 12.3: The SpamClassifier project window</st>'
  prefs: []
  type: TYPE_NORMAL
- en: <st c="37631">In</st> *<st c="37635">Figure 12</st>**<st c="37644">.3</st>*<st
    c="37646">, we can see the</st> `<st c="37663">SpamClassifier</st>` <st c="37677">project
    window.</st> <st c="37694">The project window is the main window</st> <st c="37732">where
    we will build our model.</st> <st c="37763">Let’s go over the different</st> <st
    c="37791">window components:</st>
  prefs: []
  type: TYPE_NORMAL
- en: '**<st c="37809">Left pane</st>**<st c="37819">: The left pane lists the project’s
    different sources – the ML model and its data sources, used for training</st>
    <st c="37929">and testing</st>'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**<st c="37940">Settings tab</st>**<st c="37953">: The</st> **<st c="37960">Settings</st>**
    <st c="37968">tab is where we define the different data sources for the various
    phases and general</st> <st c="38054">training parameters</st>'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**<st c="38073">Training tab</st>**<st c="38086">: The</st> **<st c="38093">Training</st>**
    <st c="38101">tab shows the progress of the</st> <st c="38132">training operation</st>'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**<st c="38150">Evaluation tab</st>**<st c="38165">: The</st> **<st c="38172">Evaluation</st>**
    <st c="38182">tab shows the performance of our model in the</st> <st c="38229">different
    phases</st>'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**<st c="38245">Preview tab</st>**<st c="38257">: We can</st> *<st c="38267">play</st>*
    <st c="38271">with our ML model and experience it in the</st> **<st c="38315">Preview</st>**
    <st c="38322">tab</st>'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**<st c="38326">Output tab</st>**<st c="38337">: The</st> **<st c="38344">Output</st>**
    <st c="38350">tab is the place where we can deploy</st> <st c="38388">our model</st>'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="38397">The list of the components reflects the phases we must go through
    when we build</st> <st c="38478">our model.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="38488">Now that we know what Create ML is, let’s start building</st>
    <st c="38546">our model.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="38556">Building our Spam Classifier model</st>
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: <st c="38591">Our Spam Classifier</st> <st c="38612">model-building process
    is based on three</st> <st c="38653">data sources – training, validation, and
    testing data.</st> <st c="38708">These three data sources are something we covered
    earlier in this chapter in the</st> *<st c="38789">Training the</st>* *<st c="38802">model</st>*
    <st c="38807">section.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="38816">First, let’s take a look at how we will prepare</st> <st c="38865">our
    data.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="38874">Preparing our data</st>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: <st c="38893">Since we are building a</st> <st c="38918">Spam Classifier model,
    we must prepare a dataset containing both spam and non-spam messages.</st> <st
    c="39011">The text classification template requires our dataset to be in the form
    of a CSV file with two columns –</st> `<st c="39116">text</st>` <st c="39120">and</st>
    `<st c="39125">label</st>`<st c="39130">. In our case, the</st> `<st c="39149">text</st>`
    <st c="39153">column represents the content of the SMS message, and the</st> `<st
    c="39212">label</st>` <st c="39217">column is the classification –</st> `<st c="39249">true</st>`
    <st c="39253">for a spam message and</st> `<st c="39277">false</st>` <st c="39282">for
    non-spam.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="39296">The ratio between the spam and the non-spam messages needs to
    reflect the real-world distribution.</st> <st c="39396">In our case, we have a
    dataset file with 300,000 records, where 10% of them are spam messages and 90%
    are</st> <st c="39502">non-spam messages.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="39520">To set the</st> **<st c="39532">training dataset</st>**<st c="39548">,
    we can drag the</st> <st c="39565">CSV file into the</st> **<st c="39584">Training
    Data</st>** <st c="39597">box (</st>*<st c="39603">Figure 12</st>**<st c="39613">.4</st>*<st
    c="39615">):</st>
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.4: Training Data with 300,000 records](img/B21795_12_4.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '<st c="39986">Figure 12.4: Training Data with 300,000 records</st>'
  prefs: []
  type: TYPE_NORMAL
- en: '*<st c="40033">Figure 12</st>**<st c="40043">.4</st>* <st c="40045">shows the</st>
    `<st c="40156">true</st>` <st c="40160">and</st> `<st c="40165">false</st>`<st
    c="40170">, as stated earlier.</st> <st c="40191">In addition, we also have a
    new</st> <st c="40223">data source in the left pane – the file we imported as
    the</st> <st c="40282">training dataset.</st>'
  prefs: []
  type: TYPE_NORMAL
- en: <st c="40299">We can handle the</st> **<st c="40318">validation data</st>**
    <st c="40333">now that</st> <st c="40342">we have the training data.</st> <st
    c="40370">As a reminder, as part of the training process, we will use the validation
    data to tune the model.</st> <st c="40469">We can provide our own validation data,
    but Create ML allows us to split it from the training dataset we’ve</st> <st c="40577">just
    supplied.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="40591">The third dataset is the</st> **<st c="40617">testing data</st>**<st
    c="40629">. We use the testing data to see how the model classifies unseen text.</st>
    <st c="40700">We can add the</st> <st c="40714">testing dataset later in the</st>
    <st c="40744">evaluation step.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="40760">Apart from choosing the different datasets, we can also set the
    number of iterations our training will go through and the</st> <st c="40883">model
    algorithm.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="40899">With each iteration, the training process can tune itself by reviewing
    the errors from the previous iteration and adjusting its parameters (like weights
    in a neural network).</st> <st c="41075">Our intuition may say that the more iterations
    we have, the more our model will be smarter.</st> <st c="41167">However, this
    is not so.</st> <st c="41192">First, at some point, having another iteration stops
    improving the model and only consumes computational resources.</st> <st c="41308">But
    the real problem is what we call overfitting.</st> **<st c="41358">Overfitting</st>**
    <st c="41369">is when an ML model learns the</st> <st c="41400">training data
    too well, including its noise.</st> <st c="41446">In this case, there will be
    issues with analyzing</st> <st c="41496">unseen data.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="41508">Another parameter is the model algorithm (</st>*<st c="41551">Figure
    12</st>**<st c="41561">.5</st>*<st c="41563">):</st>
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.5: Choosing the model algorithm](img/B21795_12_5.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '<st c="41788">Figure 12.5: Choosing the model algorithm</st>'
  prefs: []
  type: TYPE_NORMAL
- en: '*<st c="41829">Figure 12</st>**<st c="41839">.5</st>* <st c="41841">shows the</st>
    <st c="41852">pop-up menu where we can choose the model learning algorithm from
    five different options.</st> <st c="41942">The algorithm overview is not in this
    chapter’s scope, but in short, different algorithms are suitable for different
    needs and consume other resources.</st> <st c="42094">For example, the</st> **<st
    c="42111">BERT</st>** <st c="42115">algorithm is ideal for semantic understanding,
    and</st> <st c="42166">the</st> **<st c="42171">Conditional Random Field</st>**
    <st c="42195">is great for</st> <st c="42209">sequence labeling.</st> <st c="42228">In
    our case, we will choose the</st> **<st c="42260">Maximum Entropy</st>** <st c="42275">algorithm,
    which is excellent</st> <st c="42306">for classification.</st>'
  prefs: []
  type: TYPE_NORMAL
- en: <st c="42325">Now that we have all our datasets ready, we can click the</st>
    **<st c="42384">Train</st>** <st c="42389">button in the top-left corner and start</st>
    <st c="42430">our training.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="42443">Performing the training</st>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: <st c="42467">Now, we have arrived at the</st> <st c="42496">main dish – the
    training phase.</st> <st c="42528">In the training phase, the Create ML app goes
    over the training dataset using the algorithm we defined in the</st> *<st c="42638">Preparing
    our data</st>* <st c="42656">section.</st> <st c="42666">Let’s try to describe</st>
    <st c="42688">that process:</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="42701">In each iteration, the model</st> *<st c="42731">verifies itself</st>*
    <st c="42746">using the validation dataset.</st> <st c="42777">Remember that the
    validation dataset can be distinct.</st> <st c="42831">However, by default, it
    is a subset of the</st> <st c="42874">training dataset.</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="42891">The</st> *<st c="42896">duration</st>* <st c="42904">of the training
    phase is derived from three major factors – the dataset size, the number of iterations,
    and the</st> <st c="43017">chosen algorithm.</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="43034">The model doesn’t have to perform the number of iterations we
    defined in the</st> **<st c="43112">Settings</st>** <st c="43120">tab.</st> <st
    c="43126">If the validation accuracy reaches a high level,</st> *<st c="43175">the
    training will stop earlier</st>* <st c="43205">to save resources and</st> <st
    c="43228">avoid overfitting.</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="43246">At the end of the training</st> <st c="43273">process, we’ll see
    the following graph (</st>*<st c="43314">Figure 12</st>**<st c="43324">.6</st>*<st
    c="43326">):</st>
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.6: The Training tab at the end of the training process](img/B21795_12_6.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '<st c="43660">Figure 12.6: The Training tab at the end of the training process</st>'
  prefs: []
  type: TYPE_NORMAL
- en: '*<st c="43724">Figure 12</st>**<st c="43734">.6</st>* <st c="43736">shows how
    well we did in our training phase.</st> <st c="43782">We can see that we have
    reached a high accuracy after only two iterations.</st> <st c="43857">In this
    case, it is because our training dataset is well-structured and reliable.</st>
    <st c="43939">However, that won’t always be the case, so we need patience in</st>
    <st c="44002">this step.</st>'
  prefs: []
  type: TYPE_NORMAL
- en: <st c="44012">Now that our model has been trained, we need to test it.</st>
    <st c="44070">To do that, we will use our test dataset as part of the evaluation
    step (</st>*<st c="44143">Figure 12</st>**<st c="44153">.7</st>*<st c="44155">):</st>
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.7: The model evaluation step](img/B21795_12_7.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '<st c="44654">Figure 12.7: The model evaluation step</st>'
  prefs: []
  type: TYPE_NORMAL
- en: '*<st c="44692">Figure 12</st>**<st c="44702">.7</st>* <st c="44704">shows the
    evaluation step and the different datasets used to train and validate the model.</st>
    <st c="44796">We can also see that the testing data contains a dataset of 1,000
    items.</st> <st c="44869">The testing dataset</st> <st c="44889">structure is
    similar to the training and validation datasets.</st> <st c="44951">Tapping on
    the</st> **<st c="44966">Test</st>** <st c="44970">button runs the classification
    on all the 1,000 items in the dataset and measures their classification accuracy.</st>
    <st c="45084">Let’s see the test result (</st>*<st c="45111">Figure 12</st>**<st
    c="45121">.8</st>*<st c="45123">):</st>'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.8: The evaluation results](img/B21795_12_8.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '<st c="45602">Figure 12.8: The evaluation results</st>'
  prefs: []
  type: TYPE_NORMAL
- en: '*<st c="45637">Figure 12</st>**<st c="45647">.8</st>* <st c="45649">presents
    some</st> <st c="45663">terms that we need to be familiar with if we want to understand</st>
    <st c="45728">the report:</st>'
  prefs: []
  type: TYPE_NORMAL
- en: '`<st c="45825">true</st>` <st c="45829">or</st> `<st c="45833">false</st>`
    <st c="45838">(depending on the specific class) and that were correct.</st> <st
    c="45896">For example, 93% precision for the</st> `<st c="45931">false</st>` <st
    c="45936">class means that 93% of all the messages the model identifies as</st>
    `<st c="46002">false</st>` <st c="46007">were</st> <st c="46013">actually</st>
    `<st c="46022">false</st>`<st c="46027">.</st>'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`<st c="46102">true</st>` <st c="46106">class means that the model correctly
    identified 93% of all actual</st> <st c="46173">spam messages.</st>'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**<st c="46187">F1 Score</st>**<st c="46196">: The F1 score is the balance
    between precision</st> <st c="46245">and recall.</st>'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="46256">The</st> **<st c="46261">F1 Score</st>** <st c="46269">involves
    more than just measuring a model’s accuracy.</st> <st c="46324">It balances two
    important metrics –</st> **<st c="46360">precision</st>** <st c="46369">and</st>
    **<st c="46374">recall</st>** <st c="46380">– and reflects a better model performance
    measurement.</st> <st c="46436">In our case, a score of 0.96 is considered a very</st>
    <st c="46486">high performance.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="46503">Our next tab is</st> **<st c="46520">Preview</st>**<st c="46527">,
    where we can play within a playground zone (</st>*<st c="46573">Figure 12</st>**<st
    c="46583">.9</st>*<st c="46585">):</st>
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.9: The Preview tab](img/B21795_12_9.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '<st c="46760">Figure 12.9: The Preview tab</st>'
  prefs: []
  type: TYPE_NORMAL
- en: '*<st c="46788">Figure 12</st>**<st c="46798">.9</st>* <st c="46800">shows our
    model’s</st> **<st c="46819">Preview</st>** <st c="46826">tab, with an example
    message that says,</st> **<st c="46867">Call now to get an invite</st>**<st c="46892">.
    Our</st> <st c="46898">model identified this message as spam with a 92% confidence.</st>
    <st c="46959">Good job!</st>'
  prefs: []
  type: TYPE_NORMAL
- en: <st c="46968">Now, let’s see how we can deploy</st> <st c="47002">our model.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="47012">Deploying our model</st>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: <st c="47032">There’s no point in</st> <st c="47053">having a great training
    process if we can’t deploy it in Xcode.</st> <st c="47117">This is why we have
    the</st> **<st c="47141">Output</st>** <st c="47147">tab (</st>*<st c="47153">Figure
    12</st>**<st c="47163">.10</st>*<st c="47166">):</st>
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.10: The Create ML Output tab](img/B21795_12_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '<st c="47903">Figure 12.10: The Create ML Output tab</st>'
  prefs: []
  type: TYPE_NORMAL
- en: <st c="47941">The</st> **<st c="47946">Output</st>** <st c="47952">tab shows
    a summary of our model, including a new detail we haven’t seen until now – the</st>
    <st c="48042">model size.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="48053">More importantly, the</st> `<st c="48229">mlmodel</st>` <st c="48236">extension.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="48247">To use the</st> `<st c="48259">mlmodel</st>` <st c="48266">extension
    in our projects, we’ll need to use Core ML.</st> <st c="48321">That’s our</st>
    <st c="48332">next topic.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="48343">Using our model with Core ML</st>
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: <st c="48372">The</st> **<st c="48377">Core ML framework</st>**<st c="48394">’s
    goal is to allow us</st> <st c="48417">to integrate ML models into</st> <st c="48446">our
    projects.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="48459">Our first step is to add the</st> `<st c="48489">mlmodel</st>`
    <st c="48496">file that we saved from the Create ML application to Xcode.</st>
    <st c="48557">We can do that by dragging the file to the project navigator</st>
    <st c="48618">in Xcode.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="48627">The main class in the Core ML framework we will use is</st> `<st
    c="48683">MLModel</st>`<st c="48690">, which represents a ML model loaded into
    the system.</st> <st c="48744">To</st> <st c="48746">load our Spam Classifier
    model, we initialize the model in</st> <st c="48806">our code:</st>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: <st c="49003">In the preceding code example, we created a new class, called</st>
    `<st c="49066">MessageClassifier</st>`<st c="49083">, which encapsulates our ML
    integration with the Spam</st> <st c="49137">Classifier model.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="49154">We then initiate the class, passing a new</st> `<st c="49197">MLModelConfiguration</st>`<st
    c="49217">. This contains different options, but we can pass an empty instance
    at</st> <st c="49289">this stage.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="49300">Our class also contains an</st> `<st c="49328">MLModel</st>` <st
    c="49335">instance.</st> <st c="49346">To initiate the model instance, we use
    the</st> `<st c="49389">SpamClassifier</st>` <st c="49403">class, passing</st>
    <st c="49419">our configuration.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="49437">But wait – where did the</st> `<st c="49463">SpamClassifier</st>`
    <st c="49477">class</st> <st c="49484">come from?</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="49494">When we added the Spam Classifier</st> `<st c="49529">mlmodel</st>`
    <st c="49536">file into our Xcode project, Core ML generated three interfaces
    – the</st> `<st c="49607">SpamClassifier</st>` <st c="49621">class,</st> `<st
    c="49629">SpamClassifierInput</st>`<st c="49648">,</st> <st c="49650">and</st>
    `<st c="49654">SpamClassifierOutput</st>`<st c="49674">.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="49675">Now that we have our model, let’s write a function that can predict
    whether a message</st> <st c="49762">is spam:</st>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: <st c="50013">In the preceding example, we created a</st> `<st c="50053">prediction</st>`
    <st c="50063">function that receives a text message as input and</st> <st c="50114">returns</st>
    <st c="50123">a Boolean.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="50133">It starts by creating a</st> `<st c="50158">SpamClassifierInput</st>`
    <st c="50177">instance with the text input.</st> <st c="50208">Then, it generates
    a prediction result for this input by running the model’s</st> `<st c="50285">prediction()</st>`
    <st c="50297">function.</st> <st c="50308">We then get the value from the feature,
    called</st> `<st c="50355">label</st>`<st c="50360">, and compare it</st> <st
    c="50377">to</st> `<st c="50380">true</st>`<st c="50384">.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="50385">This code example demonstrates how to easily use a custom ML model
    in our</st> <st c="50460">Xcode projects.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="50475">Now, let’s try to understand if using a custom ML in our Xcode
    is</st> <st c="50542">that simple.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="50554">Where to go from here</st>
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: <st c="50576">The Core ML part of this book is unique.</st> <st c="50618">In
    most cases, I have simplified complex topics to make them more accessible for
    developers.</st> <st c="50711">However, I think the Core ML topic</st> <st c="50746">is
    different.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="50759">ML is a broad topic, beyond the scope of this chapter.</st> <st
    c="50815">Furthermore, it is a complex topic.</st> <st c="50851">Training is more
    than just delivering datasets.</st> <st c="50899">It is essential to understand
    the dataset mix between the different classes, pick the correct algorithm, and
    read the evaluation</st> <st c="51028">results carefully.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="51046">And remember that the model we created is a custom.</st> <st c="51099">This
    means that we don’t have any control over how its algorithm works and need to
    observe and fine-tune it</st> <st c="51207">over time.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="51217">In summary, ML is a complex topic, and if we want to enter this
    area, we need to approach it more in-depth than reading</st> <st c="51338">15
    pages.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="51347">Summary</st>
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: <st c="51355">This was a long but fascinating chapter about one of the most
    exciting contemporary topics – ML</st> <st c="51452">and AI.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="51459">We reviewed the basics of AI and ML, understanding what it means
    to train an ML model.</st> <st c="51547">We explored the built-in ML models in
    the iOS SDK, including NLP, analyzing images using the Vision framework, and classifying
    audio with the Sound Analysis framework.</st> <st c="51715">We learned how to
    add semantic search capabilities to the Core Spotlight framework, and if that
    wasn’t enough, we also learned how to create and integrate custom ML models into</st>
    <st c="51892">our projects.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="51905">Now, we can add some intelligence features to</st> <st c="51952">our
    apps!</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="51961">Speaking of intelligence, our next chapter discusses how we can
    integrate Siri using App Intents.</st> <st c="52060">The ML phase is not over</st>
    <st c="52085">just yet!</st>
  prefs: []
  type: TYPE_NORMAL
