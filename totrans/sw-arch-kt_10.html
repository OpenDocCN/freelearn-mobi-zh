<html><head></head><body><div id="book-content"><div id="sbo-rt-content"><div id="_idContainer096">
			<h1 id="_idParaDest-240" class="chapter-number"><a id="_idTextAnchor334"/>10</h1>
			<h1 id="_idParaDest-241"><a id="_idTextAnchor335"/>Idempotency, Replication, and Recovery Models</h1>
			<p>Distributed systems are very common in modern software architectures. The challenges of ensuring data consistency, fault tolerance, and availability become critical. This chapter is going to cover three key concepts that help address <span class="No-Break">these challenges:</span></p>
			<ul>
				<li><span class="No-Break">Idempotency</span></li>
				<li><span class="No-Break">Replication</span></li>
				<li><span class="No-Break">Recovery models</span></li>
			</ul>
			<p><strong class="bold">Idempotency</strong> is a fundamental<a id="_idIndexMarker821"/> non-functional system property that ensures operations can be executed safely and repeatedly without causing unintended side effects. In a distributed system, network failures and system crashes are common. Idempotency is essential for maintaining data integrity and consistency. By designing operations to be idempotent, engineers can build more resilient and fault-tolerant systems that can recover from partial failures without compromising the overall <span class="No-Break">system state.</span></p>
			<p><strong class="bold">Replication</strong>, on the other <a id="_idIndexMarker822"/>hand, is a technique that’s used to improve the availability and durability of data in distributed systems. By maintaining multiple copies of data across different nodes, replication provides redundancy and helps ensure that the system can continue to operate even if one or more nodes fail. However, replication introduces its own set of challenges, such as ensuring consistency between replicas and efficiently managing the <span class="No-Break">replication process.</span></p>
			<p>Finally, <strong class="bold">recovery models</strong> define<a id="_idIndexMarker823"/> the strategies and mechanisms that are used to restore the state of a distributed system after a failure or disruption. These models can range from simple backup-and-restore approaches to more sophisticated techniques. Choosing the right recovery model is crucial for building resilient distributed systems that can weather unexpected events and maintain high levels of availability <span class="No-Break">and responsiveness.</span></p>
			<p>In this chapter, we’ll explore each of these topics in greater depth, discussing their underlying principles, trade-offs, and best practices for applying them in real-world distributed applications. After this chapter, you should be able to implement idempotency, replication, and recovery models at a level suitable for <span class="No-Break">your system.</span></p>
			<h1 id="_idParaDest-242"><a id="_idTextAnchor336"/>Technical requirements</h1>
			<p>You can find the code files used in this chapter on <span class="No-Break">GitHub: </span><a href="https://github.com/PacktPublishing/Software-Architecture-with-Kotlin/tree/main/chapter-10"><span class="No-Break">https://github.com/PacktPublishing/Software-Architecture-with-Kotlin/tree/main/chapter-10</span></a></p>
			<h1 id="_idParaDest-243"><a id="_idTextAnchor337"/>Idempotency</h1>
			<p>Idempotency is a <a id="_idIndexMarker824"/>concept in software engineering that refers to the non-functional property of operations that can be performed multiple times while still having the same effect as performing it only once. In other words, an idempotent operation can be safely repeated without side effects. Let’s cover a short scenario where idempotency <span class="No-Break">is required.</span></p>
			<h2 id="_idParaDest-244"><a id="_idTextAnchor338"/>A use case where idempotency is required</h2>
			<p>Imagine that we’re<a id="_idIndexMarker825"/> building an online banking application. A key capability is <strong class="bold">Transfer Funds</strong>, in which a user transfers money from one account to another. This capability is a fundamental yet critical part of the system, and it needs to be implemented in a way that ensures the integrity and reliability of the user’s <span class="No-Break">financial transactions.</span></p>
			<p>If the <strong class="bold">Transfer Funds</strong> operation isn’t idempotent, then the user could accidentally click the <strong class="bold">Transfer</strong> button multiple times, and the system would execute the transfer operation multiple times, resulting in an unintended debit from the source account and a corresponding credit to the <span class="No-Break">destination account.</span></p>
			<p>Most mature user interfaces can avoid this situation by blocking the button once it’s pushed until a response is received. However, there are also API integrations that <span class="No-Break">require idempotency.</span></p>
			<p>This result isn’t intended by the user, and it has multiple consequences. First, if the user has insufficient funds from the second and subsequent transfer, the user will have overdraft funds and be subject to interest charges. Second, these incidents trigger user complaints and can result in the potential involvement of financial regulatory bodies. Not only the user experience but also the unintended side effect results in reputational damage to <span class="No-Break">the bank.</span></p>
			<p>To prevent these issues, the <strong class="bold">Transfer Funds</strong> operation should be designed to be idempotent. This means that no matter how many times the user clicks the <strong class="bold">Transfer Funds</strong> button, the <a id="_idIndexMarker826"/>system will only execute the transfer once, ensuring that the final state of the accounts is correct and matches the <span class="No-Break">user’s intent.</span></p>
			<h2 id="_idParaDest-245"><a id="_idTextAnchor339"/>Key aspects of idempotency</h2>
			<p>Idempotency is an <a id="_idIndexMarker827"/>important concept in software development, particularly in the context of distributed systems, APIs, and data processing pipelines. Here are some key aspects <span class="No-Break">of idempotency:</span></p>
			<ul>
				<li><strong class="bold">Constant outcomes</strong>: An idempotent operation always produces the same result, regardless of how many times it’s executed. If an operation isn’t idempotent, each subsequent execution might produce a <span class="No-Break">different outcome.</span></li>
				<li><strong class="bold">Error handling and retries</strong>: Idempotency helps in handling errors and retries gracefully. If an operation fails, the system can safely retry the operation without causing unintended <span class="No-Break">side effects.</span></li>
				<li><strong class="bold">Data consistency</strong>: Idempotent operations ensure data consistency by preventing accidental data modifications or duplications, which can occur when retrying <span class="No-Break">non-idempotent operations.</span></li>
				<li><strong class="bold">Scalability and reliability</strong>: Idempotency is crucial in distributed systems, where multiple instances of an application may be processing the same request concurrently. Idempotent operations allow the system to scale and handle failures without compromising <span class="No-Break">data integrity.</span></li>
			</ul>
			<p>Let’s cover a few practical scenarios where idempotency can <span class="No-Break">be applied.</span></p>
			<h2 id="_idParaDest-246"><a id="_idTextAnchor340"/>Scenario 1 – evolutionary database migration script</h2>
			<p>Evolutionary databases <a id="_idIndexMarker828"/>aim to create database systems that can evolve and adapt to changes over time. They aren’t defined by static and rigid models. The database schema is defined by incremental changes that build the <span class="No-Break">target schema.</span></p>
			<p>Consider Flyway, an open source database migration tool. The incremental changes are specified by <span class="No-Break">SQL scripts:</span></p>
			<pre class="source-code">
V1_create_new_tables.sql
V2_add_new_columns.sql</pre>			<p>For simplicity’s sake, let’s assume that the <strong class="source-inline">V1</strong> script only contains the following statement for creating <span class="No-Break">a table:</span></p>
			<pre class="console">
CREATE TABLE HOUSEHOLD (
id UUID primary key,
name text not null
);</pre>			<p>The <strong class="source-inline">CREATE</strong> SQL statement will create a new table called <strong class="source-inline">HOUSEHOLD</strong> if it doesn’t already exist. Otherwise, an error will be reported and the <strong class="source-inline">V1</strong> script will fail. In other words, it isn’t idempotent, and repeated executions don’t have the same outcome. Here’s an idempotent version of <span class="No-Break">the script:</span></p>
			<pre class="console">
CREATE TABLE IF NOT EXISTS HOUSEHOLD (
id UUID primary key,
name text not null
);</pre>			<p>The <strong class="source-inline">IF NOT EXIST</strong> syntax ensures the table is created if it doesn’t exist, or nothing is performed if the table already exists. The outcome is the same in either case, which is that the <strong class="source-inline">HOUSEHOLD</strong> table exists in <span class="No-Break">the database.</span></p>
			<p>The execution of the <strong class="source-inline">V2</strong> script will add a new column to this table as a non-null column. Some database vendors support clever SQL statements that create a non-null column and populate values in the same statement. For the sake of this argument, let’s assume that this isn’t supported. We’ve resorted to the classic approach of adding a nullable column, populating the value, and then setting the column to non-null. Like the modified <strong class="source-inline">V1</strong> script, we can make <span class="No-Break">it idempotent:</span></p>
			<pre class="console">
ALTER TABLE IF EXISTS HOUSEHOLD ADD COLUMN deleted boolean;
UPDATE HOUSEHOLD SET deleted = false;
ALTER TABLE IF EXISTS HOUSEHOLD ALTER COLUMN IF EXISTS deleted SET NOT NULL;
COMMIT;</pre>			<p>The <strong class="source-inline">IF EXISTS</strong> syntax ensures that the table or columns will be altered if they exist, or nothing is performed if they don’t. The outcome is the same and therefore it’s idempotent. The classic guideline would have suggested that the <strong class="bold">Data Definition Language</strong> (<strong class="bold">DDL</strong>) should <a id="_idIndexMarker829"/>be separated from the <strong class="bold">Data Manipulation Language</strong> (<strong class="bold">DML</strong>), in which <strong class="source-inline">ALTER TABLE</strong> is DDL and <strong class="source-inline">UPDATE</strong> is DML. This<a id="_idIndexMarker830"/> was suggested because DDL is immediately committed while DML requires an explicit commit. However, with idempotency, this is no longer an issue as each statement can be repeated to produce the <span class="No-Break">same outcome.</span></p>
			<h2 id="_idParaDest-247"><a id="_idTextAnchor341"/>Scenario 2 – create/update operations</h2>
			<p>Using the real-life example <a id="_idIndexMarker831"/>of villagers exchanging services, there’s a business case to ensure households are kept in the system record. However, the household users don’t know if the household has already <span class="No-Break">been persisted.</span></p>
			<p>A CRUD-based system may define create and update as two independent operations. These operations are well-suited as users want the household records to persist regardless of whether they exist. There could have been a network outage, so users may not know if their previous requests <span class="No-Break">were successful.</span></p>
			<p>In other words, users want an operation that can be repeated and yet generate the same outcome. They need an idempotent operation to ensure the household records have been stored, despite whether they <span class="No-Break">already exist.</span></p>
			<p>This operation is often referred <a id="_idIndexMarker832"/>to as <strong class="bold">upsert</strong>, which means <strong class="bold">update or insert</strong>. The key characteristics of an upsert operation are <span class="No-Break">as follows:</span></p>
			<ol>
				<li><strong class="bold">Idempotent</strong>: It can be executed repeatedly with the same outcome. If the record already exists, the record is updated; if the record doesn’t exist, the record <span class="No-Break">is created.</span></li>
				<li><strong class="bold">Atomic</strong>: The operation is executed in a transaction of serialized isolation. This means the operation was either completed or it <span class="No-Break">didn’t happen.</span></li>
				<li><strong class="bold">Option 1 – pessimistic</strong>: The pessimistic approach would check if the record already exists or not to determine whether it’s an update or a <span class="No-Break">create operation.</span></li>
				<li><strong class="bold">Option 2 – optimistic</strong>: The optimistic approach would assume the record either exists or not and perform an update or create operation, respectively. If the update operation hasn’t found the record, it switches to the create operation. Alternatively, if the create operation fails due to a unique constraint violation, it switches to the <span class="No-Break">update operation.</span></li>
			</ol>
			<p>Here’s an example of <a id="_idIndexMarker833"/>the upsert operation for a household in an SQL statement. It’s implementing the <span class="No-Break">optimistic approach:</span></p>
			<pre class="console">
INSERT INTO HOUSEHOLD (id, name, email) VALUES ('d0275532-1a0a-4787-a079-b1292ad4aadf', 'Whittington', 'info@ whittington'.com') ON DUPLICATE KEY UPDATE name = 'Whittington', email = 'info@ whittington'.com';</pre>			<p>This SQL statement attempts to insert a new household record. If the record doesn’t exist, a new row is inserted. If the execution hits a duplicate key violation, it becomes an update operation to <strong class="source-inline">name</strong> <span class="No-Break">and </span><span class="No-Break"><strong class="source-inline">email</strong></span><span class="No-Break">.</span></p>
			<p>If this operation is exposed as an external API – that is, as a REST endpoint – the contract can be expressed in the <span class="No-Break">following ways:</span></p>
			<ol>
				<li><strong class="source-inline">GET</strong>: Multiple invocations of the <strong class="source-inline">GET</strong> endpoint shall return the same result, given the system state <span class="No-Break">remains unchanged.</span></li>
				<li><strong class="source-inline">PUT</strong>: The <strong class="source-inline">PUT</strong> endpoint implies creating a new resource or replacing a representation of the household with the <span class="No-Break">request payload.</span></li>
				<li><strong class="source-inline">DELETE</strong>: The <strong class="source-inline">DELETE</strong> endpoint intends to remove the resource, regardless of whether it already exists. If the resource isn’t found, then it should return a successful <strong class="bold">Hypertext Transfer Protocol</strong> (<strong class="bold">HTTP</strong>) <span class="No-Break">status</span><span class="No-Break"><a id="_idIndexMarker834"/></span><span class="No-Break"> code.</span></li>
			</ol>
			<p>The HTTP method itself doesn’t bring idempotency. For example, if the response payload of the <strong class="source-inline">GET</strong> endpoint contains the current time or random values, then multiple invocations don’t return the same result, and therefore it’s <span class="No-Break">not idempotent.</span></p>
			<p>The <strong class="source-inline">POST</strong> and <strong class="source-inline">PATCH</strong> endpoints aren’t defined as idempotent. The <strong class="source-inline">POST</strong> endpoint in REST architecture implies the request to create a resource and assumes the resource was absent. The <strong class="source-inline">PATCH</strong> endpoint assumes the resource already exists so that the resource can be <span class="No-Break">partially </span><span class="No-Break"><a id="_idIndexMarker835"/></span><span class="No-Break">updated.</span></p>
			<p class="callout-heading">HTTP methods</p>
			<p class="callout">HTTP defines a few methods to categorize the request to perform an action on a resource. The <strong class="source-inline">GET</strong> method is a read-only operation that returns data from the server. The <strong class="source-inline">POST</strong> method creates resources in a server. The <strong class="source-inline">PUT</strong> method replaces or creates a resource. The <strong class="source-inline">PATCH</strong> method partially updates an existing resource. The <strong class="source-inline">DELETE</strong> method removes a resource from the server. The <strong class="source-inline">HEAD</strong> method returns the header of the resource without the body content. The <strong class="source-inline">OPTIONS</strong> method describes the options to communicate with the specific resource. Finally, the <strong class="source-inline">TRACE</strong> method is a diagnosis operation that echoes the final receipt of the request to provide information <span class="No-Break">for troubleshooting.</span></p>
			<h2 id="_idParaDest-248"><a id="_idTextAnchor342"/>Scenario 3 – processing events in sequence</h2>
			<p>Something that consumes events from a stream or a topic usually takes an event one at a time and processes them sequentially. If the sequence of events that’s processed is important, then there’s a need to gracefully process events in the face of duplication and out <span class="No-Break">of sequence.</span></p>
			<p>There are two levels where an event sequence could be compromised. The first level is the transport level, where the offset of the last consumed event is reset to older events due to network issues, partition changes, or consumer group changes. The second level is the application level and is where the publisher has sent <span class="No-Break">older events.</span></p>
			<p>Application-level deduplication at the consumer level could handle event sequences being compromised at the transport or application level. However, that would require publishers to provide sequential information on each event. This could be a sequence number on the event or a timestamp where an <span class="No-Break">event occurred.</span></p>
			<p>The consumer can maintain the last processed sequence number or timestamp per publisher. If the consumer receives an event where the sequence number is lower than the last to be processed, or where the timestamp is older than the last to be processed, then the consumer skips this event until a newer event <span class="No-Break">is received.</span></p>
			<p>Here’s an example implementation<a id="_idIndexMarker836"/> of an event listener that prevents older events from <span class="No-Break">being processed:</span></p>
			<pre class="source-code">
class HouseholdEventListener {
    var lastProcessedTime: Instant? = null
    @KafkaListener(
        topics = ["\${household-v1-topic}"],
        clientIdPrefix = "\${client-id}",
        groupId = "\${group-id}",
        containerFactory = "kafkaListenerContainerFactory",
        properties = ["auto.offset.reset=earliest"]
    )
    fun onMessage(
        @Payload(required = false) event: HouseholdEvent?,
        @Header(name = "kafka_eventTime", required = true) key: String,
    ) {
        if (lastProcessedTime != null &amp;&amp; event?.time?.isBefore(lastProcessedTime) == true) {
            log.warn { "Skipping event with time ${event.time} because it is before the last processed time $lastProcessedTime" }
            return
        }
        // some processing logic here
        lastProcessedTime = event?.time
    }
}</pre>			<p>Here, <strong class="source-inline">HouseholdEventListener</strong> keeps the timestamp of the last processed event. The incoming events from Kafka have a header field, <strong class="source-inline">kafka_eventTime</strong>, that’s provided by the publisher. The value is when the event occurred, not when the event <span class="No-Break">was published.</span></p>
			<p>The first event process wouldn’t perform any timestamp check. Subsequently, the listener would skip processing if the event timestamp from the header is earlier than the last processed timestamp. This indicates that the incoming event is old and can <span class="No-Break">be skipped.</span></p>
			<p>If the event isn’t skipped and has finished processing, the last processed timestamp is updated, and the event is acknowledged by the Kafka broker. The listener is now ready to consume <span class="No-Break">another event.</span></p>
			<p>In a production system, the last processed time should be persisted in the database and be in the same transaction where business processing takes place. The last processed time should be restored when the listener starts. This would allow the listener to resume its consumption of events after <span class="No-Break">a restart.</span></p>
			<p>This implementation<a id="_idIndexMarker837"/> illustrates how a consumer can detect an older event with the help of the publisher. The older event isn’t processed, and the consumer can keep the last processed timestamp as an offset to verify the <span class="No-Break">next event.</span></p>
			<p>To extend to this example, the timestamp of the last processed event can be persisted in a database so that the value is restored after <span class="No-Break">a restart.</span></p>
			<h2 id="_idParaDest-249"><a id="_idTextAnchor343"/>Scenario 4 – the multiple bounded context saga</h2>
			<p>A <strong class="bold">saga</strong> is a<a id="_idIndexMarker838"/> pattern in <strong class="bold">domain-driven design</strong> (<strong class="bold">DDD</strong>) that <a id="_idIndexMarker839"/>involves<a id="_idIndexMarker840"/> distributed transactions. The challenge is to maintain data consistency across multiple <span class="No-Break">bounded contexts.</span></p>
			<p>Let’s use our bank transfer example, where we need idempotent operations to ensure the fund is only transferred once and only once. The banking phone application intends to send a request to the <span class="No-Break">backend service.</span></p>
			<p>However, there are multiple backend services involved in this operation. First, there’s <strong class="bold">Transfer Service</strong>, which validates <span class="No-Break">the request.</span></p>
			<p>Once validated, it needs to reserve the amount in the withdrawing account until the transfer has been completed. This is done by another service called <span class="No-Break"><strong class="bold">Account Service</strong></span><span class="No-Break">.</span></p>
			<p><strong class="bold">Account Service</strong> orchestrates reserving funds by moving funds from a customer account to the corporate account. Later, it orchestrates adding funds by moving funds from the corporate account to a customer account. This is done by communicating with the legacy <strong class="bold">Core </strong><span class="No-Break"><strong class="bold">Banking System</strong></span><span class="No-Break">.</span></p>
			<p>Once the funds have been <a id="_idIndexMarker841"/>reserved, <strong class="bold">Transfer Service</strong> can request the <a id="_idIndexMarker842"/>second part of the transfer by moving the funds from the corporate account to the customer account. The request is handled by <strong class="bold">Account Service</strong>, which communicates with the legacy <strong class="bold">Core Banking System</strong> to transfer the funds. Once this has been acknowledged and completed by <strong class="bold">Core Banking System</strong>, <strong class="bold">Account Service</strong> returns the result to <strong class="bold">Transfer Service</strong> and thus completes <span class="No-Break">the transfer.</span></p>
			<p>This interaction is demonstrated in <span class="No-Break"><em class="italic">Figure 10</em></span><span class="No-Break"><em class="italic">.1</em></span><span class="No-Break">:</span></p>
			<div>
				<div id="_idContainer090" class="IMG---Figure">
					<img src="image/B21737_10_1.jpg" alt="Figure 10.1 – Example sequence for a bank transfer" width="1120" height="1296"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 10.1 – Example sequence for a bank transfer</p>
			<p>Making the<a id="_idIndexMarker843"/> whole <a id="_idIndexMarker844"/>transfer operation idempotent is complex because transactions are distributed among services. Moreover, we need a way to identify that the user only wants the transfer funds once, despite multiple attempts from the <span class="No-Break">banking application.</span></p>
			<p>Often, some parts of the system are legacy systems that may not be enhanced so easily. In this case, let’s assume <strong class="bold">Core Banking System</strong> can’t take the idempotency key in <span class="No-Break">the request.</span></p>
			<p>Let’s explore how each<a id="_idIndexMarker845"/> component involved in this process can<a id="_idIndexMarker846"/> work <span class="No-Break">toward idempotency.</span></p>
			<h3>Banking application</h3>
			<p>The first step should be<a id="_idIndexMarker847"/> the banking application <a id="_idIndexMarker848"/>generating an <strong class="bold">idempotency key</strong>, which can identify multiple attempts belonging to the same user intent. Ideally, the idempotency key should be carried to all <span class="No-Break">services involved.</span></p>
			<h3>Transfer Service</h3>
			<p><strong class="bold">Transfer Service</strong> can cache <a id="_idIndexMarker849"/>these idempotency keys for a certain period. Within that period, the same idempotency keys are treated as <span class="No-Break">duplicated requests.</span></p>
			<p>To avoid consistency issues under concurrent requests, many systems use explicit locks to ensure the requests of the same idempotency keys are processed only one at a time, across <span class="No-Break">multiple instances.</span></p>
			<p>The service can decide to skip the remaining interactions with other services and return the response that was sent previously to the banking service. This approach is OK if we are sure the remaining services have acknowledged completion of <span class="No-Break">the request.</span></p>
			<p>If, for example, there was a timeout when <strong class="bold">Transfer Service</strong> communicated with <strong class="bold">Account Service</strong>, then it may be sensible to repeat the interaction with <strong class="bold">Account Service</strong>. This allows the operation to be repaired and continue until completion. This approach also assumes that <strong class="bold">Account Service</strong> can handle duplicated requests in an <span class="No-Break">idempotent manner.</span></p>
			<h3>Account Service</h3>
			<p>In this operation, <strong class="bold">Account Service</strong> provides<a id="_idIndexMarker850"/> two functionalities: reserve funds and add funds. To be able to identify duplicate requests, the idempotency keys should be persisted alongside the records related to holding and <span class="No-Break">moving funds.</span></p>
			<p>When <strong class="bold">Account Service</strong> handles the requests of reserving or adding funds, it must check whether duplicate requests already exist by using the idempotency keys. If they do, <strong class="bold">Account Service</strong> returns the response from the records, as if it had been processed <span class="No-Break">this time.</span></p>
			<p>If the reserve fund request is rejected by <strong class="bold">Core Banking System</strong> due to insufficient funds, <strong class="bold">Account Service</strong> needs to roll back the operation by reversing the fund back to the <span class="No-Break">withdrawal account.</span></p>
			<p>Like <strong class="bold">Transfer Service</strong>, there should be some form of explicit locking to ensure only one request for a given<a id="_idIndexMarker851"/> idempotency key is processed at a time across <span class="No-Break">multiple instances.</span></p>
			<h3>Core Banking System</h3>
			<p><strong class="bold">Core Banking System</strong> is a legacy<a id="_idIndexMarker852"/> system that doesn’t support idempotency. It isn’t able to take idempotency keys or process them. Since <strong class="bold">Account Service</strong> is the service that communicates with <strong class="bold">Core Banking System</strong>, <strong class="bold">Account Service</strong> should persist the response from <strong class="bold">Core Banking System</strong> together with the corresponding <span class="No-Break">idempotency key.</span></p>
			<p>If the record of the response already exists with the idempotency key, <strong class="bold">Account Service</strong> skips communication with <strong class="bold">Core Banking System</strong> and uses the previously persisted response from <strong class="bold">Core Banking System</strong> to complete <span class="No-Break">the process.</span></p>
			<p>This is getting complex as there could be a timed-out request for <strong class="bold">Core Banking System</strong>. <strong class="bold">Account Service</strong> doesn’t know whether <strong class="bold">Core Banking System</strong> has processed the transfer or not. <strong class="bold">Account Service</strong> would need to query the recent transaction history to identify the previous request to <strong class="bold">Core Banking System</strong>, either success or failure, to recover and resume the transfer operation. Otherwise, retrying may still result in an <span class="No-Break">inconsistent state.</span></p>
			<p>Sometimes, this recovery may even involve manual correction, which is error-prone. You can see when a process can’t be idempotent as it becomes substantially more complex, inefficient, <span class="No-Break">and expensive.</span></p>
			<p>With that, we’ve run through four scenarios where idempotency is required, and we’ve explored multiple approaches for these scenarios. Now, let’s delve into a concept related to idempotency – <span class="No-Break">replication.</span></p>
			<h1 id="_idParaDest-250"><a id="_idTextAnchor344"/>Replication</h1>
			<p><strong class="bold">Replication</strong> serves as a<a id="_idIndexMarker853"/> safeguard against potential failures, allowing the system to maintain continuity of service even when individual components malfunction or <span class="No-Break">become unavailable.</span></p>
			<p>This aspect of replication has a close relationship with recovery, which will be covered later in this chapter. In short, some replication techniques can prevent system downtime, which requires recovery. Also, some replication techniques enable and enhance <span class="No-Break">recovery processes.</span></p>
			<p>Another aspect of replication is that it can improve system performance by distributing load to multiple nodes, as well as by allowing the system to scale based <span class="No-Break">on traffic.</span></p>
			<p>The copy of the data or running instances is usually called a <em class="italic">replica</em>. There are many areas where replication is applicable. Let’s take <span class="No-Break">a look.</span></p>
			<h2 id="_idParaDest-251"><a id="_idTextAnchor345"/>Data redundancy</h2>
			<p>Multiple replicas are<a id="_idIndexMarker854"/> distributed across different nodes or servers. If <a id="_idIndexMarker855"/>one node fails, the data can still be accessed from the replicated copies on other nodes. It also prevents data loss if some nodes become <span class="No-Break">permanently unavailable.</span></p>
			<p>This redundancy ensures that the overall system can continue to function, even if some nodes or components <span class="No-Break">are unavailable.</span></p>
			<p>This can apply to relational databases, NoSQL databases, durable message brokers, distributed object caches, and<a id="_idIndexMarker856"/> nodes in <strong class="bold">peer-to-peer</strong> (<span class="No-Break"><strong class="bold">P2P</strong></span><span class="No-Break">) networks.</span></p>
			<h2 id="_idParaDest-252"><a id="_idTextAnchor346"/>Service redundancy</h2>
			<p>Having the running<a id="_idIndexMarker857"/> service instances of the system <a id="_idIndexMarker858"/>distributed and replicated brings a few <span class="No-Break">key benefits.</span></p>
			<p>First, requests can be routed to the most available and responsive replica, reducing the risk of overloading a single node and improving overall system performance. This load balancing helps maintain availability by preventing bottlenecks and ensuring that the system can handle increased traffic <span class="No-Break">or workloads.</span></p>
			<p>Second, it enables the system to scale out by adding more replicas or instances as demand increases. This horizontal scalability allows the system to handle higher loads and maintain availability as the number of requests or resources <span class="No-Break">required grows.</span></p>
			<p>Moreover, if a primary node becomes unavailable, the system can automatically failover to a secondary or backup replica, ensuring a <span class="No-Break">seamless transition.</span></p>
			<p>The secondary replica can take over the workload, maintaining service continuity and <span class="No-Break">high availability.</span></p>
			<p>Replication also facilitates faster recovery as the system can restore services by promoting a healthy replica to become the <span class="No-Break">new primary.</span></p>
			<p>It’s also common for data and services to be replicated across multiple geographical locations and data centers. This practice can improve availability in the event of regional failures or disasters. If one data center or region experiences an outage, the system can continue to operate<a id="_idIndexMarker859"/> using the replicas in other locations, ensuring <a id="_idIndexMarker860"/>that the service remains available <span class="No-Break">to users.</span></p>
			<h2 id="_idParaDest-253"><a id="_idTextAnchor347"/>CAP theorem</h2>
			<p>Let’s look at a <a id="_idIndexMarker861"/>couple of replication and recovery models that <a id="_idIndexMarker862"/>we should discuss. They cater to various levels of consistency, availability performance, and scalability <span class="No-Break">non-functional requirements.</span></p>
			<p>According to the <strong class="bold">CAP theorem</strong>, also known<a id="_idIndexMarker863"/> as <strong class="bold">Brewer’s theorem</strong>, it’s impossible for a distributed system to provide all three of the following non-functional <span class="No-Break">properties simultaneously:</span></p>
			<ul>
				<li><strong class="bold">Consistency (C)</strong>: All nodes in the system have the same data at the same time. Consistency ensures that the data is always in a <span class="No-Break">valid state</span></li>
				<li><strong class="bold">Availability (A)</strong>: Every request receives a non-error response, but there’s no guarantee that it contains the most <span class="No-Break">recent data</span></li>
				<li><strong class="bold">Partition tolerance (P)</strong>: The system continues to operate despite arbitrary message loss or failure of part of <span class="No-Break">the system</span></li>
			</ul>
			<p>The theorem states that when communication between nodes fails, a distributed system can only satisfy two of the three properties (C, A, or P) at the <a id="_idIndexMarker864"/>same time. This is known as the <span class="No-Break"><strong class="bold">CAP trade-off</strong></span><span class="No-Break">.</span></p>
			<p class="callout-heading">The history of the CAP theorem</p>
			<p class="callout">The CAP theorem was proposed by Eric Brewer in 2000 during the Symposium on <strong class="bold">Principles of Distributed Computing</strong> (<strong class="bold">PODC</strong>). The <a id="_idIndexMarker865"/>theorem was later proved by Seth Gilbert and Nancy Lynch of Massachusetts Institute of Technology in 2002, in their paper <em class="italic">Brewer’s Conjecture and the Feasibility of Consistent, Available, Partition-Tolerant </em><span class="No-Break"><em class="italic">Web Services</em></span><span class="No-Break">.</span></p>
			<p>The three possible choices are <span class="No-Break">as follows:</span></p>
			<ul>
				<li><strong class="bold">Consistency and partition tolerance (CP)</strong>: The <a id="_idIndexMarker866"/>system sacrifices availability to uphold strong consistency in the face of a network partition. This is common in traditional database systems, such as <span class="No-Break">relational databases.</span></li>
				<li><strong class="bold">Availability and partition tolerance (AP)</strong>: The <a id="_idIndexMarker867"/>system remains available but forgoes maintaining consistency during network failure. This is common in <span class="No-Break">NoSQL databases.</span></li>
				<li><strong class="bold">Consistency and availability (CA)</strong>: The system offers both consistency and availability, but <a id="_idIndexMarker868"/>this is only possible in a fully connected system with no network partitions. In practice, it rarely happens, and the system must choose between consistency <span class="No-Break">and availability.</span></li>
			</ul>
			<p>Although there are <a id="_idIndexMarker869"/>three combinations, the choice is more fluid and<a id="_idIndexMarker870"/> situational. For example, a system may be initially AP, but as more nodes fail, it may fall back to a single node running <span class="No-Break">with CA.</span></p>
			<p>The CAP theorem is a concept that helps developers understand the trade-offs they need to make when designing a distributed system. It’s an important consideration when you’re choosing the appropriate data storage and processing solutions for a <span class="No-Break">particular application.</span></p>
			<p>When exploring these models, it’s important to understand and discover the non-functional properties your system should aim for. Not all models are suitable for all systems. It’s about<a id="_idIndexMarker871"/> finding the most suitable models based on your needs and <span class="No-Break">anticipated scenarios.</span></p>
			<h2 id="_idParaDest-254"><a id="_idTextAnchor348"/>Model 1 – primary-secondary</h2>
			<p>The <strong class="bold">primary-secondary</strong> (also known<a id="_idIndexMarker872"/> as <strong class="bold">single-leader</strong>) replication <a id="_idIndexMarker873"/>has a <strong class="bold">Primary</strong> node (the “leader”) that handles all write operations and replicates data changes to the <strong class="bold">Secondary</strong> nodes (the “followers”). Single-leader replication is demonstrated in <span class="No-Break"><em class="italic">Figure 10</em></span><span class="No-Break"><em class="italic">.2</em></span><span class="No-Break">:</span></p>
			<div>
				<div id="_idContainer091" class="IMG---Figure">
					<img src="image/B21737_10_2.jpg" alt="Figure 10.2 – Primary-secondary replication" width="615" height="694"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 10.2 – Primary-secondary replication</p>
			<h3>Read and write operations</h3>
			<p>The <strong class="bold">Primary</strong> node is responsible for all write operations. Whether the <strong class="bold">Primary</strong> or <strong class="bold">Secondary</strong> nodes should serve read operations has a profound impact on system quality attributes such as consistency, throughput, availability, <span class="No-Break">and resilience.</span></p>
			<p>If the <strong class="bold">Primary</strong> node serves all read operations, then the <strong class="bold">Secondary</strong> nodes can be either cold backup or hot standby. Cold backup implies the <strong class="bold">Secondary</strong> nodes aren’t running but the data files are being replicated. Hot standby implies the <strong class="bold">Secondary</strong> nodes are up but not serving <span class="No-Break">any request.</span></p>
			<p>This setup provides strong consistency, but serving both read and write operations means the <strong class="bold">Primary</strong> node takes all the load. This increases resource consumption and makes it more challenging to achieve high performance. Moreover, if the <strong class="bold">Primary</strong> node fails, it may take some time for the cold backup to start up and cause an outage. The hot standby would have better availability as the <strong class="bold">Secondary</strong> nodes are already running, but all read requests to the failed primary node are still impacted. This will cause a “blip” until one of the <strong class="bold">Secondary</strong> nodes becomes the <span class="No-Break"><strong class="bold">Primary</strong></span><span class="No-Break"> node.</span></p>
			<p>If <strong class="bold">Secondary</strong> nodes serve read requests, the throughput of read operations is increased. More nodes are available to handle read requests. If some of the <strong class="bold">Secondary</strong> nodes fail, others can continue to operate. This approach comes with the trade-off of potential inconsistency issues. Imagine if one of the <strong class="bold">Secondary</strong> nodes failed to connect to the <strong class="bold">Primary</strong> node; this <strong class="bold">Secondary</strong> node would have outdated data but still performs a read operation and provides outdated data, something that’s inconsistent with <a id="_idIndexMarker874"/><span class="No-Break">other nodes.</span></p>
			<h3>Replication</h3>
			<p>When you’re replicating data changes from the <strong class="bold">Primary</strong> node to <strong class="bold">Secondary</strong> nodes, you have two options: synchronous or asynchronous replication. An example sequence diagram of the synchronization process is shown in <span class="No-Break"><em class="italic">Figure 10</em></span><span class="No-Break"><em class="italic">.3</em></span><span class="No-Break">:</span></p>
			<div>
				<div id="_idContainer092" class="IMG---Figure">
					<img src="image/B21737_10_3.jpg" alt="Figure 10.3 – Primary-secondary synchronization – synchronous (left)/asynchronous (right)" width="1650" height="715"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 10.3 – Primary-secondary synchronization – synchronous (left)/asynchronous (right)</p>
			<p>This diagram is split vertically into two approaches. On the left-hand side, we have synchronous replication. Here, a write request is sent to the primary node. The primary node updates the data in its local storage but doesn’t commit the transaction. Then, it sends the data change to all <span class="No-Break">secondary nodes.</span></p>
			<p>This is a blocking and synchronous process where the primary node waits for responses from all secondary nodes. If all responses are successful, then the primary node commits the transaction and flushes the changes to local storage. Finally, a response is returned to the original requester. The synchronized approach maintains strong data consistency across all nodes at the cost of higher latency due to synchronous communication between the primary and <span class="No-Break">secondary nodes.</span></p>
			<p>On the right-hand side, after the primary node completes the write request, the data change is committed to local storage, and the response is returned to the requester. The data changes are synchronized in the background without blocking. This is either done as a scheduled background process or as an event that’s published to the secondary nodes. This approach has reduced latency as replication isn’t required to return a response. However, it introduces scenarios where data could <span class="No-Break">be inconsistent.</span></p>
			<p>If the communication between the primary and some secondary nodes fails, some of the secondary nodes will have the latest data and some won’t. Meanwhile, all secondary nodes serve read operations that return different versions of the <span class="No-Break">same data.</span></p>
			<p>The risk of inconsistency can be mitigated by stamping the data with a version number or timestamp. Any outdated data can be spotted and <span class="No-Break">then skipped.</span></p>
			<p>The requester can also have a sticky connection with the secondary nodes serving read requests. The data that’s returned to the requester will change in tandem with the secondary node. This provides some level of reliability that a request won’t get one version of the data, and<a id="_idIndexMarker875"/> then get an <span class="No-Break">older version.</span></p>
			<h3>Failover</h3>
			<p>If the primary node fails, one of the secondary nodes needs to become the primary node. The new primary node can be determined by the round-robin rule, or a potentially more complex leader <span class="No-Break">election algorithm.</span></p>
			<p>If data is replicated asynchronously, losing a primary node may result in losing the latest data. This happens if the primary node has updated its local storage and returned the result, but then fails before it can notify <span class="No-Break">secondary nodes.</span></p>
			<p>It’s even worse if the failed primary node gets backed up but loses the connection to some of the secondary nodes. Here, a new primary node may have been assigned. We now have a split-brain situation where there are two primary nodes, and secondary nodes are fragmented. This usually requires manual intervention to shut down one of the primary nodes and reconnect all secondary nodes to the one <span class="No-Break">primary node.</span></p>
			<p>Primary-secondary <a id="_idIndexMarker876"/>replications are commonly used in highly available databases and <span class="No-Break">message brokers.</span></p>
			<h2 id="_idParaDest-255"><a id="_idTextAnchor349"/>Model 2 – partitioned and distributed</h2>
			<p><strong class="bold">Partitioned and distributed</strong> (known as <strong class="bold">multi-leader</strong>) replication<a id="_idIndexMarker877"/> distributes<a id="_idIndexMarker878"/> data management into<a id="_idIndexMarker879"/> partitions. It allows multiple nodes to serve requests at the same time. These nodes replicate the changes to the other nodes, enabling higher write throughput <span class="No-Break">and availability.</span></p>
			<p>It’s typically used when data and services are replicated across multiple geographical locations, often in different data centers or cloud regions. This provides availability and resilience against regional failures or disasters. This is illustrated in <span class="No-Break"><em class="italic">Figure 10</em></span><span class="No-Break"><em class="italic">.4</em></span><span class="No-Break">:</span></p>
			<div>
				<div id="_idContainer093" class="IMG---Figure">
					<img src="image/B21737_10_4.jpg" alt="Figure 10.4 – Partitioned and distributed replication" width="1464" height="695"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 10.4 – Partitioned and distributed replication</p>
			<p>Requests are geographically partitioned so that users of a given region can access the corresponding services in that region. Within this region, this partitioned and distributed replication can behave exactly like primary-secondary replication, where primary nodes serve write requests and secondary nodes serve <span class="No-Break">read requests.</span></p>
			<p>Across regions, an additional synchronization process occurs so that the data in one region is copied to another. Some data is fully partitioned and regional, which means that all requests for the data are served within the designated region in normal circumstances. Some data is shared and may need to be fully replicated. This introduces the need to resolve conflicts if it’s updated in <span class="No-Break">both regions.</span></p>
			<p>This setup is more complex compared to primary-secondary replication. However, it can be justified if there are non-functional requirements such as <span class="No-Break">the following:</span></p>
			<ul>
				<li>Serve requests coming from multiple <span class="No-Break">geographic regions</span></li>
				<li>Recover in the face of total data <span class="No-Break">center failure</span></li>
				<li>Decouple from a particular cloud provider architecturally <span class="No-Break">and operationally</span></li>
				<li>Support <span class="No-Break">offline operations</span></li>
				<li>Support collaborative <span class="No-Break">update operations</span></li>
			</ul>
			<p>On the other hand, it will become difficult to uphold strong consistency if the same data across multiple regions can’t be updated at the <span class="No-Break">same time.</span></p>
			<p>If a data center has failed, requests for the corresponding partition should be routed to the running data<a id="_idIndexMarker880"/> center. Data that hasn’t been replicated in the running data center would be lost. In this situation, clients may need to roll back to the last <span class="No-Break">replicated state.</span></p>
			<h3>Resolving write conflicts and avoiding lost updates</h3>
			<p>Partitioned and distributed replication requires some mechanisms to resolve write conflicts in which the same piece of data is updated simultaneously, and perhaps differently. Let’s illustrate the resolution of write conflicts with a <span class="No-Break">real-life example.</span></p>
			<p>Imagine that each household in a village has a record of its name and a contact email address. The <em class="italic">Whittington</em> household has a record in the repository with an email address <span class="No-Break">of </span><span class="No-Break"><em class="italic">info@whittington.com</em></span><span class="No-Break">.</span></p>
			<p>This record is exposed to two different clients. Each client has read the email address, <em class="italic">info@whittington.com</em>. One client has updated the email address to <em class="italic">query@whittington.com</em>, while the other one has updated it to <em class="italic">contact@whittington.com</em>. The two clients attempt to update the value in the repository by providing their updated ones. The repository is going to receive the write requests from these <span class="No-Break">two clients.</span></p>
			<p>Both clients determine the new value based on the current value <span class="No-Break">they receive:</span></p>
			<ul>
				<li><strong class="bold">Client A</strong>: Update the current email address from <em class="italic">info@whittington.com</em> <span class="No-Break">to </span><span class="No-Break"><em class="italic">query@whittington.com</em></span></li>
				<li><strong class="bold">Client B</strong>: Update the current email address from <em class="italic">info@whittington.com</em> <span class="No-Break">to </span><span class="No-Break"><em class="italic">contact@whittington.com</em></span></li>
			</ul>
			<p>If Client A requests an update earlier than Client B does, then the process of updating the email address to <em class="italic">query@whittington.com</em> would be lost. This is because Client B almost immediately overwrote the value with <em class="italic">contact@whittington.com</em> without knowing Client A had also requested an update. This problem is <a id="_idIndexMarker881"/>called the <strong class="bold">lost </strong><span class="No-Break"><strong class="bold">update</strong></span><span class="No-Break"> problem.</span></p>
			<p>This problem is typically solved by having a version number or timestamp on the data. If an incoming request update is identified as older than the one in the system record, then it’s safe to skip the update. Having a monotonic increasing version number is a preferred method <a id="_idIndexMarker882"/>compared to timestamps due to the risk that the system clock on each machine can <span class="No-Break">be different.</span></p>
			<p>We can model this situation with the following <span class="No-Break">data class:</span></p>
			<pre class="source-code">
data class Household(
    val version: Int,
    val name: String,
    val email: String,
)</pre>			<p>Here, the <strong class="source-inline">Household</strong> class has a <strong class="source-inline">version</strong> field as an integer. This will be used for comparison during the update operation. There’s also a repository class for <strong class="source-inline">Household</strong> to handle the update request. Here’s the scenario simulated <span class="No-Break">in code:</span></p>
			<pre class="source-code">
fun main() {
    val repo = HouseholdRepository()
    val name = "Whittington"
    val email1 = "info@whittington.com"
    val email2a = "query@whittington.com"
    val email2b = "contact@whittington.com"
    val household1 = Household(0, name, email1)</pre>			<p>First, a <strong class="source-inline">household</strong> record is created as a version, after which there are two updates based <span class="No-Break">on it:</span></p>
			<pre class="source-code">
    repo.create(name) { household1 }
    repo.update(name) { household1.copy(version = 1, email = email2a)}
    repo.update(name) { household1.copy(version = 1, email = email2b)}
    repo.get(name)?.also {
        println("${it.version}, ${it.email}")
    }
}</pre>			<p>In this situation, we would expect the second update to be skipped because it was based on version zero. The second update would require refreshing the <strong class="source-inline">household</strong> record to version one and <a id="_idIndexMarker883"/>computing the <span class="No-Break">potential update.</span></p>
			<p>A version check should be in place in the repository to prevent the lost update problem. Here’s an <span class="No-Break">example implementation:</span></p>
			<pre class="source-code">
class HouseholdRepository {
    private val values: ConcurrentMap&lt;String, Household&gt; = ConcurrentHashMap()</pre>			<p>The <strong class="source-inline">HouseholdRepository</strong> class holds a <strong class="source-inline">ConcurrentMap</strong> interface that uses the household name as the key. The <strong class="source-inline">create</strong> function makes use of the atomic <strong class="source-inline">putIfAbsent</strong> function to ensure the value won’t be overwritten <span class="No-Break">by mistake:</span></p>
			<pre class="source-code">
    fun create(
        key: String,
        callback: () -&gt; Household
    ): Household {
        val household = callback()
        val result = values.putIfAbsent(key, household)
        return result ?: household
    }</pre>			<p>The <strong class="source-inline">update</strong> function checks that the updated value must be one version higher than the existing value by using the atomic <span class="No-Break"><strong class="source-inline">computeIfPresent</strong></span><span class="No-Break"> function:</span></p>
			<pre class="source-code">
    fun update(
        key: String,
        callback: (Household) -&gt; Household
    ): Household? = values.computeIfPresent(key) { _, existing -&gt;
        callback(existing).let { updated -&gt;
            if (updated.version == existing.version + 1) {
                updated
            } else {
                existing
            }
        }
    }</pre>			<p>For<a id="_idIndexMarker884"/> completeness, there’s also a <strong class="source-inline">get</strong> function so that we can get what’s kept in the map after <span class="No-Break">the run:</span></p>
			<pre class="source-code">
    fun get(key: String): Household? = values[key]
}</pre>			<p>The output of the program is <span class="No-Break">as follows:</span></p>
			<pre class="console">
1, query@whittington.com</pre>			<p>This means the second update <span class="No-Break">is skipped.</span></p>
			<h2 id="_idParaDest-256"><a id="_idTextAnchor350"/>Model 3 – quorum-based replication</h2>
			<p><strong class="bold">Quorum-based</strong> (also known as <strong class="bold">leaderless</strong>) <strong class="bold">replication</strong> requires nodes to agree on the state of the <a id="_idIndexMarker885"/>data <a id="_idIndexMarker886"/>before <a id="_idIndexMarker887"/>committing a write operation. This ensures consistency and availability, even if some nodes <span class="No-Break">have failed.</span></p>
			<p>The key difference of quorum-based replication is the lack of a primary node, a leader, or a central coordinator. Instead, the data is decentralized and distributed among the nodes in <span class="No-Break">the cluster:</span></p>
			<div>
				<div id="_idContainer094" class="IMG---Figure">
					<img src="image/B21737_10_5.jpg" alt="Figure 10.5 – Quorum-based replication" width="723" height="628"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 10.5 – Quorum-based replication</p>
			<p>A write operation is only considered successful if it’s acknowledged by the majority (quorum) of the participating nodes in the system. This quorum requirement ensures that a write is only committed if it’s been replicated to enough nodes, making the system resilient to individual <span class="No-Break">node failures.</span></p>
			<p>The quorum size is typically set to at least more than half of the total nodes, ensuring that even if some fail, the system can still make progress and maintain a consistent state. The data that’s synchronized among the nodes is versioned for a couple <span class="No-Break">of reasons:</span></p>
			<ul>
				<li>The data synchronization process needs to identify an older version of the data, as well as increment the version to indicate <span class="No-Break">an update</span></li>
				<li>Clients can read the version to understand whether the data that’s received <span class="No-Break">is outdated</span></li>
			</ul>
			<p>For example, in a five-node cluster, a quorum size of three would be required for a write operation to succeed. This way, the system can tolerate the failure of up to two nodes without compromising <span class="No-Break">data consistency.</span></p>
			<p>Since all the nodes have the same state, there’s no actual failover mechanism. Instead, each request would need to be able to remove duplicated or older responses. This can be done if the data <span class="No-Break">is versioned.</span></p>
			<p>Quorum-based replication is commonly used in distributed databases, key-value stores, P2P networks, blockchains, and<a id="_idIndexMarker888"/> coordination services, where<a id="_idIndexMarker889"/> maintaining strong consistency and availability in the face of node failures is of <span class="No-Break">utmost importance.</span></p>
			<h2 id="_idParaDest-257"><a id="_idTextAnchor351"/>Comparing the three replication models</h2>
			<p>Choosing the<a id="_idIndexMarker890"/> appropriate replication mode in a database or data system depends on several factors, including non-functional requirements regarding consistency, availability, performance, and fault tolerance. Here’s a summary and use case for <span class="No-Break">each model:</span></p>
			<table id="table001-3" class="No-Table-Style">
				<colgroup>
					<col/>
					<col/>
					<col/>
				</colgroup>
				<tbody>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">Primary-Secondary</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><strong class="bold">Partitioned </strong><span class="No-Break"><strong class="bold">and Distributed</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">Quorum-Based</strong></span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">Strong consistency</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">Eventual consistency</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">Configurable consistency</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>Simple and easy <span class="No-Break">to maintain</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">Increased complexity</span></p>
						</td>
						<td class="No-Table-Style">
							<p>Complex <span class="No-Break">quorum maintenance</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>Low tolerance for <span class="No-Break">data loss</span></p>
						</td>
						<td class="No-Table-Style">
							<p>Challenges in <span class="No-Break">conflict resolution</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">Fault tolerance</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>Performance is limited by the capacity of the leader and <span class="No-Break">replication lag</span></p>
						</td>
						<td class="No-Table-Style">
							<p>Performance is limited by the capacity of the leader and <span class="No-Break">replication lag</span></p>
						</td>
						<td class="No-Table-Style">
							<p>Additional latency to achieve consensus for <span class="No-Break">each change</span></p>
							<p>Higher <span class="No-Break">resource usage</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">Less available</span></p>
						</td>
						<td class="No-Table-Style">
							<p>Highly available; load balancer options <span class="No-Break">are available</span></p>
						</td>
						<td class="No-Table-Style">
							<p>Depends on the number of <span class="No-Break">nodes available</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>Single point <span class="No-Break">of failure</span></p>
						</td>
						<td class="No-Table-Style">
							<p>No single point <span class="No-Break">of failure</span></p>
						</td>
						<td class="No-Table-Style">
							<p>No single point <span class="No-Break">of failure</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>Suitable for traditional databases and systems that read more often than write (for example, content <span class="No-Break">management systems)</span></p>
						</td>
						<td class="No-Table-Style">
							<p>Suitable for systems spread across different regions and <span class="No-Break">collaborative applications</span></p>
						</td>
						<td class="No-Table-Style">
							<p>Suitable for distributed data stores and critical systems that <span class="No-Break">aren’t latency-sensitive</span></p>
						</td>
					</tr>
				</tbody>
			</table>
			<p>The failover mechanism is part of the recovery process, but it focuses on shifting the workload to other running nodes. Recovery also covers bringing up nodes that weren’t running. These <a id="_idIndexMarker891"/>approaches will be covered in the <span class="No-Break">next section.</span></p>
			<h1 id="_idParaDest-258"><a id="_idTextAnchor352"/>Recovery</h1>
			<p>The recovery process of a<a id="_idIndexMarker892"/> system heavily relies on accessible data replicas, except stateless systems. This implies that the recovery approach heavily relies on the <span class="No-Break">replication approach.</span></p>
			<h2 id="_idParaDest-259"><a id="_idTextAnchor353"/>Snapshots and checkpoints</h2>
			<p>The most common <a id="_idIndexMarker893"/>approach for recovery is to have a snapshot of the last known system state. Periodically saving the state of the distributed system is<a id="_idIndexMarker894"/> known <span class="No-Break">as </span><span class="No-Break"><strong class="bold">checkpointing</strong></span><span class="No-Break">.</span></p>
			<p>In the event of a failure, the system can be rolled back to the last known good checkpoint to restore the system to a consistent state. Data that didn’t persist in the snapshot will be lost. The amount of data loss would depend on how often the snapshots <span class="No-Break">are taken.</span></p>
			<h2 id="_idParaDest-260"><a id="_idTextAnchor354"/>Change logs</h2>
			<p>A system state can also <a id="_idIndexMarker895"/>be restored by replaying the change logs of all operations and transactions within the <span class="No-Break">distributed system.</span></p>
			<p>It’s common to recover distributed systems using a combination of checkpoints and change logs. This is similar to the event sourcing recovery method mentioned in <a href="B21737_09.xhtml#_idTextAnchor307"><span class="No-Break"><em class="italic">Chapter 9</em></span></a>, where an aggregate is stored by replaying all <span class="No-Break">related events.</span></p>
			<p>This approach helps recover from failures by replaying the missed or <span class="No-Break">lost operations.</span></p>
			<h2 id="_idParaDest-261"><a id="_idTextAnchor355"/>Re-route and re-balance</h2>
			<p>After a node is <a id="_idIndexMarker896"/>brought up, it needs to create or join a network of nodes. Requests may need to be re-routed and partitions may need to <span class="No-Break">be re-balanced.</span></p>
			<p>This may also trigger <a id="_idIndexMarker897"/>the election of a new<a id="_idIndexMarker898"/> primary node. Consensus protocols such as <strong class="bold">Raft</strong> (<a href="https://raft.github.io/">https://raft.github.io/</a>) and <strong class="bold">Paxos</strong> (<a href="https://www.microsoft.com/en-us/research/publication/part-time-parliament/">https://www.microsoft.com/en-us/research/publication/part-time-parliament/</a>) may be used to coordinate the actions of the other nodes, ensuring the system remains operational even when individual <span class="No-Break">nodes fail.</span></p>
			<h2 id="_idParaDest-262"><a id="_idTextAnchor356"/>Case study – Raft leader election</h2>
			<p>To<a id="_idIndexMarker899"/> demonstrate <a id="_idIndexMarker900"/>the details of recovery, we’re going to walk through a simplified <strong class="bold">Raft</strong> leader election process, as demonstrated in <span class="No-Break"><em class="italic">Figure 10</em></span><span class="No-Break"><em class="italic">.5</em></span><span class="No-Break">:</span></p>
			<div>
				<div id="_idContainer095" class="IMG---Figure">
					<img src="image/B21737_10_6.jpg" alt="Figure 10.6 – Node state transition in Raft leader election" width="1159" height="917"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 10.6 – Node state transition in Raft leader election</p>
			<p>Raft uses primary-secondary replication in which the primary node replicates data changes to all secondary<a id="_idIndexMarker901"/> nodes. The primary node keeps<a id="_idIndexMarker902"/> an integer <a id="_idIndexMarker903"/>called <strong class="bold">Terms</strong>; this number increments for each election. Each request that’s received by the primary node is stamped <span class="No-Break">by Terms.</span></p>
			<p>The primary node broadcasts heartbeat messages to all secondary nodes. They’re like pulses to keep announcing that the primary node has <span class="No-Break">been up.</span></p>
			<p>When a secondary node hasn’t received heartbeat messages over the configured time, it becomes a candidate and calls other secondary nodes to vote <span class="No-Break">for itself.</span></p>
			<p>Other secondary nodes can either accept or reject their votes. When a candidate has been accepted by receiving the most votes, they become the primary node, and others revert <span class="No-Break">to followers.</span></p>
			<p>This mechanism happens concurrently and means there will be conflicts <span class="No-Break">to resolve:</span></p>
			<ul>
				<li><strong class="bold">Conflicting elections</strong>: Conflicting elections can happen if the timed-out configurations for heartbeat messages are the same among all secondary nodes. This can be avoided by randomizing the timed-out configuration in each node. Moreover, if there are ties of conflicting elections, all elections are called off, after which another election can <span class="No-Break">be called.</span></li>
				<li><strong class="bold">Multiple leaders</strong>: If a part of the network is disconnected from another, we can end up with a split-brain situation, where each inter-connected portion starts its own election. Since the majority should be more than half of the total number of nodes, only one part can reach majority votes and elect <span class="No-Break">a leader.</span><p class="list-inset">If the original leader is in the smaller part of the split network, there will be multiple leaders when the whole network has recovered. At this point, the value <em class="italic">Terms</em> can be used to make the original leader step down because the new leader will have a higher term value than <span class="No-Break">the original.</span></p></li>
				<li><strong class="bold">Outdated candidates</strong>: Some secondary nodes could be behind others in replication but would still call for an election and put themselves as candidates. If one of them became the primary node, its outdated data became the source of truth, and some updates could <span class="No-Break">be lost.</span></li>
			</ul>
			<p>To avoid this situation, the secondary nodes will reject candidates whose Terms are lower than other <a id="_idIndexMarker904"/>candidates, and whose data isn’t up to date. A <a id="_idIndexMarker905"/>candidate who has outdated data can be spotted by the number of items in the <span class="No-Break">change log.</span></p>
			<h1 id="_idParaDest-263"><a id="_idTextAnchor357"/>Summary</h1>
			<p>In this chapter, we covered three topics: idempotency, replication, and recovery. First, we discussed four scenarios where idempotency is useful and how it can be achieved with <span class="No-Break">reference implementation.</span></p>
			<p>Then, we briefly mentioned how to replicate data and services. We brought up the CAP theorem, in which trade-offs need to be considered for each system. We also delved into three models of replication, namely primary-secondary, partitioned and distributed, <span class="No-Break">and quorum-based.</span></p>
			<p>Finally, we covered some common mechanisms of recovery, outlining how a newly launched node can become operational in the context of <span class="No-Break">distributed systems.</span></p>
			<p>In the next chapter, we’ll cover the audit and monitoring aspects of a <span class="No-Break">distributed system.</span></p>
		</div>
	</div></div></body></html>