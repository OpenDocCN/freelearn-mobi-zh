<html><head></head><body><div><div><div><div><h1 class="title"><a id="ch06"/>Chapter 6. Audio</h1></div></div></div><p>In this chapter, we will cover the following topics:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Playing sounds and music</li><li class="listitem" style="list-style-type: disc">Modifying audio properties</li><li class="listitem" style="list-style-type: disc">Fading sounds and music</li><li class="listitem" style="list-style-type: disc">Using audio in a game</li><li class="listitem" style="list-style-type: disc">Using positional audio in a game</li><li class="listitem" style="list-style-type: disc">Metering background music</li><li class="listitem" style="list-style-type: disc">Metering dialogue for animation</li><li class="listitem" style="list-style-type: disc">Recording audio</li><li class="listitem" style="list-style-type: disc">Streaming audio</li><li class="listitem" style="list-style-type: disc">Using the iPod music library</li><li class="listitem" style="list-style-type: disc">Creating a MIDI synthesizer</li><li class="listitem" style="list-style-type: disc">Speech recognition and text to speech</li></ul></div><div><div><div><div><h1 class="title"><a id="ch06lvl1sec01"/>Introduction</h1></div></div></div><p>Depending on what kind of game you're making, adding audio can be anything from a simple to a daunting task. In this chapter we will integrate sounds and music into game examples. We will also use advanced audio techniques like metering, recording, speech recognition, and more.</p></div></div>
<div><div><div><div><h1 class="title"><a id="ch06lvl1sec02"/>Playing sounds and music</h1></div></div></div><p>Most games use a variety of sound effects and at most a few different background music tracks.<strong> CocosDenshion</strong> is the audio library built into Cocos2d. It provides a number of features including the<strong> SimpleAudioEngine</strong> API. In this recipe, we will use this API to play sounds and music.<a id="id404" class="indexterm"/>
</p><div><img src="img/4002_06_01.jpg" alt="Playing sounds and music"/></div><div><div><div><div><h2 class="title"><a id="ch06lvl2sec01"/>Getting ready</h2></div></div></div><p>Please refer to the project<em> RecipeCollection02</em> for full working code of this recipe.<a id="id405" class="indexterm"/>
</p></div><div><div><div><div><h2 class="title"><a id="ch06lvl2sec02"/>How to do it...</h2></div></div></div><p>Execute the following code:</p><div><pre class="programlisting">#import "SimpleAudioEngine.h"
@implementation Ch6_SoundsAndMusic
-(CCLayer*) runRecipe {
//Initialize the audio engine
sae = [SimpleAudioEngine sharedEngine];
//Background music is stopped on resign and resumed on become active
[[CDAudioManager sharedManager] setResignBehavior:kAMRBStopPlay autoHandle:YES];
//Initialize source container
soundSources = [[NSMutableDictionary alloc] init];
//Add the sounds
[self loadSoundEffect:@"crazy_chimp.caf"];
[self loadSoundEffect:@"rapid_gunfire.caf"];
[self loadSoundEffect:@"howie_scream.caf"];
[self loadSoundEffect:@"air_horn.caf"];
[self loadSoundEffect:@"slide_whistle.caf"];
//Add the background music
[self loadBackgroundMusic:@"hiphop_boss_man_by_p0ss.mp3"];
//Add menu items
CCMenuItemSprite *musicItem = [self menuItemFromSpriteFile:@"music_note.png" tag:0];
CCMenuItemSprite *chimpItem = [self menuItemFromSpriteFile:@"you_stupid_monkey.png" tag:1];
CCMenuItemSprite *gunItem = [self menuItemFromSpriteFile:@"tommy_gun.png" tag:2];
CCMenuItemSprite *screamItem = [self menuItemFromSpriteFile:@"yaaargh.png" tag:3];
CCMenuItemSprite *airHornItem = [self menuItemFromSpriteFile:@"air_horn.png" tag:4];
CCMenuItemSprite *slideWhistleItem = [self menuItemFromSpriteFile:@"slide_whistle.png" tag:5];
//Create our menu
CCMenu *menu = [CCMenu menuWithItems: musicItem, chimpItem, gunItem, screamItem, airHornItem, slideWhistleItem, nil];
[menu alignItemsInColumns: [NSNumber numberWithUnsignedInt:3], [NSNumber numberWithUnsignedInt:3], nil];
menu.position = ccp(240,140);
[self addChild:menu];
return self;
}
//Play sound callback
-(void) playSoundNumber:(id)sender {
CCMenuItem *item = (CCMenuItem*)sender;
int number = item.tag;
if(number == 0){
[self playBackgroundMusic:@"hiphop_boss_man_by_p0ss.mp3"];
}else if(number == 1){
[self playSoundFile:@"crazy_chimp.caf"];
}else if(number == 2){
[self playSoundFile:@"rapid_gunfire.caf"];
}else if(number == 3){
[self playSoundFile:@"howie_scream.caf"];
}else if(number == 4){
[self playSoundFile:@"air_horn.caf"];
}else if(number == 5){
[self playSoundFile:@"slide_whistle.caf"];
}
}
-(void) loadBackgroundMusic:(NSString*)fn {
//Pre-load background music
[sae preloadBackgroundMusic:fn];
}
-(void) playBackgroundMusic:(NSString*)fn {
if (![sae isBackgroundMusicPlaying]) {
//Play background music
[sae playBackgroundMusic:fn];
}else{
//Stop music if its currently playing
[sae stopBackgroundMusic];
}
}
-(CDSoundSource*) loadSoundEffect:(NSString*)fn {
//Pre-load sound
[sae preloadEffect:fn];
//Init sound
CDSoundSource *sound = [[sae soundSourceForFile:fn] retain];
//Add sound to container
[soundSources setObject:sound forKey:fn];
return sound;
}
-(void) playSoundFile:(NSString*)fn {
//Get sound
CDSoundSource *sound = [soundSources objectForKey:fn];
//Play sound
[sound play];
}
-(void) cleanRecipe {
//Stop background music
[sae stopBackgroundMusic];
for(id s in soundSources){
//Release source
CDSoundSource *source = [soundSources objectForKey:s];
[source release];
}
[soundSources release];
//End engine
[SimpleAudioEngine end];
sae = nil;
[super cleanRecipe];
}
@end
</pre></div></div><div><div><div><div><h2 class="title"><a id="ch06lvl2sec03"/>How it works...</h2></div></div></div><p>The<code class="literal"> SimpleAudioEngine</code> class provides the user with a very simple interface for basic audio playback. The<code class="literal"> [SimpleAudioEngine sharedEngine]</code> singleton is merely a simplified wrapper over the<code class="literal"> [CDAudioManager sharedManager]</code> singleton provided by CocosDenshion.<a id="id406" class="indexterm"/>
</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Initialization:<p>No initialization of <code class="literal">SimpleAudioEngine</code> is necessary. In this recipe we simply maintain a pointer to <code class="literal">[SimpleAudioEngine sharedEngine]</code> to shorten some code. We set <strong>resign behavior</strong> using the following line. This changes audio behavior when the application is suspended or otherwise interrupted.
</p><div><pre class="programlisting">[[CDAudioManager sharedManager] setResignBehavior:kAMRBStopPlay autoHandle:YES];
</pre></div><p>This overrides the <code class="literal">applicationWillResignActive</code> method specified under the <code class="literal">UIApplicationDelegate</code> implemented by <code class="literal">CDAudioManager</code>. Other resign types are defined in <code class="literal">CDAudioManager.h</code>. This one stops background music on resign (pressing the home button on an iOS device) and plays the background music when the application becomes active.
<a id="id407" class="indexterm"/>
</p></li><li class="listitem" style="list-style-type: disc">Playing sound effects:<a id="id408" class="indexterm"/><p>Each sound effect that we'll play is an instance of <code class="literal">CDSoundSource</code>. "Loading" a sound effect involves pre-loading it using <code class="literal">SimpleAudioEngine</code>. Playing a sound without pre-loading it will result in a delay and diminished sound quality. To pre-load a sound, use the following line:
</p><div><pre class="programlisting">[sae preloadEffect:@"crazy_chimp.caf"];
</pre></div><p>Initializing a <code class="literal">CDSoundSource</code> object:
</p><div><pre class="programlisting">CDSoundSource *sound = [[sae soundSourceForFile:fn] retain];
</pre></div><p>And finally, maintaining a reference to that object:
</p><div><pre class="programlisting">NSMutableDictionary *soundSources = [[[NSMutableDictionary alloc] init] autorelease];
[soundSources setObject:sound forKey:fn];
</pre></div><p>To play a sound, we simply get the reference and call the play method:
</p><div><pre class="programlisting">CDSoundSource *sound = [soundSources objectForKey:fn];
[sound play];
</pre></div><p><code class="literal">SimpleAudioEngine</code> hides all the complex aspects of this process.
</p></li><li class="listitem" style="list-style-type: disc">Playing background music:<p>Playing background music is similar to playing sound effects except that there can only be one piece of background music playing at a given time:
<a id="id409" class="indexterm"/>
</p><div><pre class="programlisting">[sae preloadBackgroundMusic: @"hiphop_boss_man_by_p0ss.mp3"];
[sae playBackgroundMusic:@"hiphop_boss_man_by_p0ss.mp3"];
</pre></div><p>If necessary you can obtain a reference to the actual background music <code class="literal">CDLongAudioSource</code> object:
</p><div><pre class="programlisting">CDLongAudioSource *bgm = [CDAudioManager sharedManager].backgroundMusic;
</pre></div><p>This class is optimized for longer pieces of audio like music and narration.
</p></li></ul></div></div><div><div><div><div><h2 class="title"><a id="ch06lvl2sec04"/>There's More...</h2></div></div></div><p>Real time audio decoding and playback, especially on a mobile device, requires the use of specific audio formats.</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">CDSoundSource formats:<a id="id410" class="indexterm"/><p>The recommended encoding for sound effects is <strong>16-bit Mono Wave</strong> for uncompressed audio files and <strong>IMA4</strong> in a <strong>CAF</strong> container for lossy audio files.
</p></li><li class="listitem" style="list-style-type: disc">Converting to IMA4 audio files:<a id="id411" class="indexterm"/><p>On a Unix-based system, you can use the <strong>afconvert</strong> tool to convert from a number of formats to IMA4:
<a id="id412" class="indexterm"/>
</p></li></ul></div><div><pre class="programlisting"><strong>afconvert -f caff -d ima4 mysound.wav</strong>
</pre></div><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">CDLongAudioSource formats:<a id="id413" class="indexterm"/><p>For the playback of music and other long audio, any format supported by Apple's <code class="literal">AVAudioPlayer</code> will work. The format typically used is <strong>MP3</strong>.
</p></li><li class="listitem" style="list-style-type: disc">Memory sizes:<p>Although compressing audio reduces disk space requirements, all sound effects are stored in memory as <strong>16-bit uncompressed PCM</strong>. So, compressing sound effects will not reduce your application's memory footprint. This becomes a factor for larger and more sound intensive games.
</p></li></ul></div></div></div>
<div><div><div><div><h1 class="title"><a id="ch06lvl1sec03"/>Modifying audio properties</h1></div></div></div><p>CocosDenshion provides functionality to change the<strong> pitch, gain</strong>, and<strong> pan</strong> properties of an audio source. Pitch is the frequency, gain is volume, and pan is a way to shift volume between left and right speakers. In this example, we will create a music-bending instrument to display these properties being dynamically modified.<a id="id414" class="indexterm"/>
</p><div><img src="img/4002_06_02.jpg" alt="Modifying audio properties"/></div><div><div><div><div><h2 class="title"><a id="ch06lvl2sec05"/>Getting ready</h2></div></div></div><p>Please refer to the project<em> RecipeCollection02</em> for full working code of this recipe.<a id="id415" class="indexterm"/>
</p></div><div><div><div><div><h2 class="title"><a id="ch06lvl2sec06"/>How to do it...</h2></div></div></div><p>Execute the following code:</p><div><pre class="programlisting">#import "SimpleAudioEngine.h"
@implementation Ch6_AudioProperties
-(CCLayer*) runRecipe {
//Enable accelerometer support
self.isAccelerometerEnabled = YES;
[[UIAccelerometer sharedAccelerometer] setUpdateInterval:(1.0 / 60)];
//Add background
CCSprite *bg = [CCSprite spriteWithFile:@"synth_tone_sheet.png"];
bg.position = ccp(240,160);
[self addChild:bg];
//Initialize the audio engine
sae = [SimpleAudioEngine sharedEngine];
//Background music is stopped on resign and resumed on becoming active
[[CDAudioManager sharedManager] setResignBehavior:kAMRBStopPlay autoHandle:YES];
//Initialize note container
notes = [[NSMutableDictionary alloc] init];
noteSprites = [[NSMutableDictionary alloc] init];
//Preload tone
[sae preloadEffect:@"synth_tone_mono.caf"];
return self;
}
-(void) ccTouchesBegan:(NSSet *)touches withEvent:(UIEvent *)event {
//Process multiple touches
for(int i=0; i&lt;[[touches allObjects] count]; i++){
UITouch *touch = [[touches allObjects] objectAtIndex:i];
CGPoint point = [touch locationInView: [touch view]];
point = [[CCDirector sharedDirector] convertToGL: point];
//Use [touch hash] as a key for this sound source
NSString *key = [NSString stringWithFormat:@"%d",[touch hash]];
if([notes objectForKey:key]){
CDSoundSource *sound = [notes objectForKey:key];
[sound release];
[notes removeObjectForKey:key];
CCSprite *sprite = [noteSprites objectForKey:key];
[self removeChild:sprite cleanup:YES];
[noteSprites removeObjectForKey:key];
}
//Play our sound with custom pitch and gain
CDSoundSource *sound = [[sae soundSourceForFile:@"synth_tone_mono.caf"] retain];
[sound play];
sound.looping = YES;
[notes setObject:sound forKey:key];
sound.pitch = point.x/240.0f;
sound.gain = point.y/320.0f;
//Show music note where you touched
CCSprite *sprite = [CCSprite spriteWithFile:@"music_note.png"];
sprite.position = point;
[noteSprites setObject:sprite forKey:key];
sprite.scale = (point.y/320.0f)/2 + 0.25f;
[self addChild:sprite];
}
}
-(void) ccTouchesMoved:(NSSet *)touches withEvent:(UIEvent *)event {
//Adjust sound sources and music note positions
for(int i=0; i&lt;[[touches allObjects] count]; i++){
UITouch *touch = [[touches allObjects] objectAtIndex:i];
CGPoint point = [touch locationInView: [touch view]];
point = [[CCDirector sharedDirector] convertToGL: point];
NSString *key = [NSString stringWithFormat:@"%d",[touch hash]];
if([notes objectForKey:key]){
CDSoundSource *sound = [notes objectForKey:key];
sound.pitch = point.x/240.0f;
sound.gain = point.y/320.0f;
CCSprite *sprite = [noteSprites objectForKey:key];
sprite.position = point;
sprite.scale = (point.y/320.0f)/2 + 0.25f;
}
}
}
-(void) ccTouchesEnded:(NSSet *)touches withEvent:(UIEvent *)event {
//Stop sounds and remove sprites
for(int i=0; i&lt;[[touches allObjects] count]; i++){
UITouch *touch = [[touches allObjects] objectAtIndex:i];
CGPoint point = [touch locationInView: [touch view]];
point = [[CCDirector sharedDirector] convertToGL: point];
NSString *key = [NSString stringWithFormat:@"%d",[touch hash]];
if([notes objectForKey:key]){
//Stop and remove sound source
CDSoundSource *sound = [notes objectForKey:key];
[sound stop];
[sound release];
[notes removeObjectForKey:key];
//Remove sprite
CCSprite *sprite = [noteSprites objectForKey:key];
[self removeChild:sprite cleanup:YES];
[noteSprites removeObjectForKey:key];
}
}
}
//Adjust sound pan by turning the device sideways
- (void) accelerometer:(UIAccelerometer*)accelerometer didAccelerate:(UIAcceleration*)acceleration{
for(id s in notes){
CDSoundSource *sound = [notes objectForKey:s];
sound.pan = -acceleration.y; //"Turn" left to pan to the left speaker
}
}
@end
</pre></div></div><div><div><div><div><h2 class="title"><a id="ch06lvl2sec07"/>How it works...</h2></div></div></div><p>The first thing needed for this recipe is a short, constant, mid-range synthesized tone. This was created in<strong> GarageBand</strong> and then modified using<strong> Audacity</strong>. When you touch the screen the note is played:
</p><div><pre class="programlisting">CDSoundSource *sound = [[sae soundSourceForFile:@"synth_tone_mono.caf"] retain];
[sound play];
sound.looping = YES;
</pre></div><p>Now we need to set the<code class="literal"> pitch</code> between 0 and 2 according to the X position of the touch:
</p><div><pre class="programlisting">sound.pitch = point.x/240.0f;
</pre></div><p>We set the<code class="literal"> gain</code> property between 0 and 1 according to the Y position of the touch:
</p><div><pre class="programlisting">sound.gain = point.y/320.0f;
</pre></div><p>Tilting the device will set the<code class="literal"> pan</code> property. Tilt to the left to hear all tones more in your left ear and to the right to hear them more in your right:
</p><div><pre class="programlisting">for(id s in notes){
CDSoundSource *sound = [notes objectForKey:s];
sound.pan = -acceleration.y; //"Turn" left to pan to the left speaker
}
</pre></div><p>As you can see (and hear), audio properties can be modified in real time, while a sound is playing, to create really cool effects.<a id="id416" class="indexterm"/>
</p></div><div><div><div><div><h2 class="title"><a id="ch06lvl2sec08"/>There's More...</h2></div></div></div><p>The<code class="literal"> @"synth_tone_mono.caf"</code> file used in this recipe is specifically encoded as a<strong> mono</strong> sound effect. This is because the<strong> pan</strong> property can only be set on a mono sound effect.
</p></div></div>
<div><div><div><div><h1 class="title"><a id="ch06lvl1sec04"/>Fading sounds and music</h1></div></div></div><p>Taking a queue from Cocos2d actions, CocosDenshion provides a few classes for fading sounds and music. These are<code class="literal"> CDLongAudioSourceFader</code> and<code class="literal"> CDXPropertyModifierAction</code>. In this example, we will see how to fade in/out all sounds, individual sounds, and music. We will also see how to crossfade two music sources.<a id="id417" class="indexterm"/>
</p><div><img src="img/4002_06_03.jpg" alt="Fading sounds and music"/></div><div><div><div><div><h2 class="title"><a id="ch06lvl2sec09"/>Getting ready</h2></div></div></div><p>Please refer to the project RecipeCollection02 for full working code of this recipe.<a id="id418" class="indexterm"/>
</p></div><div><div><div><div><h2 class="title"><a id="ch06lvl2sec10"/>How to do it...</h2></div></div></div><p>Execute the following code:</p><div><pre class="programlisting">#import "SimpleAudioEngine.h"
#import "CDXPropertyModifierAction.h"
@implementation Ch6_FadingSoundsAndMusic
-(CCLayer*) runRecipe {
//Initialize the audio engine
sae = [SimpleAudioEngine sharedEngine];
//Background music is stopped on resign and resumed on becoming active
[[CDAudioManager sharedManager] setResignBehavior:kAMRBStopPlay autoHandle:YES];
//Initialize source container
soundSources = [[NSMutableDictionary alloc] init];
musicSources = [[NSMutableDictionary alloc] init];
//Add music
[self loadMusic:@"hiphop_boss_man_by_p0ss.mp3"];
[self loadMusic:@"menu_music_by_mrpoly.mp3"];
//Add sounds
[self loadSoundEffect:@"gunman_pain.caf"];
[self loadSoundEffect:@"synth_tone.caf"];
//Add menu items
/* CODE OMITTED */
return self;
}
//Play music callback
-(void) playMusicNumber:(id)sender {
CCMenuItem *item = (CCMenuItem*)sender;
int number = item.tag;
if(number == 0){
[self fadeOutPlayingMusic];
[self fadeInMusicFile:@"hiphop_boss_man_by_p0ss.mp3"];
}else if(number == 1){
[self fadeOutPlayingMusic];
[self fadeInMusicFile:@"menu_music_by_mrpoly.mp3"];
}
}
//Fade out any music sources currently playing
-(void) fadeOutPlayingMusic {
for(id m in musicSources){
//Release source
CDLongAudioSource *source = [musicSources objectForKey:m];
if(source.isPlaying){
//Create fader
CDLongAudioSourceFader* fader = [[CDLongAudioSourceFader alloc] init:source interpolationType:kIT_Exponential startVal:source.volume endVal:0.0f];
[fader setStopTargetWhenComplete:NO];
//Create a property modifier action to wrap the fader
CDXPropertyModifierAction* fadeAction = [CDXPropertyModifierAction actionWithDuration:3.0f modifier:fader];
[fader release];//Action will retain
CCCallFuncN* stopAction = [CCCallFuncN actionWithTarget:source selector:@selector(stop)];
[[CCActionManager sharedManager] addAction:[CCSequence actions:fadeAction, stopAction, nil] target:source paused:NO];
}
}
}
//Fade in a specific music file
-(void) fadeInMusicFile:(NSString*)fn {
//Stop music if its playing and return
CDLongAudioSource *source = [musicSources objectForKey:fn];
if(source.isPlaying){
[source stop];
return;
}
//Set volume to zero and play
source.volume = 0.0f;
[source play];
//Create fader
CDLongAudioSourceFader* fader = [[CDLongAudioSourceFader alloc] init:source interpolationType:kIT_Exponential startVal:source.volume endVal:1.0f];
[fader setStopTargetWhenComplete:NO];
//Create a property modifier action to wrap the fader
CDXPropertyModifierAction* fadeAction = [CDXPropertyModifierAction actionWithDuration:1.5f modifier:fader];
[fader release];//Action will retain
[[CCActionManager sharedManager] addAction:[CCSequence actions:fadeAction, nil] target:source paused:NO];
}
-(void) fadeUpAllSfx:(id)sender {
//Fade up all sound effects
[CDXPropertyModifierAction fadeSoundEffects:2.0f finalVolume:1.0f curveType:kIT_Linear shouldStop:NO];
}
-(void) fadeDownAllSfx:(id)sender {
//Fade down all sound effects
[CDXPropertyModifierAction fadeSoundEffects:2.0f finalVolume:0.0f curveType:kIT_Linear shouldStop:NO];
}
-(void) fadeUpSfxNumber:(id)sender {
//Fade up a specific sound effect
CCMenuItem *item = (CCMenuItem*)sender;
int number = item.tag;
CDSoundSource *source;
if(number == 0){
source = [soundSources objectForKey:@"gunman_pain.caf"];
}else if(number == 1){
source = [soundSources objectForKey:@"synth_tone.caf"];
}
source.gain = 0.0f;
[CDXPropertyModifierAction fadeSoundEffect:2.0f finalVolume:1.0f curveType:kIT_Linear shouldStop:NO effect:source];
}
-(void) fadeDownSfxNumber:(id)sender {
//Fade down a specific sound effect
CCMenuItem *item = (CCMenuItem*)sender;
int number = item.tag;
CDSoundSource *source;
if(number == 0){
source = [soundSources objectForKey:@"gunman_pain.caf"];
}else if(number == 1){
source = [soundSources objectForKey:@"synth_tone.caf"];
}
source.gain = 1.0f;
[CDXPropertyModifierAction fadeSoundEffect:2.0f finalVolume:0.0f curveType:kIT_Linear shouldStop:NO effect:source];
}
@end
</pre></div></div><div><div><div><div><h2 class="title"><a id="ch06lvl2sec11"/>How it works...</h2></div></div></div><p>In this recipe, we use<code class="literal"> CDLongAudioSource</code> directly as opposed to using the<code class="literal"> backgroundMusic</code> source provided by<code class="literal"> SimpleAudioEngine</code>. This allows us to have more than one long audio source playing at a given time.<a id="id419" class="indexterm"/>
</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Crossfading long audio sources:<a id="id420" class="indexterm"/><p>Crossfading involves fading one source in and one source out at the same time. First, we initialize a <code class="literal">CDLongAudioSourceFader </code>object to specify fading values and an interpolation type:
<a id="id421" class="indexterm"/>
</p><div><pre class="programlisting">CDLongAudioSourceFader* fader = [[CDLongAudioSourceFader alloc] init:source interpolationType:kIT_Linear startVal:source.volume endVal:0.0f];
[fader setStopTargetWhenComplete:NO];
</pre></div><p>In this case, we want to fade out linearly starting from the source's current volume. We then create a <code class="literal">CDXPropertyModifierAction</code> object with specified duration. We also release the fader object at this point:
<a id="id422" class="indexterm"/>
</p><div><pre class="programlisting">CDXPropertyModifierAction* fadeAction = [CDXPropertyModifierAction actionWithDuration:3.0f modifier:fader];
[fader release];
</pre></div><p>After fading the track out, we want to stop it from playing. For this, we create a <code class="literal">CCCallFuncN</code> action:
</p><div><pre class="programlisting">CCCallFuncN* stopAction = [CCCallFuncN actionWithTarget:source selector:@selector(stop)];
</pre></div><p>Finally, we run these actions in sequence:
</p><div><pre class="programlisting">[[CCActionManager sharedManager] addAction:[CCSequence actions:fadeAction, stopAction, nil] target:source paused:NO];
</pre></div><p>Running this action, along with the "fade in" action for the other track, will create the desired crossfading effect.
</p></li><li class="listitem" style="list-style-type: disc">Fading individual sound effects:<a id="id423" class="indexterm"/><p>The <code class="literal">CDXPropertyModifierAction</code> class has a convenience method for fading individual sound effects:
<a id="id424" class="indexterm"/>
</p><div><pre class="programlisting">[CDXPropertyModifierAction fadeSoundEffect:2.0f finalVolume:0.0f curveType:kIT_Linear shouldStop:YES effect:source];
</pre></div><p>In the previous example, we fade out the specified sound source for 2 seconds and then stop the source from playing when we're finished.
</p></li><li class="listitem" style="list-style-type: disc">Fading out all sound effects:<a id="id425" class="indexterm"/><p>All currently playing sound effects can be faded out as well using the following convenience method:
</p><div><pre class="programlisting">[CDXPropertyModifierAction fadeSoundEffects:2.0f finalVolume:0.0f curveType:kIT_Linear shouldStop:YES];
</pre></div><p>This applies the same "fade out" effect to all playing sound effects.
</p></li></ul></div></div></div>
<div><div><div><div><h1 class="title"><a id="ch06lvl1sec05"/>Using audio in a game</h1></div></div></div><p>While<code class="literal"> SimpleAudioEngine</code> may be simple, it is efficient enough to be used in any type of game. In this recipe, we will add sounds and music to the<strong> Bullets</strong> demo from<a class="link" href="ch04.html" title="Chapter 4. Physics"> Chapter 4</a>,<a id="id426" class="indexterm"/>
</p><div><img src="img/4002_06_04.jpg" alt="Using audio in a game"/></div><div><div><div><div><h2 class="title"><a id="ch06lvl2sec12"/>Getting ready</h2></div></div></div><p>Please refer to the project<em> RecipeCollection02</em> for full working code of this recipe.
</p></div><div><div><div><div><h2 class="title"><a id="ch06lvl2sec13"/>How to do it...</h2></div></div></div><p>Execute the following code:</p><div><pre class="programlisting">#import "Ch4_Bullets.h"
#import "SimpleAudioEngine.h"
@interface Ch6_AudioInGame : Ch4_Bullets
/* CODE OMITTED */
@end
@implementation Ch6_AudioInGame
-(CCLayer*) runRecipe {
[super runRecipe];
//Initialize the audio engine
sae = [SimpleAudioEngine sharedEngine];
//Background music is stopped on resign and resumed on becoming active
[[CDAudioManager sharedManager] setResignBehavior:kAMRBStopPlay autoHandle:YES];
//Initialize source container
soundSources = [[NSMutableDictionary alloc] init];
//Add the sounds
[self loadSoundEffect:@"bullet_fire_no_shell.caf" gain:1.0f];
[self loadSoundEffect:@"bullet_casing_tink.caf" gain:0.25f];
[self loadSoundEffect:@"gunman_jump.caf" gain:1.5f];
[self loadSoundEffect:@"box_break.wav" gain:1.5f];
//Add the background music
[self loadBackgroundMusic:@"hiphop_boss_man_by_p0ss.mp3"];
sae.backgroundMusicVolume = 0.5f;
[self playBackgroundMusic:@"hiphop_boss_man_by_p0ss.mp3"];
return self;
}
//Jump sound override
-(void) processJump {
if(onGround &amp;&amp; jumpCounter &lt; 0){
[self playSoundFile:@"gunman_jump.caf"];
}
[super processJump];
}
//Fire gun sound override
-(void) fireGun {
if(fireCount &lt;= 0){
[self playSoundFile:@"bullet_fire_no_shell.caf"];
}
[super fireGun];
}
//Box explosion sound override
-(void) boxExplosionAt:(CGPoint)p withRotation:(float)rot {
[self playSoundFile:@"box_break.wav"];
[super boxExplosionAt:p withRotation:rot];
}
//Bullet casing sound override
-(void) handleCollisionWithMisc:(GameMisc*)a withMisc:(GameMisc*)b {
if(a.typeTag == TYPE_OBJ_SHELL || b.typeTag == TYPE_OBJ_SHELL){
[self playSoundFile:@"bullet_casing_tink.caf"];
}
[super handleCollisionWithMisc:a withMisc:b];
}
@end
</pre></div></div><div><div><div><div><h2 class="title"><a id="ch06lvl2sec14"/>How it works...</h2></div></div></div><p>Using the techniques described in this chapter, we can breathe some life into our box-shooting demo by adding sounds and music.<a id="id427" class="indexterm"/>
</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Sound buffers:<p>By default, <code class="literal">CDAudioManager</code> allocates one sound buffer per sound source. So, every time we play the <code class="literal">@"bullet_fire_no_shell.caf"</code> sound effect we effectively stop that sound effect from playing if it was already in the process of playing. This is adequate for the majority of in-game sound effect use cases.
<a id="id428" class="indexterm"/>
</p></li></ul></div></div><div><div><div><div><h2 class="title"><a id="ch06lvl2sec15"/>There's more...</h2></div></div></div><p>Finding sound effects to use in your game can be a fun yet tedious process. Even though there exists a large number of royalty free sound effects floating around, it's often difficult to find the right one for a given situation. Alternatively, a microphone and some audio generation and manipulation software can go a long way. For example, the effect<code class="literal"> @"bullet_casing_tink.caf"</code> was created by playing the highest note on a piano using GarageBand. Another program,<strong> sfxr</strong>, can be used to generate simple 8-bit style sound effects. The Cocoa version,<strong> cfxr</strong>, can be downloaded here:<a class="ulink" href="http://thirdcog.eu/apps/cfxr"> http://thirdcog.eu/apps/cfxr</a>.<a id="id429" class="indexterm"/>
</p></div></div>
<div><div><div><div><h1 class="title"><a id="ch06lvl1sec06"/>Using positional audio in a game</h1></div></div></div><p>To increase the realism of the sounds we use in a game, we can modify audio properties based on in-game factors. In this example, we use<strong> source distance, audible range</strong>, and<strong> object size</strong> to determine<strong> gain, pitch</strong>, and<strong> pan</strong>. We'll demonstrate this by adding sounds to the<strong> TopDownIsometric</strong> demo from<a class="link" href="ch04.html" title="Chapter 4. Physics"> Chapter 4</a>,<a id="id430" class="indexterm"/>
</p><div><img src="img/4002_06_05.jpg" alt="Using positional audio in a game"/></div><div><div><div><div><h2 class="title"><a id="ch06lvl2sec16"/>Getting ready</h2></div></div></div><p>Please refer to the project<em> RecipeCollection02</em> for full working code of this recipe.
</p></div><div><div><div><div><h2 class="title"><a id="ch06lvl2sec17"/>How to do it...</h2></div></div></div><p>Execute the following code:<a id="id431" class="indexterm"/>
</p><div><pre class="programlisting">#import "Ch4_TopDownIsometric.h"
#import "SimpleAudioEngine.h"
enum {
CGROUP_NON_INTERRUPTIBLE = 0
};
@interface Ch6_PositionalAudio : Ch4_TopDownIsometric
/* CODE OMITTED */
@end
@implementation Ch6_PositionalAudio
-(CCLayer*) runRecipe {
//Run our top-down isometric game recipe
[super runRecipe];
//Initialize max audible range
audibleRange = 20.0f;
//Initialize the audio engine
sae = [SimpleAudioEngine sharedEngine];
//Background music is stopped on resign and resumed on becoming active
[[CDAudioManager sharedManager] setResignBehavior:kAMRBStopPlay autoHandle:YES];
//Preload the sounds
[sae preloadEffect:@"forest_birds_ambience.caf"];
[sae preloadEffect:@"kick_ball_bounce.caf"];
[sae preloadEffect:@"gunman_jump.caf"];
[sae preloadEffect:@"bullet_fire_no_shell.caf"];
//Non-interruptible ball source group
[[CDAudioManager sharedManager].soundEngine setSourceGroupNonInterruptible:CGROUP_NON_INTERRUPTIBLE isNonInterruptible:YES];
//Add the sounds
ballSource = [[sae soundSourceForFile:@"kick_ball_bounce.caf"] retain];
forestBirdsSource = [[sae soundSourceForFile:@"forest_birds_ambience.caf"] retain];
gunmanJumpSource = [[sae soundSourceForFile:@"gunman_jump.caf"] retain];
fireBallSource = [[sae soundSourceForFile:@"bullet_fire_no_shell.caf"] retain];
//Start playing forest bird source
forestBirdsSource.gain = 0.0f;
forestBirdsSource.looping = YES;
[forestBirdsSource play];
//Customize fire ball sound
fireBallSource.pitch = 2.0f;
fireBallSource.gain = 0.5f;
return self;
}
-(void) step:(ccTime)delta {
[super step:delta];
//Play forest bird source with gain based on distance from gunman
float distance = 10000.0f;
for(int i=0; i&lt;[trees count]; i++){
GameObject *tree = [trees objectAtIndex:i];
float thisDistance = distanceBetweenPoints(ccp(tree.body-&gt;GetPosition().x,tree.body-&gt;GetPosition().y),
ccp(gunman.body-&gt;GetPosition().x, gunman.body-&gt;GetPosition().y));
if(thisDistance &lt; distance){ distance = thisDistance; }
}
//If closest tree is outside of audible range we set gain to 0.0f
if(distance &lt; audibleRange){
forestBirdsSource.gain = (audibleRange-distance)/audibleRange;
}else{
forestBirdsSource.gain = 0.0f;
}
}
//Fire ball sound override
-(void) fireBall {
if(fireCount &lt; 0){
[fireBallSource play];
}
[super fireBall];
}
//Jump sound override
-(void) processJump {
if(gunman.body-&gt;GetZPosition() &lt;= 1.0f){
[gunmanJumpSource play];
}
[super processJump];
}
-(void) handleCollisionWithGroundWithObj:(GameObject*)gameObject {
[super handleCollisionWithGroundWithObj:gameObject];
//Play ball bounce sound with gain based on distance from gunman
if(gameObject.typeTag == TYPE_OBJ_BALL){
float distance = distanceBetweenPoints(ccp(gameObject.body-&gt;GetPosition().x, gameObject.body-&gt;GetPosition().y), ccp(gunman.body-&gt;GetPosition().x, gunman.body-&gt;GetPosition().y));
if(distance &lt; audibleRange){
float gain = (audibleRange-distance)/audibleRange;
float pan = (gameObject.body-&gt;GetPosition().x - gunman.body-&gt;GetPosition().x)/distance;
float pitch = ((((GameIsoObject*)gameObject).inGameSize / 10.0f) * -1) + 2;
if(distance &lt; audibleRange){
[self playBallSoundWithGain:gain pan:pan pitch:pitch];
}
}
}
}
-(void) playBallSoundWithGain:(float)gain pan:(float)pan pitch:(float)pitch {
//Play the sound using the non-interruptible source group
[[CDAudioManager sharedManager].soundEngine playSound:ballSource.soundId sourceGroupId:CGROUP_NON_INTERRUPTIBLE pitch:pitch pan:pan gain:gain loop:NO];
}
@end
</pre></div></div><div><div><div><div><h2 class="title"><a id="ch06lvl2sec18"/>How it works...</h2></div></div></div><p>Creating a realistic soundscape involves changing audio properties in creative ways.<a id="id432" class="indexterm"/>
</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Forest ambience:<p>For this recipe, we have a 30 second looping clip of forest ambience playing in place of background music. We determine the <code class="literal">gain</code> property of this sound source based on the player's distance from the closest tree:
</p><div><pre class="programlisting">if(distance &lt; audibleRange){
forestBirdsSource.gain = (audibleRange-distance)/audibleRange;
}else{
forestBirdsSource.gain = 0.0f;
}
</pre></div><p>If all trees are outside the audible range then we set the <code class="literal">gain</code> to zero.
</p></li><li class="listitem" style="list-style-type: disc">Ball bounce sounds:<p>To create a compelling ball bounce sound effect, we modify all three audio properties. The <code class="literal">gain</code> property is determined by distance:
</p><div><pre class="programlisting">float gain = (audibleRange-distance)/audibleRange;
</pre></div><p>The <code class="literal">pan</code> property is determined by X plane distance:
</p><div><pre class="programlisting">float pan = (gameObject.body-&gt;GetPosition().x - gunman.body-&gt;GetPosition().x)/distance;
</pre></div><p>Finally, the <code class="literal">pitch</code> property is determined by the ball's size:
</p><div><pre class="programlisting">float pitch = ((((GameIsoObject*)gameObject).inGameSize / 10.0f) * -1) + 2;
</pre></div><p>Together, these modifications create a variety of unique sounds. This adds depth to the auditory experience.
</p></li><li class="listitem" style="list-style-type: disc">Using multiple sound buffers:<p>Because we have multiple balls initiating bounce sound effects at the same time, a single buffer will no longer suffice. We now need the same sound to play over itself many times. To accomplish this we use a special <strong>Source Group</strong>. A source group is simply a way to group sounds together to manipulate how they get played. For example, you might want two sound sources to share a buffer. In this case, we specify a source group as being non-interruptible:
</p><div><pre class="programlisting">enum { CGROUP_NON_INTERRUPTIBLE = 0 };
[[CDAudioManager sharedManager].soundEngine setSourceGroupNonInterruptible:CGROUP_NON_INTERRUPTIBLE isNonInterruptible:YES];
</pre></div><p>Now, all sounds played using this source group will be given an open buffer. To specify a source group when playing a sound we use the following line:
</p><div><pre class="programlisting">[[CDAudioManager sharedManager].soundEngine playSound:ballSource.soundId sourceGroupId:CGROUP_NON_INTERRUPTIBLE pitch:pitch pan:pan gain:gain loop:NO];
</pre></div><p>Now, multiple ball bounce sound effects can be heard over each other with different audio properties.
</p></li><li class="listitem" style="list-style-type: disc">Maximum number of buffers:<a id="id433" class="indexterm"/><p>The maximum number of sound buffers available and the buffer increment is specified in <code class="literal">CDConfig.h</code>:
</p><div><pre class="programlisting">#define CD_BUFFERS_START 64
#define CD_BUFFERS_INCREMENT 16
</pre></div><p>In the default case, after 64 buffers are filled up, another 16 are allocated. These can be customized for applications with specific audio requirements.
</p></li></ul></div></div></div>
<div><div><div><div><h1 class="title"><a id="ch06lvl1sec07"/>Metering background music</h1></div></div></div><p>The<code class="literal"> CDAudioManager</code> class wraps the<code class="literal"> AVAudioPlayer</code> class. Using this class gives us access to lower level audio functions. In this recipe, we will dynamically read the<strong> average level</strong> and<strong> peak level</strong> of background music currently playing. We can use this information to sync or cue animations.<a id="id434" class="indexterm"/>
</p><div><img src="img/4002_06_06.jpg" alt="Metering background music"/></div><div><div><div><div><h2 class="title"><a id="ch06lvl2sec19"/>Getting ready</h2></div></div></div><p>Please refer to the project<em> RecipeCollection02</em> for full working code of this recipe.
</p></div><div><div><div><div><h2 class="title"><a id="ch06lvl2sec20"/>How to do it...</h2></div></div></div><p>Execute the following code:<a id="id435" class="indexterm"/>
</p><div><pre class="programlisting">#import "SimpleAudioEngine.h"
@implementation Ch6_MeteringMusic
-(CCLayer*) runRecipe {
//Initialize the audio engine
sae = [SimpleAudioEngine sharedEngine];
//Background music is stopped on resign and resumed on becoming active
[[CDAudioManager sharedManager] setResignBehavior:kAMRBStopPlay autoHandle:YES];
//Set peak and average power initially
peakPower = 0;
avgPower = 0;
//Init speaker sprites (speakerBase, speakerLarge and speakerSmall)
/* CODE OMITTED */
//Init meter sprites (avgMeter and peakMeter)
/* CODE OMITTED */
//Add the background music
[sae preloadBackgroundMusic:@"technogeek_by_mrpoly.mp3"];
[sae playBackgroundMusic:@"technogeek_by_mrpoly.mp3"];
//Enable metering
[CDAudioManager sharedManager].backgroundMusic.audioSourcePlayer.meteringEnabled = YES;
//Schedule step method
[self schedule:@selector(step:)];
return self;
}
-(void) step:(ccTime)delta {
[self setPeakAndAveragePower];
[self animateMeterAndSpeaker];
}
-(void) setPeakAndAveragePower {
//Update meters
[[CDAudioManager sharedManager].backgroundMusic.audioSourcePlayer updateMeters];
//Get channels
int channels = [CDAudioManager sharedManager].backgroundMusic.audioSourcePlayer.numberOfChannels;
//Average all the channels
float peakPowerNow = 0;
float avgPowerNow = 0;
for(int i=0; i&lt;channels; i++){
float peak = [[CDAudioManager sharedManager].backgroundMusic.audioSourcePlayer peakPowerForChannel:i];
float avg = [[CDAudioManager sharedManager].backgroundMusic.audioSourcePlayer averagePowerForChannel:i];
peakPowerNow += peak/channels;
avgPowerNow += avg/channels;
}
//Change from a DB level to a 0 to 1 ratio
float adjustedPeak = pow(10, (0.05 * peakPowerNow));
float adjustedAvg = pow(10, (0.05 * avgPowerNow));
//Average it out for smoothing
peakPower = (peakPower + adjustedPeak)/2;
avgPower = (avgPower + adjustedAvg)/2;
}
-(void) animateMeterAndSpeaker {
//Average meter
[avgMeter setTextureRect:CGRectMake(0,0,10,avgPower*500.0f)];
//Peak meter
peakMeter.position = ccp(100,20+peakPower*500.0f);
//Animate speaker
speakerLarge.scale = powf(avgPower,0.4f)*2;
speakerSmall.scale = powf(avgPower,0.4f)*2;
}
@end
</pre></div></div><div><div><div><div><h2 class="title"><a id="ch06lvl2sec21"/>How it works...</h2></div></div></div><p>Accessing the dynamic metering functionality requires the use of the<code class="literal"> audioSourcePlayer</code> reference inside a<code class="literal"> CDLongAudioSource</code> object, in this case,<code class="literal"> backgroundMusic</code>. Before we can begin, we enable metering:
</p><div><pre class="programlisting">[CDAudioManager sharedManager].backgroundMusic.audioSourcePlayer.meteringEnabled = YES;
</pre></div><p>Now, every cycle we collect the<strong> average</strong> and<strong> peak</strong> decibel levels for all playing channels. We average these numbers out:
</p><div><pre class="programlisting">[[CDAudioManager sharedManager].backgroundMusic.audioSourcePlayer updateMeters];
int channels = [CDAudioManager sharedManager].backgroundMusic.audioSourcePlayer.numberOfChannels;
for(int i=0; i&lt;channels; i++){
float peak = [[CDAudioManager sharedManager].backgroundMusic.audioSourcePlayer peakPowerForChannel:i];
float avg = [[CDAudioManager sharedManager].backgroundMusic.audioSourcePlayer averagePowerForChannel:i];
peakPowerNow += peak/channels;
avgPowerNow += avg/channels;
}
</pre></div><p>After that we convert our average and peak decibel levels to ratios between 0 and 1. This makes the numbers easier to apply to animations.</p><div><pre class="programlisting">//Change from a DB level to a 0 to 1 ratio
float adjustedPeak = pow(10, (0.05 * peakPowerNow));
float adjustedAvg = pow(10, (0.05 * avgPowerNow));
//Average it out for smoothing
peakPower = (peakPower + adjustedPeak)/2;
avgPower = (avgPower + adjustedAvg)/2;
</pre></div><p>We also split the difference when setting the new<code class="literal"> peakPower</code> and<code class="literal"> avgPower</code> variables. This smooths out harsh changes in volume.
</p></div></div>
<div><div><div><div><h1 class="title"><a id="ch06lvl1sec08"/>Metering dialogue for animation</h1></div></div></div><p>A<code class="literal"> LongAudioSource</code> object can be any kind of audio, not just music. In this recipe, we will use the metering technique to animate the mouth of the gregarious Senator Beauregard Claghorn.<a id="id436" class="indexterm"/>
</p><div><img src="img/4002_06_07.jpg" alt="Metering dialogue for animation"/></div><div><div><div><div><h2 class="title"><a id="ch06lvl2sec22"/>Getting ready</h2></div></div></div><p>Please refer to the project<em> RecipeCollection02</em> for full working code of this recipe.
</p></div><div><div><div><div><h2 class="title"><a id="ch06lvl2sec23"/>How to do it...</h2></div></div></div><p>Execute the following code:<a id="id437" class="indexterm"/>
</p><div><pre class="programlisting">#import "SimpleAudioEngine.h"
@implementation Ch6_MeteringDialogue
-(CCLayer*) runRecipe {
/* CODE OMITTED */
//Add the sounds
[self loadLongAudioSource:@"claghorn_a_joke_son.caf"];
[self loadLongAudioSource:@"claghorn_carolina.caf"];
/* CODE OMITTED */
//Add the background music
[self loadBackgroundMusic:@"dixie_1916.mp3"];
/* CODE OMITTED */
//Play background music
[self playBackgroundMusic:@"dixie_1916.mp3"];
//Have Claghorn introduce himself
[self playLongAudioSource:@"claghorn_howdy.caf"];
}
-(void) step:(ccTime)delta {
/* CODE OMITTED */
[self setPeakAndAveragePower];
[self animateClaghorn];
}
-(void) setPeakAndAveragePower {
//Find our playing audio source
CDLongAudioSource *audioSource = nil;
for(id s in soundSources){
CDLongAudioSource *source = [soundSources objectForKey:s];
if(source.isPlaying){
audioSource = source;
break;
}
}
//Update meters
[audioSource.audioSourcePlayer updateMeters];
/* CODE OMITTED */
}
-(void) animateClaghorn {
/* Custom mouth animation */
float level = avgPower;
//Make sure he's actually speaking
if(level == 0){
claghornEyebrows.position = ccp(240,120);
claghornMouth.position = ccp(240,120);
lastAudioLevel = level;
return;
}
//Level bounds
if(level &lt;= 0){ level = 0.01f; }
if(level &gt;= 1){ level = 0.99f; }
//Exaggerate level ebb and flow
if(level &lt; lastAudioLevel){
//Closing mouth
lastAudioLevel = level;
level = powf(level,1.5f);
}else{
//Opening mouth
lastAudioLevel = level;
level = powf(level,0.75f);
}
//If mouth is almost closed, close mouth
if(level &lt; 0.1f){ level = 0.01f; }
//Blink if level &gt; 0.8f
if(level &gt; 0.8f &amp;&amp; !isBlinking){
[self blink];
[self runAction:[CCSequence actions:[CCDelayTime actionWithDuration:0.5f],
[CCCallFunc actionWithTarget:self selector:@selector(unblink)], nil]];
}
//Raise eyebrows if level &gt; 0.6f
if(level &gt; 0.6f){
claghornEyebrows.position = ccp(240,120 + level*5.0f);
}else{
claghornEyebrows.position = ccp(240,120);
}
//Set mouth position
claghornMouth.position = ccp(240,120 - level*19.0f);
}
-(CDLongAudioSource*) loadLongAudioSource:(NSString*)fn {
//Init source
CDLongAudioSource *source = [[CDLongAudioSource alloc] init];
source.backgroundMusic = NO;
[source load:fn];
//Enable metering
source.audioSourcePlayer.meteringEnabled = YES;
//Add sound to container
[soundSources setObject:source forKey:fn];
return source;
}
-(void) playLongAudioSource:(NSString*)fn {
//Get sound
CDLongAudioSource *audioSource = [soundSources objectForKey:fn];
bool aSourceIsPlaying = NO;
for(id s in soundSources){
CDLongAudioSource *source = [soundSources objectForKey:s];
if(source.isPlaying){
[source stop];
[source rewind];
aSourceIsPlaying = YES;
break;
}
}
//Play sound
if(!aSourceIsPlaying){
//Play sound
[audioSource play];
[self runAction: [CCSequence actions: [CCDelayTime actionWithDuration:[audioSource.audioSourcePlayer duration]],
[CCCallFunc actionWithTarget:audioSource selector:@selector(stop)],
[CCCallFunc actionWithTarget:audioSource selector:@selector(rewind)], nil]];
}
}
@end
</pre></div></div><div><div><div><div><h2 class="title"><a id="ch06lvl2sec24"/>How it works...</h2></div></div></div><p>Like in the previous recipe, we use the information collected from<code class="literal"> setPeakAndAveragePower</code> to run an animation. Unlike the previous recipe, we have a number of<code class="literal"> CDLongAudioSource</code> objects to choose from. Here, we find the source that is currently playing and use it for metering:<a id="id438" class="indexterm"/>
</p><div><pre class="programlisting">CDLongAudioSource *audioSource = nil;
for(id s in soundSources){
CDLongAudioSource *source = [soundSources objectForKey:s];
if(source.isPlaying){
audioSource = source;
break;
}
}
[audioSource.audioSourcePlayer updateMeters];
</pre></div><p>After calculating<code class="literal"> avgPower</code>, we then exaggerate the peaks and valleys of that number to help simulate the rapid opening and closing of Claghorn's mouth:
</p><div><pre class="programlisting">if(level &lt; lastAudioLevel){
lastAudioLevel = level;
level = powf(level,1.5f);
}else{
lastAudioLevel = level;
level = powf(level,0.75f);
}
</pre></div><p>In addition to this, we animate blinking, eye movement, and eyebrows. Put together, the linking of multiple animations with metering creates a nice mouth movement effect.</p></div></div>
<div><div><div><div><h1 class="title"><a id="ch06lvl1sec09"/>Streaming audio</h1></div></div></div><p>In<a class="link" href="ch01.html" title="Chapter 1. Graphics"> Chapter 1</a>,<em> Graphics</em>, we used the<code class="literal"> MPMoviePlayerController</code> class to play full motion video. In this recipe, we will use a similar technique to create a streaming audio player.<a id="id439" class="indexterm"/>
</p><div><img src="img/4002_06_08.jpg" alt="Streaming audio"/></div><div><div><div><div><h2 class="title"><a id="ch06lvl2sec25"/>Getting ready</h2></div></div></div><p>Please refer to the project<em> RecipeCollection02</em> for full working code of this recipe.
</p></div><div><div><div><div><h2 class="title"><a id="ch06lvl2sec26"/>How to do it...</h2></div></div></div><p>Link the<code class="literal"> MediaPlayer</code> framework to your project. Now, execute the following code:<a id="id440" class="indexterm"/>
</p><div><pre class="programlisting">#import &lt;MediaPlayer/MediaPlayer.h&gt;
#import "AppDelegate.h"
@implementation Ch6_StreamingAudio
-(CCLayer*) runRecipe {
//Create music player buttons
[[CCSpriteFrameCache sharedSpriteFrameCache] addSpriteFramesWithFile:@"music_player.plist"];
CCMenuItemSprite *prevItem = [self menuItemFromSpriteFile:@"music_player_prev.png" target:self selector:@selector(previousSong:)];
/* CODE OMITTED */
//Create menu
/* CODE OMITTED */
//Initial variable values
sourceIndex = 0;
isPlaying = NO;
//Streaming sources
streamingSources = [[NSMutableArray alloc] init];
[streamingSources addObject:@"http://shoutmedia.abc.net.au:10326"];
[streamingSources addObject:@"http://audioplayer.wunderground.com/drgruver/Philadelphia.mp3.m3u"];
[streamingSources addObject:@"http://s8.mediastreaming.it:7050/"];
[streamingSources addObject:@"http://www.radioparadise.com/musiclinks/rp_64aac.m3u"];
[streamingSources addObject:@"http://streaming.wrek.org:8000/wrek_HD-2.m3u"];
//Init movie playing (music streamer in this case)
moviePlayer = [[MPMoviePlayerController alloc] init];
moviePlayer.movieSourceType = MPMovieSourceTypeStreaming;
moviePlayer.view.hidden = YES;
((AppDelegate*)[UIApplication sharedApplication].delegate).window addSubview:moviePlayer.view];
//Set initial stream source
[self setStreamSource];
return self;
}
//Next callback
- (void) nextSong:(id)sender {
[self setIsPlaying];
sourceIndex++;
if(sourceIndex &gt; [streamingSources count]-1){
sourceIndex = 0;
}
[self setStreamSource];
}
//Previous callback
- (void) previousSong:(id)sender {
[self setIsPlaying];
sourceIndex--;
if(sourceIndex &lt; 0){
sourceIndex = [streamingSources count]-1;
}
[self setStreamSource];
}
-(void) setIsPlaying {
if(moviePlayer.playbackState == MPMoviePlaybackStatePlaying){
isPlaying = YES;
}
}
-(void) setStreamSource {
[moviePlayer stop];
moviePlayer.contentURL = [NSURL URLWithString:[streamingSources objectAtIndex:sourceIndex]];
if(isPlaying){
[self playMusic:nil];
}
}
@end
</pre></div></div><div><div><div><div><h2 class="title"><a id="ch06lvl2sec27"/>How it works...</h2></div></div></div><p>This recipe works in a way similar to that of what we saw in<a class="link" href="ch01.html" title="Chapter 1. Graphics"> Chapter 1</a>,<em> Graphics</em>. One key difference is, here we specify the<code class="literal"> mediaSourceType</code>, and we also hide the player from view:
</p><div><pre class="programlisting">moviePlayer.movieSourceType = MPMovieSourceTypeStreaming;
moviePlayer.view.hidden = YES;
</pre></div><p>This sets up the player for audio streaming.</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Reaching the<code class="literal"> AppDelegate:</code><p>In <strong>Cocos2d</strong>, the <code class="literal">AppDelegate</code> class is the top-level class that implements the <code class="literal">UIApplicationDelegate</code> protocol. This protocol specifies the delegate to which the main <code class="literal">UIApplication</code> singleton points to. This delegate handles important application events. To add our <code class="literal">moviePlayer</code> object to our view, we access this delegate through the <code class="literal">UIApplication</code> singleton:
<a id="id441" class="indexterm"/>
</p><div><pre class="programlisting">((AppDelegate*)[UIApplication sharedApplication].delegate).window addSubview:moviePlayer.view];
</pre></div><p>As you can see, this involves <strong>casting</strong> the <code class="literal">delegate</code> property into the <code class="literal">AppDelegate* </code>type.
<a id="id442" class="indexterm"/>
</p></li><li class="listitem" style="list-style-type: disc">Switching stations:<a id="id443" class="indexterm"/><p>Changing the streaming source involves stopping playback and changing the <code class="literal">contentURL</code> property:
<a id="id444" class="indexterm"/>
</p><div><pre class="programlisting">[moviePlayer stop];
moviePlayer.contentURL = [NSURL URLWithString:[streamingSources objectAtIndex:sourceIndex]];
if(isPlaying){
[self playMusic:nil];
}
</pre></div><p>This way the user can change channels seamlessly while maintaining playback.
</p></li><li class="listitem" style="list-style-type: disc">Live streaming formats:<a id="id445" class="indexterm"/><p>The stream source examples used in this recipe use Apple's <strong>HTTP Live Streaming</strong> protocol. This allows elegant live streaming over <strong>HTTP</strong> with minimum hassle. You can read more about this protocol here: <a class="ulink" href="http://developer.apple.com/resources/http-streaming/">http://developer.apple.com/resources/http-streaming/</a>.
</p></li><li class="listitem" style="list-style-type: disc">Streaming files:<a id="id446" class="indexterm"/><p>Single files, using formats like <strong>MP3</strong>, can also be streamed over a simple <strong>HTTP</strong> server using this technique.
</p></li><li class="listitem" style="list-style-type: disc">Streaming video:<a id="id447" class="indexterm"/><p>By combining this recipe with the video playback recipe in Chapter 1, Graphics, you can also stream video. Compatible formats and other requirements are detailed at the aforementioned site. As a good rule of thumb, any file type or URL that can be played using the iOS device's built in <strong>Safari</strong> web browser can usually also be played using <code class="literal">MPMoviePlayerController</code>.
</p></li></ul></div></div><div><div><div><div><h2 class="title"><a id="ch06lvl2sec28"/>There's more...</h2></div></div></div><p>Previously, we mentioned the<code class="literal"> UIApplication</code>
<strong> singleton</strong>. A singleton is a top-level global object instantiated at runtime. Cocos2d largely embraces the singleton pattern. Any object accessed by executing a class method starting with the word "shared" ([Class<code class="literal"> sharedClass])</code> is, by convention, a singleton. You can create your own custom singleton objects using the<strong> macro</strong> encapsulated in the<code class="literal"> SynthesizeSingleton.h</code> file. For more information about this, please consult the<em> More Recipes</em> section of the<strong> Cocos2d Cookbook website</strong> at<a class="ulink" href="http://cocos2dcookbook.com/more_recipes"> http://cocos2dcookbook.com/more_recipes</a>.<a id="id448" class="indexterm"/>
</p></div></div>
<div><div><div><div><h1 class="title"><a id="ch06lvl1sec10"/>Recording audio</h1></div></div></div><p>A notable feature on most iOS devices is the ability to record audio. In this recipe, we will use the microphone to record audio and save it to a temporary location on the disk using the<code class="literal"> AVAudioRecorder</code> class. We will then play it back with a modified pitch using the<code class="literal"> CDSoundEngine</code> class.<a id="id449" class="indexterm"/>
</p><div><img src="img/4002_06_09.jpg" alt="Recording audio"/></div><div><div><div><div><h2 class="title"><a id="ch06lvl2sec29"/>Getting ready</h2></div></div></div><p>Please refer to the project<em> RecipeCollection02</em> for full working code of this recipe.
</p></div><div><div><div><div><h2 class="title"><a id="ch06lvl2sec30"/>How to do it...</h2></div></div></div><p>Link the<code class="literal"> CoreAudio</code> and<code class="literal"> AVFoundation</code> frameworks to your project. Now, execute the following code:<a id="id450" class="indexterm"/>
</p><div><pre class="programlisting">#import &lt;AVFoundation/AVFoundation.h&gt;
#import &lt;CoreAudio/CoreAudioTypes.h&gt;
#import "CocosDenshion.h"
@interface Ch6_RecordingAudio : Recipe &lt;AVAudioRecorderDelegate&gt;
{ /* CODE OMITTED */}
@implementation Ch6_RecordingAudio
-(CCLayer*) runRecipe {
//Set initial pitch and recorded temp file object
pitch = 1.0f;
recordedTmpFile = nil;
//Init audio session
[self initAudioSession];
/* CODE OMITTED */
return self;
}
-(void) initAudioSession {
//Our AVAudioSession singleton pointer
AVAudioSession * audioSession = [AVAudioSession sharedInstance];
//Set up the audioSession for playback and record.
[audioSession setCategory:AVAudioSessionCategoryPlayAndRecord error:nil];
//Activate the session
[audioSession setActive:YES error:nil];
//Init CDSoundEngine
soundEngine = [[CDSoundEngine alloc] init];
//Define source groups
NSArray *defs = [NSArray arrayWithObjects: [NSNumber numberWithInt:1],nil];
[soundEngine defineSourceGroups:defs];
}
-(void) recordAudio {
//Set settings dictionary: IMA4 format, 44100 sample rate, 2 channels
NSMutableDictionary* recordSetting = [[[NSMutableDictionary alloc] init] autorelease];
[recordSetting setValue :[NSNumber numberWithInt:kAudioFormatAppleIMA4] forKey:AVFormatIDKey];
[recordSetting setValue:[NSNumber numberWithFloat:44100.0] forKey:AVSampleRateKey];
[recordSetting setValue:[NSNumber numberWithInt: 2] forKey:AVNumberOfChannelsKey];
//Set recording temp file location on disk
recordedTmpFile = [NSURL fileURLWithPath:[NSTemporaryDirectory() stringByAppendingPathComponent: [NSString stringWithString: @"recording.caf"]]];
//Init AVAudioRecorder with location and settings
recorder = [[AVAudioRecorder alloc] initWithURL:recordedTmpFile settings:recordSetting error:nil];
//Set delegate and start recording
[recorder setDelegate:self];
[recorder prepareToRecord];
[recorder record];
}
-(void) playAudio {
//Override the audio to go back to the speaker
UInt32 audioRouteOverride = kAudioSessionOverrideAudioRoute_Speaker;
AudioSessionSetProperty(kAudioSessionProperty_OverrideAudioRoute, sizeof (audioRouteOverride),&amp;audioRouteOverride);
//Get the file path to the recorded audio
NSString *filePath = [NSTemporaryDirectory() stringByAppendingPathComponent: [NSString stringWithString: @"recording.caf"]];
//Play our recorded audio
[soundEngine loadBuffer:0 filePath: filePath];
[soundEngine playSound:0 sourceGroupId:0 pitch:pitch pan:0.0f gain:10.0f loop: NO];
}
-(void) stopRecordingAudio {
//Stop recording
[recorder stop];
}
- (void) unloadAudioSession {
//Remove temp file
NSFileManager * fm = [NSFileManager defaultManager];
if(recordedTmpFile){ [fm removeItemAtURL:recordedTmpFile error:nil]; }
//Release recorder
[recorder dealloc];
recorder = nil;
//Release sound engine
[soundEngine release];
//Deactivate audio session
AVAudioSession * audioSession = [AVAudioSession sharedInstance];
[audioSession setActive:NO error:nil];
}
@end
</pre></div></div><div><div><div><div><h2 class="title"><a id="ch06lvl2sec31"/>How it works...</h2></div></div></div><p>Recording and playing back audio will introduce us to a few new classes and concepts.<a id="id451" class="indexterm"/>
</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Initializing the audio session:<a id="id452" class="indexterm"/><p>Because we want to record audio, we have to set up a specific <strong>audio session</strong>. An audio session is a way of configuring the settings we will currently use for audio input and output. The <code class="literal">AVAudioSession</code> singleton encapsulates this functionality. First, we need to set up the <strong>session category</strong> to allow recording and playback:
<a id="id453" class="indexterm"/>
</p><div><pre class="programlisting">[[AVAudioSession sharedInstance] setCategory:AVAudioSessionCategoryPlayAndRecord error:nil];
</pre></div><p>Then we need to activate the session:
</p><div><pre class="programlisting">[[AVAudioSession sharedInstance] setActive:YES error:nil];
</pre></div><p>CocosDenshion normally does these things, but in this recipe, we need more granular control over the audio system.
</p></li><li class="listitem" style="list-style-type: disc">Initializing CDSoundEngine:<a id="id454" class="indexterm"/><p>Here we also initialize a <code class="literal">CDSoundEngine</code> object:
</p><div><pre class="programlisting">soundEngine = [[CDSoundEngine alloc] init];
NSArray *defs = [NSArray arrayWithObjects: [NSNumber numberWithInt:1],nil];
[soundEngine defineSourceGroups:defs];
</pre></div><p>We will use this to play back our recorded audio.
</p></li><li class="listitem" style="list-style-type: disc">Recording audio:<a id="id455" class="indexterm"/><p>The crux of the recipe, recording the audio, requires a few steps. First, we initialize the <code class="literal">AVAudioRecorder</code> object with the audio recording format and where we want to store our recorded audio:
</p><div><pre class="programlisting">NSMutableDictionary* recordSetting = [[[NSMutableDictionary alloc] init] autorelease];
[recordSetting setValue :[NSNumber numberWithInt:kAudioFormatAppleIMA4] forKey:AVFormatIDKey];
[recordSetting setValue:[NSNumber numberWithFloat:44100.0] forKey:AVSampleRateKey];
[recordSetting setValue:[NSNumber numberWithInt: 2] forKey:AVNumberOfChannelsKey];
recordedTmpFile = [NSURL fileURLWithPath:[NSTemporaryDirectory() stringByAppendingPathComponent: [NSString stringWithString: @"recording.caf"]]];
recorder = [[AVAudioRecorder alloc] initWithURL:recordedTmpFile settings:recordSetting error:nil];
</pre></div><p>We specify our delegate object:
</p><div><pre class="programlisting">[recorder setDelegate:self];
</pre></div><p>Finally, we start recording:
</p><div><pre class="programlisting">[recorder prepareToRecord];
[recorder record];
</pre></div><p>Recording will last until we call the stop routine:
</p><div><pre class="programlisting">[recorder stop];
</pre></div><p>Recording will not stop until either the recorder receives a <code class="literal">stop</code> message or the delegate receives an error. For example, the disk could be full.
<a id="id456" class="indexterm"/>
</p></li><li class="listitem" style="list-style-type: disc">The<code class="literal"> AVAudioRecorderDelegate</code> protocol:<a id="id457" class="indexterm"/><p>By specifying our <code class="literal">Ch6_RecordingAudio</code> class as adhering to the <code class="literal">AVAudioRecorderDelegate</code> protocol, we agree to handle a number of method calls including errors. If we fail to do so, these errors are thrown. In this example, we bypass this step for the sake of brevity, but in a professional app it is recommended that you handle any messages the <code class="literal">AVAudioRecorder</code> class might want to pass on.
</p></li><li class="listitem" style="list-style-type: disc">Playing our recorded audio:<a id="id458" class="indexterm"/><p>Once the recorded audio is stored on the disk, we can play it back. On the iPhone the speaker output is re-routed to the earbud speaker when the audio session category is <code class="literal">AVAudioSessionCategoryPlayAndRecord</code>. So, before we can properly play back the recorded audio we must reroute playback to the speakers:
</p><div><pre class="programlisting">UInt32 audioRouteOverride = kAudioSessionOverrideAudioRoute_Speaker;
AudioSessionSetProperty(kAudioSessionProperty_OverrideAudioRoute, sizeof (audioRouteOverride),&amp;audioRouteOverride);
</pre></div><p>Now, using <code class="literal">CDSoundEngine</code>, we can load the recorded audio into a buffer and play it back:
</p><div><pre class="programlisting">NSString *filePath = [NSTemporaryDirectory() stringByAppendingPathComponent: [NSString stringWithString: @"recording.caf"]];
[soundEngine loadBuffer:0 filePath: filePath];
[soundEngine playSound:0 sourceGroupId:0 pitch:pitch pan:0.0f gain:10.0f loop:NO];
</pre></div><p>In the above line, the <strong>pitch, pan,</strong> and <strong>gain</strong> properties can be modified. In this example, you can modify the pitch. Try recording your voice and then bending the pitch.
</p></li></ul></div></div></div>
<div><div><div><div><h1 class="title"><a id="ch06lvl1sec11"/>Using the iPod music library</h1></div></div></div><p>Sometimes a user might want to substitute a musical track from his or her personal collection into the background of your game. In this example, we will create a simple music player that can load songs, albums, and playlists from the<strong> iPod music library</strong> on the device.<a id="id459" class="indexterm"/>
</p><div><img src="img/4002_06_10.jpg" alt="Using the iPod music library"/></div><div><div><div><div><h2 class="title"><a id="ch06lvl2sec32"/>Getting ready</h2></div></div></div><p>Please refer to the project<em> RecipeCollection02</em> for full working code of this recipe.
</p></div><div><div><div><div><h2 class="title"><a id="ch06lvl2sec33"/>How to do it...</h2></div></div></div><p>Link the<code class="literal"> MediaPlayer</code> framework to your project. Now, execute the following code:<a id="id460" class="indexterm"/>
</p><div><pre class="programlisting">#import &lt;MediaPlayer/MediaPlayer.h&gt;
#import "AppDelegate.h"
@interface Ch6_iPodLibrary : Recipe &lt;MPMediaPickerControllerDelegate&gt;
{ /* CODE OMITTED */ }
@implementation Ch6_iPodLibrary
-(CCLayer*) runRecipe {
//Device detection
NSString *model = [[UIDevice currentDevice] model];
//Show a blank recipe if we use the simulator
if([model isEqualToString:@"iPhone Simulator"]){
message.position = ccp(240,250);
[self showMessage:@"This recipe is not compatible with the Simulator. \nPlease connect a device."];
return self;
}
/* CODE OMITTED */
//Init music player
musicPlayer = [MPMusicPlayerController iPodMusicPlayer];
[musicPlayer setRepeatMode:MPMusicRepeatModeAll];
//Initial sync of display with music player state
[self handleNowPlayingItemChanged:nil];
//Register for music player notifications
NSNotificationCenter *notificationCenter = [NSNotificationCenter defaultCenter];
[notificationCenter addObserver:self selector:@selector(handleNowPlayingItemChanged:)
name:MPMusicPlayerControllerNowPlayingItemDidChangeNotification object:musicPlayer];
[musicPlayer beginGeneratingPlaybackNotifications];
return self;
}
- (void) handleNowPlayingItemChanged:(id)notification {
//Get the current playing item
MPMediaItem *currentItem = musicPlayer.nowPlayingItem;
//Set labels
if([currentItem valueForProperty:MPMediaItemPropertyTitle]){
[songLabel setString: [NSString stringWithFormat:@"%@",[currentItem valueForProperty:MPMediaItemPropertyTitle]]];
[artistLabel setString: [NSString stringWithFormat:@"%@",[currentItem valueForProperty:MPMediaItemPropertyArtist]]];
[albumLabel setString: [NSString stringWithFormat:@"%@",[currentItem valueForProperty:MPMediaItemPropertyAlbumTitle]]];
}
//Get album artwork
MPMediaItemArtwork *artwork = [currentItem valueForProperty:MPMediaItemPropertyArtwork];
UIImage *artworkImage = nil;
if(artwork) { artworkImage = [artwork imageWithSize:CGSizeMake(100,100)]; }
//Remove current album art if necessary
if(albumArt){
[self removeChild:albumArt cleanup:YES];
albumArt = nil;
}
//Set album art
if(artworkImage){
CCTexture2D *texture = [[[CCTexture2D alloc] initWithImage:artworkImage] autorelease];
albumArt = [CCSprite spriteWithTexture:texture];
[self addChild:albumArt z:1];
albumArt.position = ccp(240,120);
albumArt.scale = 0.25f;
}
}
//Play callback
-(void)playMusic:(id)sender { [musicPlayer play]; }
//Pause callback
-(void)pauseMusic:(id)sender{ [musicPlayer pause]; }
//Stop callback
-(void)stopMusic:(id)sender{ [musicPlayer stop]; }
//Next callback
- (void)nextSong:(id)sender { [musicPlayer skipToNextItem]; }
//Previous callback
- (void)previousSong:(id)sender {
//After 3.5 seconds hitting previous merely rewinds the song
static NSTimeInterval skipToBeginningOfSongIfElapsedTimeLongerThan = 3.5;
NSTimeInterval playbackTime = musicPlayer.currentPlaybackTime;
if (playbackTime &lt;= skipToBeginningOfSongIfElapsedTimeLongerThan) {
//Previous song
[musicPlayer skipToPreviousItem];
} else {
//Rewind to beginning of current song
[musicPlayer skipToBeginning];
}
}
//Add music callback
- (void)openMediaPicker:(id)sender {
//Unit music MPMediaPickerController
MPMediaPickerController *mediaPicker = [[MPMediaPickerController alloc] initWithMediaTypes:MPMediaTypeMusic];
mediaPicker.delegate = self;
mediaPicker.allowsPickingMultipleItems = YES;
//Present picker as a modal view
((AppDelegate*)[UIApplication sharedApplication].delegate).viewController presentModalViewController:mediaPicker animated:YES];
[mediaPicker release];
}
- (void)mediaPicker: (MPMediaPickerController *)mediaPicker didPickMediaItems:(MPMediaItemCollection *)mediaItemCollection {
//Dismiss the picker
((AppDelegate*)[UIApplication sharedApplication].delegate).viewController dismissModalViewControllerAnimated:YES];
//Assign the selected item(s) to the music player and start playback.
[musicPlayer stop];
[musicPlayer setQueueWithItemCollection:mediaItemCollection];
[musicPlayer play];
}
- (void)mediaPickerDidCancel:(MPMediaPickerController *)mediaPicker {
//User chose no items, dismiss the picker
((AppDelegate*)[UIApplication sharedApplication].delegate).viewController dismissModalViewControllerAnimated:YES];
}
-(void) cleanRecipe {
//Stop player
[musicPlayer stop];
//Stop music player notifications
[[NSNotificationCenter defaultCenter] removeObserver:self name:MPMusicPlayerControllerNowPlayingItemDidChangeNotification object:musicPlayer];
[[NSNotificationCenter defaultCenter] removeObserver:self
name:MPMusicPlayerControllerPlaybackStateDidChangeNotification object:musicPlayer];
[[NSNotificationCenter defaultCenter] removeObserver:self
name:MPMusicPlayerControllerVolumeDidChangeNotification object:musicPlayer];
[musicPlayer endGeneratingPlaybackNotifications];
//Release player
[musicPlayer release];
musicPlayer = nil;
[super cleanRecipe];
}
@end
</pre></div></div><div><div><div><div><h2 class="title"><a id="ch06lvl2sec34"/>How it works...</h2></div></div></div><p>Pressing the green button opens the standard iPod media picker. Some games opt to create their own picker to better match their user interface. In this example, we chose the default media picker for the sake of simplicity.<a id="id461" class="indexterm"/>
</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Initializing<code class="literal"> MPMusicPlayerController:</code><a id="id462" class="indexterm"/><p>First, we create our <code class="literal">MPMusicPlayerController</code> object:
</p><div><pre class="programlisting">musicPlayer = [MPMusicPlayerController iPodMusicPlayer];
[musicPlayer setRepeatMode:MPMusicRepeatModeAll];
</pre></div><p>We set our player to <code class="literal">MPMusicRepeatModeAll</code>, so our <code class="literal">nextSong</code> and <code class="literal">previousSong</code>methods can wrap playing songs.
</p></li><li class="listitem" style="list-style-type: disc">Getting<strong> Now Playing</strong> audio information:<p>Every time the <strong>Now Playing</strong> item changes, we would like to be notified so we can fetch media information. To do this, we set our recipe object as an observer of the <code class="literal">musicPlayer</code> object and allow this type of notification to be received:
</p><div><pre class="programlisting">NSNotificationCenter *notificationCenter = [NSNotificationCenter defaultCenter];
[notificationCenter addObserver:self selector:@selector(handleNowPlayingItemChanged:)
name:MPMusicPlayerControllerNowPlayingItemDidChangeNotification object:musicPlayer];
[musicPlayer beginGeneratingPlaybackNotifications];
</pre></div><p>As an observer, our class will be notified by a call to the <code class="literal">handleNowPlayingItemChanged</code> method. Here, we inspect the currently playing <code class="literal">MPMediaItem</code> object for information including song title, artist name, album name, and album art:
</p><div><pre class="programlisting">MPMediaItem *currentItem = musicPlayer.nowPlayingItem;
if([currentItem valueForProperty:MPMediaItemPropertyTitle]){
[songLabel setString: [NSString stringWithFormat:@"%@",[currentItem valueForProperty:MPMediaItemPropertyTitle]]];
[artistLabel setString: [NSString stringWithFormat:@"%@",[currentItem valueForProperty:MPMediaItemPropertyArtist]]];
[albumLabel setString: [NSString stringWithFormat:@"%@",[currentItem valueForProperty:MPMediaItemPropertyAlbumTitle]]];
}
MPMediaItemArtwork *artwork = [currentItem valueForProperty:MPMediaItemPropertyArtwork];
UIImage *artworkImage = nil;
if(artwork) { artworkImage = [artwork imageWithSize:CGSizeMake(100,100)]; }
</pre></div><p>We then take this created <code class="literal">UIImage</code> object and place it into the scene using a technique described in Chapter 1, Graphics
</p></li><li class="listitem" style="list-style-type: disc">Using<code class="literal"> MPMediaPickerController:</code><a id="id463" class="indexterm"/><p>When a user touches the green button, then we initialize a <code class="literal">MPMediaPickerController</code> object and specify its delegate:
</p><div><pre class="programlisting">MPMediaPickerController *mediaPicker = [[MPMediaPickerController alloc] initWithMediaTypes:MPMediaTypeMusic];
mediaPicker.delegate = self;
mediaPicker.allowsPickingMultipleItems = YES;
</pre></div><p>We then add the picker to the screen presenting it as a 'modal view'. This lets us animate the picker sliding onto the screen:
</p><div><pre class="programlisting">((AppDelegate*)[UIApplication sharedApplication].delegate).viewController presentModalViewController:mediaPicker animated:YES];
</pre></div><p>With the picker open the user can choose from songs, playlists, albums, and so on.
</p></li><li class="listitem" style="list-style-type: disc">The<code class="literal"> MPMediaPickerControllerDelegate:</code><a id="id464" class="indexterm"/><p>In accordance with this delegate, we implement the following methods:
</p><div><pre class="programlisting">-(void) mediaPicker:(MPMediaPickerController *)mediaPicker didPickMediaItems:(MPMediaItemCollection *)mediaItemCollection;
-(void) mediaPickerDidCancel:(MPMediaPickerController *)mediaPicker;
</pre></div><p>These correspond to picking at least one item and picking none respectively. Upon picking an item or more we dismiss the modal view, add items to our player, and then play the first item:
</p><div><pre class="programlisting">((AppDelegate*)[UIApplication sharedApplication].delegate).viewController dismissModalViewControllerAnimated:YES];
[musicPlayer stop];
[musicPlayer setQueueWithItemCollection:mediaItemCollection];
[musicPlayer play];
</pre></div><p>If the user did not pick an item, we simple dismiss the modal view controller.
</p></li></ul></div></div><div><div><div><div><h2 class="title"><a id="ch06lvl2sec35"/>There's more...</h2></div></div></div><p>The<code class="literal"> MPMusicPlayerController</code> class is actually accessing the iPod functionality of the device you're currently using. Having your app access an external resource, adds a couple of extra conditions we need to account for:<a id="id465" class="indexterm"/>
</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Determining the current device type:<a id="id466" class="indexterm"/><p>As you can see from the previous code, or if you tried running this recipe in the simulator, we disable this recipe entirely when not running on a real device. We do this because the iPod music player app is not installed on the simulator and this will cause errors to be thrown. Determining the device model is simple:
</p><div><pre class="programlisting">NSString *model = [[UIDevice currentDevice] model];
</pre></div><p>This string will tell you what model your app is running on. In our case we check for the string @"iPhone Simulator".
</p></li><li class="listitem" style="list-style-type: disc">The<code class="literal"> UIApplicationDelegate</code> protocol:<a id="id467" class="indexterm"/><p>Another side effect of using the iPod resource is that music will continue to play after suspending our application. Although you can switch to the iPod app itself to stop the playing music, we would like to stop it when we suspend our app and resume it when we bring the app back. In AppDelegate.mm, our application implements some methods specified by the UIApplicationDelegate protocol:
</p><div><pre class="programlisting">- (void)applicationWillResignActive:(UIApplication *)application;
- (void)applicationDidBecomeActive:(UIApplication *)application;
</pre></div><p>Normally, Cocos2d only calls pause and resume on the CCDirector singleton here. We will add code to pause the iPod music player upon suspension and play it upon activation:
</p><div><pre class="programlisting">- (void)applicationWillResignActive:(UIApplication *)application {
[[CCDirector sharedDirector] pause];
//Pause the music player if its playing
if(![[[UIDevice currentDevice] model] isEqualToString:@"iPhone Simulator"]){
MPMusicPlayerController *musicPlayer = [MPMusicPlayerController iPodMusicPlayer];
if(musicPlayer.playbackState == MPMusicPlaybackStatePlaying){
[musicPlayer pause];
}
}
}
- (void)applicationDidBecomeActive:(UIApplication *)application {
[[CCDirector sharedDirector] resume];
//Play the music play if its paused
if(![[[UIDevice currentDevice] model] isEqualToString:@"iPhone Simulator"]){
MPMusicPlayerController *musicPlayer = [MPMusicPlayerController iPodMusicPlayer];
if(musicPlayer.playbackState == MPMusicPlaybackStatePaused){
[musicPlayer play];
}
}
}
</pre></div><p>Other code can go here as needed.
<a id="id468" class="indexterm"/>
</p></li></ul></div></div></div>
<div><div><div><div><h1 class="title"><a id="ch06lvl1sec12"/>Creating a MIDI synthesizer</h1></div></div></div><p>With the release of iOS 4.0 the iPhone, iPad, and iPod Touch can now take advantage of the powerful<strong> MIDI</strong> protocol. For games that allow the user to generate their own sounds and music, or for a game that wants a cool retro sound without a large memory footprint, MIDI synthesization is the tool for the job. In this recipe, we will create a MIDI synthesizer using the great<strong> MobileSynth</strong> library.<a id="id469" class="indexterm"/>
</p><div><img src="img/4002_06_11.jpg" alt="Creating a MIDI synthesizer"/></div><div><div><div><div><h2 class="title"><a id="ch06lvl2sec36"/>Getting ready</h2></div></div></div><p>Please refer to the project<em> RecipeCollection02</em> for full working code of this recipe.
</p></div><div><div><div><div><h2 class="title"><a id="ch06lvl2sec37"/>How to do it...</h2></div></div></div><p>Link the<code class="literal"> AudioToolbox</code> framework to your project. Now, execute the following code:<a id="id470" class="indexterm"/>
</p><div><pre class="programlisting">#import "MIDISampleGenerator.h"
static const int kWhiteKeyNumbers[] = { 0, 2, 4, 5, 7, 9, 11 };
static const int kWhiteKeyCount = sizeof(kWhiteKeyNumbers) / sizeof(int);
static const int kBlackKey1Numbers[] = { 1, 3 };
static const int kBlackKey1Count = sizeof(kBlackKey1Numbers) / sizeof(int);
static const int kBlackKey2Numbers[] = { 6, 8, 10 };
static const int kBlackKey2Count = sizeof(kBlackKey2Numbers) / sizeof(int);
@implementation Ch6_MIDISynthesization
-(CCLayer*) runRecipe {
//Init sample generator
sampleGenerator = [[MIDISampleGenerator alloc] init];
//Init keyboard
[self initKeyboard];
return self;
}
-(void) initKeyboard {
/* CODE OMITTED */
}
-(void) randomize:(id)sender {
//Randomize values including Modulation, Oscillation, Filter, etc
[sampleGenerator randomize];
}
-(bool) keyPressed:(CCSprite*)key withHash:(NSString*)hashKey {
//Set darker key color
[key setColor:ccc3(255,100,100)];
//Play note
[sampleGenerator noteOn:key.tag];
//Keep track of touch
[keyTouches setObject:[NSNumber numberWithInt:key.tag] forKey:hashKey];
return YES;
}
-(bool) keyReleased:(int)note remove:(bool)remove {
/* CODE OMITTED */
if(keyReleased){
//Stop playing note
[sampleGenerator noteOff:note];
//Remove tracking
if(remove){ [keyTouches removeObjectForKey:[NSNumber numberWithInt:note]]; }
}
return keyReleased;
}
@end
</pre></div></div><div><div><div><div><h2 class="title"><a id="ch06lvl2sec38"/>How it works...</h2></div></div></div><p>This recipe lets you play two<strong> octaves</strong> of synthesized sounds on a virtual keyboard.
</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">The<code class="literal"> MIDISampleGenerator</code> class:<a id="id471" class="indexterm"/><p>The <code class="literal">MIDISampleGenerator</code> class was created specifically for this recipe so as to obfuscate some of the grittier details of using MobileSynth. The MobileSynth library offers a dizzying array of sound synthesization options to generate sounds. These include, to name a few, Modulation, Oscillation, Filter, Arpeggio, and a few volume related effects. The <strong>Randomize</strong> button randomizes a number of these effects to quickly and easily allow the user to get a feel for the range of synthesization possibilities.
<a id="id472" class="indexterm"/>
</p></li><li class="listitem" style="list-style-type: disc">Extending the synthesizer:<a id="id473" class="indexterm"/><p>Presumably, the synthesizer could be extended to record a song (a series of timed notes) to a data file that could then be fed into the synthesizer like a player piano. This acts as an easy solution for generating a large amount of retro sounding game music that doesn't take up much space (think Mega Man). The same thing goes for sound effects.
</p></li></ul></div></div><div><div><div><div><h2 class="title"><a id="ch06lvl2sec39"/>There's more...</h2></div></div></div><p>For more information about<strong> MobileSynth</strong> you can visit their website:<a class="ulink" href="http://code.google.com/p/mobilesynth/"> http://code.google.com/p/mobilesynth/</a>
<a id="id474" class="indexterm"/>
</p></div></div>
<div><div><div><div><h1 class="title"><a id="ch06lvl1sec13"/>Speech recognition and text-to-speech</h1></div></div></div><p>Until a fateful combination of machine learning, quantum computing, and 3D printing spawns tyrannical artificial lifeforms to rule over all mankind, we need to settle for semi-intelligent devices that we program by hand. An important piece of that puzzle is language processing. In this recipe, we will use the<strong> OpenEars</strong> library to have our iOS device speak and recognize some basic English dialogue.<a id="id475" class="indexterm"/>
</p><div><img src="img/4002_06_12.jpg" alt="Speech recognition and text-to-speech"/></div><div><div><div><div><h2 class="title"><a id="ch06lvl2sec40"/>Getting ready</h2></div></div></div><p>Due to the size of the libraries required to use<strong> OpenEars</strong>, this recipe has its own project. Please refer to the project<em> Ch6_SpeechRecognition</em> for full working code of this recipe.<a id="id476" class="indexterm"/>
</p></div><div><div><div><div><h2 class="title"><a id="ch06lvl2sec41"/>How to do it...</h2></div></div></div><p>The<strong> OpenEars</strong> installation process is complex. Among other things it requires the configuration of four other libraries:<strong> flite, pocketsphinx, sphinxbase</strong>, and<strong> wince</strong>. The OpenEars library is itself an embedded XCode project that is statically linked to your project.<a id="id477" class="indexterm"/>
</p><p>It is recommended that you take a look at the<code class="literal"> Ch6_SpeechRecognition</code> project first. From there, you can carefully follow the steps listed at<a class="ulink" href="http://www.politepix.com/openears/"> http://www.politepix.com/openears/</a> to set up and configure the sample project.
</p><p>After following the steps listed on the "Getting Started" and "Configuring Your App For OpenEars" pages you can move on to the "Using OpenEars In Your App" page. Here you will be instructed to create a<strong> corpus</strong> file. This is a file with all the words and phrases we want OpenEars to recognize. Our corpus file looks like this:<a id="id478" class="indexterm"/>
</p><div><pre class="programlisting">HELLO, HAL. DO YOU READ ME, HAL?
OPEN THE POD BAY DOORS, HAL.
WHAT'S THE PROBLEM?
WHAT ARE YOU TALKING ABOUT, HAL?
I DON'T KNOW WHAT YOU'RE TALKING ABOUT, HAL.
WHERE THE HELL'D YOU GET THAT IDEA, HAL?
ALRIGHT, HAL. I'LL GO IN THROUGH THE EMERGENCY AIRLOCK.
HAL, I WON'T ARGUE WITH YOU ANYMORE. OPEN THE DOORS.
</pre></div><p>We then upload this file to the<strong> Sphinx</strong> Knowledge Base creation tool hosted by Carnegie Mellon University at this URL:<a class="ulink" href="http://www.speech.cs.cmu.edu/tools/lmtool-new.html"> http://www.speech.cs.cmu.edu/tools/lmtool-new.html</a>. The tool will generate a number of files for you. Take the<code class="literal"> .lm</code> file and rename it to a<code class="literal"> .languagemodel</code> file. Also download the<code class="literal"> .dic</code> file. Add these files to your project as outlined here:<a class="ulink" href="http://www.politepix.com/openears/yourapp/"> http://www.politepix.com/openears/yourapp/</a>.
</p><p>We're now ready to start coding. Our main piece of code will give the user some self-assured HAL 9000 responses:</p><div><pre class="programlisting">#import "cocos2d.h"
#import "AudioSessionManager.h"
#import "OpenEarsEventsObserver.h"
#import "PocketsphinxController.h"
#import "FliteController.h"
@interface MainLayer : CCLayer &lt;OpenEarsEventsObserverDelegate&gt;
{ /* CODE OMITTED */ }
@end
@implementation MainLayer
-(id) init
{
if( (self=[super init])) {
/* CODE OMITTED */
//Init AudioSessionManager and start session
audioSessionManager = [[AudioSessionManager alloc] init];
[audioSessionManager startAudioSession];
//Init pocketsphinx, flite and OpenEars
pocketsphinxController = [[PocketsphinxController alloc] init];
fliteController = [[FliteController alloc] init];
openEarsEventsObserver = [[OpenEarsEventsObserver alloc] init];
//Text to speech
[self say:@"Welcome to OpenEars."];
[self runAction:[CCSequence actions:[CCDelayTime actionWithDuration:4.0f],
[CCCallFunc actionWithTarget:self selector:@selector(welcomeMessage)], nil]];
//Start the Pocketsphinx continuous listening loop.
[pocketsphinxController startListening];
//Set this is an OpenEars observer delegate
[openEarsEventsObserver setDelegate:self];
/* CODE OMITTED */
}
return self;
}
-(void) welcomeMessage {
//Greet the user with a message about his pitiful human brain
[self say:@"Hello Dave. I've just picked up a fault in your brain. \nIt's going to go 100% failure in 72 hours. \nWould you like me to open the pod bay doors?"];
}
-(void) saySomething {
//Respond with a random response
int num = arc4random()%5;
if(num == 0){
[self say:@"This mission is too important for me to allow you to \njeopardize it Dave."];
}
/* CODE OMITTED */
}
-(void) say:(NSString*)str { /* CODE OMITTED */
//Have flite speak the message (text to speech)
[fliteController say:str];
}
-(void) suspendRecognition { /*CODE OMITTED */
//Suspend recognition
[pocketsphinxController suspendRecognition];
}
-(void) resumeRecognition { /* CODE OMITTED */
//Suspend recognition
[pocketsphinxController resumeRecognition];
}
-(void) stopListening { /* CODE OMITTED */
//Stop listening
[pocketsphinxController stopListening];
}
-(void) startListening { /* CODE OMITTED */
//Start listening
[pocketsphinxController startListening];
}
//Delivers the text of speech that Pocketsphinx heard and analyzed, along with its accuracy score and utterance ID.
- (void) pocketsphinxDidReceiveHypothesis:(NSString *)hypothesis recognitionScore:(NSString *)recognitionScore utteranceID:(NSString *)utteranceID {
//Display information
[self showMessage:[NSString stringWithFormat:@"The received hypothesis is %@ with a score of %@ and an ID of %@", hypothesis, recognitionScore, utteranceID]]; //Log it.
//Tell the user what we heard
[self say:[NSString stringWithFormat:@"You said %@",hypothesis]]; //React to it by telling our FliteController to say the heard phrase.
//Respond with a witty retort
[self runAction:[CCSequence actions:[CCDelayTime actionWithDuration:4.0f],
[CCCallFunc actionWithTarget:self selector:@selector(saySomething)], nil]];
}
@end
</pre></div></div><div><div><div><div><h2 class="title"><a id="ch06lvl2sec42"/>How it works...</h2></div></div></div><p>Try saying a few of the lines from the corpus file into the demo app. In a quiet room the results can be startlingly accurate.</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Instantiating the audio session, the controllers, and the observer:<a id="id479" class="indexterm"/><p>Before we can do anything we need to instatiate the audio session as well as the three controllers that provide text to speech and speech recognition functionality:
</p><div><pre class="programlisting">audioSessionManager = [[AudioSessionManager alloc] init];
[audioSessionManager startAudioSession];
pocketsphinxController = [[PocketsphinxController alloc] init];
fliteController = [[FliteController alloc] init];
openEarsEventsObserver = [[OpenEarsEventsObserver alloc] init];
</pre></div><p>The <code class="literal">PocketsphinxController</code> object provides the speech recognition API. The <code class="literal">FliteController</code> object provides the text to speech API. Finally, the <code class="literal">OpenEarsEventsObserver</code> provides a protocol that delegates callbacks on behalf of both controllers.
</p></li><li class="listitem" style="list-style-type: disc">Using FliteController:<a id="id480" class="indexterm"/><p>The <code class="literal">FliteController</code> API is very straightforward. Simply call the say method and Flite will produce computer-generated speech through the default audio channels.
<a id="id481" class="indexterm"/>
</p></li><li class="listitem" style="list-style-type: disc">Using PocketsphinxController:<a id="id482" class="indexterm"/><p>The <code class="literal">PocketsphinxController</code> API allows you to manage when Pocketsphinx is listening and when it is actively trying to recognize speech using the following four methods:
<a id="id483" class="indexterm"/>
</p><div><pre class="programlisting">[pocketsphinxController suspendRecognition];
[pocketsphinxController resumeRecognition];
[pocketsphinxController stopListening];
[pocketsphinxController startListening];
</pre></div><p>This basic level of control lets you manage when processor time is used to actually attempt to recognize a speech pattern.
</p></li><li class="listitem" style="list-style-type: disc">The<code class="literal"> OpenEarsEventsObserverDelegate</code> protocol:<a id="id484" class="indexterm"/><p>This protocol is in charge of calling a number of methods on behalf of <code class="literal">PocketsphinxController</code> and <code class="literal">FliteController</code>. The important method to take note of is the main Pocketsphinx speech recognition hypothesis method. This will tell you what Pocketsphinx heard and it will also give it a confidence score:
</p><div><pre class="programlisting">- (void) pocketsphinxDidReceiveHypothesis:(NSString *)hypothesis recognitionScore:(NSString *)recognitionScore utteranceID:(NSString *)utteranceID;
</pre></div><p>This method will be triggered by any discrete sound as long as Pocketsphinx is listening and attempting recognition. However, you can use the <code class="literal">recognitionScore</code> to weed out background noises and other
</p></li></ul></div></div></div></body></html>