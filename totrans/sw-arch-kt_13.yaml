- en: '13'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Testing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Software testing serves as a critical part of the software development life
    cycle, acting as a safeguard against defects and enhancing the overall quality
    of software products. Certification from **Quality Assurance** (**QA**) is often
    used as the indicator of whether the software product is ready to go live.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter delves into the fundamental principles of software testing, exploring
    its significance, methodologies, and best practices.
  prefs: []
  type: TYPE_NORMAL
- en: We will discuss the role of QA and software testers in the industry. We will
    summarize the understanding of the role and how it might mean something different
    to different people.
  prefs: []
  type: TYPE_NORMAL
- en: We will explore several types of software testing and the testing pyramid. Additionally,
    we will discuss automated testing practices, which have gained popularity for
    their ability to enhance efficiency and ensure consistent test coverage.
  prefs: []
  type: TYPE_NORMAL
- en: We will also run an exercise of strict **Test-Driven Development** (**TDD**)
    using Kotest to gain insights into this methodology.
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter aims to provide a comprehensive overview of software testing,
    equipping you with the knowledge and tools necessary to implement effective testing
    strategies. This chapter will empower you to contribute to the creation of high-quality
    software that meets user expectations and stands the test of time. We are going
    to cover the following topics in the chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: The role of QA and its involvement in software development
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The testing pyramid
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: TDD with an exercise
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: BDD
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Live testing, A/B testing, and segmentation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'You can find all the code files used in this chapter on GitHub:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/PacktPublishing/Software-Architecture-with-Kotlin/tree/main/chapter-13](https://github.com/PacktPublishing/Software-Architecture-with-Kotlin/tree/main/chapter-13%0D)'
  prefs: []
  type: TYPE_NORMAL
- en: The role of QA and software testers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The primary goals of software testing are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: To identify and rectify defects before a product reaches the end user
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To ensure the software product behaviors meet the functional specifications
    or business expectations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is essential even for a startup company or the first product launch by a
    new company.
  prefs: []
  type: TYPE_NORMAL
- en: 'The role of QA or software tester can be confusing and is often misunderstood.
    Like software architect as a role, QA is not necessarily a job title, though you
    might have seen these titles in the job market:'
  prefs: []
  type: TYPE_NORMAL
- en: QA
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: QA tester
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: QA engineer
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Quality engineer
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Software tester
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Test engineer
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Automation tester
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Software Development Engineer in** **Test** (**SDET**)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Different organizations may have different interpretations or expectations for
    each title. In this chapter, we use the term QA to represent an engineer who is
    responsible for software quality.
  prefs: []
  type: TYPE_NORMAL
- en: 'The role of a QA is illustrated in *Figure 13**.1*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.1 – The role of QA](img/B21737_13_1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.1 – The role of QA
  prefs: []
  type: TYPE_NORMAL
- en: It is important to emphasize that QA should be a full-time engagement embedded
    in the team organized by business functions, as described in [*Chapter 1*](B21737_01.xhtml#_idTextAnchor013).
    QAs, just like other engineers, are involved in understanding business priorities,
    requirement analysis, test plan creation, and acceptance criteria definitions.
  prefs: []
  type: TYPE_NORMAL
- en: However, from this point onward, QAs have a different focus than the engineers
    who develop the software for the business. QAs focus on overall testing strategies,
    test script creation, test processes and tools, **User Acceptance Test** (**UAT**)
    planning, and exploratory testing.
  prefs: []
  type: TYPE_NORMAL
- en: The objectives of QAs are like those of the engineers who develop the software.
    They both want the software to have complete features that are good enough to
    meet business expectations. QAs do have a different focus and approaches to achieving
    the objectives though – by ensuring the software is developed to a high standard
    as required.
  prefs: []
  type: TYPE_NORMAL
- en: To code or not to code?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The question of whether a QA should code often lacks clarity. QAs should leverage
    all available tools and resources to meet software quality standards. Coding can
    be essential for creating specific test scripts or enhancing tools. Ultimately,
    the debate about whether QAs should code is somewhat misguided; for many situations,
    writing code is a necessary part of their role.
  prefs: []
  type: TYPE_NORMAL
- en: Job titles for QA in the industry tend to include the term *engineers* (e.g.,
    QA engineers) when the organization expects the QA person to write code.
  prefs: []
  type: TYPE_NORMAL
- en: Software quality is everyone’s responsibility
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: It seems obvious to say that software quality is everyone’s responsibility,
    but it may not be so clear to some organizations. Software quality is best assured
    when it is embedded in the software development process from the beginning to
    the end.
  prefs: []
  type: TYPE_NORMAL
- en: That includes all the activities during the software development process, starting
    from clear business priorities to well-written code, and eventually business user
    signoff and software launch. This involves every member of the team, not just
    QAs.
  prefs: []
  type: TYPE_NORMAL
- en: QA is the role that ensures software quality is taken care of every step of
    the way, so the outcome is a high-quality and well-tested software product.
  prefs: []
  type: TYPE_NORMAL
- en: With increasing complexity in software systems and the growing demand for robust
    applications, effective testing strategies are essential. By adopting a systematic
    approach to testing, organizations can mitigate risks, reduce costs associated
    with post-release defects, and foster user trust.
  prefs: []
  type: TYPE_NORMAL
- en: By fostering an environment that prioritizes QA, organizations can not only
    improve product outcomes but also enhance team collaboration and communication.
  prefs: []
  type: TYPE_NORMAL
- en: QA’s involvement in the software development life cycle
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The team, including QAs, understands business priorities collectively. Then
    the team analyzes the requirements together and creates a couple of user stories.
    Each user story represents a unit of work and is a part of the bigger business
    feature, but each story also brings some value to the business.
  prefs: []
  type: TYPE_NORMAL
- en: A user story needs to be refined to have a set of acceptance criteria that decides
    whether the story has satisfied the expectations of stakeholders. Every acceptance
    criterion should be concise and testable.
  prefs: []
  type: TYPE_NORMAL
- en: The convention of acceptance criteria
  prefs: []
  type: TYPE_NORMAL
- en: 'An acceptance criterion can follow a popular structure of **given-when-then**.
    *Given* provides the initial context of the state of the system before the action
    is performed. *When* is the action performed given the context. *Then* is the
    expected outcome because of the action performed. An example of an acceptance
    criterion in given-when-then structure is as follows: *“Given that a household
    does not exist in the system, when the household creates an account in the system,
    then the corresponding household record* *is created.”*'
  prefs: []
  type: TYPE_NORMAL
- en: From the acceptance criteria, engineers start their technical design on how
    to make a change to satisfy the conditions. Meanwhile, QAs start creating a test
    plan on how to verify that the change has satisfied the conditions.
  prefs: []
  type: TYPE_NORMAL
- en: The test plan should be cascaded into actual test scripts. Test scripts are
    detailed executable scripts describing how the software is tested. It includes
    setting up the data (the *given*), executing the actions (the *when*), and verifying
    the results (the *then*). The test scripts can be in any format, such as a document
    of the steps, an automation script, or even an independently executed program.
    The content of the testing is more important than the format.
  prefs: []
  type: TYPE_NORMAL
- en: In addition to scripted testing, QAs perform exploratory testing, which emphasizes
    the testers’ autonomy and creativity. QAs can explore the application freely,
    learning about it while actively testing it. Often, QAs find inconsistent system
    behaviors, loopholes, or hidden defects that cannot be discovered with fixed scripts.
    Exploratory tests are often time-boxed. There will also be a document on the findings,
    bugs discovered, unusual behaviors, and areas that require further investigation.
    These documents are often hosted in an **issue tracking system** such as JIRA,
    Asana, Trello, GitHub Issues, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: QAs are also involved in planning UATs where business testers (stakeholders
    and potentially real users) are involved. QAs help shape the testing process and
    are the ones to respond to queries by business testers. This is also an opportunity
    for QAs to confirm that the requirements are fully captured and to identify any
    features missed in the scope.
  prefs: []
  type: TYPE_NORMAL
- en: Apart from business delivery-focused testing activities, QAs are also responsible
    for having an overall testing strategy to align with other teams and share best
    practices. QAs are also responsible for maintaining test processes and tools.
    Quite often, QAs enhance existing test frameworks and maintain the end-to-end
    test suite.
  prefs: []
  type: TYPE_NORMAL
- en: Up next, we are going to concentrate on the testing methodology, starting with
    the testing pyramid.
  prefs: []
  type: TYPE_NORMAL
- en: Testing pyramid
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The testing pyramid is a conceptual framework in which various levels of tests
    in software development emerge as a hierarchical structure. This concept was made
    popular by Martin Fowler in 2009 in his *The Testing Pyramid* article. The testing
    pyramid is illustrated in *Figure 13**.2*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.2 – Testing pyramid](img/B21737_13_2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.2 – Testing pyramid
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we’ll explore all the levels of the testing pyramid.
  prefs: []
  type: TYPE_NORMAL
- en: Unit testing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The bottom level of the pyramid is unit testing. Unit tests are the foundation
    of the testing pyramid. They focus on the smallest building blocks that can be
    tested in isolation. They often test the behaviors of functions, and they are
    executed as a part of the local project build.
  prefs: []
  type: TYPE_NORMAL
- en: Unit tests are comparatively easy to write and execute due to their small size
    and scope. Unit tests can be run inside the **Integrated Development Environment**
    (**IDE**), which provides the quickest feedback loop. Bugs can be found and reported
    by unit tests within minutes – if not seconds.
  prefs: []
  type: TYPE_NORMAL
- en: It is common for the local project build to fail if any unit tests are unsuccessful.
    Integrating automated unit tests into the build process helps identify bugs early
    in development. Testing and fixing bugs is most cost-effective during unit testing
    because the bugs are smaller in size, require less effort to address, and provide
    quicker feedback compared to other testing stages. Additionally, a system typically
    has more unit tests than any other type of test, as unit tests target the smallest
    components, resulting in a larger quantity compared to larger tests.
  prefs: []
  type: TYPE_NORMAL
- en: Unit tests should be meaningful
  prefs: []
  type: TYPE_NORMAL
- en: While unit tests are the smallest building blocks that can be tested, there
    are a few cases where a function is too small to be tested. If engineers struggle
    to explain what the test aims to verify, it is likely that the function is too
    small to be tested. A private function usually does not require a unit test, but
    a function that’s called by other packages (i.e., a public function) should have
    a unit test. Functions extracted merely to avoid duplicated code are unlikely
    to form a meaning that requires testing. To summarize, unit tests should be meaningful.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is an example of a unit test in Kotlin powered by the Kotest framework:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The Kotest framework provides many test templates as specifications. `FunSpec`
    is the one used in the example. The test cases are passed in as lambda expressions.
    The `test` function takes the test name as an argument. A lambda expression under
    the scope of `TestScope` is passed in for the actual test. This unit test targets
    the `findBiggestNumber` function, which is given a list of integers: `17`, `18`,
    and `6`. The `shouldBe` infix function mimics the natural English language and
    validates whether the expected result is `18`.'
  prefs: []
  type: TYPE_NORMAL
- en: Parameterized testing
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'You might question whether one test case is not enough to thoroughly test this
    function. The Kotest framework supports parameterized testing as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'For a function that takes a list of integers and returns the maximum number,
    there are many cases we can think of:'
  prefs: []
  type: TYPE_NORMAL
- en: Empty lists
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lists of one integer
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lists of two integers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All positive integers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All negative integers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A mixture of zero, positive, and negative integers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Maximum, minimum, maximum plus one, minimum minus one, and the negation of these
    integers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With parameterized testing, it is possible to test them all with code footprints
    smaller than if we had to duplicate them into separate test cases.
  prefs: []
  type: TYPE_NORMAL
- en: 'At this point, you might want to see the source code of the function being
    tested, to ensure that you have covered all cases, but do you need to? There is
    no right or wrong answer here because it represents two methods of software testing:
    **blackbox testing** and **whitebox testing**. Please note that these two testing
    styles are applicable to all levels of testing in the pyramid.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Before we discuss these two testing styles in detail, let us reveal the implementation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: It is a very simple implementation and uses the built-in `maxOrNull` Kotlin
    function to find the maximum number in the list or null for an empty list.
  prefs: []
  type: TYPE_NORMAL
- en: Blackbox testing
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Blackbox testing evaluates the functionality being tested without any knowledge
    of the internal code or structure. Testers focus merely on the inputs, expected
    outputs, and alleged functionality provided (known as the *contract*).
  prefs: []
  type: TYPE_NORMAL
- en: Whitebox testing
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Whitebox testing goes in the opposite direction. It involves examining the internal
    implementation of the functionality being tested. Testers have knowledge of the
    code and internal logic, allowing them to design test cases based on the implementation
    details.
  prefs: []
  type: TYPE_NORMAL
- en: Comparing blackbox and whitebox testing
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Blackbox testing focuses on the results and functionalities that would affect
    user experience. Not depending on implementation also enables testers to discover
    any discrepancies between actual and expected behaviors, revealing requirements
    that may not have been thoroughly defined. It may, however, miss some code branches
    in the test suite, which potentially hinders complete code coverage. Organizations
    that have independent QA teams, separated from the development teams, typically
    use blackbox testing as their default approach.
  prefs: []
  type: TYPE_NORMAL
- en: Whitebox testing enables comprehensive testing of internal logic, leading to
    the discovery of hidden bugs or vulnerabilities under specific circumstances.
    Knowing the code also helps testers identify security vulnerabilities and optimization
    opportunities that would help meet the non-functional requirements. Knowing the
    code also brings bias in test cases to unknowingly omit test cases that can comprehensively
    cover external behaviors and user experience.
  prefs: []
  type: TYPE_NORMAL
- en: There are also human factors in play between the two styles. Once a tester has
    seen the internal implementation, it is difficult to pretend not to have seen
    it before and to write bias-free blackbox tests.
  prefs: []
  type: TYPE_NORMAL
- en: Both test styles have their merits and disadvantages. Due to the human factor
    mentioned, it is recommended to start writing blackbox tests without knowing the
    implementation first and to focus on testing the external behaviors. Afterward,
    check the implementation to write whitebox test cases and focus on code branches
    and non-functional requirements.
  prefs: []
  type: TYPE_NORMAL
- en: This will lead to a topic called TDD, which will be covered later in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Component testing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Known as **module testing**, component testing is one level above unit testing
    in the pyramid. It focuses on testing the higher-order behaviors of self-contained
    modules. Component focuses on the behaviors emerging from the interactions of
    several units of code.
  prefs: []
  type: TYPE_NORMAL
- en: Component tests are also included as part of the local project build. So, if
    a component test has failed, the local project build fails. It is also often executed
    from IDE to provide a quick feedback loop.
  prefs: []
  type: TYPE_NORMAL
- en: However, component tests are bigger and require more effort to write. Each test
    usually involves setting a combination of states before the test. The test itself
    often involves multiple steps, and there are usually multiple places to verify
    the results. If there is a problem found, it is not immediately obvious where
    the problem is, and it would require some time to troubleshoot and debug. So,
    the cost of testing and fixing bugs is higher than unit testing.
  prefs: []
  type: TYPE_NORMAL
- en: One of the examples of component testing can be found in applications that use
    modular and layered architecture, as mentioned in [*Chapter 7*](B21737_07.xhtml#_idTextAnchor255).
    For example, if we use the **hexagonal architecture**, component testing can be
    conducted at the core layer to verify the pure business logic without coupling
    technology choices. This is particularly useful if the bounded context of the
    application belongs to the Core domain, as mentioned in [*Chapter 8*](B21737_08.xhtml#_idTextAnchor289).
  prefs: []
  type: TYPE_NORMAL
- en: The core layer of the Core domain is often perceived as the “crown jewel” of
    the entire system. It serves as the heartbeat around which everything else revolves.
    It makes the case to use component testing to ensure the central pure business
    behaviors are intact in every change made in the system.
  prefs: []
  type: TYPE_NORMAL
- en: Component testing the core layer of the Core domain with blackbox testing first
    would become the **Behavior-Driven Development** (**BDD**) approach, which will
    be discussed later in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Mocking external resources
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: When writing component tests, it is almost inevitable to encounter situations
    when the code tries to integrate with external resources such as queues, files,
    databases, or other applications. These integration points put a burden on the
    testers to prepare the context and increase the effort of writing the test.
  prefs: []
  type: TYPE_NORMAL
- en: 'Mocking enables testers to isolate the component being tested from external
    dependencies. There are a few common mocking scenarios:'
  prefs: []
  type: TYPE_NORMAL
- en: Verify whether the component has interacted with the external dependencies as
    expected, such as checking whether the correct API with expected parameters was
    called
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Enable the component test to run without needing external dependencies to be
    available, for example, the database
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Verify whether the component can handle the failures of external dependencies
    as expected
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Maintain states that allow testing different conditions, such as returning different
    values based on the context of the tests
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Here is an example of component testing with mocking, also using Kotest:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Firstly, this component test uses the `BehaviorSpec` from Kotest that follows
    the given-when-then format. It also matches the test pattern of **Arrange, Act,**
    **Assert** (**3A**).
  prefs: []
  type: TYPE_NORMAL
- en: The 3A test pattern
  prefs: []
  type: TYPE_NORMAL
- en: The 3A test pattern can be used in a unit test. It helps engineers and testers
    to organize tests by dividing them into three distinct sections. As a result,
    test scripts are easier to read, understand, reason, and maintain. *Arrange* is
    the initialization of preconditions and input data for the test. *Act* is the
    execution of the behaviors being tested. *Assert* is the verification of the actual
    outcome against the expected result.
  prefs: []
  type: TYPE_NORMAL
- en: 'Secondly, there is an external `ExerciseLog` dependency, which may involve
    persisting data in files or databases:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'The function record accepts an `Exercise` object and the corresponding time
    when the exercise was done:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: As the focus of the test is the logic of `ExerciseExecutor`, not `ExerciseLog`,
    we use the `mockk` function from the `ExerciseLog` interface. We set up the mock
    object to accept the invocation of the `record` function with any parameters and
    to return a `Unit`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The primary validation is that when the weather is sunny, the function returns
    `RunInThePark`, as defined by this sealed class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'The second validation is that `ExerciseExecutor` has passed the correct parameters
    to `ExerciseLog` to record this exercise. Here is the full implementation of `ExerciseExecutor`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Mocks are one of the five types of **test doubles** used in software testing.
    Here is the full list:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Mocks**: These are pre-programmed with expectations of how they should be
    used. They are used to verify whether the specific functions are invoked with
    the expected parameters'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Stubs**: These provide pre-defined responses to functions but do not verify
    interactions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Spies**: Spies log the parameters used and count the function calls. The
    actual function is still invoked.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Fakes**: These allow for a simplified implementation of the external dependencies
    for testing purposes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Dummies**: A dummy is a simple object used just to satisfy parameter requirements
    without needing to implement any behavior.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Contract testing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Contract testing focuses on the interaction between API producers and consumers.
    It only aims at the communication protocol and the message content. It should
    not be used for business case testing because we already have component testing
    covering it in the lower level of the testing pyramid.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two types of contract testing:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Consumer testing**: This focuses on the service that makes requests to another
    service. It defines the expectations of the interactions it will have with the
    producer, typically through a contract. It also verifies that the consumer service
    can handle all documented responses to the requests made. Consumer contract testing
    uses stubs or fakes to set up the target service to communicate with.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Producer testing**: This focuses on the service that provides the functionality
    or data requested by another service. It aims to assert that the producer has
    fulfilled the API contract and met the expectations of its consumers. Producer
    tests may involve running the actual service, which makes it seem as though it
    should be higher up in the testing pyramid. It is also possible that producer
    testing mocks the business logic to produce the message and response defined in
    the contract. Producer testing is often used to ensure that updates and changes
    to contracts are backward compatible.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is, however, important to have contract tests focus on the communication
    and message content only. For example, the `openapi.yaml` file. This leads to
    more reliable and maintainable systems, especially in microservices architectures.
  prefs: []
  type: TYPE_NORMAL
- en: Integration testing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Integration testing focuses on the interactions between different components
    or modules of the application. It is one level up from contract testing in the
    pyramid as integration tests do not use stubs or fakes. They identify issues when
    integrating various parts of the system and verify the parts work together as
    intended. Integration testing is also a part of the local project build.
  prefs: []
  type: TYPE_NORMAL
- en: 'Integration testing usually involves databases, file systems, external services,
    or APIs. The following are the common types of integration testing:'
  prefs: []
  type: TYPE_NORMAL
- en: '**API integration testing**: Use the exposed APIs to interact with the application
    for the given use case and to verify the result from the response.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Database integration testing**: Confirm that data is correctly processed
    in the database. This is typically related to **Create, Read, Update, Delete**
    (**CRUD**) operations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**File system integration testing**: Verify that the application can read from
    or write to files correctly, and verify the file reflects the result of the operations
    in the test.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Middleware or external service integration testing**: Verify that the integration
    of middleware or external service connectivity is correctly configured, as well
    as that the application and middleware or external service can communicate as
    intended.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Integration tests are bigger than component and unit tests due to the required
    configuration and preparation. Integration tests are also more complex to write
    and reason about. Integration tests might involve various combinations of configurations,
    for instance, supporting multiple pluggable databases or message providers, while
    the business functionality remains the same.
  prefs: []
  type: TYPE_NORMAL
- en: Some tests may become uncertain due to how external resources or external services
    behave, especially if there is asynchronous processing external to the application.
  prefs: []
  type: TYPE_NORMAL
- en: Referring to component testing, if component testing focuses on the Core layer
    of a hexagonal architecture application, then integration testing focuses on the
    adapter layer.
  prefs: []
  type: TYPE_NORMAL
- en: 'Extending the exercise code example, we are going to write an integration test
    for an implementation of the `ExerciseLog` interface that appends a line to a
    file for each invocation. Each line starts with a local date-time using UTC, separated
    by a colon, and ends with the name of the exercise, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'An integration test can be written as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: The test starts by creating a temporary file that will be deleted on exit. Then
    a list of two exercise entries is passed into the `ExerciseFileLog` object. The
    verification starts by reading the file line by line and asserts that each line
    contains the expected content.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `ExerciseFileLog` class itself is straightforward:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Test scripts should mostly be integration tests in the supporting and generic
    subdomain applications, as discussed in [*Chapter 8*](B21737_08.xhtml#_idTextAnchor289).
    This is because these subdomains usually do not contain a lot of business logic,
    or the combination of business cases is simple enough to be covered by integration
    tests.
  prefs: []
  type: TYPE_NORMAL
- en: End-to-end and automated GUI testing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: So far, all the tests we have discussed have focused on either a single backend
    service or a specific group of software components. The next level is end-to-end
    automated testing, which includes graphical user interface (GUI) testing and contract
    testing. This type of testing evaluates system behavior across multiple services
    horizontally and across various tiers vertically. Additionally, it becomes more
    transparent to business stakeholders.
  prefs: []
  type: TYPE_NORMAL
- en: End-to-end and automated GUI testing focuses on a user journey that covers multiple
    services or components in the system. For example, an end-to-end test could involve
    creating two household records, and then having one household draft a contract
    with another household. Both households would then negotiate to reach an agreed
    contract, and finally, each of them would exercise the contract for the service
    described in the contract.
  prefs: []
  type: TYPE_NORMAL
- en: End-to-end testing uses APIs for communication with various parts of the system,
    while automated GUI testing simulates human interaction with the system.
  prefs: []
  type: TYPE_NORMAL
- en: Some systems have a suite of public APIs for integration with external **Software-as-a-Service**
    (**SaaS**) platforms (as discussed in [*Chapter 6*](B21737_06.xhtml#_idTextAnchor212)).
    In this case, end-to-end testing should ensure that the user journey can be fulfilled
    by calling the exposed public APIs. The testing of this public API integration,
    known as headless integration, is as important as visual GUI testing.
  prefs: []
  type: TYPE_NORMAL
- en: The test script for one user journey is complex and fragile. It requires multiple
    services to be operational in an environment, which implies stable infrastructure
    as well. It is not practical to test all the variations of user journeys, as the
    test suite takes a long time to finish.
  prefs: []
  type: TYPE_NORMAL
- en: Tests at this level typically only cover the most crucial and user-facing features.
    They also usually only cover successful cases. The tests are run periodically,
    or on demand. If an error is found during the test, it would take a longer time
    to troubleshoot, and sometimes it could be caused by stability issues in the environment
    instead of actual bugs.
  prefs: []
  type: TYPE_NORMAL
- en: Manual and exploratory testing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Manual and exploratory testing is the highest level in the pyramid. It is not
    automated, so it is up to the QAs to manually run through the cases. This level
    of testing is the most time-consuming and laborious.
  prefs: []
  type: TYPE_NORMAL
- en: 'If a manual can be automated, QAs will aim to automate it as soon as possible
    to reduce the cost. There are a few cases where manual testing is necessary:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Usability testing**: Evaluating user experience requires subjective analysis,
    involving elements such as visual layout, design, and overall satisfaction.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Short-lived features**: Investment in automating tests may not be justified
    for short-lived features.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Context-heavy testing**: Some tests heavily depend on complex workflows,
    interactions, or context understanding. Automating these tests to be reliable
    could outweigh the effort of testing them manually.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Security testing**: Many security assessments, such as penetration testing,
    rely on the security expertise of humans to identify vulnerabilities that automated
    tests may not catch. Some tests require a quick pivot of the next step decided
    by security experts; these are difficult to automate.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Manual and exploratory testing is often executed on an ad hoc basis; however,
    some organizations allow QAs to timebox exploratory testing to discover hidden
    defects and usability issues.
  prefs: []
  type: TYPE_NORMAL
- en: Benefits of the testing pyramid
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The testing pyramid serves as a guiding principle for structuring a testing
    strategy in software development. As testing and bug fixing become more expensive
    going up each level, it is natural to prioritize unit tests, followed by component
    tests, all the way up to manual tests, so the team can achieve a more efficient
    and cost-effective QA process.
  prefs: []
  type: TYPE_NORMAL
- en: By putting test cases at their appropriate level in the pyramid, the team not
    only enhances the overall quality of the software but also allows for a quick
    iterative feedback loop that incrementally improves software development practices.
  prefs: []
  type: TYPE_NORMAL
- en: 'So far, all the test case examples in this chapter have only used Kotest. However,
    there are a few other frameworks that can be considered as well:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Atrium: [https://github.com/robstoll/atrium](https://github.com/robstoll/atrium%0D)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kluent: [https://markusamshove.github.io/Kluent/](https://markusamshove.github.io/Kluent/%0D)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Spek: [https://spekframework.github.io/spek/docs/latest/](https://spekframework.github.io/spek/docs/latest/%0D)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Up next, we are going to discuss the TDD approach.
  prefs: []
  type: TYPE_NORMAL
- en: TDD
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: TDD has a history dating back to the 1970s, when the idea of “test-first” programming
    was discussed. It was not popular until TDD became a part of **Extreme Programming**
    (**XP**), which was introduced by Kent Beck in the 1990s.
  prefs: []
  type: TYPE_NORMAL
- en: XP
  prefs: []
  type: TYPE_NORMAL
- en: XP is an agile software development methodology that aims to deliver high-quality
    software, meet evolving user requirements, and reduce risks due to uncertainties
    in the process. It has five core values — *communication*, *simplicity*, *feedback*,
    *courage*, and *respect*. It emphasizes short iterative development cycles and
    close collaboration between developers and stakeholders, encouraging frequent
    feedback to adapt to changing requirements. The key practices of XP include pair
    programming, TDD, continuous integration, and frequent releases of small and incremental
    changes.
  prefs: []
  type: TYPE_NORMAL
- en: 'In 2002, Beck published the book *Test-Driven-Development: By Example*, which
    provided detailed guidance on the TDD process and has since significantly influenced
    a lot of engineering practices, even today. TDD has even become a must-have interview
    coding practice in some organizations.'
  prefs: []
  type: TYPE_NORMAL
- en: 'TDD uses a simple workflow of writing tests and production code, as shown in
    *Figure 13**.3*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.3 – TDD workflow](img/B21737_13_3.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.3 – TDD workflow
  prefs: []
  type: TYPE_NORMAL
- en: The first step of TDD is to write a list of test scenarios. Test scenarios are
    written in business language that does not involve technical implementation. It
    describes what the expected behavior of the application is under certain conditions,
    without knowing how the application achieves it.
  prefs: []
  type: TYPE_NORMAL
- en: A test scenario is picked from the list, and we start writing the test. This
    part is interesting because the test case code usually does not compile due to
    requiring an enhancement of current APIs or a new API. This is normal because
    API contracts should be derived from the needs of the user, not the provider.
    Designing an API from users’ perspectives naturally conforms to the **Interface
    Segregation Principle** (**ISP**), which we discussed in [*Chapter 2*](B21737_02.xhtml#_idTextAnchor045).
    The test case should set up the preconditions, attempt to execute the steps, and
    verify the result.
  prefs: []
  type: TYPE_NORMAL
- en: At this moment, you are left with a test case that either does not pass (**red**)
    or does not even compile. The next step is to change the code so that the test
    passes (**green**). It is important to ensure that all other tests pass too. This
    is exactly what the influential advocator of TDD, Kent Beck, suggested when he
    said *“fake it till you* *make it”*.
  prefs: []
  type: TYPE_NORMAL
- en: 'The test will now pass, but you might not be unsatisfied because the code can
    be optimized or organized better. This is your opportunity to improve quality
    by refactoring the code while ensuring all tests continue to pass. That is why
    TDD has another name: **red-green-refactor**.'
  prefs: []
  type: TYPE_NORMAL
- en: There may be more test scenarios that need test cases written, or we may discover
    missed test scenarios. Nonetheless, the cycle repeats until there are no more
    test cases to write.
  prefs: []
  type: TYPE_NORMAL
- en: An exercise on TDD
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The essence of TDD is best experienced in practice. So, we are going to run
    through a small exercise on TDD.
  prefs: []
  type: TYPE_NORMAL
- en: The team is asked to develop a feature to allow users to create a household
    record in the system. There is no code written for this feature.
  prefs: []
  type: TYPE_NORMAL
- en: Step 1 – write a list of test scenarios
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The first step for TDD is to write a list of test scenarios. QAs and engineers
    should ask stakeholders a lot of questions and turn these answers into test scenarios.
    Here are some examples:'
  prefs: []
  type: TYPE_NORMAL
- en: What are the attributes of a household record? The answer would be a surname
    and email address.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Can two different households have the same surname? No, this is a small village
    where all households have distinct surnames.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Can a household have no surname? No.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'This is the first draft list of test scenarios from the answers:'
  prefs: []
  type: TYPE_NORMAL
- en: Fail to create a household with an empty surname
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Successfully create a household
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fail to create a household if the surname already exists
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now we can pick the first test scenario and write a test case.
  prefs: []
  type: TYPE_NORMAL
- en: Step 2 – write a test case
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We want to assert that creating a household record with an empty surname results
    in failure. Again, we are using Kotest framework’s `StringSpec` as the testing
    style:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: This test case creates a `HouseholdService` object and then invokes the `createHousehold`
    function with a `Household` object with an empty surname. The test expects the
    function to return a `Failure` object that provides an appropriate reason for
    the failure.
  prefs: []
  type: TYPE_NORMAL
- en: Obviously, the code does not compile. The `HouseholdService` and `Failure` classes
    are dreamed up by the test case. They do not exist. However, writing this test
    case requires us to consider how the API should be built and what the user’s expectations
    are.
  prefs: []
  type: TYPE_NORMAL
- en: Step 3 – make tests pass
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Your IDE should indicate compilation errors for the non-existing classes and
    functions. Hopefully, your IDE should have a “quick fix” function that creates
    classes for you. It is recommended to let the IDE first create all classes, then
    functions, so the IDE has the context to generate functions with new classes.
    These classes are empty and may look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'We are ready to run the test. It has failed with this message:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: This is a good start. The test runs and it is red (i.e., it has failed). Now
    try to *make it green* with the *simplest* *possible implementation*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Hardcoding the function to return the expected `Failure` object would be the
    simplest option, wouldn’t it? Most engineers would feel the urge to fix everything
    and make the classes reasonable. However, the goal here is to write the least
    amount of code to make the test pass. Here are the changes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: The `Failure` class has changed to a `data` class so that the test case gets
    the reason for verification. The `createHousehold` function now returns a hardcoded
    `Failure` object just to pass the test. The `Household` class has not changed.
  prefs: []
  type: TYPE_NORMAL
- en: At this point, this is only a hack implementation. However, it will evolve with
    more test cases. Let us pick the next test scenario.
  prefs: []
  type: TYPE_NORMAL
- en: Step 2 again – a new test case
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The next test scenario is the successful creation of a household record. The
    surname of the household is no longer empty, and the test expects `HouseholdService`
    to respond with a successful result that contains the created `Household` record.
    See the code of the test case here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: The test case uses the `Arb` class from the Kotest property module (`io.kotest:kotest-property`)
    to generate a random surname for the `Household` object. The test case uses a
    randomly generated string with a minimum size of three as the surname.
  prefs: []
  type: TYPE_NORMAL
- en: Again, the test case does not compile. The `Success` class does not exist, and
    the `createHousehold` function does not return such a type.
  prefs: []
  type: TYPE_NORMAL
- en: Step 3 again – make all tests pass
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Aiming to have two test cases pass is going to drive the code’s development.
    This is quite literally development driven by tests. We can use the IDE feature
    to generate the `Success` class. It is also easy enough to write one ourselves:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'The compilation error is resolved. We need to run *all* the tests during the
    TDD cycle. This is to ensure that we do not break existing tests. Test results
    show that the first test still passes, but the second test fails with the following
    message:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'We need the `createHousehold` function to return a `Success` object for successful
    creation or a `Failure` object for failure. The simplest approach is the use of
    Kotlin’s `sealed` class. Engineers may use other constructs, such as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Result4k<Household, String>` from the `String`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Either<String, Household>` from the `String`, and the right parameter is the
    type for the success response'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The `sealed` class approach would look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'The `createHousehold` function needs to evolve to handle both test cases. Doing
    so would require removing the previous hack implementation and implementing actual
    validation logic. The `Household` class is changed to a `data` class so the function
    can access the surname to perform the validation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'The function has changed the return type to `Result`. A simple validation is
    also added to ensure that only non-blank surnames are accepted:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Now all tests have passed. However, the use of the `IsNotBlank` function might
    get you thinking that non-empty strings filled with spaces or tabs should have
    resulted in failure, but these cases are not tested.
  prefs: []
  type: TYPE_NORMAL
- en: Step 4 – refactor code
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We want to enhance the first test case by parameterizing several blank strings,
    as well as mixing whitespaces, tabs, and new-line characters. The `DescribeSpec`
    in Kotest supports this type of parameterization better, so the test class is
    changed to inherit from `DescribeSpec`. This change also affects test case number
    two, and all test names are updated accordingly:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Now we have a parameterized setting for the first test, covering multiple combinations
    of blank strings. We are now satisfied enough to repeat the process.
  prefs: []
  type: TYPE_NORMAL
- en: Additional steps
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: If this exercise goes further and picks up the next test scenario, “fail to
    create a household if the surname already exists,” then it involves keeping a
    created household record somewhere to provide a stateful validation if a household
    already exists. To drive a persistent implementation, such as saving the household
    record, we need to add test scenarios such as “retrieve a household record created
    by another household service instance.” In a way, it encourages us to write better
    and more test scenarios as well.
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, as we suggest making all tests pass with the simplest possible implementation,
    we end up with the simplest but complete implementation, which fulfills both the
    **Keep it simple, stupid!** (**KISS**) and **You aren’t gonna need it** (**YAGNI**)
    principles, as discussed in [*Chapter 2*](B21737_02.xhtml#_idTextAnchor045).
  prefs: []
  type: TYPE_NORMAL
- en: The KISS principle
  prefs: []
  type: TYPE_NORMAL
- en: The KISS principle is a design philosophy emphasizing simplicity in both design
    and implementation. It was first seen in the American newspaper *Minnesota Star
    Tribune* in 1938\. The KISS acronym was coined by lead military engineer Kelly
    Johnson. The KISS principle advocates that systems should be as straightforward
    as possible, avoiding unnecessary complexity. Simplicity enhances maintainability,
    reduces the likelihood of errors, and improves user experience.
  prefs: []
  type: TYPE_NORMAL
- en: TDD is meant to be practiced as a short and iterative process, as illustrated
    by the TDD exercise steps explained earlier. Together with the simplest possible
    implementation during the process, TDD can produce simple implementations that
    are naturally 100% covered by tests.
  prefs: []
  type: TYPE_NORMAL
- en: TDD is particularly useful if QAs and engineers are learning features as they
    go because TDD encourages learning and improving both test cases and implementation
    via short iterations.
  prefs: []
  type: TYPE_NORMAL
- en: However, for well-established systems, a strict TDD approach may not be as effective.
    The APIs may already be there and there could be only one line of code that’s
    updated for the behavior change. It may just be simpler to update existing tests
    to assert the new behavior and make them fail than to update the implementation
    to make all tests pass. There may not be a need to start from nothing.
  prefs: []
  type: TYPE_NORMAL
- en: Coming next, we are going to discuss a sibling of TDD – BDD.
  prefs: []
  type: TYPE_NORMAL
- en: BDD
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: BDD evolved from TDD with the goal of addressing some of the limitations of
    TDD, such as test case classes filled with technical syntax that non-technical
    stakeholders would find difficult to read.
  prefs: []
  type: TYPE_NORMAL
- en: The concept of BDD was introduced by Dan North in 2003 during the discussions
    on improvement collaboration between technical and non-technical team members.
    This is also the year when he started the development of the **JBehave** framework
    as a replacement for the **JUnit** framework, emphasizing behaviors rather than
    tests.
  prefs: []
  type: TYPE_NORMAL
- en: The **Gherkin** language was created in the year after that, as a domain-specific
    language that is close to the natural English language. The language aims to bring
    non-technical stakeholders closer to technical team members.
  prefs: []
  type: TYPE_NORMAL
- en: 'The test scenario we have worked on during the TDD exercise can be expressed
    in the Gherkin language as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Gherkin uses a simple structured syntax to define test scenarios. The primary
    keywords include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Feature**: A feature of the application'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Scenario**: A specific situation or example'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Given**: Conditions before the test starts'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**When**: Action or event that triggers behavior'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Then**: Expected outcome'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**And/But**: Add additional steps, conditions, or expected outcome'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A test scenario written in the Gherkin language needs to be translated into
    programming languages to be executed. **Cucumber** ([https://github.com/cucumber](https://github.com/cucumber))
    is the first major tool for BDD, and it was developed around 2005\. It can translate
    test scenarios in Gherkin language to test scripts into multiple programming languages,
    such as Ruby, Rust, Java, Go, JavaScript, and Kotlin.
  prefs: []
  type: TYPE_NORMAL
- en: Specification by Example (SBE)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: BDD has a close relationship with **Specification by Example** (**SBE**). The
    term SBE was made popular by *Gojko Adzic* in his book *Specification by Example*,
    which was published in 2011.
  prefs: []
  type: TYPE_NORMAL
- en: 'SBE advocates using concrete examples in real-world scenarios to clarify specifications
    and to communicate with non-technical stakeholders. This has influenced the conventional
    format of user stories as follows: *“As a [user], I want to [feature], so that
    [business values]”*. This ensures clear and testable specifications based on real
    examples.'
  prefs: []
  type: TYPE_NORMAL
- en: A user story is further expanded to have acceptance criteria to determine whether
    the feature is completed to the user’s satisfaction. These acceptance criteria
    are reflected in the test scenarios, possibly in the Gherkin language as a BDD
    practice.
  prefs: []
  type: TYPE_NORMAL
- en: Adopting SBE and BDD has several implications. The test scenarios are written
    in Gherkin language and the vocabulary used should align with Ubiquitous Language,
    as discussed in [*Chapter 8*](B21737_08.xhtml#_idTextAnchor289). Secondly, human-readable
    test scenarios strongly suggest blackbox testing as the major approach.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, many teams using Agile methodologies would even use SBE and BDD to
    improve their requirement gathering and testing processes. In a way, the concrete
    examples from SBE and test scenarios from BDD become the de facto agreement with
    non-technical stakeholders on the understanding of the feature.
  prefs: []
  type: TYPE_NORMAL
- en: BDD adoption in Kotlin
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: BDD is still actively adopted by many teams nowadays. Many Kotlin engineers
    are still using Cucumber as their BDD tool. However, there are reasons why some
    teams make a conscious decision not to use the Gherkin language to define test
    scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: The Kotlin language is concise and less verbose than its predecessor, Java.
    Kotlin provides a lot of innate syntactic support and syntactic sugar to simplify
    the code for better readability.
  prefs: []
  type: TYPE_NORMAL
- en: With modern testing frameworks such as Kotest, Spek ([https://www.spekframework.org](https://www.spekframework.org)),
    and Kluent ([https://github.com/MarkusAmshove/Kluent](https://github.com/MarkusAmshove/Kluent)),
    it is possible to have readable Kotlin-based test scripts that mimic the Gherkin
    format for test scenarios to a good extent.
  prefs: []
  type: TYPE_NORMAL
- en: It diminishes the need to introduce a translation layer, which can sometimes
    introduce bugs during testing. It is also a balanced act between the benefits
    of reading test scenarios and the cost of translating Gherkin test scripts to
    Kotlin.
  prefs: []
  type: TYPE_NORMAL
- en: However, having BDD and SBE in mind in the agile development process is always
    beneficial, as it elicits meaningful conversations with non-technical stakeholders
    in the endeavor of understanding user requirements.
  prefs: []
  type: TYPE_NORMAL
- en: There are a few types of testing that are conducted in production environments.
    There are justifications for why they need to run in customer-facing environments,
    and we are going to explore the reasons behind them.
  prefs: []
  type: TYPE_NORMAL
- en: Live testing, A/B testing, and segmentation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Live tests are no replacement for other types of tests conducted in lower environments.
    Each type of live testing serves a unique purpose in that it can only be executed
    in a live environment.
  prefs: []
  type: TYPE_NORMAL
- en: Post-release testing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Some systems integrate with external systems that do not provide a lower environment
    for testing. Engineers would normally mitigate this risk by having a simulator
    running in lower environments. The simulator is a fake component that runs simplified
    logic just to act like the target external system. Engineers rely on documentation
    or information from the third-party company to implement the simulator.
  prefs: []
  type: TYPE_NORMAL
- en: 'This approach is not ideal, but it is better than having nothing to detect
    defects in lower environments. Several risks come with this approach:'
  prefs: []
  type: TYPE_NORMAL
- en: The simulator logic needs to closely follow the steps of external system changes.
    Otherwise, it creates a time gap of discrepancies.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The external system may release its changes without informing the team, resulting
    in malfunctioning of the system and requiring hotfixes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Engineers must ensure that the simulator never runs in production environments
    to create false data. Data damage and remediation come at a huge cost.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Having all safety measures in place, the external system may simply be unavailable
    after release. Thus, the system is only partially operational.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Regardless of whether there is a test environment for external system integration,
    some mission-critical systems, such as financial trading systems, would perform
    a “test trade” with a minimal amount to ensure that the crucial features are operational
    and the corresponding data is correct.
  prefs: []
  type: TYPE_NORMAL
- en: A/B testing and segmentation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Some tests are run in production for a longer period for reasons other than
    QA. A/B testing and segmentation are executed to discover needs and opportunities
    in the market.
  prefs: []
  type: TYPE_NORMAL
- en: 'Some organizations would segment their users into at least two groups. The
    segmentation can be done in the following ways:'
  prefs: []
  type: TYPE_NORMAL
- en: A stateless algorithm
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: User data, such as demographics or preferences
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Signed up voluntarily by users
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Random and sticky assignments
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Manually assigned to small groups
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Each group has a different user experience, and metrics are in place to measure
    business metrics such as page landing counts, purchase statistics, and customer
    satisfaction. This is a typical segmentation setup:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Control group**: The original experience; the baseline for comparisons'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Variant groups**: The modified experiences'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By conducting A/B testing, the organization can gather useful information about
    users and the market. The data collected provides a quantitative perspective on
    which user experiences lead to a better outcome. This provides insights on real-user
    behaviors using empirical evidence, and it fosters a culture of hypothesis testing
    and data-driven decision-making.
  prefs: []
  type: TYPE_NORMAL
- en: Some A/B tests could run only for a limited time just to collect enough data
    for analysis, while some could run for a very long time for continuous improvements.
    Some organizations would even run multiple A/B tests at the same time, but this
    comes at the cost of exponential complexity when performing statistical analysis.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we discussed the role and involvement of QA in the software
    development cycle. We covered the testing pyramid in depth, explored each layer
    with code examples, and mentioned some of the techniques used in test scripts
    such as blackbox and whitebox testing, mocking, and parameterized testing.
  prefs: []
  type: TYPE_NORMAL
- en: We explored the concepts of TDD. We ran through an exercise of TDD with small
    and frequent iterations, using real-life examples.
  prefs: []
  type: TYPE_NORMAL
- en: We discussed BDD, a close relative of TDD. We elaborated on its history and
    how it evolved from TDD. We also introduced SBE, which works closely with BDD
    practices. Finally, we briefly discussed the modern adoption of BDD in Kotlin.
  prefs: []
  type: TYPE_NORMAL
- en: We also briefly introduced some types and examples of testing that are executed
    in live environments and the reasons behind them.
  prefs: []
  type: TYPE_NORMAL
- en: The next chapter will cover an important aspect of software systems – security.
  prefs: []
  type: TYPE_NORMAL
