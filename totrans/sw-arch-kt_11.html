<html><head></head><body><div id="book-content"><div id="sbo-rt-content"><div id="_idContainer100">
			<h1 id="_idParaDest-264" class="chapter-number"><a id="_idTextAnchor358"/>11</h1>
			<h1 id="_idParaDest-265"><a id="_idTextAnchor359"/>Auditing and Monitoring Models</h1>
			<p>This chapter is dedicated to covering the auditing and monitoring aspects of software systems. Implementing a robust auditing and monitoring strategy is key for an organization to improve the overall reliability, security, and performance of its systems while also gaining valuable insights to support data-driven decision-making and <span class="No-Break">continuous improvement.</span></p>
			<p>This is particularly crucial for distributed systems, where the increased complexity and inter-dependencies introduce additional challenges compared to traditional <span class="No-Break">monolithic applications.</span></p>
			<p>In this chapter, we’ll explore the <span class="No-Break">following topics:</span></p>
			<ul>
				<li>The importance of auditing <span class="No-Break">and monitoring</span></li>
				<li>The challenges of distributed system auditing <span class="No-Break">and monitoring</span></li>
				<li>Key aspects of auditing <span class="No-Break">and monitoring</span></li>
				<li>Basic elements of meaningful <span class="No-Break">audit trails</span></li>
			</ul>
			<p>By the end of this chapter, you’ll have a solid understanding of how to establish robust auditing and monitoring capabilities for your systems, enabling you to proactively identify and resolve issues, ensure compliance, and maintain overall <span class="No-Break">system health.</span></p>
			<h1 id="_idParaDest-266"><a id="_idTextAnchor360"/>Technical requirements</h1>
			<p>You can find the code files used in this chapter on <span class="No-Break">GitHub: </span><a href="https://github.com/PacktPublishing/Software-Architecture-with-Kotlin/tree/main/chapter-11%0D"><span class="No-Break">https://github.com/Packt</span>
<span class="No-Break">Publishing/Software-Architecture-with-Kotlin/tree/main/chapter-11</span></a></p>
			<h1 id="_idParaDest-267"><a id="_idTextAnchor361"/>The importance of auditing and monitoring</h1>
			<p>Auditing and monitoring are two distinct but closely related concepts that are critical for the effective management and oversight of <span class="No-Break">a system.</span></p>
			<h2 id="_idParaDest-268"><a id="_idTextAnchor362"/>Auditing</h2>
			<p><strong class="bold">Auditing</strong> is the <a id="_idIndexMarker906"/>systematic approach of reviewing, examining, and verifying the various aspects of a system to ensure its compliance, security, and overall integrity. Auditing covers the following <span class="No-Break">key areas:</span></p>
			<ul>
				<li><strong class="bold">Compliance</strong>: Inspecting the system’s conformity to relevant laws, regulations from authority, industry standards, and <span class="No-Break">company policies.</span></li>
				<li><strong class="bold">Security</strong>: Assessing the system’s security infrastructure, policies, and procedures. This includes vulnerability assessments, penetration testing, data protection mechanisms, and <span class="No-Break">access controls.</span></li>
				<li><strong class="bold">Change management</strong>: Reviewing the processes and documentation associated with system changes <span class="No-Break">and updates.</span></li>
				<li><strong class="bold">Incident management</strong>: Examining the effectiveness of responses to the system incident and disaster <span class="No-Break">recovery procedures.</span></li>
				<li><strong class="bold">Performance</strong>: Evaluating the efficiency of the system’s operations, resource utilization, and <span class="No-Break">overall performance.</span></li>
			</ul>
			<p>The auditing process typically involves collecting and analyzing various system logs, configuration files, user activities, documentation, and other relevant data to identify potential issues, vulnerabilities, and areas <span class="No-Break">for improvement.</span></p>
			<p>The auditing process is typically done at regular intervals. It’s common for organizations to have quarterly, semi-quarterly, and annual audits. The cadence is usually determined by factors such as the regulatory requirements, the system’s complexity, criticality, risk profile, and the organization’s overall risk <span class="No-Break">management strategy.</span></p>
			<p>A system of higher risk would suggest a more frequent auditing cadence, and some organizations may even exercise a continuous <span class="No-Break">auditing process.</span></p>
			<p>An ad hoc auditing process may be required in the face of certain events, such as a significant system<a id="_idIndexMarker907"/> change, security incident, major industry change, or <span class="No-Break">regulatory update.</span></p>
			<h2 id="_idParaDest-269"><a id="_idTextAnchor363"/>Monitoring</h2>
			<p><strong class="bold">Monitoring</strong>, on the other <a id="_idIndexMarker908"/>hand, involves continuously observing and tracking a system’s operational state, performance, and behaviors. The following are some <span class="No-Break">monitoring activities:</span></p>
			<ul>
				<li><strong class="bold">Real-time monitoring</strong>: Continuously collecting and analyzing system metrics, such as system availability, resource utilization, network traffic, and error rates, to detect and respond to <span class="No-Break">issues promptly</span></li>
				<li><strong class="bold">Anomaly detection</strong>: Identifying unusual or unexpected system behavior that may indicate potential problems or <span class="No-Break">security threats</span></li>
				<li><strong class="bold">Trend analysis</strong>: Examining historical data to identify patterns, trends, and changes in the system’s performance and usage <span class="No-Break">over time</span></li>
				<li><strong class="bold">Alerting and notifications</strong>: Triggering alerts and notifications when predefined thresholds or conditions are met, enabling proactive <span class="No-Break">issue resolution</span></li>
				<li><strong class="bold">Dashboards and reporting</strong>: Providing visual representations of system health, performance, and key metrics to support <span class="No-Break">data-driven decision-making</span></li>
			</ul>
			<p>Monitoring typically involves deploying various monitoring middleware components, agents, and frameworks that collect, aggregate, and analyze data from different components of <span class="No-Break">the system.</span></p>
			<h2 id="_idParaDest-270"><a id="_idTextAnchor364"/>Why are auditing and monitoring important?</h2>
			<p>Auditing and monitoring <a id="_idIndexMarker909"/>are critical for the effective management and <a id="_idIndexMarker910"/>operation of any system. Here are some of the key reasons why auditing and monitoring are <span class="No-Break">so important:</span></p>
			<ul>
				<li><strong class="bold">Ensuring reliability and availability</strong>: Proactive monitoring helps identify and address issues before they escalate into system failures or downtime. Real-time alerts and incident management enable rapid response and resolution of problems, minimizing the impact on end users. Comprehensive audit trails provide the necessary information to troubleshoot the root causes of system failures, improving the system’s reliability <span class="No-Break">and availability.</span></li>
				<li><strong class="bold">Maintaining security and compliance</strong>: Audit logs and data monitoring can be used to detect and investigate security breaches, unauthorized access attempts, and other malicious activities. Compliance regulations often mandate the implementation of robust audit and monitoring capabilities to ensure the integrity and confidentiality of sensitive data and systems. Audit reports and monitoring dashboards can demonstrate an organization’s adherence to compliance requirements, reducing the risk of penalties and <span class="No-Break">reputational damage.</span></li>
				<li><strong class="bold">Optimizing performance and efficiency</strong>: Monitoring system metrics and resource utilization can help with identifying bottlenecks, optimizing resource allocation, and improving overall system performance. Audit data can provide insights into usage patterns, workload trends, and areas for <span class="No-Break">potential optimization.</span></li>
				<li><strong class="bold">Enabling data-driven decision-making</strong>: Auditing and monitoring data can be leveraged to<a id="_idIndexMarker911"/> identify <a id="_idIndexMarker912"/>patterns and generate valuable business intelligence, supporting strategic planning and decision-making. Detailed reports and visualizations can provide stakeholders with a comprehensive understanding of the system’s health, performance, and overall status. Historical data and trend analysis can help with predicting future resource requirements, planning for capacity expansions, and identifying opportunities for <span class="No-Break">process improvements.</span></li>
				<li><strong class="bold">Facilitating troubleshooting and root cause analysis</strong>: Comprehensive audit trails and monitoring data can help engineers and support teams quickly identify the root causes of problems, reducing the time required for issue resolution. Detailed event logs and contextual information can aid in reconstructing system behaviors and recreating problematic scenarios. Auditing and monitoring data can be used to validate the effectiveness of implemented fixes and ensure that issues <span class="No-Break">don’t recur.</span></li>
			</ul>
			<p>By investing in robust audit and monitoring capabilities, organizations can ensure the reliability, security, and optimization of their distributed systems, ultimately delivering better experiences <a id="_idIndexMarker913"/>for<a id="_idIndexMarker914"/> their end users <span class="No-Break">and stakeholders.</span></p>
			<h2 id="_idParaDest-271"><a id="_idTextAnchor365"/>Auditing, monitoring, and measuring systems</h2>
			<p>“<em class="italic">You can’t improve what you don’t measure</em>” is a <a id="_idIndexMarker915"/>statement from the <a id="_idIndexMarker916"/>management<a id="_idIndexMarker917"/> consultant and writer <span class="No-Break"><em class="italic">Peter Drucker</em></span><span class="No-Break">.</span></p>
			<p>Without measurement, the organization could fall into the <span class="No-Break">following scenarios:</span></p>
			<ul>
				<li><strong class="bold">Opinion-based decision-making</strong>: Without quantitative evidence, people can only express opinions they have little ground to base on. This leads to ineffective communication among stakeholders and engineers and a fragmented understanding of <span class="No-Break">the problem.</span></li>
				<li><strong class="bold">Hit-and-miss improvement</strong>: Any attempt to improve the system features or quality attributes becomes hit and miss. Some of them may work, and some of them may not, due to the lack of understanding of the problem. Even worse, there is little way to objectively reflect the effect of the improvement. The organization would then carry on the opinion-based decision-making in a <span class="No-Break">vicious cycle.</span></li>
			</ul>
			<p>On the contrary, measuring the system via monitoring benefits the organization in the <span class="No-Break">following ways:</span></p>
			<ul>
				<li><strong class="bold">Establishing baselines</strong>: Measuring the current state of a system, whether it’s performance metrics, security integrity, or compliance conformity, provides the necessary baseline against which future improvements can be assessed <span class="No-Break">and compared.</span></li>
				<li><strong class="bold">Identifying opportunities</strong>: Measurement and monitoring data can uncover problems, bottlenecks, or inefficiencies within a system that may not be apparent without <span class="No-Break">quantifiable evidence.</span></li>
				<li><strong class="bold">Tracking progress</strong>: Once improvements or changes are implemented, continuous measurement and monitoring allow organizations to track the impact and effectiveness of those changes, ensuring that they make a positive impact and that desired outcomes are being achieved. If not, the organizations can decide to pivot from the original changes to avoid <span class="No-Break">further deterioration.</span></li>
				<li><strong class="bold">Informed decision-making</strong>: Reliable data and metrics enable data-driven decision-making, allowing organizations to prioritize and allocate resources more effectively toward the areas that will yield the greatest improvements. This is also an antidote to opinion-based decision-making. Quantitative evidence is one of the best ways to align people’s understanding and to effectively drive consensus on the <span class="No-Break">improvement required.</span></li>
				<li><strong class="bold">Continuous optimization</strong>: By establishing a culture of measurement and monitoring, organizations<a id="_idIndexMarker918"/> can continuously identify new opportunities<a id="_idIndexMarker919"/> for<a id="_idIndexMarker920"/> improvement, creating a cycle of ongoing optimization <span class="No-Break">and refinement.</span></li>
			</ul>
			<h2 id="_idParaDest-272"><a id="_idTextAnchor366"/>When are auditing and monitoring not necessary?</h2>
			<p>There are a few<a id="_idIndexMarker921"/> exceptions <a id="_idIndexMarker922"/>where auditing and monitoring may not <span class="No-Break">be necessary.</span></p>
			<p>If the system is extremely simple, with very few components and minimal dependencies, the need for comprehensive audit and monitoring may <span class="No-Break">be reduced.</span></p>
			<p>In experimental, low fidelity, or proof-of-concept systems, where the primary focus is on validating a specific concept, hypothesis, or functionality, the investment in audit and monitoring may not be a top priority. However, if the system turns out to be a viable ongoing business later, it’s worth investing more in auditing <span class="No-Break">and monitoring.</span></p>
			<p>Systems that are used for testing, personal experimentation, or other low-impact use cases may not warrant the same level of auditing and monitoring as mission-critical <span class="No-Break">production systems.</span></p>
			<p>Note that some systems or organizations may not be subject to strict regulatory or compliance requirements that mandate comprehensive audit and <span class="No-Break">monitoring capabilities.</span></p>
			<p>Also, some systems are isolated and even disconnected from the internet. If they have strict control access, it may be less critical to have extensive audits <span class="No-Break">and monitoring.</span></p>
			<p>If the system is designed to be temporary or short-lived, with a well-defined lifespan, the investment in comprehensive audit and monitoring may not be justified. This applies to one-off data processing tasks or systems with a predetermined <span class="No-Break">sunset date.</span></p>
			<p>The combination of auditing and monitoring provides a comprehensive approach to managing the integrity, security, and performance of a system, especially in complex distributed environments. Audit findings can help inform and enhance monitoring strategies while monitoring data can provide valuable inputs for the audit process. It’s most beneficial if auditing and monitoring go hand in hand for <span class="No-Break">any organization.</span></p>
			<p>Implementing auditing <a id="_idIndexMarker923"/>and <a id="_idIndexMarker924"/>monitoring isn’t trivial in modern systems, where they’re usually distributed to multiple components. We’re going to discover these challenges in the <span class="No-Break">next section.</span></p>
			<h1 id="_idParaDest-273"><a id="_idTextAnchor367"/>The challenges of distributed system auditing and monitoring</h1>
			<p>Distributed<a id="_idIndexMarker925"/> systems<a id="_idIndexMarker926"/> pose several unique challenges that make their auditing and monitoring more complex than traditional <span class="No-Break">monolithic architectures:</span></p>
			<ul>
				<li><strong class="bold">Distributed data sources</strong>: In a distributed system, the relevant data and logs are scattered across multiple nodes, services, and communication channels. Collecting, aggregating, and correlating this information is a crucial but <span class="No-Break">challenging task.</span></li>
				<li><strong class="bold">Dynamic infrastructure</strong>: Distributed systems often involve highly dynamic infrastructure, with nodes and services being added, removed, or scaled on demand. Keeping track of the constantly evolving topology and resource utilization is essential for <span class="No-Break">effective monitoring.</span></li>
				<li><strong class="bold">Interdependencies and cascading failures</strong>: The intricate interdependencies between components in a distributed system can lead to cascading failures, where a failure in one part of the system triggers issues in other areas. Identifying and tracing these complex relationships is crucial for root cause analysis <span class="No-Break">and recovery.</span></li>
				<li><strong class="bold">A mixture of various technologies</strong>: Distributed systems often incorporate a diverse set of technologies, including various programming languages, data stores, and middleware components. Developing a unified approach to auditing and monitoring that can handle this heterogeneity is a <span class="No-Break">significant challenge.</span></li>
				<li><strong class="bold">Real-time responsiveness</strong>: Distributed systems are often expected to provide real-time responsiveness, requiring auditing and monitoring solutions to process and analyze data at high speeds without introducing significant latency or <span class="No-Break">performance overhead.</span></li>
				<li><strong class="bold">Compliance and regulatory requirements</strong>: Many industries and organizations have strict compliance regulations that mandate comprehensive audit trails and monitoring capabilities. Ensuring that the distributed system meets<a id="_idIndexMarker927"/> these <a id="_idIndexMarker928"/>requirements is a <span class="No-Break">critical responsibility.</span></li>
			</ul>
			<p>To overcome these challenges, we’ll explore the key aspects of auditing and monitoring with <span class="No-Break">concrete examples.</span></p>
			<h1 id="_idParaDest-274"><a id="_idTextAnchor368"/>Capturing the appropriate data</h1>
			<p>To address these<a id="_idIndexMarker929"/> challenges and establish effective auditing and monitoring practices for distributed systems, we need to capture the most appropriate, basic <span class="No-Break">building blocks.</span></p>
			<h1 id="_idParaDest-275"><a id="_idTextAnchor369"/>Audit trails</h1>
			<p>The following are <a id="_idIndexMarker930"/>essential fields that are typically captured in <span class="No-Break">audit trails:</span></p>
			<ul>
				<li><strong class="bold">Timestamp</strong>: The date and time when the event occurred. It’s important to have a universal time zone for all audit trails. <strong class="bold">Coordinated Universal Time</strong> (<strong class="bold">UTC</strong>) is a<a id="_idIndexMarker931"/> sensible choice as it’s atomic and doesn’t tie to any time zone. There’s no daylight saving or clock change complication. It can easily be converted into any local time zone. It’s also a global standard for timekeeping. This is valuable information for correlating different actions that happened around the same time to reflect <span class="No-Break">a pattern.</span></li>
				<li><strong class="bold">User IDs</strong>: The identifier of the user who performed or was affected by the action. The user’s identity must be tokenized and not contain any PII. This is often regulated by local laws and regulations, particularly on data protection and privacy. Therefore, using a tokenized user ID reduces most of the legal hassle of exposing user details. Accessing user information by user ID is restricted to only authorized individuals and <span class="No-Break">local authorities.</span></li>
				<li><strong class="bold">Event or action type</strong>: The type of event or action that’s been performed (for example, login, logout, data access, or <span class="No-Break">data modification).</span></li>
				<li><strong class="bold">Details of the action performed</strong>: The specific details of the action, which are usually the input parameters for the action. Different actions usually have different structures of data. Please note that the details may contain sensitive information that needs to be protected. The protection techniques for sensitive information will be covered in <a href="B21737_14.xhtml#_idTextAnchor442"><span class="No-Break"><em class="italic">Chapter 14</em></span></a><span class="No-Break">.</span></li>
				<li><strong class="bold">Resource accessed</strong>: The resource involved in the action that’s been performed. It’s typically linked to an aggregate, an entity, or a value object. Often, it involves multiple <span class="No-Break">of them.</span></li>
				<li><strong class="bold">Outcome</strong>: The result or consequence of the action. It’s worth noting that success and failure outcomes are equally important in terms of capturing audit trails. For success, it’s essential to capture what will happen next. For failure, any error message or invocation stack trace should be included. Also, it’s important to capture any side effects so that further investigation can be performed <span class="No-Break">on them.</span></li>
				<li><strong class="bold">Session ID</strong>: The identifier of the session during which the event occurred. Having the session ID helps any correlation investigation figure out what other actions may have been performed in the <span class="No-Break">same session.</span></li>
				<li><strong class="bold">Application ID</strong>: The identifier of the application where the event occurred. This information helps engineers pinpoint where an issue may have occurred so that the situation<a id="_idIndexMarker932"/> can <span class="No-Break">be improved.</span></li>
			</ul>
			<h2 id="_idParaDest-276"><a id="_idTextAnchor370"/>Monitoring data</h2>
			<p>The data that’s captured <a id="_idIndexMarker933"/>for monitoring can look remarkably similar to <a id="_idIndexMarker934"/>audit trails. However, monitoring has a unique focus on metrics, availability, and the non-functional properties of a system. Here are the <span class="No-Break">essential fields:</span></p>
			<ul>
				<li><strong class="bold">Timestamp</strong>: The date and time of the event. Most of the modern systems use UTC over other <span class="No-Break">time zones.</span></li>
				<li><strong class="bold">System metrics</strong>: CPU usage, memory usage, disk I/O, network traffic, messaging infrastructure, databases, <span class="No-Break">and caches.</span></li>
				<li><strong class="bold">Application metrics</strong>: The number of API calls, background job executions, response times, request rates, and <span class="No-Break">error rates.</span></li>
				<li><strong class="bold">Service health</strong>: Status of services (for example, up, down, <span class="No-Break">or degraded).</span></li>
				<li><strong class="bold">Performance metrics</strong>: The latency and throughput <span class="No-Break">of operations.</span></li>
				<li><strong class="bold">Logs</strong>: Application logs and <span class="No-Break">system logs.</span></li>
				<li><strong class="bold">Alerts</strong>: Notifications under <span class="No-Break">predefined criteria.</span></li>
				<li><strong class="bold">User activities or business metrics</strong>: General user activity patterns, not specific actions. This usually covers business-related patterns, such as “how many new users have signed up in the last 2 hours” or “how many transactions were created in the last <span class="No-Break">30 minutes.”</span></li>
			</ul>
			<h2 id="_idParaDest-277"><a id="_idTextAnchor371"/>Application log messages</h2>
			<p>Application-level log <a id="_idIndexMarker935"/>messages are generated <a id="_idIndexMarker936"/>by code written by engineers with the aid of logging frameworks. Therefore, the quality of the log messages depends <span class="No-Break">on engineers.</span></p>
			<p>Each organization should define its conventions and best practices for logging messages. Several aspects <span class="No-Break">need standardization.</span></p>
			<h3>Logging levels</h3>
			<p>Organizing logging<a id="_idIndexMarker937"/> messages by hierarchical levels provides perspectives of the system at multiple levels of abstraction. It’s like a map of the system that can be zoomed in and out. Additionally, it defines the level of responses required for what happens in the system. Typically, there are <span class="No-Break">six levels:</span></p>
			<ol>
				<li><strong class="bold">TRACE</strong>: The most detailed and fine-grained level of information. The message is very verbose and full of technical data that can be referenced to the source code. TRACE logging is usually only turned on in local development environments and exceptionally for troubleshooting critical problems in <span class="No-Break">higher environments</span></li>
				<li><strong class="bold">DEBUG</strong>: Less verbose than the trace level, the DEBUG log message provides information that may be needed for diagnosing and troubleshooting issues. The debug level is usually switched off in production environments but switched on in lower environments for <span class="No-Break">testing purposes.</span></li>
				<li><strong class="bold">INFO</strong>: A standard-level log message that announces the change in application state or that something has happened. In the context of the real-life example we previously used for villagers, an info log message could be an announcement of a new household record being created, together with some essential information such as household name. INFO log messages intend to capture only the result of successful cases, and they require no corrective action. This is also the lowest level of log messages to be shown in a <span class="No-Break">production environment.</span></li>
				<li><strong class="bold">WARN</strong>: An unexpected situation has happened in the application. There may be a problem within this instance in the process, but the application can continue to work. For example, there may be a request to delete a household that didn’t exist. It could indicate a data-consistent issue for that household record, but the application can carry on handling other requests. A WARN log message may require investigation by engineers, but not as <span class="No-Break">an emergency.</span></li>
				<li><strong class="bold">ERROR</strong>: One or more functionalities can’t be completed. This isn’t a single instance of a failure but a consistent failure of a part of the system. The system has degraded, and corrective actions may be required to recover the <span class="No-Break">failed functionality.</span></li>
				<li><strong class="bold">FATAL</strong>: A fundamental error in the crucial functionality no longer works. An example would be losing connection to a database so that none of the persistence<a id="_idIndexMarker938"/> functions can be completed. An urgent corrective action or even manual intervention is required to recover <span class="No-Break">the situation.</span></li>
			</ol>
			<h3>Log message formats</h3>
			<p>Having a consistent<a id="_idIndexMarker939"/> format in log messages helps engineers to quickly triage and identify issues. A good log message should contain a timestamp, the name of the logger, the log level, the thread name, the class name where the message was logged, and the <span class="No-Break">message itself.</span></p>
			<p>Luckily, most of this information is provided by the logging framework. However, engineers will still need to code the content of the <span class="No-Break">logging message.</span></p>
			<p>A good log message should have the <span class="No-Break">following characteristics:</span></p>
			<ol>
				<li><strong class="bold">Concise</strong>: The message should be short and ideally in <span class="No-Break">one sentence.</span></li>
				<li><strong class="bold">Mindful use of tenses</strong>: Two major tenses should be used. The past tense is used to describe what happened. Continuous tense is used for logging processes that are still running and should be concluded with a log message announcing the process has <span class="No-Break">been completed.</span></li>
				<li><strong class="bold">Key information</strong>: The message should contain the essential IDs so that engineers who read the message can troubleshoot the related issue. Engineers who wrote the log message can read the content from the console and run a drill <span class="No-Break">troubleshooting session.</span></li>
				<li><strong class="bold">Incite an action</strong>: Engineers can act on the log message, either as an investigation or confirmation of the outcome of a process as this would <span class="No-Break">be valuable.</span></li>
				<li><strong class="bold">Consistent style</strong>: A consistent <a id="_idIndexMarker940"/>style promotes easier understanding and faster response to a <span class="No-Break">log message.</span></li>
			</ol>
			<h3>Logging frameworks</h3>
			<p>Despite that different<a id="_idIndexMarker941"/> components may use different technologies and languages, the same logging framework should be used whenever possible. This would reduce the inconsistencies of log messages in the system, and thus reduce the cognitive load of engineers using the log messages for <span class="No-Break">troubleshooting purposes.</span></p>
			<h3>Structured versus unstructured logging</h3>
			<p>An <strong class="bold">unstructured log</strong> message<a id="_idIndexMarker942"/> is a<a id="_idIndexMarker943"/> plain string with some<a id="_idIndexMarker944"/> formatting, as <span class="No-Break">shown here:</span></p>
			<pre class="console">
09:50:22.261 [main] INFO  o.e.household.HouseholdRepository - Created a new household 'Whittington'</pre>			<p>Given that the format is consistent, it isn’t too bad and can be read by humans. However, when it comes to log aggregation, alert triggering, and analysis, it’s hard to extract the exact information accurately <span class="No-Break">and consistently.</span></p>
			<p><strong class="bold">Structured logging</strong>, however, promotes well-defined fields and structures so that data can easily be extracted. The previous plain unstructured text log message can be expressed as a <span class="No-Break">JSON object:</span></p>
			<pre class="source-code">
{
  "@timestamp": "2024-08-20T09:50:22.261878+01:00",
  "@version": "1",
  "message": "Created a new household 'Whittington'",
  "logger_name":
  "org.example.household.HouseholdRepository",
  "thread_name": "main",
  "level": "INFO",
  "level_value": 20000,
  "householdName": "Whittington"
}</pre>			<p>Structured logging allows for custom fields that provide even more value to the log messages for further<a id="_idIndexMarker945"/> monitoring<a id="_idIndexMarker946"/> and analysis. This<a id="_idIndexMarker947"/> feature is powered by most <span class="No-Break">logging frameworks.</span></p>
			<p>The preceding logging message is <a id="_idIndexMarker948"/>supported by the <strong class="bold">Kotlin Logging</strong> framework (<a href="https://github.com/oshai/kotlin-logging">https://github.com/oshai/kotlin-logging</a>), which <a id="_idIndexMarker949"/>wraps the <strong class="bold">Simple Logging Facade for Java</strong> (<strong class="bold">SLF4J</strong>) framework (<a href="https://www.slf4j.org/">https://www.slf4j.org/</a>). Underneath, it<a id="_idIndexMarker950"/> uses<a id="_idIndexMarker951"/> the <strong class="bold">Logback</strong> framework (<a href="https://logback.qos.ch/">https://logback.qos.ch/</a>) to configure how the log message is appended to the destination, such as the system output console. In addition, the <strong class="bold">Logstash Logback Encoder</strong> (<a href="https://github.com/logfellow/logstash-logback-encoder">https://github.com/logfellow/logstash-logback-encoder</a>) is used to<a id="_idIndexMarker952"/> format the JSON-structured log message. The dependency looks like this in a Gradle Kotlin DSL file – that <span class="No-Break">is, </span><span class="No-Break"><strong class="source-inline">build.gradlde.kts</strong></span><span class="No-Break">:</span></p>
			<pre class="source-code">
    implementation("io.github.oshai:kotlin-logging-jvm:7.0.0")
    implementation("org.slf4j:slf4j-api:2.0.16")
    implementation("ch.qos.logback:logback-classic:1.5.7")
    implementation("net.logstash.logback:logstash-logback-encoder:8.0")</pre>			<p>In the Logback configuration file, <strong class="source-inline">logback.xml</strong>, the Logstash encoder is used to format log messages as <span class="No-Break">JSON strings:</span></p>
			<pre class="source-code">
    &lt;appender name="structuredAppender" class="ch.qos.logback.core.ConsoleAppender"&gt;
        &lt;encoder class="net.logstash.logback.encoder.LogstashEncoder"&gt;
        &lt;/encoder&gt;
    &lt;/appender&gt;
    &lt;root level="debug"&gt;
        &lt;appender-ref ref="structuredAppender" /&gt;
    &lt;/root&gt;</pre>			<p>Then, <strong class="source-inline">structuredAppender</strong> is attached to the root as a log appender. The code to log a structured <a id="_idIndexMarker953"/>message is <a id="_idIndexMarker954"/><span class="No-Break">as </span><span class="No-Break"><a id="_idIndexMarker955"/></span><span class="No-Break">follows:</span></p>
			<pre class="source-code">
        log.atInfo {
            message = "Created a new household '$householdName'"
            payload = mapOf(
                "householdName" to householdName
            )
        }</pre>			<p>Apart from the main message, the <strong class="source-inline">payload</strong> field supports custom fields in key-value <span class="No-Break">pair format.</span></p>
			<p>It should be emphasized that the log message content is created in a Lambda expression, not as parameters. It’s optimal because the logging framework can choose not to execute the Lambda expression if this message has a lower log level than <span class="No-Break">the configuration.</span></p>
			<p>On the contrary, values that are passed in the log function as parameters are evaluated before the logging framework decides to use them. This may have a performance impact if we were to log<a id="_idIndexMarker956"/> very <a id="_idIndexMarker957"/>detailed information in a low log<a id="_idIndexMarker958"/> level such <span class="No-Break">as TRACE.</span></p>
			<h3>Contextual logging, or Mapped Diagnostic Context (MDC)</h3>
			<p><strong class="bold">Contextual logging</strong>, also known as <strong class="bold">Mapper Diagnostic Context</strong> (<strong class="bold">MDC</strong>), aims to group or <a id="_idIndexMarker959"/>correlate <a id="_idIndexMarker960"/>log messages with the use of <a id="_idIndexMarker961"/>IDs (for<a id="_idIndexMarker962"/> example user ID, request ID, session ID, and so on). It highlights the fact that these log messages belong to the wider business context or process. This helps engineers identify and diagnose issues by going through a small set of log messages under the <span class="No-Break">same context.</span></p>
			<p>This contextual data can also be used for monitoring and alerting. For example, it’s possible to monitor user activities by session ID to understand actions that are also performed together in <span class="No-Break">a session.</span></p>
			<p>Contextual logging can also cut through layers of abstraction in the log messages. There might be logging in the service layer, and the repository layer can be grouped by the <span class="No-Break">contextual data.</span></p>
			<p>Contextual logging is also compatible with structured logging. Contextual data is added as custom fields to the log messages within the scope so that these log messages can be grouped <span class="No-Break">and analyzed.</span></p>
			<p>Extending from the example provided for structured logging, Kotlin Logging provides a <strong class="source-inline">withLoggingContext</strong> function to <span class="No-Break">facilitate MDC:</span></p>
			<pre class="source-code">
        withLoggingContext("session" to sessionId) {
            log.atInfo {
                message = "Created a new household '$householdName'"
                payload = mapOf(
                    "householdName" to householdName
                )
            }
        }</pre>			<p>The <strong class="source-inline">withLoggingContext</strong> function accepts multiple key-value pairs as the contextual data. In this example, <strong class="source-inline">session</strong> is added as the contextual data. The Lambda expression that follows defines the scope of the context, so all the function invocations in the Lambda expression will automatically have the contextual data added as custom fields to the structured <span class="No-Break">log messages.</span></p>
			<p>Optionally, the contextual data can be surfaced in the content of log messages by adding the contextual field in the <span class="No-Break">log format:</span></p>
			<pre class="source-code">
    &lt;appender name="plainTextWithMdc" class="ch.qos.logback.core.ConsoleAppender"&gt;
        &lt;encoder&gt;
            &lt;pattern&gt;%d{HH:mm:ss.SSS} [%thread] %-5level %logger{36} MDC=%X{session} - %msg%n&lt;/pattern&gt;
        &lt;/encoder&gt;
    &lt;/appender&gt;</pre>			<p>As a result, the<a id="_idIndexMarker963"/> JSON<a id="_idIndexMarker964"/> string<a id="_idIndexMarker965"/> log message is enhanced<a id="_idIndexMarker966"/> with <span class="No-Break">contextual data:</span></p>
			<pre class="source-code">
{
  "@timestamp": "2024-08-20T09:50:22.261878+01:00",
  "@version": "1",
  "message": "Created a new household 'Whittington'",
  "logger_name": "org.example.household.HouseholdRepository",
  "thread_name": "main",
  "level": "INFO",
  "level_value": 20000,
  "session": "57fa4035-0390-406c-9f2b-7dfcfc131d5a",
  "householdName": "Whittington"
}</pre>			<p>The <strong class="source-inline">session</strong> field is automatically added to all messages that are logged inside the scope by the <strong class="source-inline">withLoggingContext</strong> function. This approach also separates the concern of logging contextual data from the main application logic. This contextual data doesn’t need to be passed into any function that’s invoked inside <span class="No-Break">the scope.</span></p>
			<p>There are wider<a id="_idIndexMarker967"/> scopes <a id="_idIndexMarker968"/>on how to centralize and aggregate data<a id="_idIndexMarker969"/> for<a id="_idIndexMarker970"/> monitoring and auditing purposes. We’re going to cover <span class="No-Break">these next.</span></p>
			<h1 id="_idParaDest-278"><a id="_idTextAnchor372"/>Centralizing and aggregating data</h1>
			<p>Previously, we <a id="_idIndexMarker971"/>discussed the challenges of auditing and monitoring distributed systems, one of which is the data that’s scattered across multiple places. It’s common to have a business process perceived as a unit but executed in multiple services and devices in <span class="No-Break">distributed systems.</span></p>
			<p>In this scenario, the auditing and monitoring data only makes sense when we can aggregate it into a centralized place for consolidation <span class="No-Break">and analysis.</span></p>
			<h2 id="_idParaDest-279"><a id="_idTextAnchor373"/>Centralized audit trail aggregation</h2>
			<p>Let’s revisit the <a id="_idIndexMarker972"/>real-life example of villagers exchanging services and imagine that we need to aggregate auditing and monitoring data from numerous services. There are three services: <strong class="bold">Household service</strong>, <strong class="bold">Contract service</strong>, and <strong class="bold">Notification service</strong>. The need to aggregate audit trails would warrant a new generic subdomain service that collects all events that happened in other services. The new service, <strong class="bold">Audit service</strong>, and its interactions with other services are depicted in <span class="No-Break"><em class="italic">Figure 11</em></span><span class="No-Break"><em class="italic">.1</em></span><span class="No-Break">:</span></p>
			<div>
				<div id="_idContainer097" class="IMG---Figure">
					<img src="image/B21737_11_1.jpg" alt="Figure 11.1 – An example of Audit service interactions" width="1204" height="596"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.1 – An example of Audit service interactions</p>
			<p><strong class="bold">Audit service</strong> consumes <a id="_idIndexMarker973"/>all events generated by the four other services. It’s<strong class="bold"> </strong>responsible for understanding these events, transforming them into standard data structures, and persisting them into permanent storage for queries in <span class="No-Break">the future.</span></p>
			<p>This interaction pattern doesn’t require other services to know the existence of <strong class="bold">Audit service</strong>, reducing coupling or dependencies. Other services may need to change code just to inform consumers of what’s happened in their domain but without the burden of <span class="No-Break">auditing requirements.</span></p>
			<p class="callout-heading">Alternative approach</p>
			<p class="callout">The alternative approach would be to have other services imperatively inform <strong class="bold">Audit service</strong>, usually by <a id="_idIndexMarker974"/>calling a <strong class="bold">REST endpoint</strong>. This would make other services depend on <strong class="bold">Audit service</strong>. It’s also more complex for synchronous REST communication to provide the same reliability guarantees compared to asynchronous events. Now, all other services are aware of auditing requirements, which is considered a leak in the bounded context <a id="_idIndexMarker975"/>of auditing. So, this isn’t a <span class="No-Break">recommended approach.</span></p>
			<h3>Audit data structure unification</h3>
			<p>The downside of<a id="_idIndexMarker976"/> this approach is that <strong class="bold">Audit service</strong> must know the schema of all auditable events of all services. There are a lot of dependencies to manage in <span class="No-Break"><strong class="bold">Audit service</strong></span><span class="No-Break">.</span></p>
			<p>There’s a workaround for this problem. If the system can be aligned to adopt a standard envelope of all events, then the auditing fields are defined at the envelope level, while domain-specific fields are defined at the <span class="No-Break">content level.</span></p>
			<p>Having said that, it’s still essential to capture the domain-specific fields as part of the audit trail. These fields can be stored in their native formats without transformation. This transformation will only be needed when retrieving <span class="No-Break">the data.</span></p>
			<h3>Linking related audit trails using IDs</h3>
			<p>The ability to link<a id="_idIndexMarker977"/> related audit<a id="_idIndexMarker978"/> trails is paramount in reporting a complete business journey. This is typically implemented by generating a <strong class="bold">correlation ID</strong> for the entry point service or any other component that the distributed system needs to associate with related audit events. The events may not necessarily be part of the same request <span class="No-Break">or transaction.</span></p>
			<p>Correlation IDs are useful for troubleshooting and understanding the relationships between different components in a distributed system within a business journey, even if they’re not directly part of the same <span class="No-Break">request flow.</span></p>
			<h3>Discoverability of event topics</h3>
			<p>In a large distributed system, having to keep track of new event topics to be consumed by <strong class="bold">Audit service</strong> could be an exhausting effort. Ideally, <strong class="bold">Audit service</strong> should be able to discover and dynamically consume event topics. There are several ways to <span class="No-Break">achieve this:</span></p>
			<ol>
				<li>Use service discovery mechanisms, such as service registries or service meshes, to discover the available event topics or <span class="No-Break">event streams.</span></li>
				<li>Use a centralized event catalog, which can be in the form of a standalone service, or just a resource such as a last-value queue that can be accessed by <span class="No-Break"><strong class="bold">Audit service</strong></span><span class="No-Break">.</span></li>
				<li>Use messaging brokers. Some (for example, RabbitMQ and Kafka) provide APIs to discover <span class="No-Break">event topics.</span></li>
				<li>Use configuration management tools such as Spring Cloud Config or Kubernetes as they provide APIs that can be used to look up <span class="No-Break">event topics.</span></li>
			</ol>
			<p>Once event topics have been looked up dynamically, as well as the standard envelope, <strong class="bold">Audit service</strong> can automatically<a id="_idIndexMarker979"/> consume and persist events in a dedicated database for <span class="No-Break">audit reporting.</span></p>
			<h3>Example of an audit trail event</h3>
			<p>Combining all the<a id="_idIndexMarker980"/> key aspects of audit trails that we discussed previously, we can come up with an example of the audit trail as a Kotlin data class. The most important element of an audit trail is the actor involved in <span class="No-Break">the event:</span></p>
			<pre class="source-code">
data class Actor(
    val id: UUID,
    val type: String,
    val involvement: String,
)</pre>			<p>The <strong class="source-inline">Actor</strong> class uses a UUID as the tokenized identifier. While it typically represents a human user, it can sometimes be a scheduled trigger or an external system that kicks off a business journey. The type of actors (for example, user, external system, or scheduler) is captured by the <strong class="source-inline">type</strong> field. The involvement of the actor is captured by the <strong class="source-inline">involvement</strong> field – for example, “executed by,” “on behalf of,” and <span class="No-Break">so on.</span></p>
			<p>They use the <strong class="source-inline">String</strong> type in contrast to enumeration for <span class="No-Break">two reasons:</span></p>
			<ul>
				<li>Adding a new enum value isn’t <span class="No-Break">backward compatible</span></li>
				<li>Removing an existing enum value isn’t <span class="No-Break">forward compatible</span></li>
			</ul>
			<p>Having it as a plain string ensures it can always be parsed to construct a full audit trail from the beginning of time, knowing that changes in values might be introduced in <span class="No-Break">the future.</span></p>
			<p>Another important element is the <span class="No-Break">resources involved:</span></p>
			<pre class="source-code">
data class Resource (
    val id: UUID,
    val type: String,
    val applicationId: String,
    val version: Int? = null
)</pre>			<p>Each resource is identified by a UUID, but it can just be a plain string. The resource also comes up as a <strong class="source-inline">type</strong> field, which can be the<a id="_idIndexMarker981"/> name of an aggregate, entity, or value object (for example, “household,” “contract,” and so on). It’s also useful to capture to which application the resource belongs. This information is captured as <strong class="source-inline">application ID</strong> (for example, “household service”). If the resource is versioned, then that’s <span class="No-Break">also captured.</span></p>
			<p>From these two data classes, the event envelope data class can be defined <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
data class EventEnvelope&lt;E&gt;(
    val id: UUID,
    val sessionId: UUID? = null,
    val correlationId: UUID? = null,
    val happenedAt: Instant,
    val action: String,
    val outcome: String,
    val actor: Actor,
    val otherActors: Set&lt;Actor&gt;? = null,
    val resource: Resource,
    val otherResources: Set&lt;Resource&gt;? = null,
    val content: E,
    val diffs: List&lt;Difference&gt;? = null,
)</pre>			<p>It starts with an event ID as a UUID type and unique identifier. The session ID is captured to correlate activities that happened in the same login session. There’s a correlation ID that links multiple business activities together. The timestamp of the event is captured as the <strong class="source-inline">happenedAt</strong> field. The <strong class="source-inline">action</strong> field captures what initiates the business journey, while the <strong class="source-inline">outcome</strong> field captures the result as the <span class="No-Break">event occurs.</span></p>
			<p>The envelope uses the <strong class="source-inline">Actor</strong> class in two ways: it initiates the business journey and sets other actors that are involved in this event. A null set is treated the same as an empty set. The <strong class="source-inline">Resource</strong> class follows the same pattern in that there’s a main resource and <span class="No-Break">other resources.</span></p>
			<p>The content of the event makes use of the generic <strong class="source-inline">E</strong> type as there will be many forms of events under <span class="No-Break">the envelope.</span></p>
			<p>Finally, there’s a <a id="_idIndexMarker982"/>generic list of differences between the main resources before and after the event. A Kotlin data class can be expressed as a JSON object, and there are open source libraries that can generate a list in JSON Patch format given two JSON objects. Then, the list of differences can be represented by a data class – that <span class="No-Break">is, </span><span class="No-Break"><strong class="source-inline">Difference</strong></span><span class="No-Break">:</span></p>
			<pre class="source-code">
data class Difference(
    val op: String,
    val path: String,
    val fromValue: Any? = null,
    val toValue: Any? = null
)</pre>			<p>This class has four fields. The <strong class="source-inline">op</strong> field represents the data operation types such as “add,” “replace,” <span class="No-Break">or “delete.”</span></p>
			<p>The <strong class="source-inline">path</strong> field is the path of the field as if it were a JSON object – for example, <em class="italic">/party/0/householdName</em>. The values that are changed before and after the event are captured as <strong class="source-inline">fromValue</strong> and <span class="No-Break"><strong class="source-inline">toValue</strong></span><span class="No-Break">, respectively.</span></p>
			<p>This audit trail envelope is just one example, and each organization should have an envelope that suits<a id="_idIndexMarker983"/> its needs. Next, we’ll turn our attention to monitoring data collection <span class="No-Break">and aggregation.</span></p>
			<h2 id="_idParaDest-280"><a id="_idTextAnchor374"/>Monitoring data collection and aggregation</h2>
			<p>Monitoring tools<a id="_idIndexMarker984"/> use a hugely<a id="_idIndexMarker985"/> different approach to collect their data. They use multiple methods to collect data from various sources, such as <span class="No-Break">the following:</span></p>
			<ul>
				<li><strong class="bold">Agents or daemons</strong>: Small software components called agents are installed on the systems being monitored. These agents collect data and send it to a central <span class="No-Break">monitoring server.</span></li>
				<li><strong class="bold">System-level metrics</strong>: These agents can collect various metrics, such as CPU usage, memory usage, disk I/O, network traffic, <span class="No-Break">and more.</span></li>
				<li><strong class="bold">Application-level metrics</strong>: Applications can log messages in the format so that they can be accounted for as a metric, or applications can submit the metric numbers directly to the monitoring tool. For example, a Kotlin/JVM application can<a id="_idIndexMarker986"/> use <strong class="bold">Java Management Extensions</strong> (<strong class="bold">JMX</strong>) to expose resource usage, application data, configuration, and performance metrics. JMX can be accessed as <strong class="bold">Managed Beans</strong> (<strong class="bold">MBeans</strong>) and can <a id="_idIndexMarker987"/>also be integrated with third-party monitoring tools for visualization and <span class="No-Break">alert purposes.</span></li>
				<li><strong class="bold">Log file collection</strong>: These agents can listen to the system standard output and system error output. These agents can also tail the log files and send them to the monitoring data source. The log messages can also be directly submitted to a data source, such as Elastic Store, for <span class="No-Break">aggregation purposes.</span></li>
				<li><strong class="bold">Agentless</strong>: By using standard network protocols, it’s possible to collect monitoring data, particularly network monitoring data, without installing an agent. For example, <strong class="bold">Window Management Instrumentation</strong> (<strong class="bold">WMI</strong>) provides an <a id="_idIndexMarker988"/>operating system interface where notifications and device-related information from the nodes are enabled. Another example is an extra node in a multicast UDP network that captures network metrics to be sent to the <span class="No-Break">monitoring tool.</span></li>
				<li><strong class="bold">API integration</strong>: Some monitoring middleware software uses direct API integrations with services, applications, and cloud platforms. It can go both ways: either the node being monitored provides an API to expose monitoring data, such as Spring Actuator, or the monitoring tool provides an API for nodes to submit <span class="No-Break">monitoring data.</span></li>
				<li><strong class="bold">Performance measurement</strong>: The performance of certain processes can be measured, and the technique depends on <span class="No-Break">the scope:</span><ul><li>Full process measurement can be performed by aspect-oriented techniques where the times when the process starts and ends are captured by wrapping the function so that its full duration can <span class="No-Break">be measured.</span></li><li>In Kotlin, partial<a id="_idIndexMarker989"/> process<a id="_idIndexMarker990"/> measurement can be performed by built-in functions. There’s one function for millisecond precision (<strong class="source-inline">measureTimeMillis</strong>) and another for nanosecond <span class="No-Break">precision (</span><span class="No-Break"><strong class="source-inline">measureNanoTime</strong></span><span class="No-Break">):</span><pre class="source-code">
val elapsedInMillis = measureTimeMillis { someProcess() }
val elapsedInNanos = measureNanoTime { someProcess() }</pre></li></ul></li>				<li><strong class="bold">Trace IDs and span IDs</strong>: A <strong class="bold">trace ID</strong> is a unique <a id="_idIndexMarker991"/>identifier that represents an end-to-end business process or request as it flows through a distributed system. It’s used to group all the individual spans (see the following paragraph) that are part of the distributed transaction or request. Trace IDs allow us to understand the complete journey of a request as it moves across multiple services, components, <span class="No-Break">and systems.</span><p class="list-inset">A <strong class="bold">span ID</strong> is a unique <a id="_idIndexMarker992"/>identifier for a single operation or unit of work within a distributed transaction or request. Spans represent individual steps or operations that are performed as part of a larger trace, such as an HTTP request, a database query, or a function call. Spans are hierarchical and can be nested within a trace to represent the different components, services, or processes involved in handling a single request. The relationship between trace IDs and span IDs is shown in <span class="No-Break"><em class="italic">Figure 11</em></span><span class="No-Break"><em class="italic">.2</em></span><span class="No-Break">:</span></p></li>
			</ul>
			<div>
				<div id="_idContainer098" class="IMG---Figure">
					<img src="image/B21737_11_2.jpg" alt="Figure 11.2 – Trace IDs and span IDs in a real-world example" width="1168" height="634"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.2 – Trace IDs and span IDs in a real-world example</p>
			<p class="list-inset">Here, one request<a id="_idIndexMarker993"/> is coming <a id="_idIndexMarker994"/>from the mobile application through <strong class="bold">Contract Service</strong> to amend a contract, while <strong class="bold">Trace ID 215</strong> and <strong class="bold">Span ID 12</strong> are assigned to this request. <strong class="bold">Contract Service</strong> requests household information from <strong class="bold">Household Service</strong> while processing the request. This means that <strong class="bold">Household Service</strong> is involved in processing this request, as indicated by <strong class="bold">Trace ID 215</strong> but a different span value – that is, <strong class="bold">Span ID 13</strong>. <strong class="bold">Contract Service</strong> notifies <strong class="bold">Notification Service</strong> to send emails to the affected households, so <strong class="bold">Notification Service</strong> is also involved in this request, using the same trace – that is, <strong class="bold">Trace ID 215</strong> – but a new span – that is, <strong class="bold">Span </strong><span class="No-Break"><strong class="bold">ID 14</strong></span><span class="No-Break">.</span></p>
			<p>With many third-party <a id="_idIndexMarker995"/>monitoring tools on the market (for example, <strong class="bold">Elastic Slack</strong> (<strong class="bold">ELK</strong>), Splunk, Datadog, Kibana, Prometheus, Grafana, New Relic, Jaeger, and others) and various methods in collecting data, it’s recommended to avoid the vendor lock-in issue. It may become <a id="_idIndexMarker996"/>too expensive <a id="_idIndexMarker997"/>to consider other monitoring tools if the system is integrated with the monitoring tools using <span class="No-Break">proprietary methods.</span></p>
			<h2 id="_idParaDest-281"><a id="_idTextAnchor375"/>OpenTelemetry (OTel)</h2>
			<p><strong class="bold">OpenTelemetry</strong> (<strong class="bold">OTel</strong>) is a <a id="_idIndexMarker998"/>community-driven open source framework that aims to standardize the way we collect, process, and export observability data from applications. It provides a set of APIs, libraries, agents, and instrumentation tools that can support various programming languages and frameworks. This interoperability makes it possible to trace and monitor applications that use different technologies, and we can monitor the <span class="No-Break">system holistically.</span></p>
			<p>Moreover, it’s cheaper to migrate from one monitoring tool to another given they all use OTel as a standard, and thus we aren’t locked into using only <span class="No-Break">one vendor.</span></p>
			<p>Setting up OTel begins with using its libraries. This is shown in the following code, which uses the Gradle <span class="No-Break">Kotlin DSL:</span></p>
			<pre class="source-code">
    implementation("io.opentelemetry:opentelemetry-api:1.43.0")
    implementation("io.opentelemetry:opentelemetry-sdk:1.43.0")
    implementation("io.opentelemetry:opentelemetry-exporter-otlp:1.43.0")
    implementation("io.opentelemetry:opentelemetry-extension-annotations:1.18.0")</pre>			<p>The next step is to configure the <strong class="source-inline">tracer</strong> and <span class="No-Break"><strong class="source-inline">span</strong></span><span class="No-Break"> processors:</span></p>
			<pre class="source-code">
val tracer: Tracer = run {
    val oltpEndpont = "http://localhost:8123"
    val otlpExporter = OtlpGrpcSpanExporter.builder()
        .<strong class="bold">setEndpoint</strong>(oltpEndpont)
        .build()
    val spanProcessor = SimpleSpanProcessor.create(otlpExporter)
    val tracerProvider = SdkTracerProvider.builder()
        .addSpanProcessor(spanProcessor)
        .build()
    OpenTelemetrySdk.builder()
        .setTracerProvider(tracerProvider)
        .buildAndRegisterGlobal()
    GlobalOpenTelemetry.<strong class="bold">getTracer</strong>("example-tracer")
}</pre>			<p>The preceding code defines an<a id="_idIndexMarker999"/> endpoint to export telemetric data to <a id="_idIndexMarker1000"/>an <strong class="bold">OpenTelemetric Protocol</strong> (<strong class="bold">OTLP</strong>) server. A simple span processor is also defined. Finally, a <strong class="source-inline">Tracer</strong> object is created to be used in the traceable process. Let’s look at how this object is used in starting and ending <span class="No-Break">a span:</span></p>
			<pre class="source-code">
fun main() {
    val span: Span = tracer
        .spanBuilder("process data")
        .<strong class="bold">startSpan</strong>()
        .apply { <strong class="bold">setAttribute</strong>("data.source", "memory") }
    try {
        println("process finished")
    } catch (e: Exception) {
        <strong class="bold">span.recordException</strong>(e)
    } finally {
        <strong class="bold">span.end</strong>()
    }
}</pre>			<p>This example <strong class="source-inline">main()</strong> function starts a span with a custom attribute added to provide contextual information. If the process succeeds, the span is acknowledged and ended. Otherwise, the span records the exception that has <span class="No-Break">been captured.</span></p>
			<p>It’s important to note that the monitoring APIs are designed to not throw errors that would otherwise interfere with the actual process. In this example, the code will run even if the OTLP server can’t <span class="No-Break">be reached.</span></p>
			<p>This data will be <a id="_idIndexMarker1001"/>exported to a monitoring tool for further usage, something we’re going to cover in the <span class="No-Break">next section.</span></p>
			<h2 id="_idParaDest-282"><a id="_idTextAnchor376"/>Metrics, visualization, and dashboards</h2>
			<p>Since monitoring data is <a id="_idIndexMarker1002"/>centralized and aggregated, a <a id="_idIndexMarker1003"/>monitoring<a id="_idIndexMarker1004"/> tool can start using this data for many purposes. For example, heartbeat messages and regular health checks of applications provide an uptime ratio per application as a metric. This metric can be visualized in a dashboard that operators and engineers <span class="No-Break">can observe.</span></p>
			<p>We must create intuitive visualizations and dashboards that provide a clear, at-a-glance understanding of the distributed system’s health, performance, and <span class="No-Break">overall status.</span></p>
			<p>The metrics that are measured and visualized on dashboards can be grouped into <span class="No-Break">two categories.</span></p>
			<ul>
				<li><strong class="bold">Service-level metrics</strong>: Known<a id="_idIndexMarker1005"/> as <strong class="bold">service-level indicators</strong> (<strong class="bold">SLIs</strong>), these metrics measure the reliability, availability, latency, and performance of a system at the service level. It focuses on the <strong class="bold">Quality of Service</strong> (<strong class="bold">QoS</strong>) provided<a id="_idIndexMarker1006"/> to users and <span class="No-Break">external systems.</span><p class="list-inset">Apart from the common metrics, such as CPU utilization, network latency, memory used, and disk space utilization, metrics that are part of the <strong class="bold">service-level objective</strong> (<strong class="bold">SLO</strong>) and <strong class="bold">service-level agreement</strong> (<strong class="bold">SLA</strong>) should be highlighted in<a id="_idIndexMarker1007"/> the<a id="_idIndexMarker1008"/> dashboard. These are sensitive metrics that could affect customer satisfaction, relationships with external entities, and the reputation of <span class="No-Break">the organization.</span></p><p class="list-inset">A typical service-level metric is the response time to a frequently used feature. Application response time is likely part of the SLO or SLA and should be measured<a id="_idIndexMarker1009"/> and<a id="_idIndexMarker1010"/> <span class="No-Break">visualized </span><span class="No-Break"><a id="_idIndexMarker1011"/></span><span class="No-Break">continuously.</span></p></li>
			</ul>
			<p class="callout-heading">SLA versus SLO versus SLI</p>
			<p class="callout">A SLA is a<a id="_idIndexMarker1012"/> formal <a id="_idIndexMarker1013"/>contract between a service provider and a customer that defines the expected level of service, including the specific performance metrics that are guaranteed and penalties for not meeting <span class="No-Break">the agreement.</span></p>
			<p class="callout">A SLO is a specific and measurable goal that defines the target level of the service. It sets the performance standards that the service provider aims <span class="No-Break">to achieve.</span></p>
			<p class="callout">A SLI is a metric that’s used to measure the performance of a service, in particular against SLOs. It provides the data needed to determine whether the SLOs are <span class="No-Break">being met.</span></p>
			<ul>
				<li><strong class="bold">Business-level metrics</strong>: Business-level metrics focus on patterns and usage that should bring awareness to the business. For example, an e-commerce system would be interested in monitoring how many new users have signed up in <span class="No-Break">the system.</span><p class="list-inset">Business-level metrics are often compared against the defined <strong class="bold">key performance indicators</strong> (<strong class="bold">KPIs</strong>), which <a id="_idIndexMarker1014"/>are used to demonstrate how effectively<a id="_idIndexMarker1015"/> an organization achieves its <strong class="bold">objectives and key </strong><span class="No-Break"><strong class="bold">results</strong></span><span class="No-Break"> (</span><span class="No-Break"><strong class="bold">OKRs</strong></span><span class="No-Break">).</span></p><p class="list-inset">The <strong class="bold">objective</strong> part of OKR is a qualitative and visionary goal that may not be measurable. However, the <strong class="bold">key results</strong> are measurable and usually set <span class="No-Break">up regularly.</span></p><p class="list-inset">In this example of users signing up for the e-commerce system, the objective can be to “<em class="italic">sign up as many active purchasing users as possible.</em>” This objective can be translated into the following <span class="No-Break">key results:</span></p><ol><li class="upper-roman">Sign up 30% of new users <a id="_idIndexMarker1016"/>in the <strong class="bold">third </strong><span class="No-Break"><strong class="bold">quarter</strong></span><span class="No-Break"> (</span><span class="No-Break"><strong class="bold">Q3</strong></span><span class="No-Break">)</span></li><li class="upper-roman">Ensure 80% of new <a id="_idIndexMarker1017"/>users stay active in<a id="_idIndexMarker1018"/> the<a id="_idIndexMarker1019"/> last 30 days <span class="No-Break">in Q3</span></li><li class="upper-roman">Ensure 50% of new users purchase at least one item in the system in the last 30 days <span class="No-Break">in Q3</span></li></ol><p class="list-inset">These key results are missions within the boundary of time. They’re measurable goals that aim to inspire <span class="No-Break">bold goals.</span></p><p class="list-inset">On the other hand, KPIs continuously measure performance. To support the aforementioned OKRs, the following KPIs need to <span class="No-Break">be measured:</span></p><ol><li class="upper-roman" value="1">The number of users signed up in the last 3 months (that is, <span class="No-Break">new users)</span></li><li class="upper-roman">The number of new users that logged in to the system in the last <span class="No-Break">30 days</span></li><li class="upper-roman">The number of new users who bought at least one item in the last <span class="No-Break">30 days</span></li></ol><p class="list-inset">The number can be collected and aggregated from either application log messages or from persistent <span class="No-Break">databases directly.</span></p></li>
			</ul>
			<h3>An example of comprehensive metrics – DORA</h3>
			<p>Measuring metrics can be <a id="_idIndexMarker1020"/>an anti-pattern if there’s a way to game the numbers but not improve anything. For example, if the metrics are only about service uptime, then it’s possible to have 100% uptime for services that can’t perform any operation other than answering <span class="No-Break">health checks.</span></p>
			<p>It’s important to have a comprehensive suite of metrics to close this loophole. If multiple metrics measure various aspects of the subject, gaming one metric would skew the others and therefore be impossible to hide. In this section, we’re going to run through an example of comprehensive metrics and how they <span class="No-Break">avoid cheating.</span></p>
			<p><strong class="bold">DevOps Research and Assessment</strong> (<strong class="bold">DORA</strong>) metrics are a set of KPIs to ensure the effectiveness and efficiency of software development and delivery processes. These metrics help organizations understand their DevOps performance and identify areas for improvement. The four primary DORA metrics are <span class="No-Break">as follows:</span></p>
			<ul>
				<li><strong class="bold">Deployment frequency</strong>: How often a production release has succeeded. A higher frequency indicates a higher velocity and responsive <span class="No-Break">development process.</span></li>
				<li><strong class="bold">Lead time for changes</strong>: The time taken between committing code to production. Shorter lead times represent a more efficient <span class="No-Break">development pipeline.</span></li>
				<li><strong class="bold">Change failure rate</strong>: The percentage of deployments that cause a failure in production. Lower rates indicate more stable and <span class="No-Break">reliable releases.</span></li>
				<li><strong class="bold">Mean time to recovery (MTTR)</strong>: The <a id="_idIndexMarker1021"/>average time taken to recover from a failure in production. Faster recovery times indicate better incident response <span class="No-Break">and resilience.</span></li>
			</ul>
			<p>Any attempt to game one of these metrics would be detected by another. For instance, if development skips running tests, the lead time for change will decrease, but the change failure rate will increase due to lack <span class="No-Break">of testing.</span></p>
			<p>The DORA team has also <a id="_idIndexMarker1022"/>developed <strong class="bold">SPACE</strong> metrics, which provide a holistic perspective of engineering productivity in addition to software delivery efficiency. Let’s see what SPACE <span class="No-Break">stands for:</span></p>
			<ul>
				<li><strong class="bold">Satisfaction</strong>: This is a quantitative and qualitative measurement of how satisfied engineers are with their work, work-life balance, <span class="No-Break">and tools</span></li>
				<li><strong class="bold">Performance</strong>: This specifies the quality, effectiveness, and impact of the software that’s <span class="No-Break">been delivered</span></li>
				<li><strong class="bold">Activity</strong>: The volume of activities that have contributed to the completion of work – for example, the number of commits and <span class="No-Break">pull requests</span></li>
				<li><strong class="bold">Communication and collaboration</strong>: This involves evaluating the effectiveness of team meetings, cross-team cooperation, and <span class="No-Break">collaborative tools</span></li>
				<li><strong class="bold">Efficiency</strong>: This measures how time, effort, and tools are effectively utilized for desired outcomes, delivery, and <span class="No-Break">waste reduction</span></li>
			</ul>
			<p>SPACE metrics are designed to cover many angles of team productivity, as well as to avoid any metric from being manipulated by having other metrics detect it. For instance, having excessive meetings might have boosted the volume of activity, but the lack of effectiveness will be caught by evaluating communication <span class="No-Break">and collaboration.</span></p>
			<p>DORA and SPACE are complementary and can be measured at the same time to provide an all-rounded insight<a id="_idIndexMarker1023"/> into the health of the team and its delivery of <span class="No-Break">software products.</span></p>
			<p>Good metrics should come as a comprehensive suite to provide a greater perspective of the <span class="No-Break">organization’s performance.</span></p>
			<h2 id="_idParaDest-283"><a id="_idTextAnchor377"/>Automated alerting and incident management</h2>
			<p>Having a visual <a id="_idIndexMarker1024"/>dashboard that shows metrics is nice, but<a id="_idIndexMarker1025"/> when it comes to detecting system faults and raising alerts, an organization can’t rely on human eyes. There should be automated alerts and a well-defined workflow of incident management so that the organization can recover the system as quickly <span class="No-Break">as possible.</span></p>
			<p>We must establish mechanisms for real-time alerting and incident management so that we can rapidly respond and resolve problems that arise in the <span class="No-Break">distributed system.</span></p>
			<p>Monitoring tools allow the organization to trigger alerts under <span class="No-Break">various conditions:</span></p>
			<ol>
				<li>Resource utilization is too high (for example, more than 90% CPU usage over <span class="No-Break">10 minutes)</span></li>
				<li>The given metric has exceeded the threshold (for example, there were more than 20 HTTP responses with status code <strong class="source-inline">400</strong> in the last <span class="No-Break">5 minutes)</span></li>
				<li>When security threats or anomalies are detected, such as unauthorized <span class="No-Break">access attempts</span></li>
				<li>A bespoke error log pattern is detected (for example, an error log message such as “Unable to authorize payment” has <span class="No-Break">been detected)</span></li>
			</ol>
			<p>The workflow for incident management varies in every organization. Some organizations have dedicated round-the-clock support teams that respond to incidents, while others have engineers to act as support persons on a rotational basis. Additionally, some organizations have three<a id="_idIndexMarker1026"/> levels of escalation in case a <a id="_idIndexMarker1027"/>major incident can’t be <span class="No-Break">solved immediately.</span></p>
			<p>There are no golden incident management procedures, but there are principles of incident management that should <span class="No-Break">be considered.</span></p>
			<ul>
				<li><strong class="bold">Establish and document the incident management workflow</strong>: The workflow needs to be defined and documented so that the people involved in incident management have a process <span class="No-Break">to follow.</span></li>
				<li><strong class="bold">Implement communication channels</strong>: It’s recommended to have a dedicated instant messaging channel for each incident so that you have relevant and focused collaboration among people. Emails and phone calls should be used for notification purposes because they don’t have a well-structured conversation format. Other people joining later in the investigation process will find it difficult <span class="No-Break">to follow.</span><p class="list-inset">Moreover, the instant messaging channel has built-in timestamps and participant identifications, which are useful for compiling the communication section of an <span class="No-Break">incident report.</span></p></li>
				<li><strong class="bold">Document the journey for each incident</strong>: It’s important to document each incident to capture the findings of the problem, the troubleshooting journey, the resolution of the problem, and the communication during the incident. This is useful for internal improvement, audit, and regulatory requirements. The incident report should also be standardized to allow for comparisons and <span class="No-Break">further analysis.</span></li>
				<li><strong class="bold">Conduct follow-up meetings</strong>: There are three other known names for this type of <a id="_idIndexMarker1028"/>meeting: <strong class="bold">after-action review</strong> (<strong class="bold">AAR</strong>), post-mortem, and autopsy meeting. The purpose of this meeting is to review and replay the incident, identify what was learned from this incident, and discuss preventative measures and any potential improvements (processes, communication, tooling, and <span class="No-Break">so on).</span></li>
			</ul>
			<p>The action items from <a id="_idIndexMarker1029"/>this meeting are prioritized in<a id="_idIndexMarker1030"/> the backlog of the responsible teams and are linked to the incident to motivate <span class="No-Break">the change.</span></p>
			<p>An example workflow for incident management is shown in <span class="No-Break"><em class="italic">Figure 11</em></span><span class="No-Break"><em class="italic">.3</em></span><span class="No-Break">:</span></p>
			<div>
				<div id="_idContainer099" class="IMG---Figure">
					<img src="image/B21737_11_3.jpg" alt="Figure 11.3 – An example workflow for incident management" width="1530" height="1277"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.3 – An example workflow for incident management</p>
			<p>In this <a id="_idIndexMarker1031"/>diagram, multiple<a id="_idIndexMarker1032"/> sources can report an incident<a id="_idIndexMarker1033"/> that occurred. The support person is informed by the incident management tool via email, phone, instant message, or a phone application. The support person triages the incident by finding the answers to the <span class="No-Break">following questions:</span></p>
			<ol>
				<li>Is it an actual incident or just a <span class="No-Break">false alarm?</span></li>
				<li>Which business area <span class="No-Break">is impacted?</span></li>
				<li>Who’s impacted by <span class="No-Break">this incident?</span></li>
				<li>How severely is the business <span class="No-Break">area impacted?</span></li>
				<li>Which team is responsible for the impacted <span class="No-Break">business area?</span></li>
				<li>Does it need to be <span class="No-Break">fixed immediately?</span></li>
			</ol>
			<p>If the incident turns out to be a false alarm, the incident is resolved. If it’s an actual incident but doesn’t require an immediate fix, then the incident will be picked up by the responsible team the next <span class="No-Break">working day.</span></p>
			<p>If the incident is major or substantial, then a second-level support person from the responsible team is involved to start the investigation immediately. During this stage, the investigation could escalate, depending on the progress of the investigation. Sometimes, another team needs to be involved, or a big decision needs to be made by upper management. Once the fix has been applied and verified, the incident <span class="No-Break">is resolved.</span></p>
			<p>If the system is mission-critical, it’s worth considering an enterprise incident management system that supports escalation policies, rotational support management, communication channels, automatic reporting, and backlog <span class="No-Break">ticket integration.</span></p>
			<p>Improvements in incident<a id="_idIndexMarker1034"/> management are often <a id="_idIndexMarker1035"/>made after an incident has occurred. It’s important for an organization to continuously learn and improve its incident <span class="No-Break">management process.</span></p>
			<h1 id="_idParaDest-284"><a id="_idTextAnchor378"/>Summary</h1>
			<p>In this chapter, we walked through the importance of auditing and monitoring. We emphasized the importance of measuring systems to avoid organizations going into the vicious cycle of opinion-based decision-making. A few exceptions of not needing auditing and monitoring <span class="No-Break">were mentioned.</span></p>
			<p>We also identified a few challenges when auditing and monitoring distributed systems. After highlighting the challenges we faced, we started to cover the key aspects of auditing <span class="No-Break">and monitoring.</span></p>
			<p>The data that’s captured for auditing and monitoring is different. A sample of the audit trail was demonstrated by Kotlin code so that we could cover the various types of data available <span class="No-Break">for monitoring.</span></p>
			<p>Next, the best practices for application-level logging were demonstrated through the use of sample code and a few logging frameworks. The techniques of structured logging and contextual logging <span class="No-Break">were covered.</span></p>
			<p>Afterward, we moved on to the aspect of centralizing and aggregating auditing and monitoring data. The approach of the standard envelope and discoverable topics for audit trails were presented. We also mentioned multiple approaches for collecting <span class="No-Break">monitoring data.</span></p>
			<p>Then, we identified two levels of metrics: the service level and the business level. We covered how a qualitative goal can be translated into quantitative measurable metrics and used <strong class="bold">DORA</strong> metrics as an example of a comprehensive suite of metrics to prevent the gaming <span class="No-Break">of metrics.</span></p>
			<p>Finally, we discussed the aspects of automated alerting and incident management. We presented a sample workflow of incident management to illustrate the importance of appropriate tooling, effective communication, <span class="No-Break">and documentation.</span></p>
			<p>The next chapter will cover the performance and scalability aspects of <span class="No-Break">software systems.</span></p>
		</div>
	</div></div></body></html>