<html><head></head><body><div><div><div><div><h1 class="title"><a id="ch10"/>Chapter 10. Camera and Microphone Support</h1></div></div></div><p>In this chapter, we will cover:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Saving to the camera roll</li><li class="listitem" style="list-style-type: disc">Reading from the camera roll</li><li class="listitem" style="list-style-type: disc">Capturing with the default camera app</li><li class="listitem" style="list-style-type: disc">Working with the built-in cameras</li><li class="listitem" style="list-style-type: disc">Recording microphone audio</li><li class="listitem" style="list-style-type: disc">Playing recorded audio</li></ul></div><div><div><div><div><h1 class="title"><a id="ch10lvl1sec01"/>Introduction<a id="id814" class="indexterm"/>
</h1></div></div></div><p>The camera and microphone are possibly the two most popular sensors built into iOS devices. In fact, iPhone owners rely on the microphone on a daily basis when making calls. Those who use Apple's FaceTime depend on both the microphone and the camera to keep in touch. And of course, everyone has taken a photo or shot a video from time-to-time.<a id="id815" class="indexterm"/>
</p><p>Developers are finding increasingly sophisticated uses for both sensors that extend far beyond the functionality provided by Apple's pre-installed applications. Image and voice recognition, augmented reality, language translation, and voice distortion are just a handful.</p><p>Adobe introduced camera and microphone support in AIR 2.6, allowing Flash developers to take advantage of both sensors within their apps. While you can work through all of this chapter's recipes using Flash Professional CS5.5, those with Flash Professional CS5 will be limited to the first recipe,<em> Saving to the camera roll</em>.</p></div></div>
<div><div><div><div><h1 class="title"><a id="ch10lvl1sec02"/>Saving to the camera roll</h1></div></div></div><p>Many iOS applications allow the user to save an image to the camera roll. Drawing tools and avatar creators are popular examples, where the user can easily show off their creation to friends and family from the device's native photo gallery.<a id="id817" class="indexterm"/>
</p><p>This recipe will show you how to save a snapshot of the stage to the device's camera roll.<a id="id818" class="indexterm"/>
</p><div><div><div><div><h2 class="title"><a id="ch10lvl2sec01"/>Getting ready</h2></div></div></div><p>From the book's accompanying code bundle, open<code class="literal"> chapter10\recipe1\recipe.fla</code> into Flash Professional.<a id="id819" class="indexterm"/>
</p><p>You will find two bitmaps and a movie clip sitting on the stage. The bitmaps have been composited to produce a background image, which we will save to the camera roll. The movie clip represents a button and will initiate the save when pressed.</p><p>The button movie clip has an instance name of<code class="literal"> saveBtn</code> and its library symbol is linked to a class named<code class="literal"> Button</code>. This class was introduced in the<em> Handling user interaction</em> recipe from<a class="link" href="ch04.html" title="Chapter 4. Porting Flash Projects to iOS"> Chapter 4</a>.</p><p>Okay, let us write some code.</p></div><div><div><div><div><h2 class="title"><a id="ch10lvl2sec02"/>How to do it...</h2></div></div></div><p>We will make use of AIR's<code class="literal"> CameraRoll</code> class for this recipe.<a id="id820" class="indexterm"/>
</p><div><ol class="orderedlist"><li class="listitem">Create a document class and name it<code class="literal"> Main</code>.</li><li class="listitem">Add the following import statements and a member variable of type<code class="literal"> CameraRoll:</code><div><pre class="programlisting">package {
<strong>import flash.display.BitmapData;
</strong>
import flash.display.MovieClip;
<strong>
import flash.events.Event;
import flash.events.MouseEvent;
import flash.media.CameraRoll;
</strong>
public class Main extends MovieClip {
<strong>private var cameraRoll:CameraRoll;
</strong>
public function Main() {
// constructor code
}
}
}
</pre></div></li><li class="listitem">Within the constructor, create a<code class="literal"> CameraRoll</code> object and listen for it dispatching<code class="literal"> Event.COMPLETE</code>. Also listen for<code class="literal"> MouseEvent.MOUSE_UP</code> being dispatched from the<code class="literal"> saveBtn</code> movie clip:<div><pre class="programlisting">public function Main() {
<strong>
cameraRoll = new CameraRoll();
cameraRoll.addEventListener(Event.COMPLETE, saved);
saveBtn.addEventListener(MouseEvent.MOUSE_UP, pressed);
</strong>
}
</pre></div></li><li class="listitem">When the save button is pressed, we will add a bitmap image of the stage to the camera roll. To prevent the button appearing in the captured bitmap image, we will hide it from view first. Add a<code class="literal"> pressed()</code> event handler:<a id="id821" class="indexterm"/><div><pre class="programlisting">private function pressed(e:MouseEvent):void {
saveBtn.visible = false;
var bitmapData:BitmapData = new BitmapData(
stage.stageWidth, stage.stageHeight, false);
bitmapData.draw(stage);
if(CameraRoll.supportsAddBitmapData)
{
cameraRoll.addBitmapData(bitmapData);
}
}
</pre></div></li><li class="listitem">Once the bitmap has been successfully added to the camera roll, we will make the button visible again. Write a<code class="literal"> saved()</code> event handler for this:<a id="id822" class="indexterm"/><div><pre class="programlisting">private function saved(e:Event):void {
saveBtn.visible = true;
}
</pre></div></li><li class="listitem">Save the class, and when prompted name the file<code class="literal"> Main.as</code>.</li><li class="listitem">Move back to your FLA.</li><li class="listitem">Publish the app and deploy it to your device.</li><li class="listitem">Launch the app and press the<strong> SAVE</strong> button. Go to the Photos app where you will see your image saved to the camera roll as shown in the following screenshot:<a id="id823" class="indexterm"/></li></ol></div><div><img src="img/1383_10_01.jpg" alt="How to do it..."/></div></div><div><div><div><div><h2 class="title"><a id="ch10lvl2sec03"/>How it works...</h2></div></div></div><p>The<code class="literal"> CameraRoll</code> class allows access to the device's photo library and belongs to the<code class="literal"> flash.media</code> package.<a id="id824" class="indexterm"/>
</p><p>Calling the<code class="literal"> CameraRoll.addBitmapData()</code> method will save a specified bitmap to the device. Upon a successful save,<code class="literal"> Event.COMPLETE</code> is dispatched.<a id="id825" class="indexterm"/>
</p><p>For this recipe, we created and passed a<code class="literal"> BitmapData</code> object to the<code class="literal"> addBitmapData()</code> method. The<code class="literal"> BitmapData</code> object contained a bitmap representation of the stage, which was created by calling the<code class="literal"> BitmapData.draw()</code> method and passing the<code class="literal"> stage</code> property to it.<a id="id826" class="indexterm"/>
</p><p>The static<code class="literal"> CameraRoll.supportsAddBitmapData</code> property was also used. It determines whether or not saving bitmap data to the device's camera roll is supported for your target platform. Although this property returns<code class="literal"> true</code> for all iOS devices, it is wise to check if you are writing cross-platform code.<a id="id827" class="indexterm"/>
</p></div><div><div><div><div><h2 class="title"><a id="ch10lvl2sec04"/>There's more...</h2></div></div></div><p>The following information will be of use to you when saving to the camera roll.<a id="id828" class="indexterm"/>
</p><div><div><div><div><h3 class="title"><a id="ch10lvl3sec01"/>Handling a failed save</h3></div></div></div><p>Don't assume that a bitmap will always successfully save to the camera roll. For example, the device may not have the required storage space available.<a id="id829" class="indexterm"/>
</p><p>When a bitmap cannot be added, the<code class="literal"> CameraRoll</code> object will dispatch<code class="literal"> ErrorEvent.ERROR</code>. Querying the<code class="literal"> ErrorEvent</code> object's<code class="literal"> text</code> property retrieves a message associated with the error.<a id="id830" class="indexterm"/>
</p><p>Your code should listen for this event and handle any failed attempts at adding bitmap data. Perform a search for<code class="literal"> flash.media.CameraRoll</code> within Adobe Community Help for a full list of possible errors.</p></div><div><div><div><div><h3 class="title"><a id="ch10lvl3sec02"/>Saving specific display objects</h3></div></div></div><p>Although we grabbed the entire stage for this recipe, you can create a bitmap image of any display object and add it to the camera roll. Simply create a<code class="literal"> BitmapData</code> object and call its<code class="literal"> draw()</code> method, passing your target display object as an argument. The<code class="literal"> BitmapData</code> object's dimensions should be made to match that of your display object.<a id="id831" class="indexterm"/>
</p></div><div><div><div><div><h3 class="title"><a id="ch10lvl3sec03"/>Video and the camera roll</h3></div></div></div><p>At present, the AIR SDK does not provide support for adding video content to the camera roll.<a id="id832" class="indexterm"/>
</p></div></div><div><div><div><div><h2 class="title"><a id="ch10lvl2sec05"/>See also</h2></div></div></div><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><em>Reading from the camera roll</em></li></ul></div></div></div>
<div><div><div><div><h1 class="title"><a id="ch10lvl1sec03"/>Reading from the camera roll</h1></div></div></div><p>Depending on the version of the AIR SDK you are using, it is possible to load an image from the device's camera roll. AIR for iOS facilitates this by launching the native Photos application and allowing the user to select an image. The image can then be loaded and added to your display list.<a id="id833" class="indexterm"/>
</p><p>Let us see how to write a simple app that loads an image selected from the camera roll.</p><p>The steps covered here are applicable only to those using Flash Professional CS5.5. The AIR 2.0 SDK used by Flash Professional CS5 does not feature an API for loading images from the camera roll.</p><div><div><div><div><h2 class="title"><a id="ch10lvl2sec06"/>Getting ready</h2></div></div></div><p>An FLA has been provided as a starting point for this recipe. From the book's accompanying code bundle, open<code class="literal"> chapter10\recipe2\recipe.fla</code> into Flash Professional CS5.5.</p><p>A movie clip with an instance name of<code class="literal"> browseBtn</code> can be found on the stage. The clip's library symbol is linked to a class named<code class="literal"> Button</code>, which was introduced in the<em> Handling user interaction</em> recipe from<a class="link" href="ch04.html" title="Chapter 4. Porting Flash Projects to iOS"> Chapter 4</a>.</p><div><img src="img/1383_10_02.jpg" alt="Getting ready"/></div><p>Let us write some code to let the user browse for, and load an image from the camera roll after pressing the<code class="literal"> browseBtn</code> movie clip.<a id="id834" class="indexterm"/>
</p></div><div><div><div><div><h2 class="title"><a id="ch10lvl2sec07"/>How to do it...</h2></div></div></div><p>We will make use of several classes, including<code class="literal"> CameraRoll, Loader</code>, and<code class="literal"> MediaPromise</code>.</p><div><ol class="orderedlist"><li class="listitem">Create a document class and name it<code class="literal"> Main</code>.</li><li class="listitem">Import the required classes and add two member variables—one of type<code class="literal"> CameraRoll</code> and the other of type<code class="literal"> Loader:</code><div><pre class="programlisting">package {
<strong>
import flash.display.Loader;
</strong>
import flash.display.MovieClip;
<strong>
import flash.events.Event;
import flash.events.MediaEvent;
import flash.events.MouseEvent;
import flash.media.CameraRoll;
import flash.media.MediaPromise;
</strong>
public class Main extends MovieClip {
<strong>
private var cameraRoll:CameraRoll;
private var loader:Loader;
</strong>
public function Main() {
// constructor code
}
}
}
</pre></div></li><li class="listitem">Instantiate a<code class="literal"> CameraRoll</code> object and listen for it dispatching<code class="literal"> MediaEvent.SELECT</code> and<code class="literal"> Event.CANCEL</code>. Also, listen for the<code class="literal"> browseBtn</code> movie clip being pressed:<div><pre class="programlisting">public function Main() {
<strong>
cameraRoll = new CameraRoll();
cameraRoll.addEventListener(MediaEvent.SELECT,
photoSelected);
cameraRoll.addEventListener(Event.CANCEL, cancelled);
browseBtn.addEventListener(MouseEvent.MOUSE_UP,
buttonPressed);
</strong>
}
</pre></div></li><li class="listitem">When the<code class="literal"> browseBtn</code> movie clip is pressed, we will hide it from view and also launch the native Photos application. Add the following method to handle this:<a id="id835" class="indexterm"/><div><pre class="programlisting">private function buttonPressed(e:MouseEvent):void {
browseBtn.visible = false;
if(CameraRoll.supportsBrowseForImage)
{
cameraRoll.browseForImage();
}
}
</pre></div></li><li class="listitem">We will make the<code class="literal"> browseBtn</code> movie clip visible again if the user cancels from the Photos application:<div><pre class="programlisting">private function cancelled(e:Event):void {
browseBtn.visible = true;
}
</pre></div></li><li class="listitem">If the user makes a selection, then we will create a<code class="literal"> Loader</code> object and start loading the photo. Add the<code class="literal"> photoSelected()</code> method to handle this:<a id="id836" class="indexterm"/><div><pre class="programlisting">private function photoSelected(e:MediaEvent):void {
var photoPromise:MediaPromise = e.data;
loader = new Loader();
loader.contentLoaderInfo.addEventListener(Event.COMPLETE,
photoLoaded);
loader.loadFilePromise(photoPromise);
}
</pre></div></li><li class="listitem">Finally, write the<code class="literal"> photoLoaded()</code> event handler, which will be called when the photo's image has successfully loaded. This method will re-size and orientate the image before adding it to the display list:<a id="id837" class="indexterm"/><div><pre class="programlisting">private function photoLoaded(e:Event):void {
var mc:Loader = e.currentTarget.loader as Loader;
var scale:Number;
if(mc.width &gt; mc.height)
{
scale = stage.stageHeight / mc.width;
mc.scaleX = scale;
mc.scaleY = scale;
mc.x = stage.stageWidth;
mc.rotation = 90;
addChild(mc);
}
else
{
scale = stage.stageWidth / mc.width;
mc.scaleX = scale;
mc.scaleY = scale;
addChild(mc);
}
}
</pre></div></li><li class="listitem">Save the class and name the file<code class="literal"> Main.as</code> when prompted.</li><li class="listitem">Also, move back to your FLA and save it too.</li><li class="listitem">Publish the FLA and deploy the resultant<code class="literal"> .ipa</code> file to your device.</li><li class="listitem">Launch the app, tap the<strong> BROWSE</strong> button, and then select an image from the camera roll. Your app will load and display the image.</li></ol></div></div><div><div><div><div><h2 class="title"><a id="ch10lvl2sec08"/>How it works...</h2></div></div></div><p>The<code class="literal"> flash.media.CameraRoll</code> class allows access to the device's photo library.<a id="id838" class="indexterm"/>
</p><p>Its<code class="literal"> browseForImage()</code> method opens the native Photos application, allowing the user to select an image from the device's camera roll. At this point, your application will lose focus and will wait in the background.<a id="id839" class="indexterm"/>
</p><p>When a selection is made by the user, your application will regain focus and the<code class="literal"> CameraRoll</code> object will dispatch<code class="literal"> MediaEvent.SELECT</code>. If however, the user cancels out of the Photos app, then<code class="literal"> Event.CANCEL</code> is dispatched instead.<a id="id840" class="indexterm"/>
</p><p>In this recipe, the<code class="literal"> browseForImage()</code> method is called in response to the user pressing the<strong> BROWSE</strong> button. However, just before the call is made, the static<code class="literal"> CameraRoll.supportsBrowseForImage</code> property is checked. This determines whether or not browsing for an image is supported by your target platform. Although the property returns<code class="literal"> true</code> for all iOS devices, it is useful when targeting multiple platforms.<a id="id841" class="indexterm"/>
</p><p>Once the user has selected an image, the<code class="literal"> photoSelected()</code> event handler is called and a<code class="literal"> MediaEvent</code> object is passed to it. From the<code class="literal"> MediaEvent</code> object, we retrieve information regarding the selected image by querying its<code class="literal"> data</code> property. This returns a<code class="literal"> MediaPromise</code> object, which we pass to a<code class="literal"> Loader</code> object's<code class="literal"> loadFilePromise()</code> method to actually load the image. Once complete, the<code class="literal"> Loader</code> object will dispatch<code class="literal"> Event.COMPLETE</code>.<a id="id842" class="indexterm"/>
</p><p>The<code class="literal"> photoLoaded()</code> handler captures the<code class="literal"> Loader</code> object's<code class="literal"> COMPLETE</code> event and displays the actual image on screen. Images saved to the camera roll can be of a much higher resolution than the stage's dimensions and can be either portrait or landscape orientation. The<code class="literal"> photoLoaded()</code> method scales the image to fit the stage and if it has a landscape aspect ratio, rotates it by 90 degrees.<a id="id843" class="indexterm"/>
</p><div><h3 class="title"><a id="tip21"/>Tip</h3><p>The<code class="literal"> MediaPromise</code> class also provides a<code class="literal"> file</code> property, which can be used to obtain a URL to the selected camera roll image. While this property will be valid for certain platforms, such as Android, it will always return<code class="literal"> null</code> on iOS. When writing cross-platform code, use<code class="literal"> Loader.loadFilePromise()</code> rather than attempting to obtain and pass a URL to<code class="literal"> Loader.load()</code>.</p></div><p>You can obtain more information regarding<code class="literal"> flash.media.CameraRoll</code> and<code class="literal"> flash.media.MediaPromise</code> from Adobe Community Help.<a id="id844" class="indexterm"/>
</p></div><div><div><div><div><h2 class="title"><a id="ch10lvl2sec09"/>There's more...</h2></div></div></div><p>When saving photos to a device, iOS embeds additional metadata with the image. Depending on the application you are writing, the following information may be useful.</p><div><div><div><div><h3 class="title"><a id="ch10lvl3sec04"/>Parsing Exif data</h3></div></div></div><p>Photos taken on iOS devices adhere to the<strong> Exchangeable image file (Exif)</strong>  format and can contain thumbnail data and tags of additional information. These tags can describe anything ranging from the GPS coordinates associated with the image to its orientation.<a id="id845" class="indexterm"/>
</p><p>Although the AIR SDK does not directly provide support for these tags, there are some third-party parsers available. Take a look at<a class="ulink" href="http://code.shichiseki.jp/as3/ExifInfo"> http://code.shichiseki.jp/as3/ExifInfo</a> and<a class="ulink" href="http://www.mxml.it/index.php/2010/01/04/reading-exif-data-with-actionscript-30"> www.mxml.it/index.php/2010/01/04/reading-exif-data-with-actionscript-30</a>. Additionally, the Exif specification can be found at<a class="ulink" href="http://www.exif.org/exif2-2.pdf"> www.exif.org/exif2-2.pdf</a>.</p></div></div><div><div><div><div><h2 class="title"><a id="ch10lvl2sec10"/>See also</h2></div></div></div><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><em>Saving to the camera roll</em></li></ul></div></div></div>
<div><div><div><div><h1 class="title"><a id="ch10lvl1sec04"/>Capturing with the default camera app</h1></div></div></div><p>Most iOS devices have a built-in camera. More recent models have two—one mounted on the rear and another on the front. Users can capture photos and shoot video using the camera app that comes pre-installed. Third-party applications can also utilize the camera with many applications simply launching the default camera app for this purpose. Once the user has finished with the camera, the third-party app is able to access the photo or video that was taken.<a id="id846" class="indexterm"/>
</p><p>AIR 2.6 and above provides the<code class="literal"> CameraUI</code> class, making it possible to launch and use the default camera app. This recipe will show you how to do this from Flash Professional CS5.5. AIR 2.0 and Flash CS5 do not provide camera support.<a id="id847" class="indexterm"/>
</p><div><div><div><div><h2 class="title"><a id="ch10lvl2sec11"/>Getting ready</h2></div></div></div><p>You will need a device that features a camera. The fourth-generation iPod touch, iPad 2, and all models of iPhone have cameras.<a id="id848" class="indexterm"/>
</p><p>From the book's accompanying code bundle, open<code class="literal"> chapter10\recipe3\recipe.fla</code> into Flash Professional CS5.5.</p><p>You will find a movie clip named<code class="literal"> captureBtn</code> and a dynamic text field named<code class="literal"> output</code> positioned on the stage. The button clip's library symbol is linked to a class named<code class="literal"> Button</code>, which was introduced in the<em> Handling user interaction</em> recipe from<a class="link" href="ch04.html" title="Chapter 4. Porting Flash Projects to iOS"> Chapter 4</a>.</p><p>We will create a simple app that launches the default camera app when the button is pressed, allowing the user to capture a photo.<a id="id849" class="indexterm"/>
</p></div><div><div><div><div><h2 class="title"><a id="ch10lvl2sec12"/>How to do it...</h2></div></div></div><p>Let us write the ActionScript required to do this.<a id="id850" class="indexterm"/>
</p><div><ol class="orderedlist"><li class="listitem">Create a document class and name it<code class="literal"> Main</code>.</li><li class="listitem">Import the various classes required for this recipe and create a member variable of type<code class="literal"> CameraUI:</code><div><pre class="programlisting">package {
import flash.display.MovieClip;
<strong>
import flash.events.Event;
import flash.events.MediaEvent;
import flash.events.MouseEvent;
import flash.media.CameraUI;
import flash.media.MediaPromise;
import flash.media.MediaType;
</strong>
public class Main extends MovieClip {
private var camera:CameraUI;
public function Main() {
// constructor code
}
}
}
</pre></div></li><li class="listitem">Within the constructor, instantiate a<code class="literal"> CameraUI</code> object and listen for it dispatching<code class="literal"> MediaEvent.COMPLETE</code> and<code class="literal"> Event.CANCEL</code>. Also, listen for the user pressing the<code class="literal"> captureBtn</code> movie clip:<div><pre class="programlisting">public function Main() {
<strong>
camera = new CameraUI();
camera.addEventListener(MediaEvent.COMPLETE, captured);
camera.addEventListener(Event.CANCEL, cancelled);
captureBtn.addEventListener(MouseEvent.MOUSE_UP, pressed);
}
</strong>
</pre></div></li><li class="listitem">When the button is pressed, we will launch the camera app allowing the user to take a photo. Add a<code class="literal"> pressed()</code> event handler for this:<a id="id851" class="indexterm"/><div><pre class="programlisting">private function pressed(e:MouseEvent):void {
if(CameraUI.isSupported)
{
camera.launch(MediaType.IMAGE);
}
}
</pre></div></li><li class="listitem">When the user returns from the camera app, we will check that the photo was successfully obtained and write confirmation to the<code class="literal"> output</code> text field. Handle this by adding a<code class="literal"> captured()</code> method to your class:<a id="id852" class="indexterm"/><div><pre class="programlisting">private function captured(e:MediaEvent):void {
var mediaPromise:MediaPromise = e.data;
if(mediaPromise != null)
{
output.text = "Photo captured.";
}
}
</pre></div></li><li class="listitem">The user can cancel from the default camera app, discarding any photo that they may have taken. Add an event handler for this, stating within the<code class="literal"> output</code> text field that the operation was cancelled:<div><pre class="programlisting">private function cancelled(e:Event):void {
output.text = "Cancelled.";
}
</pre></div></li><li class="listitem">Save the class and name the file<code class="literal"> Main.as</code> when prompted.</li><li class="listitem">Move back to your FLA and save it too.</li><li class="listitem">Publish the app and launch it once you have deployed the IPA to your device.</li><li class="listitem">Tap the<strong> CAPTURE</strong> button to launch the default camera app. Take a photo and press the<strong> Use</strong> button. A message will be displayed confirming that the photo was successfully captured and is now accessible by your app.</li></ol></div></div><div><div><div><div><h2 class="title"><a id="ch10lvl2sec13"/>How it works...</h2></div></div></div><p>The<code class="literal"> flash.media.CameraUI</code> class allows access to the default camera app. Calling its<code class="literal"> launch()</code> method will open the camera app and allow the user to capture either an image or video. At this point, your application will lose focus and will wait in the background. Once the user has finished, your application will regain focus and the<code class="literal"> CameraUI</code> object will dispatch<code class="literal"> MediaEvent.COMPLETE</code>. If the user cancels out of the camera app, then<code class="literal"> Event.CANCEL</code> will be dispatched instead.<a id="id853" class="indexterm"/>
</p><p>When calling<code class="literal"> launch()</code>, you must pass a constant defined by<code class="literal"> flash.media.MediaType</code>, specifying whether you wish to take a photo or shoot video. For this recipe, we passed<code class="literal"> MediaType.IMAGE</code>.</p><p>The captured media is accessed using the<code class="literal"> data</code> property of the<code class="literal"> COMPLETE</code> event's<code class="literal"> MediaEvent</code> object. This property is an instance of the<code class="literal"> MediaPromise</code> class and can be used to load the image or even access its data.<a id="id854" class="indexterm"/>
</p><p>Notice the use of the static<code class="literal"> isSupported</code> property within the<code class="literal"> pressed()</code> event handler. It determines whether or not access to the default camera app is supported by the device that is currently running your app.<a id="id855" class="indexterm"/>
</p><p>You can obtain more information regarding<code class="literal"> flash.media.CameraUI</code> and<code class="literal"> flash.media.MediaPromise</code> from Adobe Community Help.</p></div><div><div><div><div><h2 class="title"><a id="ch10lvl2sec14"/>There's more...</h2></div></div></div><p>The following information will help complete your understanding.</p><div><div><div><div><h3 class="title"><a id="ch10lvl3sec05"/>Handling errors</h3></div></div></div><p>A<code class="literal"> CameraUI</code> object will dispatch an error if the default camera app is already in use. You can capture this event by listening for<code class="literal"> flash.events.ErrorEvent.ERROR</code>. Query the<code class="literal"> ErrorEvent</code> object's<code class="literal"> errorID</code> and<code class="literal"> text</code> properties to discover more about the error.<a id="id856" class="indexterm"/>
</p></div><div><div><div><div><h3 class="title"><a id="ch10lvl3sec06"/>Displaying the captured image</h3></div></div></div><p>We didn't go so far as to actually load and display the photo that was taken with the default camera app. This can be achieved by creating a<code class="literal"> Loader</code> object and passing the photo's<code class="literal"> MediaPromise</code> object to the loader's<code class="literal"> loadFilePromise()</code> method. Refer to the previous recipe,<em> Reading from the camera roll</em>, for more detail.<a id="id857" class="indexterm"/>
</p></div><div><div><div><div><h3 class="title"><a id="ch10lvl3sec07"/>Saving the captured image to the camera roll</h3></div></div></div><p>Unlike some other mobile operating systems, the captured photo isn't actually stored by iOS in the camera roll. If you want the photo to appear in the camera roll, you will need to manually add it yourself. This is done by using a<code class="literal"> Loader</code> object to load your<code class="literal"> MediaPromise</code> object's binary data, then writing its bitmap data to the camera roll using a<code class="literal"> CameraRoll</code> instance.<a id="id858" class="indexterm"/>
</p><p>Refer to the<em> Reading from the camera roll</em> and the<em> Saving to the camera roll</em> recipes from earlier in this chapter.<a id="id859" class="indexterm"/>
</p></div><div><div><div><div><h3 class="title"><a id="ch10lvl3sec08"/>Capturing video</h3></div></div></div><p>While we captured a photo using the default camera app, a simple code change is all that is required to shoot video instead. You can see this in the following code snippet where<code class="literal"> MediaType.VIDEO</code> is passed to the<code class="literal"> CameraUI</code> object's<code class="literal"> launch()</code> method:<a id="id860" class="indexterm"/>
</p><div><pre class="programlisting">camera.launch(MediaType.VIDEO);
</pre></div><p>It is not possible for the user to change between photo and camera mode while using the default camera app launched from AIR. You can only use the camera app for capturing a single media type at any one time.</p><p>Take a look at the<em> Playing local H.264 video</em> recipe from<a class="link" href="ch12.html" title="Chapter 12. Working with Video and Audio"> Chapter 12</a> to see how to playback your captured video.</p></div><div><div><div><div><h3 class="title"><a id="ch10lvl3sec09"/>Reading the captured data</h3></div></div></div><p>It is also possible to directly access the binary data that represents the image or video captured from the camera. This is useful for applications that perhaps need to write the media directly to the device's file system, upload the data to a server, or to simply parse or alter the data in some way. The<code class="literal"> MediaPromise</code> object provides an<code class="literal"> open()</code> method that can be used to access the data. You can then read it into a<code class="literal"> ByteArray</code> object.<a id="id861" class="indexterm"/>
</p><p>To do this within this recipe's example, add the following member variables:</p><div><pre class="programlisting">private var dataSource:IDataInput;
private var eventSource:IEventDispatcher;
</pre></div><p>Add the following code snippet at the end of the<code class="literal"> captured()</code> event handler:</p><div><pre class="programlisting">dataSource = mediaPromise.open();
eventSource = dataSource as IEventDispatcher;
eventSource.addEventListener(Event.COMPLETE, dataCaptured);
</pre></div><p>Now write an event handler to copy the data into a<code class="literal"> ByteArray</code> object:</p><div><pre class="programlisting">private function dataCaptured(e:Event):void {
var mediaBytes:ByteArray = new ByteArray();
dataSource.readBytes(mediaBytes);
}
</pre></div><p>Also include the following import statements:</p><div><pre class="programlisting">import flash.events.IEventDispatcher;
import flash.utils.ByteArray;
import flash.utils.IDataInput;
</pre></div><p>You will now have access to the media's binary data within the<code class="literal"> dataCaptured()</code> method.<a id="id862" class="indexterm"/>
</p></div></div><div><div><div><div><h2 class="title"><a id="ch10lvl2sec15"/>See also</h2></div></div></div><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><em>Saving to the camera roll</em></li><li class="listitem" style="list-style-type: disc"><em>Reading from the camera roll</em></li><li class="listitem" style="list-style-type: disc"><em>Working with the built-in cameras</em></li></ul></div></div></div>
<div><div><div><div><h1 class="title"><a id="ch10lvl1sec05"/>Working with the built-in cameras</h1></div></div></div><p>While launching and using the default camera app provides the user with the native camera experience that they are familiar with, it may not be appropriate for all types of applications. In addition to<code class="literal"> CameraUI</code>, AIR also provides the<code class="literal"> Camera</code> class, which receives the video data captured by the device's on-board camera, allowing it to be directly displayed within your app.<a id="id863" class="indexterm"/>
</p><p>In this recipe, you will learn how to receive a video stream from the camera and display it within your app using Flash Professional CS5.5. The<code class="literal"> Camera</code> class is not supported by Flash CS5 and AIR 2.0 for iOS.</p><div><div><div><div><h2 class="title"><a id="ch10lvl2sec16"/>Getting ready</h2></div></div></div><p>You will need a device that features a camera. The fourth generation iPod touch, iPad 2, and all models of iPhone have cameras.<a id="id864" class="indexterm"/>
</p><p>From the book's accompanying code bundle, open<code class="literal"> chapter10\recipe4\recipe.fla</code> into Flash Professional CS5.5.</p><p>A landscape aspect ratio has been set for the stage and this has also been reflected within the FLA's AIR for iOS settings.</p></div><div><div><div><div><h2 class="title"><a id="ch10lvl2sec17"/>How to do it...</h2></div></div></div><p>Follow these steps to receive video from the camera and display it on the stage:<a id="id865" class="indexterm"/>
</p><div><ol class="orderedlist"><li class="listitem">Create a document class and name it<code class="literal"> Main</code>.</li><li class="listitem">Declare two member variables—one of type<code class="literal"> Camera</code> and the other of type<code class="literal"> Video:</code><div><pre class="programlisting">package {
import flash.display.MovieClip;
<strong>
import flash.media.Camera;
import flash.media.Video;
</strong>
public class Main extends MovieClip {
<strong>private var camera:Camera;
</strong>
<strong>private var video:Video;
</strong>
public function Main() {
// constructor code
}
}
}
</pre></div></li><li class="listitem">Within the constructor, obtain a reference to the device's default camera and attach it to a<code class="literal"> Video</code> object. Also, add the<code class="literal"> Video</code> object to the stage allowing the video data to be viewed by the user:<a id="id866" class="indexterm"/><div><pre class="programlisting">public function Main() {
<strong>
if(Camera.names.length &gt; 0)
{
camera = Camera.getCamera();
camera.setMode(stage.stageWidth, stage.stageHeight,
stage.frameRate);
video = new Video(camera.width, camera.height);
video.attachCamera(camera);
addChild(video);
}
</strong>
}
</pre></div></li><li class="listitem">Save the class as<code class="literal"> Main.as</code>. Also move back to your FLA and save it too.</li><li class="listitem">Publish the FLA and test it on your device.</li><li class="listitem">Hold the device in landscape orientation. Video from the rear-facing camera will be rendered to the screen.</li></ol></div></div><div><div><div><div><h2 class="title"><a id="ch10lvl2sec18"/>How it works...</h2></div></div></div><p>The<code class="literal"> flash.media.Camera</code> class is a singleton, meaning only one instance of it can exist. To guarantee this, the class has no public constructor. Instead, access to the camera is obtained by calling the<code class="literal"> Camera</code> class'<code class="literal"> getCamera()</code> static method, which returns the<code class="literal"> Camera</code> instance for you to work with.<a id="id867" class="indexterm"/>
</p><p>Once the<code class="literal"> Camera</code> instance is obtained, the capture mode to be used by the camera can be specified. This is done by calling<code class="literal"> setMode()</code> and passing to it a width, height, and target frame rate. For this recipe, we passed the stage's dimensions and frame rate. If the specified requirements cannot be met by the camera, then it will use a mode which is the closest match.</p><p>In order to display the live video being streamed from the camera, it must be attached to a<code class="literal"> Video</code> object. The<code class="literal"> flash.media.Video</code> class inherits<code class="literal"> DisplayObject</code> allowing any<code class="literal"> Video</code> object to be added to the display list. First the<code class="literal"> Video</code> object is created and a width and height for it are passed to its constructor—we set its dimensions to match those used by the camera. Then a call to<code class="literal"> attachCamera()</code> is made, providing the<code class="literal"> Video</code> object with access to the<code class="literal"> Camera</code> object's video stream. Finally, the<code class="literal"> Video</code> object is added to the display list by calling<code class="literal"> addChild()</code>.<a id="id868" class="indexterm"/>
</p><p>Before attempting to connect to a camera, you should first check that one is available. The<code class="literal"> Camera.names</code> static property returns an array of available cameras. We checked at the beginning of the document class' constructor that the array's length was greater than<code class="literal"> 0</code> before proceeding. Alternatively, check for<code class="literal"> null</code> being returned by<code class="literal"> Camera.getCamera()</code>.</p><p>For more information regarding camera support, perform a search for<code class="literal"> flash.media.Camera</code> and<code class="literal"> flash.media.Video</code> within Adobe Community Help.</p></div><div><div><div><div><h2 class="title"><a id="ch10lvl2sec19"/>There's more...</h2></div></div></div><p>Let us look at some additional options when capturing live video from the camera.</p><div><div><div><div><h3 class="title"><a id="ch10lvl3sec10"/>Portrait mode</h3></div></div></div><p>On iOS, a<code class="literal"> Camera</code> object captures video in landscape orientation. If your application uses a portrait aspect ratio, then you will need to swap the camera's capture dimensions and also rotate and re-position the<code class="literal"> Video</code> object. To do this, make the following changes to this recipe's constructor:<a id="id869" class="indexterm"/>
</p><div><pre class="programlisting">camera = Camera.getCamera();
<strong>
camera.setMode(stage.stageHeight, stage.stageWidth,
stage.frameRate);
</strong>
video = new Video(camera.width, camera.height);
video.attachCamera(camera);
<strong>video.rotation = 90;
video.x += stage.stageWidth;
</strong>
</pre></div><p>Remember to change the stage's dimensions and update the AIR for iOS settings to use a portrait aspect ratio. There is a performance hit when capturing portrait video due to the rotation applied to the<code class="literal"> Video</code> object. Where possible, try to use landscape for applications that use the camera.<a id="id870" class="indexterm"/>
</p></div><div><div><div><div><h3 class="title"><a id="ch10lvl3sec11"/>Selecting a camera</h3></div></div></div><p>The<code class="literal"> Camera.getCamera()</code> static method connects to the rear-facing camera by default. For devices that support more than one, you can specify a camera by passing a string representing the zero-based index position within the array specified by<code class="literal"> Camera.names</code>. For example, the following code uses the iPhone 4/4S's front-facing camera:<a id="id871" class="indexterm"/>
</p><div><pre class="programlisting">camera = Camera.getCamera("1");
</pre></div><p>It is important that you pass a string rather than an integer when making this call.</p><p>Only one camera can be active at any one time on iOS. If you connect to a second camera, then the previous camera's connection will be dropped.</p></div><div><div><div><div><h3 class="title"><a id="ch10lvl3sec12"/>Grabbing a bitmap image</h3></div></div></div><p>It is possible to capture a bitmap image from the camera's live video stream. The following code extracts the bitmap data from the video's current frame and stores it within a<code class="literal"> Bitmap</code> object:<a id="id872" class="indexterm"/>
</p><div><pre class="programlisting">var bd:BitmapData = new BitmapData(video.width, video.height,
false);
bd.draw(video);
var b:Bitmap = new Bitmap(bd);
</pre></div><p>As you can see, the<code class="literal"> BitmapData</code> object's dimensions are made to match those of the video. The current frame is then drawn into the<code class="literal"> BitmapData</code> object, which is used to create the actual bitmap.</p></div><div><div><div><div><h3 class="title"><a id="ch10lvl3sec13"/>Live streaming</h3></div></div></div><p>For this recipe, we simply used the camera's video stream locally on the device. However, by using the<code class="literal"> NetConnection</code> and<code class="literal"> NetStream</code> classes, it is possible to transmit the video stream to a Flash Media Server, where it can be broadcast to other clients. This is ideal for live video chat applications or other collaborative projects.<a id="id873" class="indexterm"/>
</p><p>Both classes belong to the<code class="literal"> flash.net</code> package. More detail is available from Adobe Community Help.</p></div><div><div><div><div><h3 class="title"><a id="ch10lvl3sec14"/>Using the stage</h3></div></div></div><p>It is also possible to place and size a<code class="literal"> Video</code> object on the stage using the Flash IDE rather than ActionScript. Simply right-click on the<strong> Library</strong> panel and select<strong> New Video</strong> from the context menu. From the<strong> Video Properties</strong> panel that appears, click on the<strong> Video (ActionScript-controlled)</strong> radio button before clicking on<strong> OK</strong>. A video clip will appear in the library, which you can drag to the stage and assign an instance name to.<a id="id874" class="indexterm"/>
</p></div></div><div><div><div><div><h2 class="title"><a id="ch10lvl2sec20"/>See also</h2></div></div></div><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><em>Saving to the camera roll</em></li><li class="listitem" style="list-style-type: disc"><em>Capturing with the default camera app</em></li></ul></div></div></div>
<div><div><div><div><h1 class="title"><a id="ch10lvl1sec06"/>Recording microphone audio</h1></div></div></div><p>AIR provides an API that enables an application to connect to the built-in microphone. The microphone's raw data can be obtained, recorded for later use, processed as it is received, or routed to the device's speakers.<a id="id875" class="indexterm"/>
</p><p>This recipe will show you how to use the<code class="literal"> Microphone</code> and<code class="literal"> ByteArray</code> classes to capture and record audio. You will need Flash Professional CS5.5 as microphone access for iOS is not supported by CS5 and AIR 2.0.</p><div><div><div><div><h2 class="title"><a id="ch10lvl2sec21"/>Getting ready</h2></div></div></div><p>While all recent models from the iOS family contain a built-in microphone, previous generations of the iPod touch don't. The second and third-generation devices do, however, provide support for an external microphone, which can be used for this recipe.<a id="id876" class="indexterm"/>
</p><p>From the book's accompanying code bundle, open<code class="literal"> chapter10\recipe5\recipe.fla</code> into Flash Professional CS5.5.</p><p>Sitting on the stage you will find a dynamic text field with an instance name of<code class="literal"> output</code> and three movie clips. Two of the movie clips represent buttons and are named<code class="literal"> recordBtn</code> and<code class="literal"> stopBtn</code> respectively. The<code class="literal"> stopBtn</code> clip is positioned directly behind the<code class="literal"> recordBtn</code> clip but sits on its own timeline layer for easy access. The third movie clip is named<code class="literal"> micStatus</code> and covers the entire background. It is used to indicate when recording is taking place.<a id="id877" class="indexterm"/>
</p><p>The library symbols for<code class="literal"> recordBtn</code> and<code class="literal"> stopBtn</code> are linked to a base class named<code class="literal"> Button</code>. This class was introduced in the<em> Handling user interaction</em> recipe from<a class="link" href="ch04.html" title="Chapter 4. Porting Flash Projects to iOS"> Chapter 4</a>.</p><p>We will add ActionScript to start recording data from the microphone when the user taps the<code class="literal"> recordBtn</code> movie clip. Audio capture will end when<code class="literal"> stopBtn</code> is pressed. To give feedback to the user that recording is taking place, we will move the<code class="literal"> micStatus</code> movie clip's<code class="literal"> playhead</code> to frame<code class="literal"> 2</code>. The text field will be used to output confirmation that audio was successfully recorded.<a id="id878" class="indexterm"/>
</p><p>This recipe will concentrate on the recording of microphone audio. We will cover playback of the audio in the next recipe.</p></div><div><div><div><div><h2 class="title"><a id="ch10lvl2sec22"/>How to do it...</h2></div></div></div><p>Now let us write the ActionScript for this. Follow these steps:<a id="id879" class="indexterm"/>
</p><div><ol class="orderedlist"><li class="listitem">Create a document class and name it<code class="literal"> Main</code>.</li><li class="listitem">Import the various classes required for this recipe and create two member variables—one to reference the device's microphone and another to store data captured from it:<div><pre class="programlisting">package {
import flash.display.MovieClip;
<strong>
import flash.events.MouseEvent;
import flash.events.SampleDataEvent;
import flash.media.Microphone;
import flash.utils.ByteArray;
</strong>
public class Main extends MovieClip {
<strong>private var mic:Microphone;
private var soundData:ByteArray;
</strong>
public function Main() {
// constructor code
}
}
}
</pre></div></li><li class="listitem">Within the constructor, set up the movie clips and create a connection to the device's microphone:<div><pre class="programlisting">public function Main() {
<strong>
micStatus.gotoAndStop(1);
recordBtn.visible = true;
stopBtn.visible = false;
recordBtn.addEventListener(MouseEvent.MOUSE_UP,
pressedRecordBtn);
stopBtn.addEventListener(MouseEvent.MOUSE_UP,
pressedStopBtn);
mic = Microphone.getMicrophone();
if(!Microphone.isSupported || mic == null)
{
recordBtn.visible = false;
}
</strong>
}
</pre></div></li><li class="listitem">Add a handler for each button being pressed:<div><pre class="programlisting">private function pressedRecordBtn(e:MouseEvent):void {
startRecording();
}
microphone audiorecordingprivate function pressedStopBtn(e:MouseEvent):void {
stopRecording();
}
</pre></div></li><li class="listitem">Next add a method that sets up the microphone and starts listening for live audio data. We will also instantiate a<code class="literal"> ByteArray</code> object named<code class="literal"> soundData</code>, which will be used to store the captured data:<div><pre class="programlisting">private function startRecording():void {
micStatus.gotoAndStop(2);
recordBtn.visible = false;
stopBtn.visible = true;
soundData = new ByteArray();
mic.gain = 100;
mic.rate = 44;
mic.addEventListener(SampleDataEvent.SAMPLE_DATA,
sampleData);
}
</pre></div></li><li class="listitem">Add an event handler that gets called every time audio data is available from the microphone. We will write a maximum of 2 MB of this audio data to our<code class="literal"> ByteArray</code> object for later use:<div><pre class="programlisting">private function sampleData(e:SampleDataEvent):void {
while(e.data.bytesAvailable)
{
var sample:Number = e.data.readFloat();
soundData.writeFloat(sample);
}
if(soundData.length &gt; 2097152)
{
stopRecording();
}
}
</pre></div></li><li class="listitem">Finally add a method that stops listening for live audio data from the microphone. The total number of bytes recorded will be written to the<code class="literal"> output</code> text field:<div><pre class="programlisting">private function stopRecording():void {
micStatus.gotoAndStop(1);
stopBtn.visible = false;
mic.removeEventListener(SampleDataEvent.SAMPLE_DATA,
sampleData);
output.text = (soundData.length + " bytes recorded");
}
</pre></div></li><li class="listitem">Save the class and name its file<code class="literal"> Main.as</code>.</li><li class="listitem">Move back to your FLA and save it.</li><li class="listitem">Publish the FLA and deploy the resultant<code class="literal"> .ipa</code> file to your device.<a id="id881" class="indexterm"/></li><li class="listitem">Launch the app, tap the<strong> RECORD</strong> button and start speaking into the microphone. When you are finished, tap the<strong> STOP</strong> button.</li></ol></div><p>The amount of audio data (in bytes) that was recorded will be written to the screen.</p></div><div><div><div><div><h2 class="title"><a id="ch10lvl2sec23"/>How it works...</h2></div></div></div><p>Microphone support is provided by the<code class="literal"> flash.media.Microphone</code> class. To connect to the device's microphone, make a call to the static<code class="literal"> Microphone.getMicrophone()</code> method, which will return a new<code class="literal"> Microphone</code> instance. If a microphone can't be found, then<code class="literal"> null</code> will be returned instead.<a id="id882" class="indexterm"/>
</p><p>The following code snippet is the call being made from within our document class' constructor:</p><div><pre class="programlisting">mic = Microphone.getMicrophone();
</pre></div><p>Once you have a<code class="literal"> Microphone</code> object, you can adjust the audio data that will be received. We did this within the<code class="literal"> startRecording()</code> method by setting the<code class="literal"> Microphone</code> object's gain and sample rate.<a id="id883" class="indexterm"/>
</p><p>The gain is used to boost the microphone's signal and is set using the<code class="literal"> gain</code> property. A value of<code class="literal"> 100</code> was used to maximize its loudness.</p><p>The sample rate dictates the quality of the audio that is captured and is specified by the<code class="literal"> rate</code> property. Higher sample rates produce clearer audio but demand more from the CPU and require increased space to store. We set the<code class="literal"> rate</code> property to<code class="literal"> 44</code>, specifying an actual sample frequency of 44 kHz. In other words, we will capture sound from the microphone 44,100 times per second! This is the highest permitted sample rate and records the clearest sound.</p><p>To actually start capturing audio from the microphone, add a<code class="literal"> SampleDataEvent.SAMPLE_DATA</code> listener to the<code class="literal"> Microphone</code> object. The<code class="literal"> SAMPLE_DATA</code> event is continually dispatched as the microphone's audio buffer fills. We added the<code class="literal"> SAMPLE_DATA</code> event listener within the<code class="literal"> startRecording()</code> method immediately after setting the gain and sample rate:<a id="id884" class="indexterm"/>
</p><div><pre class="programlisting">mic.gain = 100;
mic.rate = 44;
mic.addEventListener(SampleDataEvent.SAMPLE_DATA, sampleData);
</pre></div><p>Each<code class="literal"> SampleDataEvent</code> object has a<code class="literal"> data</code> property, which is a<code class="literal"> ByteArray</code> containing the current audio sampled from the microphone. Recording the audio is a simple case of copying this temporary data into a more permanent<code class="literal"> ByteArray</code> object. You can see the code for this within the<code class="literal"> SampleData()</code> event handler, where a loop is used to extract the sampled data and write it to the<code class="literal"> soundData</code> member variable:</p><div><pre class="programlisting">while(e.data.bytesAvailable)
{
var sample:Number = e.data.readFloat();
soundData.writeFloat(sample);
}
</pre></div><p>Each sample is represented by a floating point value. The loop, therefore, reads a float from the audio buffer and writes it to the<code class="literal"> soundData</code> member variable. This process continues until the data stored within the<code class="literal"> SampleDataEvent</code> object is empty.</p><p>To prevent the app from completely exhausting the device's memory, the<code class="literal"> sampleData()</code> handler checks the size of the<code class="literal"> soundData</code> member variable. If it exceeds 2 MB (2,097,152 bytes) in size, then recording is stopped and the number of recorded bytes is written to the<code class="literal"> output</code> text field.<a id="id885" class="indexterm"/>
</p><p>Audio capture is stopped by removing the<code class="literal"> SAMPLE_DATA</code> event listener from the<code class="literal"> Microphone</code> object. Take a look at the<code class="literal"> stopRecording()</code> method to see this.<a id="id886" class="indexterm"/>
</p><p>For more information regarding audio capture, perform a search for<code class="literal"> flash.media.Microphone, flash.events.SampleDataEvent</code>, and<code class="literal"> flash.utils.ByteArray</code> within Adobe Community Help.</p></div><div><div><div><div><h2 class="title"><a id="ch10lvl2sec24"/>There's more...</h2></div></div></div><p>Following are some additional options open to you when recording from the microphone.</p><div><div><div><div><h3 class="title"><a id="ch10lvl3sec15"/>Microphone activity</h3></div></div></div><p>You can determine the amount of sound that the microphone is detecting by querying the<code class="literal"> Microphone</code> object's<code class="literal"> activityLevel</code> property. This will return a value ranging from<code class="literal"> 0</code> to<code class="literal"> 100</code>, with<code class="literal"> 0</code> being returned when no sound is detected.<a id="id887" class="indexterm"/>
</p><p>It is also possible using the<code class="literal"> setSilenceLevel()</code> method to specify an activity level threshold that must be met before audio is accepted by the microphone. The higher the activity level that is passed as a parameter, the louder an audio source must be before it is detected. This method also accepts an optional second parameter, which specifies the number of milliseconds of inactivity that must pass before sound is considered to have stopped.<a id="id888" class="indexterm"/>
</p><p>As an example, add the following to your<code class="literal"> startRecording()</code> method:<a id="id889" class="indexterm"/>
</p><div><pre class="programlisting">mic.setSilenceLevel(50, 2000);
mic.addEventListener(ActivityEvent.ACTIVITY, activityChanged);
</pre></div><p>Now add the following event handler:</p><div><pre class="programlisting">private function activityChanged(e:ActivityEvent):void {
output.text = "activating: " + e.activating + ", " +
"activity level: " + mic.activityLevel;
if(e.activating == false)
{
stopRecording();
}
}
</pre></div><p>Finally, add the following import statement:</p><div><pre class="programlisting">import flash.events.ActivityEvent;
</pre></div><p>Test these changes on your device. Your app won't dispatch<code class="literal"> SAMPLE_DATA</code> events until the microphone's silence level is exceeded. Also, once activated, the microphone will deactivate again if silence occurs for more than two seconds.</p></div><div><div><div><div><h3 class="title"><a id="ch10lvl3sec16"/>Live streaming</h3></div></div></div><p>The microphone's audio data was simply used locally in this recipe. However, it is possible, using the<code class="literal"> NetConnection</code> and<code class="literal"> NetStream</code> classes, to transmit the data to a Flash Media Server for broadcast to other clients. Additional detail can be found on Adobe Community Help by searching for both classes, which belong to the<code class="literal"> flash.net</code> package.<a id="id890" class="indexterm"/>
</p></div></div><div><div><div><div><h2 class="title"><a id="ch10lvl2sec25"/>See also</h2></div></div></div><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><em>Playing recorded audio</em></li></ul></div></div></div>
<div><div><div><div><h1 class="title"><a id="ch10lvl1sec07"/>Playing recorded audio</h1></div></div></div><p>After capturing the microphone's raw audio data, you will need a means of playing it back. This recipe will show you how to send the data to your device's speaker.<a id="id891" class="indexterm"/>
</p><div><div><div><div><h2 class="title"><a id="ch10lvl2sec26"/>Getting ready</h2></div></div></div><p>If you have completed the<em> Recording microphone audio</em> recipe, then you can work from the code you wrote for it. Alternatively, from the book's accompanying code bundle, open<code class="literal"> chapter10\recipe6\recipe.fla</code> and use it as a starting point.</p><p>Currently the FLA will record audio from the microphone and store it within a member variable of type<code class="literal"> ByteArray</code> named<code class="literal"> soundData</code>. We will add code that plays back the audio once the user has finished recording it.</p></div><div><div><div><div><h2 class="title"><a id="ch10lvl2sec27"/>How to do it...</h2></div></div></div><p>The following changes are required to read and playback the recorded audio:<a id="id892" class="indexterm"/>
</p><div><ol class="orderedlist"><li class="listitem">Open<code class="literal"> Main.as</code>.</li><li class="listitem">Import the following three classes:<div><pre class="programlisting">import flash.display.MovieClip;
<strong>import flash.events.Event;
</strong>
import flash.events.MouseEvent;
import flash.events.SampleDataEvent;
import flash.media.Microphone;
<strong>import flash.media.Sound;
import flash.media.SoundChannel;
</strong>
import flash.utils.ByteArray;
</pre></div></li><li class="listitem">Also add a<code class="literal"> Sound</code> and<code class="literal"> SoundChannel</code> member variable:<div><pre class="programlisting">private var mic:Microphone;
private var soundData:ByteArray;
<strong>private var sound:Sound;
private var channel:SoundChannel;
</strong>
</pre></div></li><li class="listitem">The<code class="literal"> stopRecording()</code> method will need to make an additional call to initiate playback of the recorded audio. Add the following line at the end of the method:<a id="id893" class="indexterm"/><div><pre class="programlisting">private function stopRecording():void {
micStatus.gotoAndStop(1);
stopBtn.visible = false;
mic.removeEventListener(SampleDataEvent.SAMPLE_DATA,
sampleData);
<strong>playRecording();
</strong>
}
</pre></div></li><li class="listitem">Now write the<code class="literal"> playRecording()</code> method, which will initiate playback of the audio:<a id="id894" class="indexterm"/><div><pre class="programlisting">private function playRecording():void {
soundData.position = 0;
sound = new Sound();
sound.addEventListener(SampleDataEvent.SAMPLE_DATA,
playSampleData);
channel = sound.play();
channel.addEventListener(Event.SOUND_COMPLETE,
playbackComplete);
</pre></div></li><li class="listitem">Add a method that periodically pulls data from the<code class="literal"> soundData</code> object for playback:<div><pre class="programlisting">private function playSampleData(e:SampleDataEvent):void {
for(var i:int=0; i&lt;8192 &amp;&amp; soundData.bytesAvailable&gt;0; i++)
{
var sample:Number = soundData.readFloat();
e.data.writeFloat(sample);
e.data.writeFloat(sample);
}
}
</pre></div></li><li class="listitem">Finally, reset the button movie clips once audio playback is complete:<div><pre class="programlisting">private function playbackComplete(e:Event):void {
recordBtn.visible = true;
stopBtn.visible = false;
}
</pre></div></li><li class="listitem">Save your changes to the class.</li><li class="listitem">Publish the FLA and test it on your device.</li><li class="listitem">Start recording some audio and when you are finished, tap the<strong> STOP</strong> button.</li></ol></div><p>The recorded audio will be played back through your device's speaker. If you don't hear anything then increase your speaker's volume and try again.</p></div><div><div><div><div><h2 class="title"><a id="ch10lvl2sec28"/>How it works...</h2></div></div></div><p>Both the<code class="literal"> Sound</code> and<code class="literal"> SoundChannel</code> classes are used for audio playback.<a id="id896" class="indexterm"/>
</p><p>We create a<code class="literal"> Sound</code> object and add a<code class="literal"> SAMPLE_DATA</code> event listener to it. This event is dispatched when there is no more audio data for the<code class="literal"> Sound</code> object to play:</p><div><pre class="programlisting">sound = new Sound();
sound.addEventListener(SampleDataEvent.SAMPLE_DATA,
playSampleData);
</pre></div><p>A call is also made to the object's<code class="literal"> play()</code> method, which returns a<code class="literal"> SoundChannel</code> instance allowing playback to be monitored. We listen for the<code class="literal"> SoundChannel</code> object dispatching<code class="literal"> SOUND_COMPLETE</code> to determine when audio playback has ended:<a id="id897" class="indexterm"/>
</p><div><pre class="programlisting">channel = sound.play();
channel.addEventListener(Event.SOUND_COMPLETE,
playbackComplete);
</pre></div><p>Initially the<code class="literal"> Sound</code> object doesn't contain any audio data. The data from the entire recording is instead held by the<code class="literal"> soundData</code> member variable, which is a<code class="literal"> ByteArray</code>. As the<code class="literal"> Sound</code> object has no audio data to play, it immediately dispatches a<code class="literal"> SAMPLE_DATA</code> event, which is captured by the<code class="literal"> playSampleData()</code> handler.<a id="id898" class="indexterm"/>
</p><p>Within<code class="literal"> playSampleData()</code>, we extract some audio data from the<code class="literal"> soundData</code> member variable and feed it to the<code class="literal"> Sound</code> object. This provides the<code class="literal"> Sound</code> object with enough data to start playing audio. Each time its buffer runs low, it will dispatch another<code class="literal"> SAMPLE_DATA</code> event and we will feed it more data. This process continues until the entire recording has been played.</p><p>The following is the code from the<code class="literal"> playSampleData()</code> handler that is responsible for writing data to the<code class="literal"> Sound</code> object's buffer:</p><div><pre class="programlisting">for(var i:int=0; i&lt;8192 &amp;&amp; soundData.bytesAvailable&gt;0; i++)
{
var sample:Number = soundData.readFloat();
e.data.writeFloat(sample);
e.data.writeFloat(sample);
}
</pre></div><p>The<code class="literal"> Sound</code> object's buffer is accessed through the<code class="literal"> SampleDataEvent</code> parameter's<code class="literal"> data</code> property. We, therefore, take a sample from the<code class="literal"> soundData</code> member variable and write it to the<code class="literal"> data</code> property's<code class="literal"> ByteArray</code>. The<code class="literal"> readFloat()</code> method is used to read a sample from<code class="literal"> soundData</code>, while<code class="literal"> writeFloat()</code> is used to write the same sample into the<code class="literal"> Sound</code> object's buffer—each sample is represented by a floating point value.<a id="id899" class="indexterm"/>
</p><p>However, we don't just write a single sample to the buffer—it would instantly empty again. Instead, we take the opportunity to write 8192 stereo samples, providing the object with 64 KB of audio data. Typically you can write between 2048 and 8192 stereo samples at a time. However, a runtime exception will be thrown if you attempt to write more than 64 KB of data to the buffer.</p><p>To create a stereo sample, we write each recorded sample to the<code class="literal"> Sound</code> object twice:</p><div><pre class="programlisting">e.data.writeFloat(sample);
e.data.writeFloat(sample);
</pre></div><p>While the microphone records monophonic data, your device is capable of stereo output. Therefore, when writing audio data to a<code class="literal"> Sound</code> object, you need to write the sample to both the left and right channels. The first call to<code class="literal"> writeFloat()</code> sends the sample to the left channel, while the second call sends it to the right.<a id="id900" class="indexterm"/>
</p><p>For more information, perform a search for<code class="literal"> flash.media.Sound</code> and<code class="literal"> flash.media.SoundChannel</code> within Adobe Community Help.</p></div><div><div><div><div><h2 class="title"><a id="ch10lvl2sec29"/>There's more...</h2></div></div></div><p>There are a few final pieces of information related to microphone audio playback.</p><div><div><div><div><h3 class="title"><a id="ch10lvl3sec17"/>Working with lower sample rates</h3></div></div></div><p>The<code class="literal"> Sound</code> class uses a sample rate of 44 kHz. If audio from the microphone was captured at an alternative frequency, then you will need to upscale it from the lower rate to 44 kHz before feeding it to the<code class="literal"> Sound</code> object.<a id="id901" class="indexterm"/>
</p><p>For example, if the<code class="literal"> Microphone</code> object's<code class="literal"> rate</code> property was set to a frequency of 22 kHz when recording, you would need to adjust the playback loop within<code class="literal"> playSampleData()</code> to the following:</p><div><pre class="programlisting">for(var i:int=0; i&lt;4096 &amp;&amp; soundData.bytesAvailable&gt;0; i++)
{
var sample:Number = soundData.readFloat();
e.data.writeFloat(sample);
e.data.writeFloat(sample);
e.data.writeFloat(sample);
e.data.writeFloat(sample);
}
</pre></div><p>Essentially the same sample is written to each channel twice, which up-scales the 22 kHz recording to 44 kHz. Notice that 4096 iterations of the loop are performed compared to 8192 previously. This is to ensure that no more than 64 KB of audio data is written to the<code class="literal"> Sound</code> object's buffer, which is its upper limit.</p><p>The example provided here is somewhat simplistic and not recommended for the majority of the sample rates. A more thorough approach is to generate the missing data by interpolating between existing samples. In most cases, it is likely that you will want to avoid re-sampling your audio in realtime as doing so can be computationally expensive.</p><p>Additional detail regarding sample rate conversion can be found on Wikipedia:<a class="ulink" href="http://en.wikipedia.org/wiki/Sample_rate_conversion"> http://en.wikipedia.org/wiki/Sample_rate_conversion</a>. Also, take a look at the SoundTouch AS3 library, which allows real time audio processing using ActionScript 3.0:<a class="ulink" href="http://https://github.com/also/soundtouch-as3"> https://github.com/also/soundtouch-as3</a>.<a id="id902" class="indexterm"/>
</p></div><div><div><div><div><h3 class="title"><a id="ch10lvl3sec18"/>Saving captured data</h3></div></div></div><p>This and the previous recipe have simply held the recorded audio data in memory. Your application, however, may require recordings to be persistent. Using the classes provided in the<code class="literal"> flash.filesystem</code> package, you can write binary data to your device and read it back later.<a id="id903" class="indexterm"/>
</p><p>The following code snippet saves our recorded audio to the device:</p><div><pre class="programlisting">var stream:FileStream = new FileStream();
var file:File = File.documentsDirectory.resolvePath("audio.dat");
stream.open(file, FileMode.WRITE);
stream.writeBytes(soundData);
stream.close();
</pre></div><p>Retrieving the data is just as easy:</p><div><pre class="programlisting">soundData = new ByteArray();
var stream:FileStream = new FileStream();
var file:File = File.documentsDirectory.resolvePath("audio.dat");
stream.open(file, FileMode.READ);
stream.readBytes(soundData);
</pre></div><p>Data written to the file system can only be accessed by the app that placed it there. When the app is uninstalled, any data belonging to it is deleted.</p></div><div><div><div><div><h3 class="title"><a id="ch10lvl3sec19"/>Exporting as WAV or MP3</h3></div></div></div><p>For this and the previous recipe, we have simply worked with the raw PCM data captured from the microphone. However, you may want to save your data in common audio formats such as MP3 and WAV. Unfortunately, AIR does not provide APIs for exporting in either of these formats. Instead, you will need to rely on third-party libraries.<a id="id904" class="indexterm"/>
</p><p>WAV encoding is provided by the<code class="literal"> WAVWriter</code> class, which is available at:<a class="ulink" href="http://code.google.com/p/ghostcat/source/browse/trunk/ghostcatfp10/src/ghostcat/media/WAVWriter.as?spec=svn424&amp;r=424"> http://code.google.com/p/ghostcat/source/browse/trunk/ghostcatfp10/src/ghostcat/media/WAVWriter.as?spec=svn424&amp;r=424</a>.</p><p>MP3 encoding can be achieved using the Shine library:<a class="ulink" href="http://https://github.com/kikko/Shine-MP3-Encoder-on-AS3-Alchemy"> https://github.com/kikko/Shine-MP3-Encoder-on-AS3-Alchemy</a>.</p></div></div><div><div><div><div><h2 class="title"><a id="ch10lvl2sec30"/>See also</h2></div></div></div><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><em>Recording microphone audio</em></li><li class="listitem" style="list-style-type: disc"><em>Controlling audio playback, <a class="link" href="ch12.html" title="Chapter 12. Working with Video and Audio">Chapter 12</a></em></li><li class="listitem" style="list-style-type: disc"><em>Referencing an app's common directories, <a class="link" href="ch13.html" title="Chapter 13. Connectivity, Persistence, and URI Schemes">Chapter 13</a></em><a id="id905" class="indexterm"/></li><li class="listitem" style="list-style-type: disc"><em>Writing files, <a class="link" href="ch13.html" title="Chapter 13. Connectivity, Persistence, and URI Schemes">Chapter 13</a></em></li></ul></div></div></div></body></html>