- en: '*Chapter 6*: Threads and Coroutines'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapter, we had a glance at how our application can efficiently
    serve thousands of requests per second—to discuss why immutability is important,
    we introduced a race condition problem using two threads.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we'll dive deeper into how to launch new threads in Kotlin
    and the reasons why coroutines can scale much better than threads. We will discuss
    how the Kotlin compiler treats coroutines and the relationship between coroutine
    scopes and dispatchers. We'll discuss the concept of **structured concurrency**,
    and how it helps us prevent resource leaks in our programs.
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ll cover the following topics in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Looking deeper into threads
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introducing coroutines and suspend functions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Starting coroutines
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jobs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Coroutines under the hood
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dispatchers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Structured concurrency
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: After reading this chapter, you'll be familiar with Kotlin's concurrency primitives
    and how to best utilize them.
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In addition to the requirements from the previous chapters, you will also need
    a **Gradle**-enabled **Kotlin** project to be able to add the required dependencies.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can find the source code for this chapter here: [https://github.com/PacktPublishing/Kotlin-Design-Patterns-and-Best-Practices/tree/main/Chapter06](https://github.com/PacktPublishing/Kotlin-Design-Patterns-and-Best-Practices/tree/main/Chapter06).'
  prefs: []
  type: TYPE_NORMAL
- en: Looking deeper into threads
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before we dive into the nuances, let's discuss what kinds of problems threads
    can solve.
  prefs: []
  type: TYPE_NORMAL
- en: In your laptop, you have a CPU with multiple cores – probably four of them,
    or even eight. This means that it can do four different computations *in parallel*,
    which is pretty amazing considering that 15 years ago, a single-core CPU was the
    default and even two cores were only for enthusiasts.
  prefs: []
  type: TYPE_NORMAL
- en: '*But even back then, you were not limited to doing only a single task at a
    time, right?* You could listen to music and browse the internet at the same time,
    even on a single-core CPU. *How does your CPU manage to pull that off?* Well,
    the same way your brain does. It juggles tasks. When you''re reading a book while
    listening to your friend talking, part of the time, you''re not reading, and part
    of the time, you''re not listening – that is, until we get at least two cores
    in our brains.'
  prefs: []
  type: TYPE_NORMAL
- en: The servers you run your code on have pretty much the same CPU. This means that
    they can serve four requests simultaneously. *But what if you have 10,000 requests
    per second?* You can't serve them in parallel because you don't have 10,000 CPU
    cores. But you can try and serve them concurrently.
  prefs: []
  type: TYPE_NORMAL
- en: The most basic concurrency model provided by JVM is known as a **thread**. Threads
    allow us to run code concurrently (but not necessarily in parallel) so that we
    can make better use of multiple CPU cores, for example. They are more lightweight
    than processes. One process may spawn hundreds of threads. Unlike processes, sharing
    data between threads is easy. But that also introduces a lot of problems, as we'll
    see later.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s learn how to create two threads in Java first. Each thread will output
    numbers between `0` and `100`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'The output will look something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Note that the output will vary between executions and that at no point is it
    guaranteed to be interleaved.
  prefs: []
  type: TYPE_NORMAL
- en: 'The same code in Kotlin would look as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'In Kotlin, there''s less boilerplate because there''s a function that helps
    us create a new thread. Notice that, unlike Java, we don''t need to call `start()`
    to launch the thread. It starts by default. If we would like to postpone it for
    later, we can set the `start` parameter to `false`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: Another useful concept from Java is **daemon threads**. These threads don't
    prevent JVM from exiting and are very good for non-critical background tasks.
  prefs: []
  type: TYPE_NORMAL
- en: 'In Java, the API is not fluent, so we''ll have to assign our thread to a variable,
    set it to be a daemon thread, and then start it. In Kotlin, this is much simpler:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: Notice that although we asked this thread to print numbers up to one million,
    it prints only a few hundred. That's because it's a daemon thread. When the parent
    thread stops, all the daemon threads stop as well.
  prefs: []
  type: TYPE_NORMAL
- en: Thread safety
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There are entire books written about **thread safety** and there are good reasons
    for this. Concurrency bugs that are caused by a lack of thread safety are the
    hardest ones to track. They're hard to reproduce because you'll usually need a
    lot of threads competing for the same resource in order for an actual race to
    happen. Because this book is about Kotlin and not thread safety in general, we'll
    only scratch the surface of this topic. If you're interested in the topic of thread
    safety in the JVM language, you should check out the book *Java Concurrency in
    Practice*, by Brian Goetz.
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ll start with the following example, which creates 100,000 threads to increment
    a `counter`. To make sure that all the threads complete their work before we check
    the value, we''ll use `CountDownLatch`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: The reason this code doesn't print the correct number is that we introduced
    a data race since the `++` operation is not atomic. So, if more threads try to
    increment our counter, then there are more chances for data races.
  prefs: []
  type: TYPE_NORMAL
- en: 'Unlike Java, there''s no `synchronized` keyword in Kotlin. The reason for this
    is that Kotlin designers believe that a language shouldn''t be tailored to a particular
    concurrency model. Instead, there''s a `synchronized()` function we can use:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: Now, our code prints `100,000`, as expected.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you miss the synchronized methods from Java, there''s the `@Synchronized`
    annotation in Kotlin. Java''s `volatile` keyword is also replaced by the `@Volatile`
    annotation instead. The following table shows us an example of this comparison:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Table 6.1 – Comparison between Java and Kotlin (synchronized and volatile
    methods)'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Table_01.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Table 6.1 – Comparison between Java and Kotlin (synchronized and volatile methods)
  prefs: []
  type: TYPE_NORMAL
- en: The reason `Synchronized` and `Volatile` are annotations and not keywords is
    because Kotlin can be compiled on other platforms in addition to JVM. But the
    concepts of `synchronized` methods or `volatile` variables exist for JVM specifically.
  prefs: []
  type: TYPE_NORMAL
- en: Why are threads expensive?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There is a price to pay whenever we create a new thread. Each thread needs a
    new memory stack.
  prefs: []
  type: TYPE_NORMAL
- en: '*What if we simulate some work inside each thread by putting it to sleep?*'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following piece of code, we''ll attempt to create 10,000 threads, each
    sleeping for a relatively short period:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: Each thread requires one megabyte of RAM for its stack. Creating so many threads
    will require lots of communication with your operating system and a lot of memory.
    We attempt to identify whether we ran out of memory by catching the relevant exception.
  prefs: []
  type: TYPE_NORMAL
- en: Depending on your operating system, this will result in either `OutOfMemoryError`
    or the entire system becoming very slow.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, there are ways to limit how many threads are run at once using the
    **Executors API**. This API was introduced back in **Java 5**, so it should be
    pretty well-known to you.
  prefs: []
  type: TYPE_NORMAL
- en: 'Using that API, we can create a new thread pool of a specified size. Try setting
    the `pool` size to `1`, the number of cores on your machine to `100` and `2000`,
    and see what happens:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we would like to submit a new task. We can do this by calling `pool.submit()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE77]'
  prefs: []
  type: TYPE_PRE
- en: By incrementing `counter` once before `sleep` and once after, we are simulating
    some business logic – for example, preparing some JSON and then parsing the response
    – while `sleep` itself simulates a network operation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, we need to make sure that the pool terminates and give it `20` seconds
    to do so by using the following lines:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE79]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE80]'
  prefs: []
  type: TYPE_PRE
- en: Notice that it took us 20 seconds to complete. That's because a new task cannot
    begin until the previous tasks *wake up* and finish their jobs.
  prefs: []
  type: TYPE_NORMAL
- en: And that's exactly what happens in a multithreaded system that is not concurrent
    enough.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we'll discuss how coroutines try to solve this problem.
  prefs: []
  type: TYPE_NORMAL
- en: Introducing coroutines
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In addition to the threading model provided by Java, Kotlin also has a **coroutines**
    model. Coroutines might be considered lightweight threads, and we'll see what
    advantages they provide over an existing model of threads shortly.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first thing you need to know is that coroutines are not part of the language.
    They are simply another library provided by JetBrains. For that reason, if we
    want to use them, we need to specify this in our Gradle configuration file; that
    is, `build.gradle.kts`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE82]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE83]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE84]'
  prefs: []
  type: TYPE_PRE
- en: 'Important Note:'
  prefs: []
  type: TYPE_NORMAL
- en: By the time you read this book, the latest version of the Coroutines library
    will be **1.6** or greater.
  prefs: []
  type: TYPE_NORMAL
- en: First, we will compare starting a new thread and a new coroutine.
  prefs: []
  type: TYPE_NORMAL
- en: Starting coroutines
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We've already seen how to start a new thread in Kotlin in the *Looking deeper
    into threads* section. Now, let's start a new coroutine instead.
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ll create almost the same example we did with threads. Each coroutine will
    increment some counter, sleep for a while to emulate some kind of I/O, and then
    increment it again:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE85]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE86]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE87]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE88]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE89]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE90]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE91]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE92]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE93]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE94]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE95]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE96]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE97]'
  prefs: []
  type: TYPE_PRE
- en: The first way of starting a new coroutine is by using the `launch()` function.
    Again, note that this is simply another function and not a language construct.
  prefs: []
  type: TYPE_NORMAL
- en: Another interesting point here is the call to the `delay()` function, which
    we use to simulate some I/O-bound work, such as fetching something from a database
    or over the network.
  prefs: []
  type: TYPE_NORMAL
- en: Like the `Thread.sleep()` method, it puts the current coroutine to sleep. But
    unlike `Thread.sleep()`, other coroutines can work while it sleeps soundly. This
    is because `delay()` is marked with a `suspend` keyword, which we'll discuss in
    the *Jobs* section.
  prefs: []
  type: TYPE_NORMAL
- en: If you run this code, you'll see that the task takes about 200 ms with coroutines,
    while with threads, it either takes 20 seconds or runs out of memory. And we didn't
    have to change our code that much. That's all thanks to the fact that coroutines
    are highly concurrent. They can be suspended without blocking the thread that
    runs them. Not blocking a thread is great because we can use fewer OS threads
    (which are expensive) to do more work.
  prefs: []
  type: TYPE_NORMAL
- en: If you run this code in your IntelliJ IDEA, you'll notice that `GlobalScope`
    is marked as a `GlobalScope` shouldn't be used in real-world projects unless the
    developer understands how it works under the hood. Otherwise, it may cause unintended
    leaks. We'll learn about better ways of launching coroutines later in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Although we've seen that coroutines are much more concurrent than threads, there's
    nothing magical in them. Now, let's learn about another way of starting a coroutine,
    as well as some issues coroutines may still suffer from.
  prefs: []
  type: TYPE_NORMAL
- en: The `launch()` function that we just discussed starts a coroutine that doesn't
    return anything. In contrast, the `async()` function starts a coroutine that returns
    some value.
  prefs: []
  type: TYPE_NORMAL
- en: Calling `launch()` is much like calling a function that returns `Unit`. But
    most of our functions return some kind of result. For that purpose, we have the
    `async()` function. It also launches a coroutine, but instead of returning a job,
    it returns `Deferred<T>`, where `T` is the type that you expect to get later.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, the following function will start a coroutine that generates a
    UUID asynchronously and returns it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE98]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE99]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE100]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE101]'
  prefs: []
  type: TYPE_PRE
- en: 'If we run the following code from our `main` method, though, it won''t print
    the expected result. The result that this code prints instead of some UUID value
    is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE102]'
  prefs: []
  type: TYPE_PRE
- en: The returned object from a coroutine is called a job. Let's understand what
    this is and how to use it correctly.
  prefs: []
  type: TYPE_NORMAL
- en: Jobs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The result of running an asynchronous task is called a `Thread` object represents
    an actual OS thread, the `job` object represents an actual coroutine.
  prefs: []
  type: TYPE_NORMAL
- en: 'This means that what we tried to do is this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE103]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE104]'
  prefs: []
  type: TYPE_PRE
- en: '`job` has a simple life cycle. It can be in one of the following states:'
  prefs: []
  type: TYPE_NORMAL
- en: '**New**: Created but not started yet.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`launch()` function, for example. This is the default state.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Completed**: Everything went well.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Canceled**: Something went wrong.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Two more states are relevant to jobs that have child jobs:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Completing**: Waiting to finish executing children before completing'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Canceling**: Waiting to finish executing children before canceling'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you want to learn more about parent and child jobs, jump to the *Parent jobs*
    section of this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: The job we've confused with its value is in the Active state, meaning that it
    hasn't finished computing our UUID yet.
  prefs: []
  type: TYPE_NORMAL
- en: 'A job that has a value is known as being `Deffered`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE105]'
  prefs: []
  type: TYPE_PRE
- en: We'll discuss the `Deferred` value in more detail in [*Chapter 8*](B17816_08_ePub.xhtml#_idTextAnchor198),
    *Designing for Concurrency*.
  prefs: []
  type: TYPE_NORMAL
- en: 'To wait for a job to complete and get the actual value, we can use the `await()`
    function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE106]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE107]'
  prefs: []
  type: TYPE_PRE
- en: 'This code doesn''t compile, though:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE108]'
  prefs: []
  type: TYPE_PRE
- en: The reason for this is that, as stated in the error itself, our `main()` function
    is not marked with a `suspend` keyword and isn't a coroutine either.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can fix this by wrapping our code in a `runBlocking` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE109]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE110]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE111]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE112]'
  prefs: []
  type: TYPE_PRE
- en: This function will block our main thread until all the coroutines finish. It
    is an implementation of the Bridge design pattern from [*Chapter 4*](B17816_04_ePub.xhtml#_idTextAnchor115),
    *Getting Familiar with Behavioral Patterns*, which allows us to connect between
    regular code and code that uses coroutines.
  prefs: []
  type: TYPE_NORMAL
- en: Running this code now will produce the expected output of some random UUID.
  prefs: []
  type: TYPE_NORMAL
- en: 'Important Note:'
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, while discussing coroutines, we will sometimes omit `runBlocking`
    for conciseness. You can always find the full working examples in this book's
    GitHub repository.
  prefs: []
  type: TYPE_NORMAL
- en: The `job` object also has some other useful methods, which we'll discuss in
    the following sections.
  prefs: []
  type: TYPE_NORMAL
- en: Coroutines under the hood
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'So, we''ve mentioned the following facts a couple of times:'
  prefs: []
  type: TYPE_NORMAL
- en: Coroutines are like lightweight threads. They need fewer resources than regular
    threads, so you can create more of them.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Instead of blocking an entire thread, coroutines suspend themselves, allowing
    the thread to execute another piece of code in the meantime.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*But how do coroutines work?*'
  prefs: []
  type: TYPE_NORMAL
- en: 'As an example, let''s take a look at a function that composes a user profile:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE113]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE114]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE115]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE116]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE117]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE118]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE119]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE120]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE121]'
  prefs: []
  type: TYPE_PRE
- en: Here, our function takes around 1.6 seconds to complete. Its execution is completely
    sequential, and the executing thread will be blocked for the entire time.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can redesign this function so that it works with coroutines, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE122]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE123]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE124]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE125]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE126]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE127]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE128]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE129]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE130]'
  prefs: []
  type: TYPE_PRE
- en: Without the `suspend` keyword, our asynchronous code simply won't compile. We'll
    cover what the `suspend` keyword means later in this section.
  prefs: []
  type: TYPE_NORMAL
- en: 'To understand what each of the asynchronous functions looks like, let''s take
    a look at one of them as an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE131]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE132]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE133]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE134]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE135]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let''s compare the performance of the two functions: one that is written
    in a blocking manner, and another that uses coroutines.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can wrap both functions using a `runBlocking` function, as we''ve seen previously,
    and measure the time it takes them to complete using `measureTimeMillis`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE136]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE137]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE138]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE139]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE140]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE141]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE142]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE143]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE144]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE145]'
  prefs: []
  type: TYPE_PRE
- en: 'The output will be something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE146]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE147]'
  prefs: []
  type: TYPE_PRE
- en: The execution time of the concurrent coroutines is the maximum of the longest
    coroutine, while with sequential code, it's the sum of all functions.
  prefs: []
  type: TYPE_NORMAL
- en: Having understood the first two examples, let's look at another way to write
    the same code.
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ll mark each of the functions with the `suspend` keyword:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE148]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE149]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE150]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE151]'
  prefs: []
  type: TYPE_PRE
- en: If you run this example, the performance will be the same as the blocking code.
    *So, why would we want to use suspendable functions?*
  prefs: []
  type: TYPE_NORMAL
- en: Suspendable functions don't block the thread. Looking at the bigger picture,
    by using the same number of threads, we can serve far more users, all thanks to
    the smart way Kotlin rewrites suspendable functions.
  prefs: []
  type: TYPE_NORMAL
- en: 'When the Kotlin compiler sees the `suspend` keyword, it knows it can split
    and rewrite the function, like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE152]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE153]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE154]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE155]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE156]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE157]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE158]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE159]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE160]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE161]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE162]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE163]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE164]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE165]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE166]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE167]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE168]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE169]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE170]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE171]'
  prefs: []
  type: TYPE_PRE
- en: This rewritten code uses the **State design pattern** from [*Chapter 4*](B17816_04_ePub.xhtml#_idTextAnchor115),
    *Getting Familiar with Behavioral Patterns*, to split the execution of the function
    into many steps. By doing so, we can release the thread that executes coroutines
    at every stage of the state machine.
  prefs: []
  type: TYPE_NORMAL
- en: 'Important Note:'
  prefs: []
  type: TYPE_NORMAL
- en: This is not a perfect depiction of the generated code. The goal is to demonstrate
    the idea behind what the Kotlin compiler does, but some subtle implementation
    details are omitted for brevity.
  prefs: []
  type: TYPE_NORMAL
- en: Note that unlike the asynchronous code we produced earlier, the state machine
    itself is sequential and takes the same amount of time as the blocking code to
    execute all its steps.
  prefs: []
  type: TYPE_NORMAL
- en: It is a fact that none of these steps block any threads, which is important
    in this example.
  prefs: []
  type: TYPE_NORMAL
- en: Canceling a coroutine
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: If you are a Java developer, you may know that stopping a thread is quite complicated.
  prefs: []
  type: TYPE_NORMAL
- en: For example, the `Thread.stop()` method is deprecated. There's `Thread.interrupt()`,
    but not all threads are checking this flag, not to mention setting a `volatile`
    flag, which is often suggested but is very cumbersome.
  prefs: []
  type: TYPE_NORMAL
- en: If you're using a thread pool, you'll get `Future`, which has the `cancel(boolean
    mayInterruptIfRunning)` method. In Kotlin, the `launch()` function returns a job.
  prefs: []
  type: TYPE_NORMAL
- en: This job can be canceled. The same rules from the previous example apply, though.
    If your coroutine never calls another `suspend` function or the `yield` function,
    it will disregard `cancel()`.
  prefs: []
  type: TYPE_NORMAL
- en: 'To demonstrate that, we''ll create one coroutine that yields once in a while:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE172]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE173]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE174]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE175]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE176]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE177]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE178]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE179]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE180]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE181]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE182]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, after each `print` statement, the coroutine calls the `yield`
    function. If it was canceled, it will print the stack trace.
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ll also create another coroutine that doesn''t yield:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE183]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE184]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE185]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE186]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE187]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE188]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE189]'
  prefs: []
  type: TYPE_PRE
- en: This coroutine never yields and prints its results every `100` iterations to
    avoid spamming the console.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s try cancelling both coroutines:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE190]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE191]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE192]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE193]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we''ll wait for the results:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE194]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE195]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE196]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE197]'
  prefs: []
  type: TYPE_PRE
- en: By invoking `join()`, we can wait for the execution of the coroutine to complete.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s look at the output of our code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE198]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE199]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE200]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE201]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE202]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE203]'
  prefs: []
  type: TYPE_PRE
- en: 'A few interesting points we can learn from this experiment regarding the behavior
    of coroutines are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Canceling the `cancellable` coroutine doesn't happen immediately. It may still
    print a line or two before being canceled.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We can catch `CancellationException`, but our coroutine will be marked as canceled
    anyway. Catching that exception doesn't automatically allow us to continue.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now, let's understand what happened. The coroutine checks whether it was canceled,
    but only when it is switching between states. Since the non-cancellable coroutine
    didn't have any suspending functions, it never checked if it was asked to stop.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the `cancellable` coroutine, we used a new function: `yield()`. We could
    have called `yield()` on every loop iteration, but decided to do that every 100th
    one. This function checks whether there is anybody else that wants to do some
    work. If there''s nobody else, the execution of the current coroutine will resume.
    Otherwise, another coroutine will start or resume from the point where it stopped
    earlier.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that without the `suspend` keyword on our function or a coroutine generator,
    such as `launch()`, we can''t call `yield()`. This is true for any function marked
    with `suspend`: it should either be called from another `suspend` function or
    from a coroutine.'
  prefs: []
  type: TYPE_NORMAL
- en: Setting timeouts
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let's consider the following situation. *What if, as happens in some cases,
    fetching the user's profile takes too long? What if we decided that if the profile
    takes more than 0.5 seconds to return, we'll just show no profile?*
  prefs: []
  type: TYPE_NORMAL
- en: 'This can be achieved using the `withTimeout()` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE204]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE205]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE206]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE207]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE208]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE209]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE210]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE211]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE212]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE213]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE214]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE215]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE216]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE217]'
  prefs: []
  type: TYPE_PRE
- en: We set the timeout to be `500` milliseconds, and our coroutine will delay for
    between `0` and `1000` milliseconds, giving it a 50 percent chance of failing.
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ll `await` the results from the coroutine and see what happens:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE218]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE219]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE220]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE221]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE222]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE223]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE224]'
  prefs: []
  type: TYPE_PRE
- en: Here, we benefit from the fact that `try` is an expression in Kotlin. So, we
    can return a result immediately from it.
  prefs: []
  type: TYPE_NORMAL
- en: If the coroutine manages to return before the timeout, the value of `result`
    becomes `profile`. Otherwise, we receive `TimeoutCancellationException` and set
    the value of `result` to `no profile`.
  prefs: []
  type: TYPE_NORMAL
- en: A combination of timeouts and `try`-`catch` expressions is a really powerful
    tool that allows us to create robust interactions.
  prefs: []
  type: TYPE_NORMAL
- en: Dispatchers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When we ran our coroutines using the `runBlocking` function, their code was
    executed on the main thread.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can check this by running the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE225]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE226]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE227]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE228]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE229]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE230]'
  prefs: []
  type: TYPE_PRE
- en: 'In contrast, when we run a coroutine using `GlobalScope`, it runs on something
    called `DefaultDispatcher`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE231]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE232]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE233]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE234]'
  prefs: []
  type: TYPE_PRE
- en: 'This prints the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE235]'
  prefs: []
  type: TYPE_PRE
- en: '`DefaultDispatcher` is a thread pool that is used for short-lived coroutines.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Coroutine generators, such as `launch()` and `async()`, rely on default arguments,
    one of which is the dispatcher they will be launched on. To specify an alternative
    dispatcher, you can provide it as an argument to the coroutine builder:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE236]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE237]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE238]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE239]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE240]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding code prints the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE241]'
  prefs: []
  type: TYPE_PRE
- en: 'In addition to the `Main` and `Default` dispatchers, which we''ve already discussed,
    there is also an `IO` dispatcher, which is used for long-running tasks. You can
    use it similarly for other dispatchers by providing it to the coroutine builder,
    like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE242]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE243]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE244]'
  prefs: []
  type: TYPE_PRE
- en: Structured concurrency
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: It is a very common practice to spawn coroutines from inside another coroutine.
  prefs: []
  type: TYPE_NORMAL
- en: The first rule of structured concurrency is that the parent coroutine should
    always wait for all its children to complete. This prevents resource leaks, which
    is very common in languages that don't have the **structured concurrency** concept.
  prefs: []
  type: TYPE_NORMAL
- en: 'This means that if we look at the following code, which starts 10 child coroutines,
    the parent coroutine doesn''t need to wait explicitly for all of them to complete:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE245]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE246]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE247]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE248]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE249]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE250]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE251]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE252]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE253]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE254]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE255]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE256]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE257]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let''s decide that one of the coroutines throws an exception after some
    time:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE258]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE259]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE260]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE261]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE262]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE263]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE264]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE265]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE266]'
  prefs: []
  type: TYPE_PRE
- en: If you run this code, something interesting happens. Not only does the coroutine
    itself terminate, but also all its siblings are terminated as well.
  prefs: []
  type: TYPE_NORMAL
- en: What happens here is that an uncaught exception bubbles up to the parent coroutine
    and cancels it. Then, the parent coroutine terminates all the other child coroutines
    to prevent any resource leaks.
  prefs: []
  type: TYPE_NORMAL
- en: 'Usually, this is the desired behavior. If we''d like to prevent child exceptions
    from stopping the parent as well, we can use `supervisorScope`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE267]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE268]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE269]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE270]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE271]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE272]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE273]'
  prefs: []
  type: TYPE_PRE
- en: By using `supervisorScope`, even if one of the coroutines fails, the parent
    job won't be affected.
  prefs: []
  type: TYPE_NORMAL
- en: The parent coroutine can still terminate all its children by using the `cancel()`
    function. Once we invoke `cancel()` on the parent job, all of its children are
    canceled too.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we''ve discussed the benefits of structured concurrency, let''s reiterate
    one point from the start of this chapter: using `GlobalScope` and the fact that
    it''s marked as a `GlobalScope` exposes functions such as `launch()` and `async()`,
    it doesn''t benefit from structured concurrency principles and is prone to resource
    leaks when used incorrectly. For that reason, you should avoid using `GlobalScope`
    in real-world applications.'
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we covered how to create threads and coroutines in Kotlin,
    as well as the benefits of coroutines over threads.
  prefs: []
  type: TYPE_NORMAL
- en: Kotlin has simplified syntax for creating threads, compared to Java. But it
    still has the overhead of memory and, often, performance. Coroutines can solve
    these issues; use coroutines whenever you need to execute some code concurrently
    in Kotlin.
  prefs: []
  type: TYPE_NORMAL
- en: At this point, you should know how to start a coroutine and how to wait for
    it to complete, getting its results in the process. We also covered how coroutines
    are structured and learned about how they interact with dispatchers.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we touched upon the topic of structured concurrency, a modern idea
    that helps us prevent resource leaks in concurrent code easily.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we'll discuss how we can use these concurrency primitives
    to create scalable and robust systems that suit our needs.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What are the different ways to start a coroutine in Kotlin?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: With structured concurrency, if one of the coroutines fails, all the siblings
    will be canceled as well. How can we prevent that behavior?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the purpose of the `yield()` function?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
