- en: A/B Testing Your App
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: All successful app developers learn from the feedback they get from their users.
    They investigate it and determine if they need to improve, to remove, or to add
    features in order to better support of the user's workflow. In this chapter, we
    will investigate what tools we can use to get feedback from our users if we cannot
    ask them in person. Multiple iterations of testing and optimizing are required
    to build an app that solves your customer's problem. Split testing (or A/B testing)
    is an ongoing process that can help you find the workflow, which will lead to
    the highest conversions. Using split testing, you can, for example, find the best
    registration flow for your app. In [Chapter 10](b81516a3-47fe-4318-a8e6-2bc8f2f34a04.xhtml),
    *There is an API For That!*, we have seen some good suggestions of what you can
    do to improve the onboarding process. Now you can also run some experiments and
    measure what works best for your app. It can also give you feedback about other
    topics, such as user retainment, engagement, or in-app purchases. We will see
    why obtaining statistics matters and what we could learn from them.
  prefs: []
  type: TYPE_NORMAL
- en: Pragmatic as we are, we will investigate what tools we can use for this purpose.
    We will have a quick look on how Firebase, remote config and analytics, could
    work for us. Split testing is a methodology that you can use any time, even when
    your app is already in the store. Finally, we will see what we can do for split
    testing our App or Play Store listing.
  prefs: []
  type: TYPE_NORMAL
- en: 'Specifically, in this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: See why statistics matter
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Learn what actionable metrics are
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Check out what split testing is and how it can help us to improve our apps
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Investigate what tools we can use for testing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Figure out how to use Firebase Remote Config and Firebase Analytics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Why do statistics matter?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Without statistics, you will have little to no feedback. You will be blind
    to all insights you could otherwise have obtained from your users and their behavior.
    Do not release your app without any implementation required for obtaining analytical
    data:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b0a974ee-4d71-4bef-9cef-16a2da9199aa.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In general, statistics could inform us about the following:'
  prefs: []
  type: TYPE_NORMAL
- en: User acquisition performance
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: User behavior and conversion
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: User demographics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: User behavior by segment or cohort
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Financial insights
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'So, the right statistics tell us something about app usage. It gives an answer
    to questions such as: How well is the app doing and what exactly does "doing well"
    mean? Is this about the number of downloads? The number of active users? The number
    of daily new users? It is important not just to have statistics, but to have actionable
    metrics. It is easy to gather a lot of data. It is more difficult to determine
    what numbers really matter. Do not get drowned in numbers. Determine what your
    business objectives are so you know what to measure. It is important to have concrete
    numbers so you can instantly act upon them by doing the right things.'
  prefs: []
  type: TYPE_NORMAL
- en: About actionable metrics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In [Chapter 10](b81516a3-47fe-4318-a8e6-2bc8f2f34a04.xhtml), *There is an API
    For That!*, we already had a preview on the concept of conversions and metrics.
    Gathering statistics about your mobile app usage matters, as it often is the only
    way to get feedback from your users. If we want to learn something about this
    feedback, it is important to realize that the quality of the statics you obtain
    is more important than the quantity. While it may be tempting to gather as much
    data as possible, the opposite is actually true. Focus on what really matters.
    Actionable metrics is what we want. Ash Maurya writes about this in his books
    *Running Lean and Scaling Lean*. He claims user growth is more important than
    your total user base, and he certainly has a point there.
  prefs: []
  type: TYPE_NORMAL
- en: Acquisition and engagement are important metric categories. Acquisition numbers
    tell you something about your app's downloads, the number of new users, and the
    number of active users. Engagement is about how often your users are opening your
    app (and keep using it), retention, and churn rates (the users that have abandoned
    your app). It is interesting to learn how many of the users that have downloaded
    your app will stick with your app? And will they still be using your app after
    1 week or 1 month? The other important metrics are customer lifetime value and
    key funnel behavior, but let's start with acquisition and engagement first.
  prefs: []
  type: TYPE_NORMAL
- en: Acquisition
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before users will download your app, they need to be aware of its existence.
    You need to promote it on social media, on your website, or in some other way.
    How else would one know that it exists and that your app is really awesome? Getting
    new users every day is important, as your number of active users will drop otherwise.
    No matter how cool your app is, it will not work for some people. That does not
    have to be an issue. As long as the numbers for acquisition is higher than the
    churn rate, your app will grow.
  prefs: []
  type: TYPE_NORMAL
- en: Engagement
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: User engagement metrics are all about your app's stickiness. People spend more
    and more time on mobile devices, which of course is a good thing for your app.
    But people also have little more than the attention span of a goldfish so average
    churn rates (app users that no longer use your app) are often higher for mobile
    apps.
  prefs: []
  type: TYPE_NORMAL
- en: You might wonder how much time a user spends on the app during a session or
    during a certain period. A session is any kind of interaction until the attention
    of the user gets interrupted by something else, such as an incoming phone call.
    To improve your app's retention rate, you should often remind users about the
    app or you should provide them with a good reason to visit the app on a regular
    basis. Email and push notifications can be used to get the user's attention again,
    thus maintaining app awareness.
  prefs: []
  type: TYPE_NORMAL
- en: The retention rate is about the number of users that remain active after a certain
    period of time, let's say, after 2 months or more. The churn rate is about the
    users that no longer use your app after the same period of time. To grow, the
    retention rate needs to be higher than the churn rate. To do so, your app constantly
    needs to deliver value by providing relevant content, incentives, and new or improved
    features. In short, you continuously need to give your users reason to come back
    to your app.
  prefs: []
  type: TYPE_NORMAL
- en: Daily or weekly active users are the most valuable ones as they will be the
    easiest ones to convert later. The higher the engagement rate, the more valuable
    the app is to your users. They could become an ambassador of your app by making
    referrals, or contribute to your app's monetization by clicking on advertisements
    or by making in-app purchases (revenue).
  prefs: []
  type: TYPE_NORMAL
- en: Conversions and pirate metrics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Pirate metrics, as we have seen in [Chapter 10](b81516a3-47fe-4318-a8e6-2bc8f2f34a04.xhtml),
    *There is an API For That!*, are about the conversion of your app users. Here
    the conversion steps are shown from acquisition to revenue:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/100d500d-807a-40fc-b50e-f80adb118e45.png)'
  prefs: []
  type: TYPE_IMG
- en: 'For our app, in particular, it comes down to these steps: **Awareness**, **Visit
    and search store**, **Download app**, **Open app**, **Activation (Register),**
    and finally **Retention**. To keep things simple, for now, the ad income or in-app
    purchase (revenue) is not displayed here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f6141e2c-a433-4f5b-9685-0f962fecf626.png)'
  prefs: []
  type: TYPE_IMG
- en: With each step, you lose a number of users. That is a completely normal phenomenon,
    but you need to make sure that you will not lose too many of them on the way.
    Let's say 1,000 people learn about the existence of your app by reading about
    it on a website or on Twitter. 800 of them click on the link to view the app in
    the store.
  prefs: []
  type: TYPE_NORMAL
- en: 'They see the app''s icon, some screenshots, a description, and some feedback
    from other users. About 300 users think, "Hmm, this is not for me". So, only 500
    users will download the app. 100 of them forget about it while downloading (on
    their way home, something else is asking for their attention: A call? A whatsapp
    message?). Eventually, 400 users will open the app. They see an onboarding story
    with a clear call to action. The app asks them to register using Facebook or Twitter.
    Probably 200 of them will do this. The remainder of the users have the intention
    to do this later (but they probably will forget about it). 200 users start exploring
    the app and, if they are not often reminded about the app, and if the app does
    not give them sufficient reasons to return to it, they will forget about it within
    a couple of days. After 1 week only 50 users are still using the app, and after
    1 month only 25 of them are still active.'
  prefs: []
  type: TYPE_NORMAL
- en: Is this a negative scenario? Not at all. It is a very realistic one for a lot
    of apps. If you want to make a difference between a failing and a successful app,
    then you need to think of this. Also, we did not even discuss the monetization
    part yet. In [Chapter 17](0efea3a6-95f2-42d3-9a36-a34bdbef1014.xhtml), *Monetization
    and Pricing Strategy*, we will have a look at that part specifically.
  prefs: []
  type: TYPE_NORMAL
- en: Fortunately, we have tools to improve the conversion rate. It is important to
    learn what the exact conversion percentages are. If, of all the users that have
    downloaded the app, only a small percentage sign up, then you will know you have
    work to do. There probably is something in your onboarding process that is preventing
    people from signing up. In that particular case, you need to find out if the on-boarding
    barrier is too high and what you can do to change this. Another example is the
    conversion number for in-app purchases. It also is an interesting pattern if you
    notice that they visit that part of your app where they can make such a purchase
    without ever converting to customers (actually buying something). There is something
    that needs to be changed there. Perhaps the added value for the products are unclear
    or maybe the pricing level is just too high.
  prefs: []
  type: TYPE_NORMAL
- en: Get to know your audience
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: But what is it that you need to change? If you have a small number of beta users,
    you can just text them to ask. There are also tools available to include some
    sort of survey, but most people consider them as annoying. It might help if you
    offer them specific incentives (a free purchase, for example). They could be digital
    incentives, such as the well-known badges (gamification) or real-life incentives.
    If you are interested in the latter, checkout Kiip at [http://www.kiip.me/developers](http://www.kiip.me/developers)
    for some examples. They have a great SDK that you can add to your app. For example,
    it enables you to offer a free cup of coffee to your user if he has fully completed
    his profile.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you want to know who your app users are, you need to have additional information
    about them, such as their locations and what they expect from your app. It is
    also interesting to know something about their age, gender, the types of devices
    they use, and at what moments or in what situations they use your app. Knowing
    your audience well is vital in order to be able to create an app that fully meets
    the user''s expectations. And, in the end, it also leads to better monetization
    of your app. In fact, this is why Facebook ads have way better conversions than
    Google ads. Facebook knows much more about their audience and about each individual,
    so advertisements can be targeted more specifically, thus making the ad **Click
    Through Rate** (**CTR**) higher. We will learn more about this in [Chapter 14](d9145149-0f4e-47b6-bc9d-ff46e5e63304.xhtml),
    *Growing Traction and Improving Retention*, about traction and retention. First,
    let''s see what we need to do to learn more about our app''s audience:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0934ebf1-de0a-4715-9e72-196159c58b5f.png)'
  prefs: []
  type: TYPE_IMG
- en: Split testing can help us to improve our apps
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A/B testing, also known as split testing, in its most basic form comes down
    to two different implementations shown at random to different kinds of people.
    A small number, say 5%, are shown the new feature, A, which could be something
    like a new feature or a new view, and another 5% will see feature B. The remainder
    of the users will not see the new feature yet. The feature that will prove to
    be most popular (by conversion or otherwise, depending on the objectives) will
    be fully implemented and offered to the complete audience of your app.
  prefs: []
  type: TYPE_NORMAL
- en: 'In case you want to find out what works best for signing up users, you can
    set up a split test like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/03c4be9c-4714-4f58-b00f-b27f34d2c1d5.png)'
  prefs: []
  type: TYPE_IMG
- en: 'So 50% of your test audience sees variation A, showing a button that says Sign
    up, which will lead 26% of the visiting users to sign up. The other 74% might
    think "Hmm, this is not for me", or decide to sign-up later: something they probably
    will forget about. What happens with the other 50% of the test audience? They
    will see variation B. It displays a Get started! button. If we look at this variant,
    we see that 63% of the audience decides to sign up:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8da6789f-4ff8-43b9-9003-b7384a65f7ed.png)'
  prefs: []
  type: TYPE_IMG
- en: In theory, this proves that variation B is the one that should be implemented
    as it leads to the highest conversions. The reality is somewhat different. If
    we have little to no knowledge of our audience the preceding conclusion may be
    true, but if we do know a little more about our audience we might not accept the
    results on face value and might consider other questions. Is the audience that
    sees variation A comparable to the audience that sees variation B? There may be
    specific customer segments that specifically prefer one feature above another.
  prefs: []
  type: TYPE_NORMAL
- en: We will never find out if we will just do random tests. As stated earlier, we
    can increase our success on our app monetization only if we know what our audience
    is and what they want. Step 1 is getting to know our audience (by gathering user
    data) and step 2 is to take this knowledge into account when doing A/B tests.
    What if we could choose our target audience and see what works best for them?
    There are tools available that could help us to do a little bit more sophisticated
    split testing. We will look at them in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Keep the differences between variations subtle
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The difference between A and B in our example is very subtle, and that is for
    a reason. If the difference between the two variations is too big, you will not
    know what it is that you are testing:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0a7c9d7c-6314-4ff2-96f6-7cbee58af55b.png)'
  prefs: []
  type: TYPE_IMG
- en: The preceding is a brilliant example of what not to do. If your onboarding split
    test shows that variant A leads to a 61% conversion and variant B leads to a 66%
    conversion rate, then what does the outcome prove? Not only is the difference
    in conversion percentages not very convincing, it also is not clear what has led
    to a slightly better conversion. Was it the background color that did the trick?
    Or the text (call to action)? Or maybe was it the color of the Sign up button?
    We will never know. This test has too many parameters.
  prefs: []
  type: TYPE_NORMAL
- en: Think of what the objective of the test is. What is your hypothesis and how
    can you prove it using a split test? Test one element at a time, so you know what
    change was responsible for the improved conversion. Run multiple split tests,
    as a single test will typically not provide sufficient information to fully understand
    what works best. Remember, it is not important what you think that your users
    will do. It is important what your users do. And you better find out as early
    as possible.
  prefs: []
  type: TYPE_NORMAL
- en: The other things that you should take into account are events that may influence
    your tests. Running a test around holidays or particular events may have a different
    outcome. Also, conversion rates may be different on different days of the week.
    For these reasons, always make sure you are running tests for at least a couple
    of weeks.
  prefs: []
  type: TYPE_NORMAL
- en: Tools for split testing and getting actionable metrics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: From a technical perspective, it is pretty easy to do web split-testing experiments.
    Mobile-optimizing experiments, on the other hand, are more difficult to accomplish.
    The Play Store or the App Store are the most important reasons for this. A web
    browser always is connected, but apps live on a device which is not always connected.
  prefs: []
  type: TYPE_NORMAL
- en: 'Although mobile-app split testing is not as mature yet as for website A/B testing,
    there are many tools available that can help you test your users. Once you have
    decided what metrics you want to measure, you can pick the tool that is most convenient
    for that purpose:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1a307f5e-eab0-4af7-beb8-bd1a53f6a62e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Among others, you can use some of the following tools:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Firebase:** This comes with many options, such as remote configurations and
    analytics. Firebase is a good candidate for split testing your app if you combine
    these two features. Remote configurations allow to make instant updates to the
    appearance of your app. Perhaps you are using Firebase already for data storage,
    real-time data sharing or for onboarding purposes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Taplytics**: This is a split-testing tool that you can use to make changes
    that do not require an update in the Play Store or App Store. Without even changing
    code, you can have multiple fast-test iterations, which makes it one of the most
    suitable solutions for mobile split-testing purposes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Fabric**: The Fabric SDK comes with many handy tools, about onboarding. It
    is a platform that makes it easy to install and maintain SDKs, including, for
    example, Optimizely. In addition to a Fabric account, you also need to set up
    an Optimizely account. Optimizely can help to easily integrate split testing into
    apps. It is a well-known testing tool and is available for both iOS and Android.
    Just as is the case with Firebase and Taplytics, there are no App Store or Play
    Store updates required to run A/B tests.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The other interesting tools are SplitForce, Flurry Analytics, Amazing A/B testing,
    Arise, Switchboard, Leanplum, and Apptimize. They all support both iOS and Android.
    Customer segments are supported by most of them. This functionality allows you
    to run tests for a particular type of audience. Depending on your objectives,
    you need to pick the tools that suit your needs best. As an example, we will take
    a look at Firebase remote config and Firebase analytics specifically to see how
    this works.
  prefs: []
  type: TYPE_NORMAL
- en: Using Firebase for split testing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You can use Firebase for split testing your Android or iOS app. Tutorials on
    how to set things up for Firebase and remote configurations specifically can be
    found at [https://firebase.google.com/docs/remote-config/](https://firebase.google.com/docs/remote-config/).
  prefs: []
  type: TYPE_NORMAL
- en: For this example, we will be looking at an Android implementation. Download
    the sample project from [https://github.com/mikerworks/packt-lean-firebase-split-testing](https://github.com/mikerworks/packt-lean-firebase-split-testing).
    The Android Kotlin app that you will find there is to demonstrate how you can
    run split tests for the onboarding flow of an app. It uses Firebase remote configurations
    and Firebase analytics.
  prefs: []
  type: TYPE_NORMAL
- en: 'The project has been setup using the Firebase option of the Tools menu of Android
    Studio. The Firebase assistant can help you to configure your project for `Analytics`
    and `Remote Config`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c0d7cc1d-2d45-46d4-9755-935c55e1549c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'For the sample project, it has been set up already. In the `build.gradle` file
    within the `app` folder, you will find these dependencies for Firebase:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The `google-services.json` file in the project should be replaced by your own
    file. You can download it from Firebase as soon as you have configured your app.
    (Choose settings in the project overview.) You can use the Firebase assistant
    to do so or you can go to the developers console of Firebase at [https://console.firebase.google.com](https://console.firebase.google.com):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/57838c6c-8362-435f-9bdf-ff26e9f070f4.png)'
  prefs: []
  type: TYPE_IMG
- en: 'If you do not have a Firebase account yet, you need to create one first. In
    the console, you can add and configure your project:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/fed2165b-e79e-4837-b9d0-16498be56b67.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In the project overview, you can go to the Grow section and choose the Remote
    config option. If you choose the A/B testing on the right, you can determine what
    variants you want to split test:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8b875e57-8abc-494a-b2ba-270149e7489c.png)'
  prefs: []
  type: TYPE_IMG
- en: Let’s say the example project is an app that has already been published. And
    let’s say we want to test a new onboarding experience. By clicking on the Create
    experiment button, we can test what works best. We want to figure out how which
    variant leads to the highest conversion for sign-ups.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two variants: Variant A and Variant B. The Control group will see
    the app as is; they will not see any variations:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/20fe5e18-e002-4505-a3e3-b4c57a721462.png)'
  prefs: []
  type: TYPE_IMG
- en: 'You can define one or more parameters for the experiment. Each variant has
    its own values for these parameters. Things that we could test are for example:
    the background color of the Sign up button (Blue or green), the sign up text or
    the background image (strawberries or oranges). As you can see, you can set up
    multiple parameters, but it is best practice to limit them to two or three.'
  prefs: []
  type: TYPE_NORMAL
- en: You can define a user segment for your split test. In this example, we will
    just target 5% of the user base to keep it simple. More sophisticated segmentation
    options are also available. For example, you can target a specific country or
    users in the age group of 18 to 36\. You can create very specific segments if
    you have obtained a lot of information about your users.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0f3af1c4-f420-4d1f-b2e1-24c0cf334c68.png)'
  prefs: []
  type: TYPE_IMG
- en: The app can read any of these values that you define here. The default ones
    can be found in the project in the `remote_config_defaults.xml` file (in the `res`/`xml`
    folder). We need them to let the app function properly in case the remote config
    values cannot be retrieved (because there is no internet connection, for example).
  prefs: []
  type: TYPE_NORMAL
- en: In the MainActivity app, you can see how it is done. The Firebase remote configuration
    and analytics are initialized here. The developer's mode is enabled for the debug
    variant. This will ensure that there is no caching of data, which allows us to
    test the variants first.
  prefs: []
  type: TYPE_NORMAL
- en: 'We are also telling the `firebaseRemoteConfig` instance that it should use
    the variables for the `remote_config_defaults.xml` file as a fall-back option:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Finally, we are logging the device token. Later, we need this token to test
    a specific variant on our test device. At the end of this code snippet, we fetch
    the data and listen for the results.
  prefs: []
  type: TYPE_NORMAL
- en: 'If all the parameters and values have been retrieved, we tell the `firebaseRemoteConfig`
    object to apply these values. The call to the `applyRemoteConfiguration` method
    ensures that the UI will be updated:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we set all the colors and texts that are applicable to the current variant:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'This will result in displaying variant A or variant B for the onboarding flow.
    Since we want to measure the differences in conversion between these two variants,
    we set a user property for the `fireBaseAnalytics` object, and if the user clicks
    on the sign up button, we log the event like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: With this approach, we can measure the number of clicks on the sign up button
    and we can see the results in the Firebase analytics dashboard console for each
    variant.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we need to test both variants. If you run the app for the first time
    and everything goes well, you will find something like this in the log output
    (filter on: token):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Copy the token value and go back to the Firebase console. There you can set
    up a test device. Paste the token at the field Instance ID token and choose Variant
    A or Variant B:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/83a87294-fc9d-4868-8e58-22984db46075.png)'
  prefs: []
  type: TYPE_IMG
- en: 'If you choose Variant A and run the app now, it will look like the screenshot
    shown on the left. It has a background filled with strawberries and it has a blue
    SIGN UP button. However, if you choose Variant B at the Firebase console and run
    the app again, it will suddenly show oranges in the background and it has a green
    SIGN UP button. Variant B is shown on the right:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b8b900d6-9266-4249-88aa-0d32abd01c04.png)'
  prefs: []
  type: TYPE_IMG
- en: Will this onboarding screen with the blue Call to Action button and a background
    of strawberries be the winner? Or will we see the highest conversion (sign up)
    for the onboarding view that uses a green button and a background of oranges?
    Only time will tell what the outcome will be.
  prefs: []
  type: TYPE_NORMAL
- en: If we run this split test live for a couple of weeks, we will know which of
    the two results provide the highest conversion. The winning variant will be the
    one that we are going to roll out for all users.
  prefs: []
  type: TYPE_NORMAL
- en: This was just a brief example. There are many other options available to be
    discovered that are not covered in this chapter, as it is just an introduction
    to split testing. However, you have an idea of the possibilities now.
  prefs: []
  type: TYPE_NORMAL
- en: 'To learn more about Firebase split testing specifically, have a look at:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://developer.android.com/distribute/best-practices/develop/in-app-a-b-testing.html](https://developer.android.com/distribute/best-practices/develop/in-app-a-b-testing.html)
    or [https://techcrunch.com/2017/10/31/google-firebase-gets-predictions-crashlytics-integration-and-a-new-ab-testing-service/](https://techcrunch.com/2017/10/31/google-firebase-gets-predictions-crashlytics-integration-and-a-new-ab-testing-service/)
    or [https://firebase.google.com/docs/remote-config/use-config-ios](https://firebase.google.com/docs/remote-config/use-config-ios).'
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we have seen why statistics matter and which statistics matter.
    We have learned about split testing and what the do’s and don’ts are. We have
    some idea of what tools are available for it and what we need to do to set up
    a split test of our own apps. We learned something about metrics and about the
    importance of acquisition and retention.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will learn more about retention and how we can further
    improve it. We are going to improve traction and examine some practical approaches
    to accomplish that for our app. Let's get started.
  prefs: []
  type: TYPE_NORMAL
