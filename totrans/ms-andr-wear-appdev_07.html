<html><head></head><body><div><div><div><div><h1 class="title"><a id="ch07"/>Chapter 7.  Voice Interactions, Sensors, and Tracking </h1></div></div></div><div><table border="0" cellspacing="0" cellpadding="0" class="blockquote" summary="Block quote"><tr><td valign="top"> </td><td valign="top"><p>
<em>"All I have is a voice."</em>
</p></td><td valign="top"> </td></tr><tr><td valign="top"> </td><td colspan="2" align="right" valign="top" style="text-align: center">--<em>W. H. Auden</em></td></tr></table></div><p>In this chapter, we cover the voice capabilities offered by the Wear API and define voice actions interfacing with our <code class="literal">Today</code> app from the previous chapter. We also introduce device sensors and discuss how they can be used to track data.</p><div><h3 class="title"><a id="note13"/>Note</h3><p>The code accompanying this chapter is available for reference on GitHub (<a class="ulink" href="https://github.com/siddii/mastering-android-wear/tree/master/Chapter_7">https://github.com/siddii/mastering-android-wear/tree/master/Chapter_7</a>). For the sake of brevity, only code snippets are included as needed. The reader is encouraged to download the referenced code from GitHub and follow along as they progress through the chapter.</p></div><div><div><div><div><h1 class="title"><a id="ch07lvl1sec44"/>Voice capabilities</h1></div></div></div><p>If you lived your adolescence through the eighties, chances are you got all your knowledge of wearable device voice interactions from this guy:</p><p>
</p><div><img src="img/image00194.jpeg" alt="Voice capabilities"/></div><p style="clear:both; height: 1em;"> </p><p>
</p><p>Three decades on, here you are, itching to find out whether the <code class="literal">Wear</code> API offers a
system-provided voice action that enables you to summon your car. I'm afraid, not yet. The complete list of system-provided voice actions is presented in the subsection that follows.</p><div><h3 class="title"><a id="note14"/>Note</h3><p>You can visit the Android's developer site (<a class="ulink" href="https://developer.android.com/training/wearables/apps/voice.html">https://developer.android.com/training/wearables/apps/voice.html</a>) for more insight on the voice capabilities for your wearable app.</p></div><p>By system-provided voice actions, we mean the voice actions that are built into the Wear platform, that is, provided out of the box for developer use.</p><p>In contrast, the term app-provided voice actions refer to those that are specific to your app.</p><div><div><div><div><h2 class="title"><a id="ch07lvl2sec30"/>System-provided voice actions</h2></div></div></div><p>System-provided voice actions must be filtered according to the specific activity you want to start when the phrase corresponding to the voice action is spoken. For instance, note to self.</p><p>The Wear platform supports the following voice intents:</p><div><ul class="itemizedlist"><li class="listitem">Take a note</li><li class="listitem">Call a car/taxi</li><li class="listitem">Set alarm</li><li class="listitem">Set timer</li><li class="listitem">Start/stop a run</li><li class="listitem">Start/stop a bike ride</li><li class="listitem">Start stopwatch</li><li class="listitem">Start/stop a run</li><li class="listitem">Start/stop a workout</li><li class="listitem">Show step count</li><li class="listitem">Show heart rate</li></ul></div></div><div><div><div><div><h2 class="title"><a id="ch07lvl2sec31"/>App-provided voice actions</h2></div></div></div><p>Depending on your needs, the system-provided voice actions may not be enough. In that case, you can choose to register a start action for your app the same way you register a launcher icon on a handheld.</p><p>To start <code class="literal">TodayActivity</code> using a voice action, specify a label attribute with a text value set to whatever you say after the <code class="literal">Start</code> keyword. In this sample code, we use our app name as the label attribute. The existence of an intent-filter tag recognizes the voice action <code class="literal">Start Today</code> and launches the <code class="literal">TodayActivity</code> activity:</p><pre class="programlisting">&lt;activity 
  android:name=".TodayActivity" 
  android:label="@string/app_name"&gt; 
  &lt;intent-filter&gt; 
    &lt;action android:name="android.intent.action.MAIN" /&gt; 
    &lt;category android:name="android.intent.category.LAUNCHER" /&gt; 
  &lt;/intent-filter&gt; 
&lt;/activity&gt; 
</pre></div></div></div>
<div><div><div><div><h1 class="title"><a id="ch07lvl1sec45"/>New feature - adding to-do items through voice commands</h1></div></div></div><p>Let's get ready to write some code. In the last chapter, we augmented our <code class="literal">Today</code> app to allow us to add to-do items through a paired handheld app. The wearable then surfaced notifications based on configured contexts.</p><p>Now, let's spice that up by adding voice interactions to the mix. We'll use the wearable app to take to-do notes through voice commands. This will involve extending the context-aware notifications feature we implemented with the ability to add to-do items using voice inputs. Furthermore, we will supply the context along with the to-do item.</p><p>For example, if we were to say "home make dinner", our wearable app will create a to-do item named <em>Make dinner</em> and associate it with the <code class="literal">Home</code> context. In the same way, if we were to say "work set up monthly review meeting", the app will create a to-do item named <em>Set up monthly review meeting</em> and associate it with the <code class="literal">Work</code> context.</p><p>A few things to keep in mind before we step through the code:</p><div><ul class="itemizedlist"><li class="listitem">At the time of this writing, Android Wear emulators do not support voice inputs. So we opted to use a physical wear device.</li><li class="listitem">Now, if you recall, we had mentioned previously that we don't really need a physical device to build Android Wear apps. While that is true for the most part, there are cases where the emulators cannot emulate physical device behaviors such as voice inputs, motion sensing, and so on. In these cases, we really have no option besides getting hold of a physical device for a fuller Android wear development experience. Besides, if you're serious about Android Wear development, you might as well consider getting a physical device because it really helps speed up your development.</li><li class="listitem">It is important to note that while voice interactions are not presently supported in Android Wear emulators, Google might up their support for voice interactions in the future. We'll be keeping an eye on that.</li></ul></div><div><div><div><div><h2 class="title"><a id="ch07lvl2sec32"/>Add to-do Item - a new action in the wearable app</h2></div></div></div><p>Let's get started. One of the first things we will do is add an <code class="literal">Add Todo Item</code> action to our <code class="literal">arrays.xml</code> file:</p><pre class="programlisting">&lt;?xml version="1.0" encoding="utf-8"?&gt; 
&lt;resources&gt; 
  &lt;string-array name="actions"&gt; 
    &lt;item&gt;Day of Year&lt;/item&gt; 
    &lt;item&gt;On this day...&lt;/item&gt; 
    &lt;item&gt;Add Todo Item&lt;/item&gt; 
  &lt;/string-array&gt; 
&lt;/resources&gt; 
</pre><p>This newly configured action is now displayed on our screen, as shown here:</p><p>
</p><div><img src="img/image00195.jpeg" alt="Add to-do Item - a new action in the wearable app"/></div><p style="clear:both; height: 1em;"> </p><p>
</p></div></div>
<div><div><div><div><h1 class="title"><a id="ch07lvl1sec46"/>The AddTodoItem activity in the wearable app</h1></div></div></div><p>We wire in the handler for the selection of the <code class="literal">AddTodoItem</code> activity:</p><pre class="programlisting">@Override 
public void onClick(WearableListView.ViewHolder viewHolder)  
{ 
  Log.i(TAG, "Clicked list item" +  viewHolder.getAdapterPosition()); 
  if (viewHolder.getAdapterPosition() == 0)  
  { 
    Intent intent = new Intent(this, DayOfYearActivity.class); 
    startActivity(intent); 
  }  
  else if (viewHolder.getAdapterPosition() == 1)  
  { 
    Intent intent = new Intent(this, OnThisDayActivity.class); 
    startActivity(intent); 
  }  
  else if (viewHolder.getAdapterPosition() == 2) 
  { 
    displaySpeechRecognizer(); 
  } 
 
//Create an intent that can start the Speech Recognizer activity 
private void displaySpeechRecognizer()  
{ 
  Intent intent = new  Intent(RecognizerIntent.ACTION_RECOGNIZE_SPEECH); 
  intent.putExtra(RecognizerIntent.EXTRA_LANGUAGE_MODEL, 
  RecognizerIntent.LANGUAGE_MODEL_FREE_FORM); 
  // Start the activity, the intent will be populated with the speech text 
  startActivityForResult(intent, Constants.SPEECH_REQUEST_CODE); 
} 
</pre><p>Clicking on the <strong>Add Todo Item</strong> action has the following effect:</p><p>
</p><div><img src="img/image00196.jpeg" alt="The AddTodoItem activity in the wearable app"/></div><p style="clear:both; height: 1em;"> </p><p>
</p></div>
<div><div><div><div><h1 class="title"><a id="ch07lvl1sec47"/>Handling speech inputs</h1></div></div></div><p>The <code class="literal">onActivityResult</code> method callback fires when the speech recognizer returns with the voice input intent. Note how we extract the spoken text and then call the <code class="literal">GoogleApiClient</code> API if the voice command begins with one of our predefined contexts, namely <code class="literal">home</code> or <code class="literal">work</code>:</p><pre class="programlisting">// This callback is invoked when the Speech Recognizer returns. 
// This is where you process the intent and extract the speech text from the intent. 
@Override 
protected void onActivityResult(int requestCode, int resultCode,  Intent data)  
{ 
  if (requestCode == Constants.SPEECH_REQUEST_CODE &amp;&amp; resultCode  == RESULT_OK) 
  { 
    List&lt;String&gt; results = data.getStringArrayListExtra( RecognizerIntent.EXTRA_RESULTS); 
    spokenText = results.get(0); 
    // Do something with spokenText 
    Log.i(TAG, "Spoken Text = " + spokenText); 
    if (spokenText.startsWith("home") ||  spokenText.startsWith("work"))  
    { 
      Log.i(TAG, "Creating Google Api Client"); 
      mGoogleApiClient = new GoogleApiClient.Builder(this) 
      addApi(Wearable.API) 
      .addConnectionCallbacks(this) 
      .addOnConnectionFailedListener(this) 
      .build(); 
       mGoogleApiClient.connect(); 
    } 
  }  
  else  
  { 
    super.onActivityResult(requestCode, resultCode, data); 
  } 
} 
</pre><p>Android Wear parses the speech input and presents the spoken text as a confirmation, as shown here:</p><p>
</p><div><img src="img/image00197.jpeg" alt="Handling speech inputs"/></div><p style="clear:both; height: 1em;"> </p><p>
</p><p>Once <code class="literal">GoogleClient</code> is connected, that is, the <code class="literal">onConnected</code> handler fires, we extract the <code class="literal">todoItem</code> text after excluding the context (<code class="literal">home</code> or <code class="literal">work</code>) and send the to-do item as a message to the handheld app using the <code class="literal">Wearable Data</code> API:</p><pre class="programlisting">@Override 
public void onConnected(Bundle bundle) 
{ 
  Log.i(TAG, "Connected to Data Api"); 
  if(spokenText != null) 
  { 
    if (spokenText.startsWith("home")) 
    { 
      String todoItem = spokenText.substring("home".length()); 
      sendMessage(Constants.HOME_TODO_ITEM, todoItem.getBytes()); 
    } 
    else if(spokenText.startsWith("work"))  
    { 
      String todoItem = spokenText.substring("work".length()); 
      sendMessage(Constants.WORK_TODO_ITEM, todoItem.getBytes()); 
    } 
  } 
} 
 
private void sendMessage(final String path, final byte[] data)  
{ 
  Log.i(TAG, "Sending message to path " + path); 
  Wearable.NodeApi.getConnectedNodes(mGoogleApiClient).setResultCallback( 
  new ResultCallback&lt;NodeApi.GetConnectedNodesResult&gt;()  
  { 
    @Override 
    public void onResult(NodeApi.GetConnectedNodesResult nodes)  
    { 
      for (Node node : nodes.getNodes())  
      { 
        Wearable.MessageApi 
        sendMessage(mGoogleApiClient, node.getId(), path, data); 
        spokenText = null; 
      } 
    } 
  }); 
} 
</pre></div>
<div><div><div><div><h1 class="title"><a id="ch07lvl1sec48"/>Handheld app</h1></div></div></div><p>Over on the handheld app, we implement the <code class="literal">onMessageReceived</code> handler to process the message received from the wearable. Remember, the handheld app is where we do the heavy-lifting work. In this case, it is the creation of a to-do item:</p><pre class="programlisting">@Override 
public void onMessageReceived(MessageEvent messageEvent) 
{ 
  super.onMessageReceived(messageEvent); 
  Log.i(TAG, "Message received" + messageEvent); 
  if(Constants.ON_THIS_DAY_REQUEST.equals(messageEvent.getPath())) 
  { 
    //read Today's content from Wikipedia 
    getOnThisDayContentFromWikipedia(); 
  }  
  else  
  { 
    String todo = new String(messageEvent.getData()); 
    if (Constants.HOME_TODO_ITEM.equals(messageEvent.getPath()))  
    { 
      Log.i(TAG, "Adding home todo item '" + todo + "'"); 
      TodoItems.addItem(this, "Home", todo); 
    }  
    else if (Constants.WORK_TODO_ITEM.equals(messageEvent.getPath()))  
    { 
      Log.i(TAG, "Adding work todo item '" + todo + "'"); 
      TodoItems.addItem(this, "Work", todo);     } 
  } 
} 
</pre><p>The added to-do item is displayed in the to-do list on our handheld's <code class="literal">Today - Todos</code> app, as shown here:</p><p>
</p><div><img src="img/image00198.jpeg" alt="Handheld app"/></div><p style="clear:both; height: 1em;"> </p><p>
</p></div>
<div><div><div><div><h1 class="title"><a id="ch07lvl1sec49"/>Motion sensors</h1></div></div></div><p>Motion sensors let us monitor the motion of a device through space, such as a rotation, swing, shake, or tilt. The movement may be relative to its immediate environment as is the case when you mimic a steering wheel in a car simulation. In this case, we monitor its motion relative to its own frame of reference or that of the application running on it.</p><p>However, the movement may also be relative to the environment surrounding the device, namely the world. An example of the latter is determining absolute speed from inside a moving vehicle. The device may be stationary inside the vehicle, but it is moving with respect to the earth at the same speed as the vehicle itself.</p><p>The Android platform lets us monitor the motion of a device using a broad array of sensors—some are hardware-based, such as the gyroscope and accelerometer. Others are
software-based or they may be hardware-based but dependent on other hardware sensors. Examples are the rotation vector sensor, the gravity sensor, the significant motion sensor, the step counter sensor and the step detector sensor. You can read all about these on the developers site (<a class="ulink" href="https://developer.android.com/guide/topics/sensors/sensors_motion.html">https://developer.android.com/guide/topics/sensors/sensors_motion.html</a>).</p><p>Our concern in this section is to provide a very brief treatment of two hardware sensors that are at the very heart of all motion sensing the gyroscope and the accelerometer. Understanding the principles underlying these sensors will give us an appreciation for the physics that pervades the behavior of all motion sensors and will leave us with an intuitive sense of how to go about solving our application problems through the indirect use of these sensors via the API available to us.</p><div><div><div><div><h2 class="title"><a id="ch07lvl2sec33"/>Gyroscope</h2></div></div></div><p>A gyroscope is, at its most basic level, a device consisting of a wheel or disk mounted so that it can spin freely about an axis without being influenced by the orientation of the mount that encloses it.</p><p>The following image helps us better visualize the construction:</p><p>
</p><div><img src="img/image00199.jpeg" alt="Gyroscope"/></div><p style="clear:both; height: 1em;"> </p><p>
</p><p>For the purposes of gaining an intuitive understanding, we just need to digest the fact that the properties of a gyroscope are only manifested while the rotor (disk) is rotating about its axis. When the disk is not rotating, the device does not exhibit any useful properties. But when rotating, the orientation of this axis is unaffected by the tilting or rotation of the mounting. This is in accordance with the conservation of angular momentum, and in essence, this is what makes a gyroscope useful for measuring or maintaining orientation.</p></div><div><div><div><div><h2 class="title"><a id="ch07lvl2sec34"/>Accelerometer</h2></div></div></div><p>An accelerometer is an instrument for measuring acceleration, typically that of an automobile, ship, aircraft, or spacecraft, or that involved in the vibration of a machine, building, or other structure.</p><p>Accelerometers find application in many fields of science and industry. For example, accelerometers are used to detect and monitor vibrations in rotating machinery. They are also used in tablets and digital cameras to ensure that images are always displayed upright on screen.</p><p>In the domain of wear devices, an acceleration sensor measures the acceleration applied to the device, which includes the forces of gravity. In general, the accelerometer is typically a good choice if you are monitoring device motion. It is available in almost every
Android-powered handheld and tablet. It consumes significantly less power than the other motion sensors.</p></div></div>
<div><div><div><div><h1 class="title"><a id="ch07lvl1sec50"/>New feature - tracking our steps</h1></div></div></div><p>Everyone loves step counters. How about we build one for our wearable device? Not much to talk about here, so let's dive into the code.</p><div><div><div><div><h2 class="title"><a id="ch07lvl2sec35"/>Add to-do item - a new action in the wearable app</h2></div></div></div><p>The first thing we will do here is to add a menu <code class="literal">item</code> to the wearable app. Let's call it <code class="literal">Step Count</code>. Our changes to <code class="literal">arrays.xml</code> file would be as follows:</p><pre class="programlisting">&lt;?xml version="1.0" encoding="utf-8"?&gt; 
&lt;resources&gt; 
    &lt;string-array name="actions"&gt; 
        &lt;item&gt;Day of Year&lt;/item&gt; 
        &lt;item&gt;On this day...&lt;/item&gt; 
        &lt;item&gt;Add Todo Item&lt;/item&gt; 
        &lt;item&gt;Step Count&lt;/item&gt; 
    &lt;/string-array&gt; 
&lt;/resources&gt; 
</pre><p>This action should now show up on the wearable app, as shown in the following figure:</p><p>
</p><div><img src="img/image00200.jpeg" alt="Add to-do item - a new action in the wearable app"/></div><p style="clear:both; height: 1em;"> </p><p>
</p><p>Click on the <code class="literal">Step Count</code> menu item to launch the corresponding <code class="literal">StepCounterActivity</code> activity. The code for that class is given here. Note how the activity implements the <code class="literal">SensorEventListener</code> class. We hook up the correct sensor type using the <code class="literal">SensorManager</code> class in the <code class="literal">onCreate</code> handler for this activity. Take note of the other handlers you would expect this activity to be associated with owing to its implementation of the <code class="literal">SensorEventListener</code> class:</p><pre class="programlisting">public class StepCounterActivity extends Activity implements SensorEventListener  
{ 
  private SensorManager mSensorManager; 
  private Sensor mSensor; 
 
  // Steps counted since the last reboot 
  private int mSteps = 0; 
 
  private static final String TAG =  StepCounterActivity.class.getName(); 
 
  @Override 
  protected void onCreate(Bundle savedInstanceState)  
  { 
    super.onCreate(savedInstanceState); 
    setContentView(R.layout.activity_daily_step_counter); 
 
    mSensorManager = (SensorManager) getSystemService(Context.SENSOR_SERVICE); 
    mSensor = mSensorManager.getDefaultSensor(Sensor.TYPE_STEP_COUNTER);   } 
 
  @Override 
  protected void onResume()  
  { 
    super.onResume(); 
    mSensorManager.registerListener(this, mSensor,  SensorManager.SENSOR_DELAY_NORMAL); 
    refreshStepCount(); 
  } 
 
  @Override 
  protected void onPause()  
  { 
    super.onPause(); 
    mSensorManager.unregisterListener(this); 
  } 
 
  @Override 
  public void onSensorChanged(SensorEvent event)  
  { 
    Log.i(TAG,"onSensorChanged - " + event.values[0]); 
    if(event.sensor.getType() == Sensor.TYPE_STEP_COUNTER)  
    { 
      Log.i(TAG,"Total step count: " + mSteps); 
      mSteps = (int) event.values[0]; 
      refreshStepCount(); 
    } 
  } 
  private void refreshStepCount()  
  { 
    TextView desc = (TextView)  findViewById(R.id.daily_step_count_desc); 
    desc.setText(getString(R.string.daily_step_count_desc,  mSteps)); 
  } 
 
  @Override 
  public void onAccuracyChanged(Sensor sensor, int accuracy)  
  { 
    Log.i(TAG,"onAccuracyChanged - " + sensor); 
  } 
} 
</pre><p>This is how our new activity appears on the wearable device:</p><p>
</p><div><img src="img/image00201.jpeg" alt="Add to-do item - a new action in the wearable app"/></div><p style="clear:both; height: 1em;"> </p><p>
</p><p>As shown in the preceding code, the type of sensor we use here is denoted by the <code class="literal">TYPE_STEP_COUNTER</code> constant of the <code class="literal">Sensor</code> class. This type of sensor gets the number of steps that the user has taken since the last reboot of the wearable device. The important thing to remember about this sensor type is that applications need to stay registered because the step counter does not track steps if it is not activated.</p><p>We chose this basic type of sensor because our focus was on using the API. Feel free to explore the <code class="literal">Sensor</code> API class here to study the other sensors available to you. In particular, take a look at the <code class="literal">TYPE_STEP_DETECTOR</code> sensor type. This one triggers an event every time the user takes a step. Unlike the step counter, which tracks steps taken over a period of time, the step detector is ideal for detecting a step at the very moment it is taken.</p><p>You can also think about how you would go about implementing a step counter for a given day—an exercise left to the interested reader who wants to make the most of our <code class="literal">Today</code> app.</p></div></div>
<div><div><div><div><h1 class="title"><a id="ch07lvl1sec51"/>Summary</h1></div></div></div><p>In this chapter, we demonstrated the creation of app-provided voice actions using the <code class="literal">Wear</code> API to launch our <code class="literal">Today Todo</code> app. We also introduced motion sensor concepts and examined the API classes that let us avail of these sensors. We then applied these concepts to augment our sample <code class="literal">Today</code> application with a simple activity that tracks the number of steps a user has taken.</p></div></body></html>