<html><head></head><body><div><div><div><div><h1 class="title"><a id="ch10"/>Chapter 10. Scene Management with Scene Graphs</h1></div></div></div><p>In this chapter, we will cover the following recipes:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Implementing the first scene using a scene graph</li><li class="listitem" style="list-style-type: disc">Adding local and relative transformations</li><li class="listitem" style="list-style-type: disc">Adding parent-child support in the scene graph</li><li class="listitem" style="list-style-type: disc">Creating complex models with a transformation graph</li><li class="listitem" style="list-style-type: disc">Implementing picking with the ray trace technique</li><li class="listitem" style="list-style-type: disc">Implementing 2D textured button widgets</li><li class="listitem" style="list-style-type: disc">Navigating the scene with a camera system</li><li class="listitem" style="list-style-type: disc">Implementing the scene with multiple views</li></ul></div><div><div><div><div><h1 class="title"><a id="ch10lvl1sec83"/>Introduction</h1></div></div></div><p>In all our previous chapters, we programed various recipes in a modeled centric way where we have an engine manager (renderer) that does all the required rendering activities for models. This approach is great for learning purposes, but in a real use case, we need scalability and manageability where multiple complex scenes can be handled easily. This chapter will introduce the scene-graph paradigm that allows you to program and manage complex scenes efficiently.</p><p><strong>Scene graph-based architecture</strong>: The present design we used in existing recipes contains a <a id="id755" class="indexterm"/>renderer engine, which works in conjunction with other helper classes to render programed models. This simple architecture is wonderful for quick prototyping purposes. This has already been demonstrated in all the recipes in previous chapters.</p><p>The modern 3D graphics use cases are not only limited to render a few chunks of objects in the 3D space, but the real-time challenge is to produce a state-of-the-art graphics engine that meets all modern graphical requirements. These include optimized rendering of complex scenes that involve a hierarchy of nodes, particles, mesmerizing shading effects, states, semantic logics, level of details, event handling, geospatial services, and so on. To meet these requirements, a modern 3D graphics application uses a scene graph-based architecture. The scene graph architecture encapsulates the hierarchical structure of a complete 3D scene, which has mainly two aspects: semantics and rendering. The semantic aspect works like a database, which manages the visual representation and state management. Think of it like a visual database that tells the graphical system the scene that's going to come and the scene that's not in use so that it can be released along with its resources for better optimization and memory management. On the other hand, the rendering aspect deals with the life cycle management of drawable entities or a model, which includes initialization, deinitialization, processing, control management and displaying them on screen.</p><p>The scene graph is a big <a id="id756" class="indexterm"/>and evolving topic. Covering all its (requirement) aspects is out of the scope of this title. In this chapter, we will create a small architecture that allows you to manage multiple scenes; each scene can consist of multiple lights, cameras, and models. Complex models can be created using the parent-child relationships, with the help of local and relative transformations. Models can be applied to predefined materials dynamically and all this will be done outside the graphics engine in a separate C++ file. This will keep the scene-graph hierarchy logic preserved at a single place so that it can be managed easily.</p><p><strong>Difference with the existing design</strong>: This chapter uses the knowledge of our existing rendering engine to produce the scene graph-based architecture. The existing design mainly consists of a renderer and model classes. The former is responsible for managing models, creating a single view, and processing events. On the other hand, the latter contains lights, material, performs the event handling process, and renders 3D objects.</p><p>For real-time 3D <a id="id757" class="indexterm"/>applications, we need to extend our design to meet the requirements of the scene graph architecture:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><strong>Hierarchical relationship</strong>: Various modules of the system can be arranged in a hierarchical fashion. For example, the <code class="literal">Application</code> module contains the <code class="literal">Renderer</code> module inside and the application works in a singleton fashion. However, it can produce many threads to run one renderer instance in each. Each <code class="literal">Renderer</code> instance contains a <code class="literal">Scene</code> module, which contains the <code class="literal">Model</code> and <code class="literal">Camera</code>. The scene module can create different views from various cameras to visualize the rendering of models on screen.</li><li class="listitem" style="list-style-type: disc"><strong>Objects with parent-child relationship</strong>: The objects of the similar type must support a parent-child relationship. In the parent-child relationship, a parent manages all its children automatically. This way, semantics and rendering can be managed in an optimized way.</li><li class="listitem" style="list-style-type: disc"><strong>Transforming graphs</strong>: Each renderable object in a system stores the transformation with respect to its parent. In order to understand this, let's take an example of a simple 3D model car that comprises of four tires, four doors, and a car body. If we want to translate this car by 2 units in the <em>x</em> axis direction, then using the existing design, we need to move all the nine parts of the car by 2 units. However, if we make the doors and tires as the children of the body of the car, then we do not need to worry about moving all nine parts; only the parent part (car body) will be enough to move all the related parts.</li><li class="listitem" style="list-style-type: disc"><strong>Multiple scene management</strong>: In the existing design, creating multiple scenes is not possible; in fact, everything is drawn as a single scene.</li><li class="listitem" style="list-style-type: disc"><strong>Separating semantic and rendering</strong>: The rendering of objects must be loosely coupled with semantics. The rendering output can be affected by a number of factors, such as change in state, user input, or both. The design should be flexible enough to manage states and events.</li><li class="listitem" style="list-style-type: disc"><strong>Level of Detail</strong> (<strong>LOD</strong>): LOD uses the computed information of an object and reveals <a id="id758" class="indexterm"/>how far it is from the camera view or an observer. If the object is outside the viewing frustum, then it can be ignored <a id="id759" class="indexterm"/>before it consumes vital resources of the system. The object in the frustum view, which are far away from the camera, can be rendered at a lower fidelity in which a fewer polygons and small textures can be used.</li><li class="listitem" style="list-style-type: disc"><strong>State encapsulation</strong>: It's important that each node or object in the system contains a state that is able to reveal the nature of the object. This way several similar types of objects can be clubbed together by traversing the parent-child hierarchy; this will be highly efficient in avoiding random state switches, for example, texture loading and binding.</li></ul></div><p>This chapter <a id="id760" class="indexterm"/>will take us through a systematic approach to develop scene graphs:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><strong>Implementing the first scene in the scene graph</strong> (<strong>recipe 1</strong>): This recipe will build the foundation of scene graph, in which it will support scene, model, light and the material module. The modeling will be done outside the rendering engine in the <code class="literal">NativeTemplate.cpp</code>.</li><li class="listitem" style="list-style-type: disc"><strong>Adding local and relative transformation</strong> (<strong>recipe 2</strong>): This recipe will introduce the local and the relative transformation concept to the existing scene graph. Local transformation is only applicable within the renderable object, whereas relative transformation is received from a parent and propagated to its children.</li><li class="listitem" style="list-style-type: disc"><strong>Adding parent-child support in the scene graph</strong> (<strong>recipe 3</strong>): This recipe builds the parent-child relationship between similar types of objects.</li><li class="listitem" style="list-style-type: disc"><strong>Creating complex models using a transformation graph</strong> (<strong>recipe 4</strong>): This recipe will make use of previous recipe concepts and demonstrate how to build complex animated models, such as a revolving windmill.</li><li class="listitem" style="list-style-type: disc"><strong>Implementing picking using the ray trace technique</strong> (<strong>recipe 5</strong>): This recipe will add the support of events to the scene graph and help in implementing the ray trace-based picking technique that allows you to select 3D objects in a scene.</li><li class="listitem" style="list-style-type: disc"><strong>Implementing 2D textured button widgets</strong> (<strong>recipe 6</strong>): Implementing 2D widgets uses the <a id="id761" class="indexterm"/>screen coordinate system. This recipe contains another subrecipe, which implements clicking on the button widget.</li><li class="listitem" style="list-style-type: disc"><strong>Navigating a scene with the camera system</strong> (<strong>recipe 7</strong>): This recipe will implement the camera support to the scene.</li><li class="listitem" style="list-style-type: disc"><strong>Implementing a scene using multiple views</strong> (<strong>recipe 8</strong>): This recipe enables scene graphics to render multiple views to a single scene.</li></ul></div></div></div>
<div><div><div><div><h1 class="title"><a id="ch10lvl1sec84"/>Implementing the first scene using a scene graph</h1></div></div></div><p>Let's start by <a id="id762" class="indexterm"/>looking at the block diagram of the existing engine (left) with the new expected scene graph (right) design. This design is segregated <a id="id763" class="indexterm"/>into many simpler reusable modules, where each module is self-explanatory in the image itself. The <code class="literal">Object</code> module is a base class for most of the other modules. These modules exhibit the parent-child relationship. Similarly, modules that support the event handling process must be inherited from the <code class="literal">Event</code>.</p><div><img src="img/5527OT_10_01.jpg" alt="Implementing the first scene using a scene graph"/></div><p>In the following image, you can see the hierarchical relationship among different modules in the scene graph. The <code class="literal">Renderer</code> is a graphics engine that contains various scenes. These scenes can be added to and removed from the rendering engine dynamically. A scene contains one or more cameras as per its requirements; it also contains models that the scene needs to render.</p><p>Transformation is managed in the model-view-projection analogy, where the modeling transformation is carried out in the <code class="literal">Model</code> module and the projection and viewing transformation is calculated in the <code class="literal">Camera</code> module. As we are aware, any renderable object must be derived from the <code class="literal">Model</code> class, which exhibits a parent-child relationship, where the parent is fully responsible for managing the life cycle of their children. The events in the system flow in the top-down direction and the native application receives the events and passes them on to the <code class="literal">Renderer</code>, which further propagates the event to the scene. The scene detects the view to which the event belongs to and the events are sent to all corresponding Model's derived classes in the view where it's finally handled:</p><div><img src="img/5527OT_10_02.jpg" alt="Implementing the first scene using a scene graph"/></div><div><div><div><div><h2 class="title"><a id="ch10lvl2sec273"/>Getting ready</h2></div></div></div><p>This first recipe will implement the basic structure of the scene graph architecture described previously <a id="id764" class="indexterm"/>in the introduction section. For this <a id="id765" class="indexterm"/>recipe, we will implement the <code class="literal">Renderer</code>, <code class="literal">Scene</code>, <code class="literal">Light</code>, and <code class="literal">Material</code> modules. For the <code class="literal">Model</code> class, the changes are very minor. In the scene graph approach, the <code class="literal">Renderer</code> has simplified with the addition of other modules. As we move on to subsequent recipes, we will break down the complexity further into simpler modules:</p><div><img src="img/5527OT_10_03.jpg" alt="Getting ready"/></div><p>In the next section, we will understand the step-by-step procedure to implement our first scene. This recipe builds the foundation class of the scene graph, where we will describe the class structure and the definition of important member functions.</p><div><div><h3 class="title"><a id="tip03"/>Tip</h3><p>Coding the definition of all functions may not be possible in this recipe. We will suggest our readers to follow the <code class="literal">SG1_withSceneLightMaterial</code> recipe provided with the sample code of this chapter to view the full source.</p></div></div></div><div><div><div><div><h2 class="title"><a id="ch10lvl2sec274"/>How to do it...</h2></div></div></div><p>Here are the <a id="id766" class="indexterm"/>steps to implement the scene graph <a id="id767" class="indexterm"/>architecture:</p><div><ol class="orderedlist arabic"><li class="listitem">The new <code class="literal">Renderer</code> class is created in <code class="literal">RendererEx.h</code>; this new version has very less code compared to the older version. It manages all the scenes contained in it and takes care of the life cycle, such as initialization and rendering:<div><pre class="programlisting">   class Renderer{
   std::vector &lt;Scene*&gt; scenes; // Scene List   

public:
void initializeScenes();     // Initialize Engine
void resize( int w, int h );// resize screen
void render();             // Render the Scenes
void addScene(Scene* scene);// Add new scene
   bool removeScene( Scene* scene); // Remove the scene
};</pre></div></li><li class="listitem">Define the member functions of <code class="literal">RendererEx.cpp</code>, as shown in the following code:<div><pre class="programlisting">// When renderer initializes it initiates each Scene
void Renderer::initializeScenes(){ 
     for( int i=0; i&lt;scenes.size();  i++ )
            scenes.at(i)-&gt;initializeScene();
}

// Resize all the scenes to adapt new window size
void Renderer::resize( int w, int h ){
  for( int i=0; i&lt;scenes.size();  i++ )
    scenes.at(i)-&gt;resize(w, h); 
}

// Add a new Scene into the rendering engine
void Renderer::addScene( Scene* scene){
  if(!scene) return;

  for( int i=0; i&lt;scenes.size();  i++ ){
      if(scenes.at(i) == scene ){
          return; // If already added return;
      }
  }

  scenes.push_back( scene );
  scene-&gt;setRenderer(this);
}

// No longer need a scene, then remove it
bool Renderer::removeScene(Scene* scene){
  for( int i=0; i&lt;scenes.size();  i++ ){
if(scenes.at(i) == scene){
scenes.erase(scenes.begin()+i); 
return true; 
}
  }
  return false;
}

// Render Each Scene
void Renderer::render(){ 
    glClearColor(0.0f, 0.0f, 0.0f, 1.0f);
    glClear(GL_COLOR_BUFFER_BIT|GL_DEPTH_BUFFER_BIT);

    for( int i=0; i&lt;scenes.size();  i++ )
        scenes.at(i)-&gt;render();
}</pre></div></li><li class="listitem">Create <a id="id768" class="indexterm"/>the <code class="literal">Light</code> class in <code class="literal">Light.h</code>/<code class="literal">.cpp</code> <a id="id769" class="indexterm"/>and implement it, as shown in the following code:<div><pre class="programlisting">class Light {
  private:
    int lightID;
  public:
    Material material;
    glm::vec4 position;
    GLfloat constantAttenuation, linearAttenuation,
            quadraticAttenuation;
    Light() {}
    Light(Material mt, glm::vec4 p, GLfloat ca = 1.0,
               GLfloat la = 0.2, GLfloat qa = 0.05) {
        material                = mt;
        position               = p;
        constantAttenuation    = ca;
        linearAttenuation      = la;
        quadraticAttenuation   = qa;
        enabled                = false;
    }
};</pre></div></li><li class="listitem">Similarly, create <code class="literal">Material.h</code>/<code class="literal">.cpp</code> and implement the <code class="literal">Material</code> class as follows:<div><pre class="programlisting">class Material{
public:
   glm::vec4 ambient, diffuse, specular;
   GLfloat shines;
   std::string name;
MaterialType typeOfMaterial;
   Material(glm::vec4  ambient, glm::vec4 diffuse,
 glm::vec4 specular, GLfloat shiness);
   Material(const Material &amp; p);
Material &amp; operator = (const Material &amp; p);
Material(MaterialType type = MaterialNone);
};</pre></div></li><li class="listitem">Define <a id="id770" class="indexterm"/>some common material <a id="id771" class="indexterm"/>types. For more information, refer to the sample code of this recipe:<div><pre class="programlisting">typedef enum {
    MaterialNone,
    MaterialGold,
    MaterialCopper,
} MaterialType;

// Copper Material
const vec4 CopperAmbient(0.19f, 0.07f, 0.022f, 1.0f);
const vec4 CopperDiffuse(0.70f, 0.27f, 0.082f, 1.0f);
const vec4 CopperSpecular(0.2f, 0.13f, 0.086f, 1.0f);
const GLfloat   CopperShiness = 2.8f;

// Gold Material
const vec4 GoldAmbient(0.24f, 0.19f, 0.07f, 1.0f);
const vec4 GoldDiffuse(0.75f, 0.60f, 0.22f, 1.0f);
const vec4 GoldSpecular(0.62f,0.55f, 0.36f, 1.0f);
const GLfloat   GoldShiness=51.2f;</pre></div><div><div><h3 class="title"><a id="note54"/>Note</h3><p>All float data type (<code class="literal">GLfloat</code> or <code class="literal">float</code>) variables should be declared explicitly with the additional <code class="literal">f</code> sign in the end. Otherwise, during assignment, the variables will be treated as double and casted to the floating type, which will drastically decrease the performance.</p></div></div></li><li class="listitem">Create a scene class in <code class="literal">Scene.h</code>. This manages the models it contains inside. Currently, it does not contain any camera in it. We will add the camera later in this chapter. The scene provides many services to models, such as managing shader programs, transformation services, rendering of models, and so on. Each scene can be recognized with a unique name. While rendering <a id="id772" class="indexterm"/>each model, the scene <a id="id773" class="indexterm"/>maintains the reference of the current rendering model in the <code class="literal">currentModel</code>:<div><pre class="programlisting">class Scene{
public:
Scene(string name="",Renderer* parentObj = NULL);  virtual ~Scene(void);       // Destructor
   void initializeScene();      // Initialize Scene
   inline ProgramManager* SceneProgramManager(){
 return &amp;ProgramManagerObj; }
    inline Transform*  SceneTransform() {
 return &amp;TransformObj;  }
    void render();              // Render the Models
    void initializeModels();    // Initialize Models
    void clearModels();         // Remove models
    void addModel( Model* );   // Add into model list
    void addLight( Light* );   // Add lights
    Renderer* getRenderer();    // Get scene's renderer
    void setUpProjection();      // Set projection
    std::vector&lt;Light*&gt;&amp; getLights(){ return lights; }

private:
    ProgramManager   ProgramManagerObj;
    Transform      TransformObj;
    vector&lt;Model*&gt; models; // Model's List
    vector&lt;Light*&gt; lights; // Light's List
    Renderer* renderManager;  // Scene's Renderer
    Model* currentModel;   // Current Model in use
};</pre></div></li><li class="listitem">A scene contains multiple lights and models; these models and lights are added to the scene using the <code class="literal">addModel</code> and <code class="literal">addLight</code> function defined in the <code class="literal">Scene.cpp</code>:<div><pre class="programlisting">void Scene::addModel(Model* model){
    if(!model) { return; }
models.push_back( model );
model-&gt;setSceneHandler(this);
}

void Scene::addLight( Light* lightObj){
    for(int i =0; i&lt;lights.size(); i++){
        if(lights.at(i) == lightObj) return;
    }
    lights.push_back(lightObj);
}</pre></div></li><li class="listitem">Create the <a id="id774" class="indexterm"/><code class="literal">Model</code> class in <code class="literal">ModelEx.h</code>. This <a id="id775" class="indexterm"/>new version of the <code class="literal">Model</code> class contains the material and parent scene object:<div><pre class="programlisting">class Model {
public:
   Model(Scene* SceneHandler, Model* model,
        ModelType type, string objectName="");  
  
   // Define setter and getter function for Scene
   // and material class. 

// Reuse the older Model class existing methods

protected:
   Scene*  SceneHandler; 
Material materialObj;
};</pre></div></li><li class="listitem">As the <code class="literal">ObjLoader</code> class is also a derivative of the <code class="literal">Model</code> class, it must also contain the reference of the scene under which it will execute. Modify the <code class="literal">ObjLoader</code> constructor to hold the scene reference and create two new functions (<code class="literal">ApplyLight</code>, <code class="literal">ApplyMaterial</code>) to apply the light and material information:<div><pre class="programlisting">class ObjLoader : public Model{
public:
    // Constructor for ObjLoader
    ObjLoader( Scene* parent, Model* model, MeshType
 mesh, ModelType type);
    void ApplyLight();   // Apply scenes light
    void ApplyMaterial();// Object's material

    // Rest of the function are same, for more info please
    // refer to SG1_withSceneLightMaterial recipe.
};</pre></div></li><li class="listitem">The new method to apply light and materials must be applied before rendering the mesh object to the <code class="literal">ObjLoader::render</code> method, as given in the following code:<div><pre class="programlisting">void ObjLoader::Render(){
    glUseProgram(program-&gt;ProgramID);
    ApplyMaterial();
    ApplyLight();

    // Apply Transformation.
 // Bind with Vertex Array Object for OBJ

    // Draw Geometry
    glDrawArrays(GL_TRIANGLES, 0, IndexCount );
    glBindVertexArray(0);
}</pre></div></li><li class="listitem">In <code class="literal">NativeTemplate.cpp</code>, create a scene in the <code class="literal">GraphicsInit</code> function and add a <a id="id776" class="indexterm"/>light and mesh object to it. Execute the <a id="id777" class="indexterm"/>scene by adding these objects to the engine:<div><pre class="programlisting">Renderer* engine   = NULL; 
ObjLoader* Suzzane = NULL; 
Scene* scene1      = NULL;

bool GraphicsInit(){
  // Create a new Renderer instance 
   engine = new Renderer(); 

// Add a new scene named "Mesh Scene" to engine
   scene1 = new Scene("MeshScene", engine);
    
   // Create a new light and set into the scene
   scene1-&gt;addLight(new Light(Material(MaterialWhite)
 ,glm::vec4(0.0, 0.0, 10.0, 1.0)));
    
   // Create Suzzane,added into the scene1.
   Suzzane = new ObjLoader(scene1,NULL,SUZZANE,None);
Suzzane-&gt;SetMaterial(Material(MaterialCopper));

   // Add Suzzane into Scene 
scene1-&gt;addModel( Suzzane); 
   
// Initialize engine 
engine-&gt;initializeScenes(); 
}</pre></div></li><li class="listitem">Similarly, the <code class="literal">GraphicsRender</code> function renders the mesh model and updates the scene and related modules. In this recipe, it applies various predefined material types on the mesh model for every one second:<div><pre class="programlisting">bool GraphicsRender(){
    static int i=0;   static clock_t start = clock();
 // Switch material each second
    if(clock()-start &gt; CLOCKS_PER_SEC){
        start = clock(); 
        (i %=6)++; //Plus one to avoid None type
  
       // Assign a new material   
        Suzzane-&gt;SetMaterial(Material(MaterialType(i)));
    }
   engine-&gt;render();
}</pre></div></li></ol></div></div><div><div><div><div><h2 class="title"><a id="ch10lvl2sec275"/>How it works...</h2></div></div></div><p>The <code class="literal">Renderer</code> class in the scene graph model is highly simplified compared to the earlier overloaded version; <code class="literal">Scenes</code> are a containment of the <code class="literal">Renderer</code> class. A scene must be created dynamically and added to the rendering engine. Similarly, it can be removed from the engine, which allows you to save vital memory resources and CPU cycles. Every scene has a <a id="id778" class="indexterm"/>unique name that can be used to retrieve the scene <a id="id779" class="indexterm"/>from the engine; the scene has a containment relationship with lights and models. Each scene can have multiple lights. However, the present implementation only supports a single light; the models retrieve the light information from their respective scenes. The implementation of a Model class has not changed much except for the fact that from now onwards the materials can be applied at runtime using the light information from the scene. The scene graph allows sharing the models from one scene to another without any overhead, thus making it highly flexible.</p><div><div><h3 class="title"><a id="note55"/>Note</h3><p>In order to differentiate the <code class="literal">Renderer</code> and <code class="literal">Model</code> classes of the older graphics engine with the scene graph architecture, the filenames of the newer class are suffixed with <code class="literal">Ex</code> (<code class="literal">RendererEx.h</code>/<code class="literal">.cpp</code>, <code class="literal">ModelEx.h</code>/<code class="literal">.cpp</code>).</p></div></div><p>The scene graph architecture allows you to create modeling of the scenes and the control logic outside the engine; this is a more generic and expected way of programming. This recipe uses <code class="literal">NativeTemplate.cpp</code> as an external file for modeling and rendering purposes. In this file, the initialization scene is done in the <code class="literal">GraphicsInit()</code>. First, the <code class="literal">graphicsEngine</code> rendering engine object is created. This engine is set to the <code class="literal">Scene's</code> object called <code class="literal">scene1</code> and the parameterized constructor of the <code class="literal">Scene</code> contains its name and the parent object of the rendering engine in which it resides. The scene contains a white light source, which is situated 10 units away in the <em>z</em> direction.</p><p>The <code class="literal">Model</code> object, namely, <code class="literal">Suzzane,</code> is created using the parameterized constructor of <code class="literal">ObjLoader</code> and is applied to the predefined copper colored material type.</p><p>The scene is controlled in <code class="literal">GraphicsRender()</code>. In this function, various types of materials are <a id="id780" class="indexterm"/>applied at runtime after a regular interval of one second, as shown in the following image:</p><div><img src="img/5527OT_10_04.jpg" alt="How it works..."/></div></div><div><div><div><div><h2 class="title"><a id="ch10lvl2sec276"/>See also</h2></div></div></div><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Refer to the <a id="id781" class="indexterm"/><em>Building prototypes using the GLPI framework</em> recipe in <a class="link" href="ch02.html" title="Chapter 2. OpenGL ES 3.0 Essentials">Chapter 2</a>, <em>OpenGL ES 3.0 Essentials</em></li></ul></div></div></div>
<div><div><div><div><h1 class="title"><a id="ch10lvl1sec85"/>Adding local and relative transformations</h1></div></div></div><p>Transformation can be divided into two types:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><strong>Local transformation</strong>: This type of transformation is only applicable to an object; it does not affect its child objects. For example, if two objects are in a parent-child <a id="id782" class="indexterm"/>relationship, then applying the local scale transformation will not scale the child object.</li><li class="listitem" style="list-style-type: disc"><strong>Relative transformation</strong>: This type of transformation is applied with respect to the parent <a id="id783" class="indexterm"/>of the object. Here, the transformation of the parent is propagated to the children, thereby affecting the geometrical vertex positions in the 3D space. For example, in this case, the scaling transformation to the parent object will scale all its children and their children.<div><div><h3 class="title"><a id="note56"/>Note</h3><p>If an object does not have a parent (called the <code class="literal">root</code> object), then the OpenGL ES coordinate system will be considered its parent. The next recipe will discuss more about the parent-child relationship.</p></div></div></li></ul></div><p>This recipe will create two mesh objects (<code class="literal">Torus</code>, <code class="literal">Suzzane</code>) and produce an effect similar to the moon's (<code class="literal">Suzzane</code>) revolution around the <code class="literal">Earth</code> (<code class="literal">Torus</code>). The moon not only revolves around Earth, but also revolves around its own axis at the same time.</p><div><div><h3 class="title"><a id="note57"/>Note</h3><p>For more information on the internals of the 3D transformation, you can refer to <em>Implementing scene with the model, view, and projection analogies</em> recipe in <a class="link" href="ch02.html" title="Chapter 2. OpenGL ES 3.0 Essentials">Chapter 2</a>, <em>OpenGL ES 3.0 Essentials</em>. This topic covers various types of transformation, transformation matrix conventions, homogenous coordinates, and transformation operations, such as translation, scaling, and rotation.</p></div></div><div><div><div><div><h2 class="title"><a id="ch10lvl2sec277"/>Getting ready</h2></div></div></div><p>This recipe requires the first recipe as a prerequisite; you are advised to understand the implementation of the first recipe. You can locate the source of the current recipe (<code class="literal">SG2_withSG1+Transformation</code>) that is provided with the sample code in this chapter.</p></div><div><div><div><div><h2 class="title"><a id="ch10lvl2sec278"/>How to do it...</h2></div></div></div><p>Here are the steps to <a id="id784" class="indexterm"/>implement local- and relative-transformation in the existing scene graph architecture:</p><div><ol class="orderedlist arabic"><li class="listitem">In <code class="literal">ModelEx.h</code>, add <a id="id785" class="indexterm"/>the following member variables in <code class="literal">Model</code> class. These variables are responsible for storing the local and relative transformation matrix. It also has a center of the origin around which the transformation will be applied:<div><pre class="programlisting">     mat4 transformation; mat4 transformationLocal; vec3 center;</pre></div></li><li class="listitem">Go to <code class="literal">ModelEx.cpp</code> and implement the local transformation function and the relative transformation function:<div><pre class="programlisting">   // Many line skipped, refer to source for CTOR/DTOR
   void Model::Rotate(float angle,float x,float y,float z){
  transformation = translate( transformation, center);
  transformation=rotate(transformation,angle,vec3(x,y,z));
  transformation = translate( transformation, -center);
}

void Model::Translate(float x, float y, float z ){
 transformation = translate(transformation,vec3(x,y,z));
}

void Model::Scale(float x, float y, float z ){    
 transformation = scale(transformation,vec3(x,y,z)); }

void Model::RotateLocal(float ang,float x,float y,float z){
transformationLocal = rotate(transformationLocal, ang,
                           vec3( x, y, z ) ); }

void Model::TranslateLocal(float x, float y, float z ){
    transformationLocal = translate
(transformationLocal, vec3( x, y, z ));
}
void Model::ScaleLocal(float x, float y, float z ){
          transformationLocal=scale(transformationLocal,vec3(x,y,z));
}
void Model::SetCenter(vec3 cntrPoint){center=cntrPoint;}
vec3 Model::GetCenter(){ return center; }</pre></div></li><li class="listitem">This step is <a id="id786" class="indexterm"/>extremely important; it provides the <a id="id787" class="indexterm"/>thumb rule to apply local and relative transformation in the <code class="literal">Model</code> functions derivative classes. For more information, see the implementation of the <code class="literal">Render()</code> function in the <code class="literal">ObjLoader.cpp</code> and add the following member functions to the respective variables:<div><pre class="programlisting">ObjLoader::Render(){
  // USE PROGRAM, APPLY MATERIAL AND LIGHT
     // APPLY RELATIVE TRANSFORMATION
      TransformObj-&gt;TransformPushMatrix();
      *TransformObj-&gt;TransformGetModelMatrix() =
*TransformObj-&gt;TransformGetModelMatrix()
*transformation;

      // APPLY LOCAL TRANSFORMATION
      TransformObj-&gt;TransformPushMatrix();
      *TransformObj-&gt;TransformGetModelMatrix() =
*TransformObj-&gt;TransformGetModelMatrix()
*transformationLocal;
            // RENDER GEOMETRY, REUSE CODE
            // POP LOCAL TRANSFORMATION
      TransformObj-&gt;TransformPopMatrix(); // Local Level
    
      Model::Render();
   // POP RELATIVE TRANSFORMATION
      TransformObj-&gt;TransformPopMatrix();
   }</pre></div></li><li class="listitem">In <code class="literal">NativeTemplate.cpp</code>, edit the <code class="literal">GraphicsInit()</code> function, as shown in the following code:<div><pre class="programlisting">// GLOBAL VARIABLES
//  Renderer* graphicsEngine;  ObjLoader* Suzzane;
//  ObjLoader* Torus; Scene* scene1;

  graphicsEngine = new Renderer();
  scene1         = new Scene("MeshScene", graphicsEngine);
  Suzzane        = new ObjLoader(scene1, NULL, SUZZANE, None);
  Torus          = new ObjLoader(scene1, NULL, TORUS, None);

// Set Light and Material
  scene1-&gt;addLight(new Light(Material(MaterialWhite),
  glm::vec4(0.0, 0.0, 10.0, 1.0)));
  Suzzane-&gt;SetMaterial(Material(MaterialCopper));
  Torus-&gt;SetMaterial(Material(MaterialGold));
  Torus-&gt;Scale(0.40, 0.40, 0.4);
  
  scene1-&gt;addModel( Suzzane ); //Add Suzzane to scene
  scene1-&gt;addModel( Torus );   //Add Torus to scene

// Set position in the 3D space.
  Suzzane-&gt;SetCenter(glm::vec3 (-3.0, 0.0, 0.0));
  Suzzane-&gt;Translate(3.0, 0.0, 0.0);

  graphicsEngine-&gt;initializeScenes(); //Init Scene</pre></div></li><li class="listitem">Use the same file and edit the <code class="literal">GraphicsRender()</code> function to apply the relative and local transformation on <code class="literal">Suzzane</code>, as shown in the following code:<div><pre class="programlisting">bool GraphicsRender() {
    Suzzane-&gt;Rotate(1.0, 0.0, 1.0, 0.0);     // Relative
    Suzzane-&gt;RotateLocal(6.0, 0.0, 1.0, 0.0);// Local
    graphicsEngine-&gt;render();    return true;</pre></div></li></ol></div></div><div><div><div><div><h2 class="title"><a id="ch10lvl2sec279"/>How it works…</h2></div></div></div><p>The transformation <a id="id788" class="indexterm"/>of each <code class="literal">Model</code> object is stored locally in the <a id="id789" class="indexterm"/>transformation and transformationLocal variable. These variables store the translate, rotate, and scaling information. The former variable accumulates all the transformation applied to the parent and its ancestors; each parent object propagates its transformation information to its children. The latter variable only stores the transformation information that is applied to the current object locally; it never passes this transformation to its children. The mechanism that differentiates between relative and local transformation needs to be implemented by a developer in the <code class="literal">Model</code> derived class in the <code class="literal">Render</code> function (see step three in the previous section):</p><div><img src="img/5527OT_10_05.jpg" alt="How it works…"/></div><p>In the current recipe, Torus will act as a reference to the center point of the parent OpenGL ES coordinate system. More specifically, the Torus will render to the OpenGL ES origin, which is (0.0, 0.0, and 0.0). The model is also scaled down and it appears like a center point. The <a id="id790" class="indexterm"/>
<code class="literal">Suzzane</code> performs two types of rotations in order to <a id="id791" class="indexterm"/>demonstrate the relative and local transformation. In the former transformation, the <code class="literal">Suzzane</code> will be placed 3 units away from the origin and also set with a center (0.0, 0.0, and -3.0) so that it can revolve around the new origin (center). However, in the latter transformation, <code class="literal">Suzzane</code> rotates around its own axis. In the <code class="literal">GraphicsRender</code> function, <code class="literal">Suzzane</code> is rotated by one degree on each frame locally and relatively, as shown in the following image:</p><div><img src="img/5527OT_10_06.jpg" alt="How it works…"/></div></div><div><div><div><div><h2 class="title"><a id="ch10lvl2sec280"/>See also</h2></div></div></div><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><em>Adding parent-child support in the scene graph</em></li></ul></div></div></div>
<div><div><div><div><h1 class="title"><a id="ch10lvl1sec86"/>Adding parent-child support in the scene graph</h1></div></div></div><p>This recipe <a id="id792" class="indexterm"/>is a very important milestone <a id="id793" class="indexterm"/>in the architecture of scene graphs; needless to say, a scene graph is all about the hierarchical connectivity. In the current concept, we maintain the parent-child relationship among similar types of objects. This recipe contains two subrecipes:</p><div><ol class="orderedlist arabic"><li class="listitem">Building a simple parent-child relationship among renderable objects</li><li class="listitem">Understanding the concept of a dummy parent<div><div><h3 class="title"><a id="note58"/>Note</h3><p>The parent-child relationship is applicable to all renderable objects (derived from the <code class="literal">Model</code> class) and logical engine entities, such as scenes, renderer, and so on. In the present scene graph architecture, this relationship is achieved through the <code class="literal">Object</code> class. This class allows you to add/remove children dynamically; each object can be recognized with a user-defined name.</p></div></div></li></ol></div><div><div><div><div><h2 class="title"><a id="ch10lvl2sec281"/>How to do it...</h2></div></div></div><p>Make use of the last recipe that we implemented in this chapter and the following steps to add the support of the parent-child relationship:</p><div><ol class="orderedlist arabic"><li class="listitem">Create <code class="literal">Object.h</code> and edit the following code. Each object of this class has a name, a parent, and one of more children stored in the child list. The parent's information is set in the constructor. This class provides high level functions for retrieving the parent or child information, which can be added or removed at fly time. The function of each name is self-explanatory to describe the kind of job it performs:<div><pre class="programlisting">class Object{
public:
    Object(string name="", Object* parentObj=NULL);
    virtual ~Object(){}
    void SetName(string mdlName){ name = mdlName;}
    string GetName() { return name; }

    void SetChild(Object* child = 0);
    void RemoveFromParentChildList();
    Object*  GetParent() { return parent; }
    vector&lt;Object*&gt;* GetChildren(){ return &amp;childList; }
    
    void SetVisible(bool flag,bool applyToChildren=false);
    bool GetVisible(){ return isVisible; }

protected:
    string name;          // Model's name
    Object* parent;      // Model's parent
    vector&lt;Object*&gt; childList; // Model's child list
 bool isVisible;      // Is Model Visible
};</pre></div></li><li class="listitem">Create <a id="id794" class="indexterm"/><code class="literal">Object.cpp</code> and define high level methods that cannot be defined inline in the header file. The constructor accepts the name and the parent (<code class="literal">parentObj</code>) of the object; the <code class="literal">RemoveParent</code> removes the parent of an object and ensures that none of the children <a id="id795" class="indexterm"/>exists in the parent <code class="literal">childList</code>:<div><pre class="programlisting">Object::Object(std::string objectName, Object* parentObj){
    parent = NULL;          name = objectName;
    SetParent(parentObj);   return;
}

void Object::RemoveParent()
{ RemoveFromParentChildList(); parent = NULL; }

void Object::SetChild(Object* child){
    for(int i =0; i&lt;childList.size(); i++){ 
if(child == childList.at(i)) { return; } 
 }
    child-&gt;parent = this;
    childList.push_back(child);
}

void Object::RemoveFromParentChildList(){
   for(int i=0; parent&amp;&amp;i&lt;parent-&gt;childList.size(); i++){
        if(this == parent-&gt;childList.at(i))
             { parent-&gt;childList.erase
(parent-&gt;childList.begin()+i); return; }
   }
}</pre></div></li><li class="listitem">Implement the <code class="literal">setVisible</code> and propagate the visibility of the children based on the last parameter: <code class="literal">applyToChildren</code>, if applicable:<div><pre class="programlisting">void Model::SetVisible(bool flag, bool applyToChildren){
    isVisible = flag;
    if(applyToChildren){
      for(int i =0; i&lt;childList.size(); i++)
        dynamic_cast&lt;Model*&gt;(childList.at(i))-&gt;
SetVisible( flag, applyToChildren );}
}</pre></div></li><li class="listitem">Derive the <code class="literal">Renderer</code>, <code class="literal">Scene</code>, and <code class="literal">Model</code> class from the <code class="literal">Object</code> class.</li><li class="listitem">In the derived version for <code class="literal">Model</code> classes, handle the object visibility, as given in the following code. For more information, refer to <code class="literal">ObjLoader::Render</code>:<div><pre class="programlisting">ObjLoader::Render(){
  // REUSE CODE, APPLY RELATIVE TRANSFORMATION
if(isVisible){
      // APPLY LOCAL TRANSFORMATION
// RENDER GEOMETRY, REUSE CODE   
   // POP LOCAL TRANSFORMATION
}
   // POP RELATIVE TRANSFORMATION
   }</pre></div></li><li class="listitem">Implement the rendering of child models:<div><pre class="programlisting">void Model::Render(){
    for(int i =0; i&lt;childList.size(); i++)
        dynamic_cast&lt;Model*&gt;(childList.at(i))-&gt;Render();
}</pre></div></li><li class="listitem">Use <a id="id796" class="indexterm"/><code class="literal">NativeTemplate.cpp</code> and add implement the parent-child modeling:<div><pre class="programlisting">Renderer* graphicsEngine; Scene* scene1;
ObjLoader *Sphere, *BaseSphere, *Cube[2];

bool GraphicsInit(){
    graphicsEngine = new Renderer();
    scene1 = new Scene("MeshScene", graphicsEngine);
    scene1-&gt;addLight(new Light(Material(MaterialWhite)
,vec4(0.0,0.0,10.0,1.0)));
    BaseSphere =  new ObjLoader   (scene1,NULL,SPHERE,None);
    BaseSphere-&gt;SetMaterial(Material(MaterialGold));
    BaseSphere-&gt;ScaleLocal(1.5,1.5,1.5);
    int j = 0;
    for(int i=-1; i&lt;2; i+=2){
      Cube[j] = new ObjLoader(scene1,BaseSphere,CUBE,None);
      Cube[j]-&gt;SetMaterial(Material(MaterialCopper));
      Cube[j]-&gt;Translate(10.0*i, 0.0, 0.0);
      for(int i=-1; i&lt;2; i+=2){
        Sphere=new ObjLoader(scene1,Cube[j],SPHERE,None);
        Sphere-&gt;SetMaterial(Material(MaterialSilver));
        Sphere-&gt;Translate(0.0, -5.0*i, 0.0);
      } j++;
    }
    scene1-&gt;addModel( BaseSphere);
    graphicsEngine-&gt;initializeScenes();
}

bool GraphicsRender(){
    BaseSphere-&gt;Rotate(1.0, 0.0, 1.0, 0.0);
    Cube[0]-&gt;Rotate(-1.0, 1.0, 0.0, 0.0);
    Cube[1]-&gt;Rotate( 1.0, 1.0, 0.0, 0.0);
    graphicsEngine-&gt;render();
}</pre></div></li></ol></div></div><div><div><div><div><h2 class="title"><a id="ch10lvl2sec282"/>How it works...</h2></div></div></div><p>Any renderable (<code class="literal">Model</code> and <code class="literal">derivatives</code>) or nonrenderable entities (<code class="literal">Renderer</code>, <code class="literal">Scene</code>, and <code class="literal">derivative</code>) can be derived from the <code class="literal">Object</code> class in order to achieve the parent-child relationship. The <code class="literal">Object</code> class stores the parent's information in the parent variable and child information in a vector list called <code class="literal">childList</code>; any other class object can access the parent and child information using the <code class="literal">GetParent()</code> and <code class="literal">GetChildren()</code> function.</p><div><div><h3 class="title"><a id="note59"/>Note</h3><p>Each parent is responsible for taking care of its children's execution life cycle. For example, a parent scene will automatically load the children scenes one by one. Similarly, a <code class="literal">Model</code> loads its children and manages their initialization to load the required shaders, propagating parent's transformation to children and rendering of each child model.</p></div></div><p>This recipe <a id="id797" class="indexterm"/>contains seven models (five sphere (one <a id="id798" class="indexterm"/>big, four small), two cubes), as shown in the following left-hand side image. The parent-child relationship is shown in the following right-hand side image in which the yellow sphere is the parent of two copper colored cubes and each cube has two silver color sphere attached to it. The yellow sphere rotates around the <em>y</em> axis; this makes all children elements to rotate around the yellow sphere, while the cubes revolve around the <em>y</em> axis. At the same time, they revolve around their own <em>x</em> axis, one in a clockwise direction and another in an anticlockwise direction:</p><div><img src="img/5527OT_10_07.jpg" alt="How it works..."/></div><div><div><h3 class="title"><a id="note60"/>Note</h3><p>Refer to <em>Create complex models with a transformation graph</em> recipe. This recipe guides you to create a windmill model using the parent-child relationship and local/relative transformation.</p></div></div></div><div><div><div><div><h2 class="title"><a id="ch10lvl2sec283"/>There's more...</h2></div></div></div><p>Look at the following image and try to figure out how we can solve it with the existing parent-child relationship approach.</p><p><strong>Problem statement</strong>:</p><p>A set of semi-circumferences (created from cubes) are arranged in a concentric fashion, where each <a id="id799" class="indexterm"/>semi-circumference rotates in the <a id="id800" class="indexterm"/>opposite direction with respect to its neighboring semi-circumference:</p><div><img src="img/5527OT_10_08.jpg" alt="There's more..."/></div><p>In the present situation, we have eight concentric semi-circumferences. Considering the innermost semi-circumference as the parent of others, one really has to scratch one's head to solve it (give it a try).</p><p>Sometimes, there are complex parent-child situations that can be solved easily. As a solution to this problem, we can create eight parents, apply transformations as required, create two parent objects (innermost), and add children, based on the direction of the rotation. Finally, move one parent clockwise and another anticlockwise. This recipe uses the previous solution with the dummy parent, which is described ahead.</p><p>So far, we have seen the all parent of the renderable entities, which are also renderable. This is where dummy parent concepts come into the picture. This allows you to create a parent, which does <a id="id801" class="indexterm"/>not have any geometry. Therefore, it cannot be rendered and provides a logical parent-child relationship. The <code class="literal">Render</code> method does not render anything and is only used to apply transformation. The local transformation here does not make any sense as the object's geometry does not exist:</p><div><pre class="programlisting">class DummyModel : public Model{
public:
   DummyModel(Scene* SceneHandler, Model* model, ModelType type,
           string objectName = "");  // Constructor
   virtual ~DummyModel(){}      // Destructor
      void Render();           // Render the dummy model.
};

DummyModel::DummyModel(Scene*  parentScene, Model* model, ModelType type,std::string objectName):Model(parentScene, model, type, objectName){}          // DummyModel CTOR.

void DummyModel::Render(){
   SceneHandler-&gt;SceneTransform()-&gt;TransformPushMatrix();
   ApplyModelsParentsTransformation();//Parent Transformation
       Model::Render(); // Base renderer process the childs
   SceneHandler-&gt;SceneTransform()-&gt;TransformPopMatrix();
}</pre></div></div><div><div><div><div><h2 class="title"><a id="ch10lvl2sec284"/>See also</h2></div></div></div><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><em>Creating complex models with transformation graph</em></li></ul></div></div></div>
<div><div><div><div><h1 class="title"><a id="ch10lvl1sec87"/>Creating complex models with a transformation graph</h1></div></div></div><p>A <a id="id802" class="indexterm"/>transformation graph is a forest of <a id="id803" class="indexterm"/>semantic transformations in which each node represents a tree of models. Combining all of these tree models produces a complex 3D model structure. The following image on the left-hand side shows a semantic model of the transformation. The right-hand side image shows a tree structure represented by each of the nodes in the semantic transformation graph:</p><div><img src="img/5527OT_10_09.jpg" alt="Creating complex models with a transformation graph"/></div><div><div><h3 class="title"><a id="note61"/>Note</h3><p>Transformation graphs use the parent-child relationship extensively. Without this, the transform graph hierarchy is very difficult to manage. A transformation graph represents node hierarchies, in which each child node contains the transformation information (translate, scale, and rotate) with respect to its parent.</p></div></div><p>This recipe is the hybrid of the previous two recipes. It will use the parent-child relationship and the local and relative transformation to produce a semantic transformation graph. In this recipe, you will learn how to create a complex windmill model with basic mesh models, such as cube, cylinder, and sphere.</p><div><div><div><div><h2 class="title"><a id="ch10lvl2sec285"/>How to do it...</h2></div></div></div><p>This recipe does not require any special changes in the scene-graph engine. Use <code class="literal">NativeTemplate.cpp</code> and edit the <code class="literal">GraphicsInit</code> and <code class="literal">GraphicsRender</code>, as shown in the following code:</p><div><pre class="programlisting">Renderer*    graphicsEngine;   Scene* scene1;
ObjLoader    *Base,   *Stand, *MotorShaft, *CubePlane;
ObjLoader    *Sphere,  *Torus, *Suzzane;

bool GraphicsInit(){
    graphicsEngine = new Renderer();
    scene1 = new Scene("MeshScene", graphicsEngine);
    scene1-&gt;addLight(new Light(
            Material(MaterialWhite),vec4(0.0, 0.0, 10.0, 1.0)));
    
    Base =  new ObjLoader(scene1, Sphere, CUBE);// Base
    Base-&gt;SetMaterial(Material(MaterialSilver));
    Base-&gt;SetName(std::string("Base"));
    Base-&gt;ScaleLocal(1.5, 0.25, 1.5);
    
    Stand = new ObjLoader(scene1,Base,SEMI_HOLLOW_CYLINDER);// Stand
    Stand-&gt;SetMaterial(Material(MaterialSilver));
    Stand-&gt;SetName(std::string("Stand"));
    Stand-&gt;Translate(0.0, 4.0, 0.0);
    Stand-&gt;ScaleLocal(0.5, 4.0, 0.5);
    
    MotorShaft = new ObjLoader(scene1,Stand,CUBE); // MotorShaft
    MotorShaft-&gt;SetMaterial(Material(MaterialSilver));
    MotorShaft-&gt;SetName(std::string("MotorShaft"));
    MotorShaft-&gt;Translate(0.0, 4.0, 1.0);
    MotorShaft-&gt;ScaleLocal(0.5, 0.5, 2.0);
    
    Sphere = new ObjLoader(scene1,MotorShaft,SPHERE);// MotorEngine
    Sphere-&gt;SetMaterial(Material(MaterialGold));
    Sphere-&gt;Translate(0.0, 0.0, 2.0);
    Sphere-&gt;SetName(std::string("Sphere"));
    
    for(int i=0; i&lt;360; i+=360/18){ // 20 Fan Blades
        CubePlane =  new ObjLoader   ( scene1, Sphere, CUBE);
        CubePlane-&gt;SetMaterial(Material(MaterialCopper));
        CubePlane-&gt;SetName(std::string("FanBlade"));
        CubePlane-&gt;Translate(0.0, 2.0, 0.0);
        CubePlane-&gt;SetCenter(glm::vec3(0.0, -2.0, 0.0));
        CubePlane-&gt;ScaleLocal(0.20, 2.0, 0.20);
        CubePlane-&gt;Rotate(i, 0.0, 0.0, 1.0);
    }

    scene1-&gt;addModel( Base);
    graphicsEngine-&gt;initializeScenes(); return true;
}

bool GraphicsRender(){
    Sphere-&gt;Rotate(3.0, 0.0, 0.0, 1.0);
    Base-&gt;Rotate(1.0, 0.0, 1.0, 0.0);
        graphicsEngine-&gt;render(); return true;
}</pre></div></div><div><div><div><div><h2 class="title"><a id="ch10lvl2sec286"/>How it works...</h2></div></div></div><p>The windmill model comprises of a total of 24 parts: one base, one stand, one motor shaft, one motor engine, and 20 fan blades. The base, motor shaft, and fan blades are made up of cube meshes, whereas the stand and motor engine is made up of cylinder and sphere meshes respectively. All these parts must be arranged in the correct parent-child order and at the same time applied to correct placement, using the local and relative transformation in the 3D space. A picture is worth a thousand words, by looking at the following image, you must have <a id="id804" class="indexterm"/>got the idea on how a <a id="id805" class="indexterm"/>complete model is woven part by part.</p><p>Let's understand the working of this windmill. In the <code class="literal">GraphicsInit()</code>, the first thing that we need is the base of the windmill, which is created using a perfect cube (<strong>A</strong>). This cube is locally scaled in order to produce a shape depicted by (<strong>B</strong>). Next, the stand is made from a cylinder and translated to four units (<strong>C</strong>) before the origin and then scaled (<strong>D</strong>) so that it perfectly expands in the vertical direction to fit in to the base. The base here is the parent of the stand. The motor shaft is also made up of the (<strong>E</strong>) cube, which translates into four units (<strong>F</strong>). This model is scaled locally in order to give it the (<strong>G</strong>) shape.</p><div><div><h3 class="title"><a id="note62"/>Note</h3><p>Every transformation that we apply is with respect to its parent. Therefore, in the present case, four units in the vertical direction are with respect to the stand, which is the parent of the <code class="literal">MotorShaft</code>.</p></div></div><p>Create a sphere in order to produce a <code class="literal">MotorEngine</code> (<strong>H</strong>) and render it to the <strong>+Z</strong> direction by two units (<strong>I</strong>). The final part is to create the fan blade. Each fan blade is made up of a cube (<strong>J</strong>). This cube needs to render away from the parent center by four units in the vertical direction (<strong>K</strong>). The translate blade is then applied to the local scaling in order to create a blade like shape (<strong>L</strong>). Similarly, this process of producing blades is repeated 20 times to build the complete fan (<strong>M</strong>, <strong>N</strong>).</p><p>Finally, once the geometry is created, the parent node (base) of the windmill is added to the scene. Why haven't the other models been added to the scene? In previous recipes, we mentioned that each parent model takes care of its children. As the base is added to the scene, it takes care of its child elements. The same rule is applicable to all child elements, which are themselves parents of other items:</p><div><img src="img/5527OT_10_10.jpg" alt="How it works..."/></div><p>The windmill fan blades rotate by three degrees around the <em>z</em> axis of each frame. This transformation can be simply achieved by applying the rotation on the sphere, which is the parent of <a id="id806" class="indexterm"/>all blades. Similarly, in <a id="id807" class="indexterm"/>order to revolve the whole model around the <em>y</em> axis, apply a one degree rotation on the base in the <code class="literal">GraphicsRender()</code>.</p></div><div><div><div><div><h2 class="title"><a id="ch10lvl2sec287"/>See also</h2></div></div></div><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><em>Adding parent-child support in the scene graph</em></li><li class="listitem" style="list-style-type: disc"><em>Adding local and relative transformations</em></li></ul></div></div></div>
<div><div><div><div><h1 class="title"><a id="ch10lvl1sec88"/>Implementing picking with the ray trace technique</h1></div></div></div><p>Picking <a id="id808" class="indexterm"/>is a process of selecting objects in the 3D space contained in a scene by user inputs. This is a very common requirement in <a id="id809" class="indexterm"/>3D graphic applications, where you may be interested in an object tapped by an end user. The tapped point contains position in the screen coordinate system, which is a reference to the viewport. This reference point can be used in various picking techniques to detect the tapped object. In the present recipe, we will use a very versatile picking technique called "ray picking" or "ray trace pick".</p><p>In this technique, a ray is simulated using the tapped point in the scene. When the ray intersects with an object, it's assumed to be clicked on. The ray can be intersected with multiple objects in a given scene; the selected objects can be collected and sorted according to the distance from the viewpoint in order to become the closest selected object. In this recipe, we will implement the ray trace picking technique, which is highly accurate in pinpointing 3D objects.</p><p>The following steps provide an overview of implementing ray tracing picking:</p><div><ol class="orderedlist arabic"><li class="listitem">Detect the tapped point on screen (Sx, Sy).</li><li class="listitem">Use (Sx, Sy) and find unprojected coordinates on the near (Nx, Ny) and far plane (Fx, Fy).</li><li class="listitem">Create a ray from (Nx, Ny) and (Fx, Fy) unprojected coordinates.</li><li class="listitem">Consider each triangle of the mesh geometry and perform the ray triangle intersection. The test can be optimized using a low polygon mesh.</li></ol></div><div><div><div><div><h2 class="title"><a id="ch10lvl2sec288"/>How to do it...</h2></div></div></div><p>Here are the <a id="id810" class="indexterm"/>steps to implement ray-trace <a id="id811" class="indexterm"/>picking:</p><div><ol class="orderedlist arabic"><li class="listitem">Create an interface class called <code class="literal">GestureEvent</code> derived from <code class="literal">Event</code> in a new file called <code class="literal">Event.h</code>/<code class="literal">.cpp</code>. This will provide the necessary interfaces for touch screen events. Classes that want to utilize the benefits of gesturing must be derived from the <code class="literal">GestureEvent</code> class:<div><pre class="programlisting">class Event {
 public:
   Event(){          // Define CTOR };
   virtual ~Event(){ // Define DTOR };
};
class GestureEvent : public Event {
  public:
   GestureEvent():Event(){  // Define CTOR }
   virtual ~GestureEvent(){ // Define DTOR }
   virtual void TouchEventDown(float x, float y) = 0;
   virtual void TouchEventMove(float x, float y) = 0;    
   virtual void TouchEventRelease(float x, float y) = 0;
};</pre></div></li><li class="listitem">The <code class="literal">Renderer</code>, <code class="literal">Scene</code>, and <code class="literal">Model</code> class need to be inherited with <code class="literal">GestureEvent</code> in order to support touch events. Include the <code class="literal">Event.h</code> header file in their respective classes:<div><pre class="programlisting">class Renderer: public Object, public GestureEvent
class Scene    : public Object, public GestureEvent
class Model    : public Object, public GestureEvent</pre></div></li><li class="listitem">Propagate gesture events to all scenes in the <code class="literal">Renderer</code> class:<div><pre class="programlisting">void Renderer::TouchEventDown(float x, float y){
    for( int i=0; i&lt;scenes.size();  i++ )
        { scenes.at(i)-&gt;TouchEventDown(x, y); } }
// Similarly, implement TouchEventMove &amp;
// TouchEventRelease like TouchEventDown.</pre></div></li><li class="listitem">Implement gesture interfaces in the <code class="literal">Scene</code> class and propagate the received touch events from renderer to all the models contained in the following code:<div><pre class="programlisting">void Scene::TouchEventDown(float x, float y){
    for( int i=0; i&lt;models.size(); i++ ){
      models.at(i)-&gt;TouchEventDown(x, y); }
}
//Similarly, defineTouchEventMove &amp; TouchEventRelease</pre></div></li><li class="listitem">Implement gesture interfaces in the <code class="literal">Model</code> and apply them to each child:<div><pre class="programlisting">void Model::TouchEventDown(float x, float y){
    for(int i =0; i&lt;childList.size(); i++){
      dynamic_cast&lt;Model*&gt;
       (childList.at(i))-&gt;TouchEventDown(x, y);}
}
//Similarly, define TouchEventMove &amp; TouchEventRelease</pre></div></li><li class="listitem">Create a <a id="id812" class="indexterm"/><code class="literal">Ray.h</code>/<code class="literal">.cpp</code> <a id="id813" class="indexterm"/>file and define the <code class="literal">Ray</code> class, as given in the following code:<div><pre class="programlisting">class Ray{
 public:
   vec3 dest, dir; // Destination and Direction
   Ray(){ dest = vec3(); dir = vec3(); }
   Ray(vec3 de, vec3 di){ dest = de; dir = di; }
   Ray(const Ray &amp; r){ dest=r.dest; dir=r.dir; }
   Ray &amp; operator=(const Ray&amp;r)
{dest=r.dest; dir=r.dir; return *this; }
};</pre></div></li><li class="listitem">Create a function called <code class="literal">IntersectWithRay</code> in the base <code class="literal">Model</code> class and implement in the <code class="literal">ObjLoader</code> derived class:<div><pre class="programlisting">bool ObjLoader::IntersectWithRay(Ray ray0,vec3&amp; intersect){
    vec4 p0, p1, p2;
    // COMPUTE EACH TRIANGLE AND CHECK INTERSECTION
    for(uint i=0; i&lt;objMeshModel-&gt;vertices.size(); i+=3){
     p0=vec4(objMeshModel-&gt;vertices.at(i).position,1);
     p1=vec4(objMeshModel-&gt;vertices.at(i+1).position,1);
     p2=vec4(objMeshModel-&gt;vertices.at(i+2).position,1);
     mat4 mat = *TransformObj-&gt;TransformGetModelMatrix();

     p0 = mat*GetEyeCoordinatesFromRoot() * p0;
     p1 = mat*GetEyeCoordinatesFromRoot() * p1;
     p2 = mat*GetEyeCoordinatesFromRoot() * p2;

     if (intersectLineTriangle(ray0.destination,
     ray0.dir, vec3(p0.x,p0.y,p0.z),
     vec3(p1.x,p1.y,p1.z), vec3(p2.x,p2.y,p2.z),
     intersect))
     { return true; }
    }
    return false;
}</pre></div></li><li class="listitem">Create a <a id="id814" class="indexterm"/>function called <code class="literal">IntersectWithRay</code> in the base <code class="literal">Model</code> class and implement it in the derived <a id="id815" class="indexterm"/>version classes, such as <code class="literal">ObjLoader</code>, in the present scenario:<div><pre class="programlisting">void ObjLoader::TouchEventDown( float x, float y ){
   GLint vp[4] = { 0, 0, 0, 0 }; //Store's viewport
   glGetIntegerv( GL_VIEWPORT, vp );
   vec4 viewport(vp[0], vp[1],vp[2], vp[3]);
   vec3 win(x, vp[3]-y, 0.0);
   vec3 nearPoint = glm::unProject(win, *TransformObj-&gt;
   TransformGetModelViewMatrix(), *TransformObj-&gt; TransformGetProjectionMatrix(), viewport);
   win.z = 1.0; // On the far plane.
   vec3 farPoint = glm::unProject(win,
*TransformObj-&gt;TransformGetModelViewMatrix(), *TransformObj-&gt;TransformGetProjectionMatrix(), viewport);
    Ray ray0(nearPoint, farPoint-nearPoint);
    glm::vec3 intersectionPoint;
    if(IntersectWithRay( ray0, intersectionPoint)){
      printf("Intersect with %s", GetName().c_str());
        isPicked = !isPicked;
     }

    Model::TouchEventDown(x,y); //Propagate to children
}</pre></div></li></ol></div></div><div><div><div><div><h2 class="title"><a id="ch10lvl2sec289"/>How it works...</h2></div></div></div><p>The <code class="literal">GestureEvent</code> class receives the tap event (Sx, Sy) in the screen coordinate system from the main application in Renderer and passes it to Model classes via the respective parent scene. These coordinates are then used to calculate unprojected coordinates on the near and far plane. In the present recipe, we have used the <code class="literal">glm::unproject</code> API:</p><p><strong>Syntax</strong>:</p><div><pre class="programlisting">void glm::unproject(vec3 const&amp; win, mat4 const&amp; modelView,
mat4 const&amp; proj, vec4 const&amp; viewport);</pre></div><div><table border="1"><colgroup><col style="text-align: left"/><col style="text-align: left"/></colgroup><thead><tr><th style="text-align: left" valign="bottom">
<p>Variable</p>
</th><th style="text-align: left" valign="bottom">
<p>Description</p>
</th></tr></thead><tbody><tr><td style="text-align: left" valign="top">
<p><code class="literal">win</code></p>
</td><td style="text-align: left" valign="top">
<p>Components <em>x</em>, <em>y</em> specify screen coordinates. The <em>z</em> with value zero and one specify the near and far plane respectively.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p><code class="literal">modelView</code></p>
</td><td style="text-align: left" valign="top">
<p>This specifies the product of the view and model matrix.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p><code class="literal">proj</code></p>
</td><td style="text-align: left" valign="top">
<p>This specifies the project matrix of the current scene.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p><code class="literal">viewport</code></p>
</td><td style="text-align: left" valign="top">
<p>This specifies the current dimension of the viewport region.</p>
</td></tr></tbody></table></div><p>The unproject <a id="id816" class="indexterm"/>inverts the operation of <a id="id817" class="indexterm"/>projection calculation in which world coordinates are used to calculate screen coordinate in the following order:</p><div><pre class="programlisting">Screen Coordinates =&gt; Viewport =&gt; Projection =&gt; ModelView =&gt; World coordinates</pre></div><div><img src="img/5527OT_10_11.jpg" alt="How it works..."/></div><p>Unprojected coordinates on the near plane (Nx, Ny) and the far plane (Fx, Fy) are used to shoot a ray from the near to the far plane, as shown in the preceding image (<strong>B</strong>). When this ray hits a 3D object, it is considered to be picked. Mathematically, this picking is performed by taking the intersection of mesh polygons and ray produced. For the sake of simplicity, we used the line and triangle intersection in the present recipe, as shown in  image (<strong>A</strong>). The mesh is iterated for each triangle in it and intersected by the ray using the <code class="literal">IntersectWithRay</code> function, which is inherited from <code class="literal">Model</code>. This function must be overridden in the derived version in order to perform the intersection test. The <code class="literal">ObjLoader</code> class overrides this function and calculates the ray-triangle intersection using the <code class="literal">glm::intersectLineTriangle</code> API. This recipe paints all the selected 3D mesh objects with <a id="id818" class="indexterm"/>ambient red, which are intersected by the ray. In order to find the closest selected object, sort the entire selected item and choose the closest one from the camera view.</p></div><div><div><div><div><h2 class="title"><a id="ch10lvl2sec290"/>See also</h2></div></div></div><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><em>Implementing 2D textured button widgets</em></li></ul></div></div></div>
<div><div><div><div><h1 class="title"><a id="ch10lvl1sec89"/>Implementing 2D textured button widgets</h1></div></div></div><p>OpenGL ES <a id="id819" class="indexterm"/>does not provide built-in UI components, such as buttons, radio box, checkbox, and so on. In general, these components are called 2D widgets and are laid out in the HUD in the screen coordinate system, where the <em>z</em> component is either zero or not at all used. This recipe will guide us to design and lay out 2D widgets on the screen coordinate system using OpenGL ES.</p><p>This recipe contains two recipes:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">The first recipe allows you to create the geometry of a simple button. Geometrical coordinates are specified in the local screen coordinate system, which is useful in designing the layout.</li><li class="listitem" style="list-style-type: disc">The second recipe is implemented in the <em>There's more...</em> section of this recipe, where we used the ray-picking technique, making the button clickable. Selecting the button will change its color.</li></ul></div><p>The next image shows the output of the first recipe. It contains six buttons of 32 x 32 dimensions. Each button is scaled by a factor of two, resulting in the final dimension of 64 x 64. The extreme left hand-side button (up button) is the parent of all the remaining buttons. This means any property applied to the parent will be propagated to all its children.</p><div><div><div><div><h2 class="title"><a id="ch10lvl2sec291"/>How to do it...</h2></div></div></div><p>Here are the steps to implement this recipe:</p><div><ol class="orderedlist arabic"><li class="listitem">Create <code class="literal">Button.h</code>/<code class="literal">.cpp</code> and define the <code class="literal">Button</code> class derived from the <code class="literal">Model</code> class:<div><pre class="programlisting">class Button : public Model{
public:
    Button(Scene* parent,Model* model,ModelType type,vec3*
 vertices,vec2* textureCoordinates,char* texture);
    virtual ~Button();      // Destructor for Button class
    void InitModel();    // Initialize our Button class
    void Render();       // Render the Button class
private:
 char MVP, TEX; Image* image;  char* textureImage;
    vec3 vertices[4]; vec2 texCoordinates[4];  
};</pre></div></li><li class="listitem">The <code class="literal">Button</code> <a id="id820" class="indexterm"/>class renders the geometry of the button. A button geometry has four vertices on which a texture is pasted, with the help of texture coordinates:<div><pre class="programlisting">void Button::Render(){
    glBindBuffer(GL_ARRAY_BUFFER, 0);
    glUseProgram(program-&gt;ProgramID);
    
    glDisable(GL_CULL_FACE); // Disable culling
    glEnable(GL_BLEND);      // Enable blending
    glBlendFunc(GL_SRC_ALPHA,GL_ONE_MINUS_SRC_ALPHA);

    glActiveTexture (GL_TEXTURE0);
    glUniform1i(TEX, 0);
    if (image)
  {glBindTexture(GL_TEXTURE_2D,image-&gt;getTextureID());}
    
    TransformObj-&gt;TransformPushMatrix(); //Parent Level
    ApplyModelsParentsTransformation();
    
    if(isVisible){
        TransformObj-&gt;TransformPushMatrix(); // Local Level
        ApplyModelsLocalTransformation();
        
        glEnableVertexAttribArray(VERTEX_POSITION);
        glEnableVertexAttribArray(TEX_COORD);
        glVertexAttribPointer(TEX_COORD, 2, GL_FLOAT,
GL_FALSE, 0, &amp;texCoordinates[0]);
        glVertexAttribPointer(VERTEX_POSITION, 3, GL_FLOAT,
                GL_FALSE, 0, &amp;vertices[0]);
        glUniformMatrix4fv( MVP, 1, GL_FALSE,TransformObj-&gt;
TransformGetModelViewProjectionMatrix());
        glDrawArrays(GL_TRIANGLE_STRIP, 0, 4); // Draw
        TransformObj-&gt;TransformPopMatrix();//Local Level
    }

    Model::Render();
    TransformObj-&gt;TransformPopMatrix(); //Parent Level
}</pre></div></li><li class="listitem">Set up the heads up display using the orthographic projection system:<div><pre class="programlisting">void Scene::setUpProjection(){
  TransformObj.TransformSetMatrixMode(PROJECTION_MATRIX );
  TransformObj.TransformLoadIdentity();
  int viewport_matrix[4];
  glGetIntegerv( GL_VIEWPORT, viewport_matrix );
  TransformObj.TransformOrtho( 0, viewport_matrix[2],
 viewport_matrix[3], 0 , -1, 1);
  TransformObj.TransformSetMatrixMode( VIEW_MATRIX );
  TransformObj.TransformLoadIdentity();
  TransformObj.TransformSetMatrixMode( MODEL_MATRIX );
  TransformObj.TransformLoadIdentity(); return;    
}</pre></div></li><li class="listitem">In <code class="literal">NativeTemplate.cpp</code>, edit the <code class="literal">GraphicsInit()</code> function, as given in the following code. This function lays out buttons on the screen coordinate system. These buttons accept geometrical vertices and texture coordinates as an input, which are optional parameters. If these parameters are not supplied. The dimension <a id="id821" class="indexterm"/>of the button will be equal to the image size. The texture coordinate has default values (0.0, 0.0) and (1.0, 1.0) as the bottom-left and top-right respectively:<div><pre class="programlisting">Renderer* graphicsEngine; 
Scene* scene2;
Button* buttonUp, *buttonDown, *buttonLeft,
Button* buttonRight, *buttonForward, *buttonBackward;

bool GraphicsInit(){
   graphicsEngine = new Renderer();    
vec2 texCoords[4]={ 
vec2(0.0, 0.0),
vec2(1.0,0.0), 
vec2(0.0, 1.0), 
vec2(1.0,1.0) 
};

vec3 vertices[4]={ 
vec3(0.0,0.0,0.0), 
vec3(400.0,0.,0.),
                          vec3(0.0,400.0,0.0),
vec3(400.0,400.0,0.0)
};
    
    scene2      = new Scene("ButtonScene");    
    buttonUp     = new Button(scene2, NULL, None,
NULL, texCoords, "dir_up.png");
    buttonUp-&gt;SetName(std::string("Direction Up"));
    buttonUp-&gt;Translate(50.0, 100, 0.0);
    buttonUp-&gt;Scale(2.0, 2.0, 2.0);
        
    // MAKE THE buttonUp AS PARENT OF OTHER BUTTONS
    buttonBackward = new Button(scene2, buttonUp,
None, NULL, texCoords, "dir_down.png");
    buttonBackward-&gt;SetName(string("Direction Backward"));
    buttonBackward-&gt;Translate(250.0, 0.0, 0.0);
    buttonBackward-&gt;SetCenter(vec3(16, 16, 0));
    buttonBackward-&gt;Rotate(-135.0, 0.0, 0.0, 1.0);
    // SIMILARLY DEFINE OTHER BUTTONS. . . . .
 // buttonDown, buttonLeft, buttonRight, buttonForward
    
    scene2-&gt;addModel(buttonUp); // ADD TO THE SCENE
    graphicsEngine-&gt;addScene(scene2);
    graphicsEngine-&gt;initializeScenes(); return true;
}</pre></div></li></ol></div></div><div><div><div><div><h2 class="title"><a id="ch10lvl2sec292"/>How it works...</h2></div></div></div><p>The geometry of the 2D button widget is created using four vertices, which are specified in the screen coordinate system. This geometry is textured with the specified image with the help of texture coordinates on the geometry. OpenGL ES works in the Cartesian system, where the origin exists in the center of the viewport dimension in the logical coordinate system. Viewport also has the same coordinate system and works in the pixel coordinate system, but the origin in this case exists in the bottom-left corner as shown in the following image. In contrast, the 2D widget is designed in the device coordinate system, where the origin is considered as the top-left corner (see the following image).</p><p>Now, head-up-display is a mechanism in which we can formulate the device coordinate system by using the OpenGL ES coordinate system and the viewport. For this, we need to render the projection system of the scene with an orthographic view where the origin is shifted in the top-right corner in the <code class="literal">setUpProjection</code> function.</p><p>The button <a id="id822" class="indexterm"/>class objects are created in <code class="literal">NativeTemplate.cpp</code> in the <code class="literal">GraphicsInit()</code> function, where six buttons are created with different images on it. Each button is given a unique name so that it can be used later in the camera recipe. The following image shows these buttons on the right-hand side. In order to make the job simpler for placement of icons in the 2D HUD screen space, we made the first button (up direction) as the parent of other buttons. This way, we all buttons can be resized and moved by applying a single operation on the parent itself. Finally, render these buttons to the HUD using <code class="literal">GraphicsRender()</code>:</p><div><img src="img/5527OT_10_12.jpg" alt="How it works..."/></div></div><div><div><div><div><h2 class="title"><a id="ch10lvl2sec293"/>There's more...</h2></div></div></div><p>Unlike how we implemented the picking technique in the last recipe, this time we will implement the picking technique in the button class, which will help us to know which button has been clicked on so that a user can perform the appropriate action in response to it. Refer to the next recipe in order to see how these buttons control the camera moved in a scene.</p><p>The <code class="literal">Button</code> <a id="id823" class="indexterm"/>class must be derived from the <code class="literal">GestureEvent</code> class and implemented to virtual gesture functions, such as <code class="literal">TouchEventDown</code> and <code class="literal">TouchEventRelease</code> in order to handle the gesture event and propagate them to child member objects:</p><div><pre class="programlisting">class Button : public Model, public GestureEvent
    {//Multiple code skipped};
void Button::TouchEventDown(float x, float y){
    GLint viewport_matrix[4]   = { 0, 0, 0, 0 };
    glGetIntegerv( GL_VIEWPORT, viewport_matrix );
    glm::vec4 viewport(viewport_matrix[0],viewport_matrix[1],
                       viewport_matrix[2],viewport_matrix[3]);
    glm::vec3 win(x, viewport_matrix[3]-y, 0.0);
    mat4 matMV  = *TransformObj-&gt;TransformGetModelMatrix();
    mat4 matMVP = *TransformObj-&gt;TransformGetModelMatrix();
    glm::vec3 nearPoint = unProject(win, mat, matMVP, viewport);
    win.z = 1.0;
    glm::vec3 farPoint = unProject(win, matMV,matMVP, viewport);
    Ray ray0(nearPoint, farPoint-nearPoint);
    
    glm::vec3 intersectionPoint;
    if(IntersectWithRay( ray0, intersectionPoint)){
        printf("Intersect with %s", this-&gt;GetName().c_str());
        isPicked = !isPicked; clicked = true; return;
    }
    Model::TouchEventDown(x,y);
}

void Button::TouchEventRelease( float x, float y ){
    clicked = false; isPicked = false;
    Model::TouchEventRelease(x,y);
}</pre></div><p>This class must override the <code class="literal">IntersectWithRay</code> function. In this, it performs a line and triangle intersection with two triangles that contains the button geometry. The following image shows the change in the color of the button when the touch down event occurs. The button gets restored to the original color when the touch release event fires:</p><div><img src="img/5527OT_10_13.jpg" alt="There's more..."/></div><p>Let's take a <a id="id824" class="indexterm"/>look at the following code:</p><div><pre class="programlisting">bool Button::IntersectWithRay(Ray ray0, vec3&amp; intersectionPoint){
    // CHECK INTERSECTION WITH FIRST TRIANGLE
    mat4 = *TransformObj-&gt;TransformGetModelMatrix();
    p0 = mat * GetEyeCoordinatesFromRoot() * vec4(vertices[0], 1.0);
    p1 = mat * GetEyeCoordinatesFromRoot() * vec4(vertices[1], 1.0);
    p2 = mat * GetEyeCoordinatesFromRoot() * vec4(vertices[2], 1.0);
    if ( intersectLineTriangle(ray0.destination, ray0.direction,
         vec3(p0.x,p0.y,p0.z), vec3(p1.x,p1.y,p1.z),
         vec3(p2.x,p2.y,p2.z), intersectionPoint)){
        return true;
    }

    // CHECK INTERSECTION WITH SECOND TRIANGLE
    p0 = mat * GetEyeCoordinatesFromRoot() * vec4(vertices[1], 1.0);;
    p1 = mat * GetEyeCoordinatesFromRoot() * vec4(vertices[3], 1.0);;
    p2 = mat * GetEyeCoordinatesFromRoot() * vec4(vertices[2], 1.0);;
    if ( intersectLineTriangle(ray0.destination, ray0.direction,
          vec3(p0.x,p0.y,p0.z), vec3(p1.x,p1.y,p1.z),
          vec3(p2.x,p2.y,p2.z), intersectionPoint)){
       return true;
    }
    return false;
}</pre></div></div><div><div><div><div><h2 class="title"><a id="ch10lvl2sec294"/>See also</h2></div></div></div><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><em>Refer to the Rendering text on Head Up Display recipe in <a class="link" href="ch08.html" title="Chapter 8. Font Rendering">Chapter 8</a>, Font Rendering</em></li></ul></div></div></div>
<div><div><div><div><h1 class="title"><a id="ch10lvl1sec90"/>Navigating the scene with a camera system</h1></div></div></div><p>In 3D graphics, a camera allows you to navigate <a id="id825" class="indexterm"/>through the 3D space; it can be used to perform the rotation and displacement on any arbitrary axis. In OpenGL ES, there is nothing such as a camera. This has to be implemented programmatically. Implementing a camera is extremely simple. In fact, we do not require any specific OpenGL ES APIs for this and it's all about manipulating matrices. In this recipe, we will simulate a first person camera.</p><div><div><div><div><h2 class="title"><a id="ch10lvl2sec295"/>How to do it...</h2></div></div></div><p>Reuse the last implement recipe and perform the following steps to implement the camera system:</p><div><ol class="orderedlist arabic"><li class="listitem">Create a <code class="literal">Camera.h</code>/<code class="literal">.cpp</code> file and define a <code class="literal">Camera</code> class derived from <code class="literal">Object</code>. This class contains three unit vectors: <code class="literal">Left</code>, <code class="literal">Up</code>, and <code class="literal">Forward</code>, which store directional unit vectors in the 3D space along the <em>x</em>, <em>y</em>, and <em>z</em> axis respectively. The <code class="literal">Position</code> specifies the location of the camera and Target specifies the location of the camera view:<div><pre class="programlisting">   struct ViewPort{ int x, y, width, height; };
   struct CameraViewParams{ float left, right, bottom, top,
   front, back; float fov, nearPlane, farPlane; };

   class Camera : public Object{
   vec3 Forward, Up, Right, Position, Target;
   CameraType type; // Type of cameras

   protected:
   int viewport_matrix[4]; ViewPort viewPortParam;
   CameraViewParams cameraViewParameters;

   public:
   Camera(string name, Scene* parent = NULL,
   CameraType camType = perspective);

   void Viewport (int x, int y, int width, int height);
   virtual void Render ();
   void Rotate(vec3 orientation, float angle);
   void MoveForwards( GLfloat Distance );
   // Similarly,define MoveBackwards, StrafeRightSide etc.

   void SetLeft(float val) {cameraViewParameters.left=val;}
   // Similarly,define SetRight, SetBottom, SetTop Etc.
        
   float GetLeft(){ return cameraViewParameters.left; }
   //Similarly, define GetRight, GetBottom, GetTop etc Etc.
   vec3 PositionCamera(){return Position + Forward;}
};</pre></div></li><li class="listitem">Define <a id="id826" class="indexterm"/>the rotation of the camera, as <a id="id827" class="indexterm"/>given in the following code:<div><pre class="programlisting">#define DEGREE_TO_RADIAN   M_PI / 180.0f
#define RADIAN_TO_DEGREE   180.0f / M_PI
#define COS(Angle) (float)cos(Angle*DEGREE_TO_RADIAN)
#define SIN(Angle) (float)sin(Angle*DEGREE_TO_RADIAN)

void Camera::Rotate(vec3 orientation, float angle){
  if(orientation.x == 1.0){ //Rotate along X axis
   Forward=normalize(Forward*COS(angle)+Up*SIN(angle));
   Up     = -cross( Forward, Right ); }

  if(orientation.y == 1.0){ //Rotate along Y axis
    Forward=normalize(Forward*COS(angle)-Right*SIN(angle));
    Right  = cross( Forward, Up ); }

  if(orientation.z == 1.0){ //Rotate along Z axis
   Left = normalize(Right*COS(angle)+Up*SIN(angle));
   Up   = -cross(Forward, Right); }
}</pre></div></li><li class="listitem">Make the camera move along the three axes using the move function, as shown in the following code:<div><pre class="programlisting">void Camera::MoveForwards(GLfloat d){   
  Position += Forward*d;
}

void Camera::StrafeRightSide(GLfloat d){
  Position += Left*d;
}

void Camera::StrafeUpside(GLfloat d){
  Position += Up*d;
}

void Camera::MoveBackwards(GLfloat d){
  MoveForwards( -d );
}

void Camera::StrafeLeftSide(GLfloat d){
  StrafeRightSide(-d);
}

void Camera::StrafeDownside(GLfloat d){
  StrafeUpside(-d); 
}</pre></div></li><li class="listitem">The <a id="id828" class="indexterm"/><code class="literal">Camera::Render()</code> sets up the <a id="id829" class="indexterm"/>projection matrix in the following code:<div><pre class="programlisting">void Camera::Render(){
  Scene* scene = dynamic_cast&lt;Scene*&gt;(this-&gt;GetParent());
  Transform* TransformObj = scene-&gt;SceneTransform();
  glViewport( viewPortParam.x, viewPortParam.y,
  viewPortParam.width, viewPortParam.height );
  TransformObj-&gt;TransformSetMatrixMode(PROJECTION_MATRIX);
  TransformObj-&gt;TransformLoadIdentity();

  if ( type == perspective ){
     // Multiple code line skipped
     // Apply perspective view:TransformPerspective
  }else{
     // Multiple code line skipped
     // Apply Orthographic view: TransformOrtho
  }
}
    
TransformObj-&gt;TransformSetMatrixMode(VIEW_MATRIX);
TransformObj-&gt;TransformLoadIdentity();
vec3 viewPoint = Position + Forward;
TransformObj-&gt;TransformLookAt(&amp;Position,&amp;viewPoint,&amp;Up);
    
TransformObj-&gt;TransformSetMatrixMode(MODEL_MATRIX);
TransformObj-&gt;TransformLoadIdentity();
}</pre></div></li><li class="listitem">Combine the two scenes that we created in previous recipes. The first scene contains the windmill. The second scene contains pick buttons. The former scene will <a id="id830" class="indexterm"/>be rendered to the perspective <a id="id831" class="indexterm"/>camera. However, the latter will make use of the HUD camera:<div><pre class="programlisting">Camera *camera1, *camera2;
bool GraphicsInit(){
    graphicsEngine = new Renderer();
    scene1   = new Scene("MeshScene", graphicsEngine);
    camera1 = new Camera("Camera1", NULL);
    scene1-&gt;addCamera(camera1);
    // Multiple code lines skipped
    graphicsEngine-&gt;initializeScenes();
    
    scene2   = new Scene("ButtonScene");
    camera2 = new CameraHUD("Camera2", scene2);
    // Multiple code line skipped
    graphicsEngine-&gt;addScene(scene2);
    graphicsEngine-&gt;initializeScenes();}

bool GraphicsResize(int width, int height){
   graphicsEngine-&gt;resize(width, height);
   camera1-&gt;Viewport(0, 0, width, height);
   camera2-&gt;Viewport(0, 0, width, height);}</pre></div></li></ol></div></div><div><div><div><div><h2 class="title"><a id="ch10lvl2sec296"/>How it works...</h2></div></div></div><p>A camera contains three orientation unit vectors: the forward (0.0, 0.0, and -1.0), right (1.0, 0.0, and 0.0), and up vector (0.0, 1.0, and 0.0). The first vector points to a direction where the camera is heading. For example, in the present case, the camera will move in the negative <em>z</em> axis direction. Similarly, the right vector specifies the direction of the movement in the <em>x</em> axis and the up vector in the <em>y</em> axis. The up vector can also be understood like a head, which specifies whether the camera is viewing a scene in the upside (0.0, 1.0, and 0.0) or upside down (0.0, -1.0, and 0.0) direction.</p><p>Using these vectors, the camera can be moved along any of the three axes. For example, if you want to move the camera five units ahead, then the product of <code class="literal">|5| *</code> forward will place your camera at (0.0, 0.0, or -5.0) looking in the same direction, whereas moving the camera right by four units places the camera at (4.0, 0.0, or -5.0). Again, the camera still looks in the negative <em>z</em> direction. In the present recipe, the camera's current position is translated using functions, such as <code class="literal">MoveForwards</code>, <code class="literal">StrafeRightSide</code>, <code class="literal">StrafeUpSide</code>, and so on. The orientation of the camera along <em>x</em>, <em>y</em>, or <em>z</em> axis can be changed using the <code class="literal">Rotate</code> function.</p><div><div><h3 class="title"><a id="note63"/>Note</h3><p>The camera displacement on any arbitrary axis specified by the forward, right, and up unit vector does not affect the orientation of the camera. The orientation remains unchanged and the camera will continue to look in the same direction specified by the forward vector. The orientation of the camera can only be effected when the camera rotates along any of the arbitrary axis.</p></div></div><div><img src="img/5527OT_10_14.jpg" alt="How it works..."/></div><p>The preceding image (part <strong>1</strong>) shows the effect of rotation on the forward (<strong>OC</strong>), right (<strong>OA</strong>), and up (<strong>OB</strong>) vectors, when the rotation of 45 degree is performed along the <em>z</em> axis. This <a id="id832" class="indexterm"/>results (image part <strong>2</strong>) in the new right (<strong>OE</strong>) and new <a id="id833" class="indexterm"/>up (<strong>OF</strong>) vector. The forward vector has no changes as it rotates along the <em>z</em> axis:</p><div><img src="img/5527OT_10_15.jpg" alt="How it works..."/></div></div><div><div><div><div><h2 class="title"><a id="ch10lvl2sec297"/>There's more...</h2></div></div></div><p>The current recipe contains two cameras for each scene. The first camera renders the perspective projection system. The second camera renders the scene to the head-up-display in the orthographic projection view. The <code class="literal">Camera</code> class that we implemented in the last recipe cannot be programmed for HUD camera requirements. Therefore, we need a new <code class="literal">Camera</code> derivative class called <code class="literal">CameraHUD</code> to implement HUD.</p><p>The following code shows the implementation of the HUD camera. The <code class="literal">Render</code> function is overridden. This function queries the current viewport dimensions and maps it to the orthographic left-right and top-bottom parameters in such a way that the origin shifts from center to the top-left, same as the device screen coordinate system. For more information on <a id="id834" class="indexterm"/>HUD, refer to the <em>See also</em> subsection in <a id="id835" class="indexterm"/>this recipe:</p><div><pre class="programlisting">class CameraHUD : public Camera{
public:
    CameraHUD(std::string name, Scene* parent = NULL);
    void Render();
    virtual ~CameraHUD();
};

   // Code skipped, see sample for CTOR and DTOR definition.
   void CameraHUD::Render(){ // Render HUD VIEW
    Scene* scene = dynamic_cast&lt;Scene*&gt;(this-&gt;GetParent());
    glViewport( viewPortParam.x, viewPortParam.y,
           viewPortParam.width, viewPortParam.height );

    Transform*  TransformObj = scene-&gt;SceneTransform();
    TransformObj-&gt;TransformSetMatrixMode(PROJECTION_MATRIX);
    TransformObj-&gt;TransformLoadIdentity();

    glGetIntegerv( GL_VIEWPORT, viewport_matrix );
    TransformObj-&gt;TransformOrtho( viewport_matrix[0],
       viewport_matrix[2], viewport_matrix[3],
        viewport_matrix[1] , -1, 1);
    // Code skipped, Load Model/View Matrix with Identity matrix.
   
}</pre></div></div><div><div><div><div><h2 class="title"><a id="ch10lvl2sec298"/>See also</h2></div></div></div><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><em>Refer to the Rendering text on Head Up Display recipe in <a class="link" href="ch08.html" title="Chapter 8. Font Rendering">Chapter 8</a>, Font Rendering</em></li></ul></div></div></div>
<div><div><div><div><h1 class="title"><a id="ch10lvl1sec91"/>Implementing the scene with multiple views</h1></div></div></div><p>One of the <a id="id836" class="indexterm"/>most common requirements for real time 3D applications is to render a scene to multiple view windows simultaneously. For example, a CAD/CAM-based application renders a scene to four types of views: perspective, orthographic front, side, and top view. In the scene graph architecture, multiple views are achieved with the help of rendering a scene to two or more cameras.</p><p>This recipe extends the last recipe to supporting multiple cameras, where each camera has different viewport region (which could be overlapped) and can have separate clear colors (depending on the requirement).</p><div><div><div><div><h2 class="title"><a id="ch10lvl2sec299"/>How to do it...</h2></div></div></div><p>Here are the <a id="id837" class="indexterm"/>steps to implement this recipe:</p><div><ol class="orderedlist arabic"><li class="listitem">Now on, the screen clear color and buffer clearing will be applied within the Camera view itself. Remove the clear code from <code class="literal">Renderer::render()</code>. Define a <code class="literal">vec4</code> type variable called <code class="literal">clearColor</code> to store the clear color information:<div><pre class="programlisting">void Camera::SetClearColor(glm::vec4 color){
    clearColor = color;
}</pre></div></li><li class="listitem">Apply the clear color information and framebuffers in <code class="literal">Camera::render()</code>. In the same function, make sure that <code class="literal">glViewPort</code> and <code class="literal">glScissor</code> are passed on with exactly same dimensions. The <code class="literal">glScissor()</code> works if the scissor test is enabled. It defines a rectangular screen space region in the screen coordinate system beyond which nothing will be drawn:<div><pre class="programlisting">void Camera::Render(){
   // Setup Viewport Info
   glViewport( viewPortParam.x, viewPortParam.y,
   viewPortParam.width, viewPortParam.height );
   // Apply scissoring
   glScissor ( viewPortParam.x, viewPortParam.y,
   viewPortParam.width, viewPortParam.height );

   glClearColor( clearColor.x, clearColor.y,
   clearColor.z, clearColor.w );
   glClear(GL_COLOR_BUFFER_BIT|GL_DEPTH_BUFFER_BIT);
    
   // Reuse code for Setting up Projection/Model/View
}</pre></div></li><li class="listitem">In <code class="literal">NativeTemplate.cpp</code>, edit the <code class="literal">GraphicsInit()</code> function as follows:<div><pre class="programlisting">Camera *camera1, *camera2, *camera3, *camera4;
bool GraphicsInit(){
    graphicsEngine = new Renderer();
    scene1  = new Scene("MeshScene", graphicsEngine);
    camera1 = new Camera("Camera1", scene1);
    camera2 = new Camera("Camera2", scene1);
    camera3 = new Camera("Camera3", scene1);
    camera4 = new Camera("Camera4", scene1);
    // Multiple code line skipped
}</pre></div></li><li class="listitem">Use <a id="id838" class="indexterm"/><code class="literal">GraphicsResize()</code> and define the viewport size for all the four cameras defined in the preceding code. Specify the clear color information for each camera in order to paint the background of view:<div><pre class="programlisting">bool GraphicsResize( int width, int height ){
   graphicsEngine-&gt;resize(width, height);
   // Third Quadrant
   camera1-&gt;Viewport(0, 0, width/2, height/2);
   camera1-&gt;SetClearColor(glm::vec4(0.0, 0.0, 0.0, 1.0));
   // Second Quadrant
   camera2-&gt;Viewport(0, height/2, width/2, height/2);
   camera2-&gt;SetClearColor(glm::vec4(1.0, 1.0, 1.0, 1.0));
   // Fourth Quadrant
   camera3-&gt;Viewport(width/2, 0, width/2, height/2);
   camera3-&gt;SetClearColor(glm::vec4(1.0, 0.0, 1.0, 1.0));
   // First Quadrant
   camera4-&gt;Viewport(width/2,height/2,width/2,height/2);
   camera4-&gt;SetClearColor(glm::vec4(1.0, 1.0, 0.0, 1.0));}</pre></div></li></ol></div></div><div><div><div><div><h2 class="title"><a id="ch10lvl2sec300"/>How it works...</h2></div></div></div><p>A multiview scene has multiple cameras rendering the present scene to different parts of screen regions. Each different region is specified by the viewport dimension specified in the camera. In order to support multiple views in the scene graph, we need to:</p><div><ol class="orderedlist arabic"><li class="listitem">Specify the viewport region. This will produce screen coordinates from the world coordinates of the scene with respect to the specified viewport dimension.</li><li class="listitem">Clear the color. This is the color used to clear the color buffer each time framebuffer is drawn.</li><li class="listitem">When a clear command is specified, it clears the complete framebuffer. As a consequence, you may not be able to see different views at all because the last camera's clear command has cleared the existing drawing in the framebuffer. This unexpected clearing of the color buffer can be avoided using the scissor test. In OpenGL ES 3.0, you can scissor a framebuffer region using the <code class="literal">glScissor</code> command, which defines a rectangular screen space region in the screen coordinate system beyond which nothing will be drawn.</li></ol></div><p>The following <a id="id839" class="indexterm"/>command needs to the specified in order to achieve multiple cameras before using any model, view, and projection matrix:</p><div><pre class="programlisting">glViewport( viewPortParam.x, viewPortParam.y,
          viewPortParam.width, viewPortParam.height );
glScissor ( viewPortParam.x, viewPortParam.y,
         viewPortParam.width, viewPortParam.height );
glClearColor( clearColor.x, clearColor.y,
         clearColor.z, clearColor.w );
glClear(GL_COLOR_BUFFER_BIT|GL_DEPTH_BUFFER_BIT);</pre></div><div><img src="img/5527OT_10_16.jpg" alt="How it works..."/></div></div><div><div><div><div><h2 class="title"><a id="ch10lvl2sec301"/>There's more...</h2></div></div></div><p>The <code class="literal">glScissor()</code> will only work if the scissor test is enabled; <code class="literal">glScissor</code> defines a rectangle and calls the scissor box in window coordinates. The first two arguments: <code class="literal">x</code> and <code class="literal">y</code> specify the lower-left corner of the box. The width and height specifies the dimensions of the box.</p><p>To enable and disable the scissor test, call <a class="ulink" href="https://www.khronos.org/opengles/sdk/docs/man/xhtml/glEnable.xml">https://www.khronos.org/opengles/sdk/docs/man/xhtml/glEnable.xml</a> and <a class="ulink" href="https://www.khronos.org/opengles/sdk/docs/man/xhtml/glDisable.xml">https://www.khronos.org/opengles/sdk/docs/man/xhtml/glDisable.xml</a> with the <code class="literal">GL_SCISSOR_TEST</code> argument. This test is initially disabled. When the scissor test is enabled, only pixels <a id="id840" class="indexterm"/>that lie within the scissor box can be modified by drawing commands. Window coordinates have integer values at the shared corners of framebuffer pixels.</p><p><strong>Syntax</strong>:</p><div><pre class="programlisting">void glScissor(GLint x, GLint y, GLsizei width, GLsizei height);</pre></div><div><table border="1"><colgroup><col style="text-align: left"/><col style="text-align: left"/></colgroup><thead><tr><th style="text-align: left" valign="bottom">
<p>Variables</p>
</th><th style="text-align: left" valign="bottom">
<p>Description</p>
</th></tr></thead><tbody><tr><td style="text-align: left" valign="top">
<p><code class="literal">x</code>, <code class="literal">y</code></p>
</td><td style="text-align: left" valign="top">
<p>This <a id="id841" class="indexterm"/>specifies the lower-left corner of the scissor box. The initial value of <code class="literal">x</code>, <code class="literal">y</code> is (<code class="literal">0</code>, <code class="literal">0</code>).</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p><code class="literal">width</code>, <code class="literal">height</code></p>
</td><td style="text-align: left" valign="top">
<p>This specifies the <code class="literal">width</code> and <code class="literal">height</code> of the scissor box. When a GL context is first attached to a window, the width and height are set to the dimensions of that window.</p>
</td></tr></tbody></table></div></div><div><div><div><div><h2 class="title"><a id="ch10lvl2sec302"/>See also</h2></div></div></div><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><em>Refer to the Rendering text on Head Up Display recipe in <a class="link" href="ch08.html" title="Chapter 8. Font Rendering">Chapter 8</a>, Font Rendering</em></li></ul></div></div></div></body></html>