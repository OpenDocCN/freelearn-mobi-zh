- en: '11'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Auditing and Monitoring Models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter is dedicated to covering the auditing and monitoring aspects of
    software systems. Implementing a robust auditing and monitoring strategy is key
    for an organization to improve the overall reliability, security, and performance
    of its systems while also gaining valuable insights to support data-driven decision-making
    and continuous improvement.
  prefs: []
  type: TYPE_NORMAL
- en: This is particularly crucial for distributed systems, where the increased complexity
    and inter-dependencies introduce additional challenges compared to traditional
    monolithic applications.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we’ll explore the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: The importance of auditing and monitoring
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The challenges of distributed system auditing and monitoring
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Key aspects of auditing and monitoring
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Basic elements of meaningful audit trails
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By the end of this chapter, you’ll have a solid understanding of how to establish
    robust auditing and monitoring capabilities for your systems, enabling you to
    proactively identify and resolve issues, ensure compliance, and maintain overall
    system health.
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'You can find the code files used in this chapter on GitHub: [https://github.com/Packt
    Publishing/Software-Architecture-with-Kotlin/tree/main/chapter-11](https://github.com/PacktPublishing/Software-Architecture-with-Kotlin/tree/main/chapter-11%0D)'
  prefs: []
  type: TYPE_NORMAL
- en: The importance of auditing and monitoring
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Auditing and monitoring are two distinct but closely related concepts that are
    critical for the effective management and oversight of a system.
  prefs: []
  type: TYPE_NORMAL
- en: Auditing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Auditing** is the systematic approach of reviewing, examining, and verifying
    the various aspects of a system to ensure its compliance, security, and overall
    integrity. Auditing covers the following key areas:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Compliance**: Inspecting the system’s conformity to relevant laws, regulations
    from authority, industry standards, and company policies.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Security**: Assessing the system’s security infrastructure, policies, and
    procedures. This includes vulnerability assessments, penetration testing, data
    protection mechanisms, and access controls.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Change management**: Reviewing the processes and documentation associated
    with system changes and updates.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Incident management**: Examining the effectiveness of responses to the system
    incident and disaster recovery procedures.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Performance**: Evaluating the efficiency of the system’s operations, resource
    utilization, and overall performance.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The auditing process typically involves collecting and analyzing various system
    logs, configuration files, user activities, documentation, and other relevant
    data to identify potential issues, vulnerabilities, and areas for improvement.
  prefs: []
  type: TYPE_NORMAL
- en: The auditing process is typically done at regular intervals. It’s common for
    organizations to have quarterly, semi-quarterly, and annual audits. The cadence
    is usually determined by factors such as the regulatory requirements, the system’s
    complexity, criticality, risk profile, and the organization’s overall risk management
    strategy.
  prefs: []
  type: TYPE_NORMAL
- en: A system of higher risk would suggest a more frequent auditing cadence, and
    some organizations may even exercise a continuous auditing process.
  prefs: []
  type: TYPE_NORMAL
- en: An ad hoc auditing process may be required in the face of certain events, such
    as a significant system change, security incident, major industry change, or regulatory
    update.
  prefs: []
  type: TYPE_NORMAL
- en: Monitoring
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Monitoring**, on the other hand, involves continuously observing and tracking
    a system’s operational state, performance, and behaviors. The following are some
    monitoring activities:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Real-time monitoring**: Continuously collecting and analyzing system metrics,
    such as system availability, resource utilization, network traffic, and error
    rates, to detect and respond to issues promptly'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Anomaly detection**: Identifying unusual or unexpected system behavior that
    may indicate potential problems or security threats'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Trend analysis**: Examining historical data to identify patterns, trends,
    and changes in the system’s performance and usage over time'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Alerting and notifications**: Triggering alerts and notifications when predefined
    thresholds or conditions are met, enabling proactive issue resolution'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Dashboards and reporting**: Providing visual representations of system health,
    performance, and key metrics to support data-driven decision-making'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Monitoring typically involves deploying various monitoring middleware components,
    agents, and frameworks that collect, aggregate, and analyze data from different
    components of the system.
  prefs: []
  type: TYPE_NORMAL
- en: Why are auditing and monitoring important?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Auditing and monitoring are critical for the effective management and operation
    of any system. Here are some of the key reasons why auditing and monitoring are
    so important:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Ensuring reliability and availability**: Proactive monitoring helps identify
    and address issues before they escalate into system failures or downtime. Real-time
    alerts and incident management enable rapid response and resolution of problems,
    minimizing the impact on end users. Comprehensive audit trails provide the necessary
    information to troubleshoot the root causes of system failures, improving the
    system’s reliability and availability.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Maintaining security and compliance**: Audit logs and data monitoring can
    be used to detect and investigate security breaches, unauthorized access attempts,
    and other malicious activities. Compliance regulations often mandate the implementation
    of robust audit and monitoring capabilities to ensure the integrity and confidentiality
    of sensitive data and systems. Audit reports and monitoring dashboards can demonstrate
    an organization’s adherence to compliance requirements, reducing the risk of penalties
    and reputational damage.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Optimizing performance and efficiency**: Monitoring system metrics and resource
    utilization can help with identifying bottlenecks, optimizing resource allocation,
    and improving overall system performance. Audit data can provide insights into
    usage patterns, workload trends, and areas for potential optimization.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Enabling data-driven decision-making**: Auditing and monitoring data can
    be leveraged to identify patterns and generate valuable business intelligence,
    supporting strategic planning and decision-making. Detailed reports and visualizations
    can provide stakeholders with a comprehensive understanding of the system’s health,
    performance, and overall status. Historical data and trend analysis can help with
    predicting future resource requirements, planning for capacity expansions, and
    identifying opportunities for process improvements.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Facilitating troubleshooting and root cause analysis**: Comprehensive audit
    trails and monitoring data can help engineers and support teams quickly identify
    the root causes of problems, reducing the time required for issue resolution.
    Detailed event logs and contextual information can aid in reconstructing system
    behaviors and recreating problematic scenarios. Auditing and monitoring data can
    be used to validate the effectiveness of implemented fixes and ensure that issues
    don’t recur.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By investing in robust audit and monitoring capabilities, organizations can
    ensure the reliability, security, and optimization of their distributed systems,
    ultimately delivering better experiences for their end users and stakeholders.
  prefs: []
  type: TYPE_NORMAL
- en: Auditing, monitoring, and measuring systems
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: “*You can’t improve what you don’t measure*” is a statement from the management
    consultant and writer *Peter Drucker*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Without measurement, the organization could fall into the following scenarios:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Opinion-based decision-making**: Without quantitative evidence, people can
    only express opinions they have little ground to base on. This leads to ineffective
    communication among stakeholders and engineers and a fragmented understanding
    of the problem.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Hit-and-miss improvement**: Any attempt to improve the system features or
    quality attributes becomes hit and miss. Some of them may work, and some of them
    may not, due to the lack of understanding of the problem. Even worse, there is
    little way to objectively reflect the effect of the improvement. The organization
    would then carry on the opinion-based decision-making in a vicious cycle.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'On the contrary, measuring the system via monitoring benefits the organization
    in the following ways:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Establishing baselines**: Measuring the current state of a system, whether
    it’s performance metrics, security integrity, or compliance conformity, provides
    the necessary baseline against which future improvements can be assessed and compared.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Identifying opportunities**: Measurement and monitoring data can uncover
    problems, bottlenecks, or inefficiencies within a system that may not be apparent
    without quantifiable evidence.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Tracking progress**: Once improvements or changes are implemented, continuous
    measurement and monitoring allow organizations to track the impact and effectiveness
    of those changes, ensuring that they make a positive impact and that desired outcomes
    are being achieved. If not, the organizations can decide to pivot from the original
    changes to avoid further deterioration.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Informed decision-making**: Reliable data and metrics enable data-driven
    decision-making, allowing organizations to prioritize and allocate resources more
    effectively toward the areas that will yield the greatest improvements. This is
    also an antidote to opinion-based decision-making. Quantitative evidence is one
    of the best ways to align people’s understanding and to effectively drive consensus
    on the improvement required.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Continuous optimization**: By establishing a culture of measurement and monitoring,
    organizations can continuously identify new opportunities for improvement, creating
    a cycle of ongoing optimization and refinement.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When are auditing and monitoring not necessary?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There are a few exceptions where auditing and monitoring may not be necessary.
  prefs: []
  type: TYPE_NORMAL
- en: If the system is extremely simple, with very few components and minimal dependencies,
    the need for comprehensive audit and monitoring may be reduced.
  prefs: []
  type: TYPE_NORMAL
- en: In experimental, low fidelity, or proof-of-concept systems, where the primary
    focus is on validating a specific concept, hypothesis, or functionality, the investment
    in audit and monitoring may not be a top priority. However, if the system turns
    out to be a viable ongoing business later, it’s worth investing more in auditing
    and monitoring.
  prefs: []
  type: TYPE_NORMAL
- en: Systems that are used for testing, personal experimentation, or other low-impact
    use cases may not warrant the same level of auditing and monitoring as mission-critical
    production systems.
  prefs: []
  type: TYPE_NORMAL
- en: Note that some systems or organizations may not be subject to strict regulatory
    or compliance requirements that mandate comprehensive audit and monitoring capabilities.
  prefs: []
  type: TYPE_NORMAL
- en: Also, some systems are isolated and even disconnected from the internet. If
    they have strict control access, it may be less critical to have extensive audits
    and monitoring.
  prefs: []
  type: TYPE_NORMAL
- en: If the system is designed to be temporary or short-lived, with a well-defined
    lifespan, the investment in comprehensive audit and monitoring may not be justified.
    This applies to one-off data processing tasks or systems with a predetermined
    sunset date.
  prefs: []
  type: TYPE_NORMAL
- en: The combination of auditing and monitoring provides a comprehensive approach
    to managing the integrity, security, and performance of a system, especially in
    complex distributed environments. Audit findings can help inform and enhance monitoring
    strategies while monitoring data can provide valuable inputs for the audit process.
    It’s most beneficial if auditing and monitoring go hand in hand for any organization.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing auditing and monitoring isn’t trivial in modern systems, where
    they’re usually distributed to multiple components. We’re going to discover these
    challenges in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: The challenges of distributed system auditing and monitoring
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Distributed systems pose several unique challenges that make their auditing
    and monitoring more complex than traditional monolithic architectures:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Distributed data sources**: In a distributed system, the relevant data and
    logs are scattered across multiple nodes, services, and communication channels.
    Collecting, aggregating, and correlating this information is a crucial but challenging
    task.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Dynamic infrastructure**: Distributed systems often involve highly dynamic
    infrastructure, with nodes and services being added, removed, or scaled on demand.
    Keeping track of the constantly evolving topology and resource utilization is
    essential for effective monitoring.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Interdependencies and cascading failures**: The intricate interdependencies
    between components in a distributed system can lead to cascading failures, where
    a failure in one part of the system triggers issues in other areas. Identifying
    and tracing these complex relationships is crucial for root cause analysis and
    recovery.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**A mixture of various technologies**: Distributed systems often incorporate
    a diverse set of technologies, including various programming languages, data stores,
    and middleware components. Developing a unified approach to auditing and monitoring
    that can handle this heterogeneity is a significant challenge.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Real-time responsiveness**: Distributed systems are often expected to provide
    real-time responsiveness, requiring auditing and monitoring solutions to process
    and analyze data at high speeds without introducing significant latency or performance
    overhead.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Compliance and regulatory requirements**: Many industries and organizations
    have strict compliance regulations that mandate comprehensive audit trails and
    monitoring capabilities. Ensuring that the distributed system meets these requirements
    is a critical responsibility.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To overcome these challenges, we’ll explore the key aspects of auditing and
    monitoring with concrete examples.
  prefs: []
  type: TYPE_NORMAL
- en: Capturing the appropriate data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To address these challenges and establish effective auditing and monitoring
    practices for distributed systems, we need to capture the most appropriate, basic
    building blocks.
  prefs: []
  type: TYPE_NORMAL
- en: Audit trails
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following are essential fields that are typically captured in audit trails:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Timestamp**: The date and time when the event occurred. It’s important to
    have a universal time zone for all audit trails. **Coordinated Universal Time**
    (**UTC**) is a sensible choice as it’s atomic and doesn’t tie to any time zone.
    There’s no daylight saving or clock change complication. It can easily be converted
    into any local time zone. It’s also a global standard for timekeeping. This is
    valuable information for correlating different actions that happened around the
    same time to reflect a pattern.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**User IDs**: The identifier of the user who performed or was affected by the
    action. The user’s identity must be tokenized and not contain any PII. This is
    often regulated by local laws and regulations, particularly on data protection
    and privacy. Therefore, using a tokenized user ID reduces most of the legal hassle
    of exposing user details. Accessing user information by user ID is restricted
    to only authorized individuals and local authorities.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Event or action type**: The type of event or action that’s been performed
    (for example, login, logout, data access, or data modification).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Details of the action performed**: The specific details of the action, which
    are usually the input parameters for the action. Different actions usually have
    different structures of data. Please note that the details may contain sensitive
    information that needs to be protected. The protection techniques for sensitive
    information will be covered in [*Chapter 14*](B21737_14.xhtml#_idTextAnchor442).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Resource accessed**: The resource involved in the action that’s been performed.
    It’s typically linked to an aggregate, an entity, or a value object. Often, it
    involves multiple of them.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Outcome**: The result or consequence of the action. It’s worth noting that
    success and failure outcomes are equally important in terms of capturing audit
    trails. For success, it’s essential to capture what will happen next. For failure,
    any error message or invocation stack trace should be included. Also, it’s important
    to capture any side effects so that further investigation can be performed on
    them.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Session ID**: The identifier of the session during which the event occurred.
    Having the session ID helps any correlation investigation figure out what other
    actions may have been performed in the same session.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Application ID**: The identifier of the application where the event occurred.
    This information helps engineers pinpoint where an issue may have occurred so
    that the situation can be improved.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Monitoring data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The data that’s captured for monitoring can look remarkably similar to audit
    trails. However, monitoring has a unique focus on metrics, availability, and the
    non-functional properties of a system. Here are the essential fields:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Timestamp**: The date and time of the event. Most of the modern systems use
    UTC over other time zones.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**System metrics**: CPU usage, memory usage, disk I/O, network traffic, messaging
    infrastructure, databases, and caches.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Application metrics**: The number of API calls, background job executions,
    response times, request rates, and error rates.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Service health**: Status of services (for example, up, down, or degraded).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Performance metrics**: The latency and throughput of operations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Logs**: Application logs and system logs.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Alerts**: Notifications under predefined criteria.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**User activities or business metrics**: General user activity patterns, not
    specific actions. This usually covers business-related patterns, such as “how
    many new users have signed up in the last 2 hours” or “how many transactions were
    created in the last 30 minutes.”'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Application log messages
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Application-level log messages are generated by code written by engineers with
    the aid of logging frameworks. Therefore, the quality of the log messages depends
    on engineers.
  prefs: []
  type: TYPE_NORMAL
- en: Each organization should define its conventions and best practices for logging
    messages. Several aspects need standardization.
  prefs: []
  type: TYPE_NORMAL
- en: Logging levels
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Organizing logging messages by hierarchical levels provides perspectives of
    the system at multiple levels of abstraction. It’s like a map of the system that
    can be zoomed in and out. Additionally, it defines the level of responses required
    for what happens in the system. Typically, there are six levels:'
  prefs: []
  type: TYPE_NORMAL
- en: '**TRACE**: The most detailed and fine-grained level of information. The message
    is very verbose and full of technical data that can be referenced to the source
    code. TRACE logging is usually only turned on in local development environments
    and exceptionally for troubleshooting critical problems in higher environments'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**DEBUG**: Less verbose than the trace level, the DEBUG log message provides
    information that may be needed for diagnosing and troubleshooting issues. The
    debug level is usually switched off in production environments but switched on
    in lower environments for testing purposes.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**INFO**: A standard-level log message that announces the change in application
    state or that something has happened. In the context of the real-life example
    we previously used for villagers, an info log message could be an announcement
    of a new household record being created, together with some essential information
    such as household name. INFO log messages intend to capture only the result of
    successful cases, and they require no corrective action. This is also the lowest
    level of log messages to be shown in a production environment.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**WARN**: An unexpected situation has happened in the application. There may
    be a problem within this instance in the process, but the application can continue
    to work. For example, there may be a request to delete a household that didn’t
    exist. It could indicate a data-consistent issue for that household record, but
    the application can carry on handling other requests. A WARN log message may require
    investigation by engineers, but not as an emergency.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**ERROR**: One or more functionalities can’t be completed. This isn’t a single
    instance of a failure but a consistent failure of a part of the system. The system
    has degraded, and corrective actions may be required to recover the failed functionality.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**FATAL**: A fundamental error in the crucial functionality no longer works.
    An example would be losing connection to a database so that none of the persistence
    functions can be completed. An urgent corrective action or even manual intervention
    is required to recover the situation.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Log message formats
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Having a consistent format in log messages helps engineers to quickly triage
    and identify issues. A good log message should contain a timestamp, the name of
    the logger, the log level, the thread name, the class name where the message was
    logged, and the message itself.
  prefs: []
  type: TYPE_NORMAL
- en: Luckily, most of this information is provided by the logging framework. However,
    engineers will still need to code the content of the logging message.
  prefs: []
  type: TYPE_NORMAL
- en: 'A good log message should have the following characteristics:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Concise**: The message should be short and ideally in one sentence.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Mindful use of tenses**: Two major tenses should be used. The past tense
    is used to describe what happened. Continuous tense is used for logging processes
    that are still running and should be concluded with a log message announcing the
    process has been completed.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Key information**: The message should contain the essential IDs so that engineers
    who read the message can troubleshoot the related issue. Engineers who wrote the
    log message can read the content from the console and run a drill troubleshooting
    session.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Incite an action**: Engineers can act on the log message, either as an investigation
    or confirmation of the outcome of a process as this would be valuable.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Consistent style**: A consistent style promotes easier understanding and
    faster response to a log message.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Logging frameworks
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Despite that different components may use different technologies and languages,
    the same logging framework should be used whenever possible. This would reduce
    the inconsistencies of log messages in the system, and thus reduce the cognitive
    load of engineers using the log messages for troubleshooting purposes.
  prefs: []
  type: TYPE_NORMAL
- en: Structured versus unstructured logging
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'An **unstructured log** message is a plain string with some formatting, as
    shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Given that the format is consistent, it isn’t too bad and can be read by humans.
    However, when it comes to log aggregation, alert triggering, and analysis, it’s
    hard to extract the exact information accurately and consistently.
  prefs: []
  type: TYPE_NORMAL
- en: '**Structured logging**, however, promotes well-defined fields and structures
    so that data can easily be extracted. The previous plain unstructured text log
    message can be expressed as a JSON object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Structured logging allows for custom fields that provide even more value to
    the log messages for further monitoring and analysis. This feature is powered
    by most logging frameworks.
  prefs: []
  type: TYPE_NORMAL
- en: 'The preceding logging message is supported by the `build.gradlde.kts`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'In the Logback configuration file, `logback.xml`, the Logstash encoder is used
    to format log messages as JSON strings:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, `structuredAppender` is attached to the root as a log appender. The code
    to log a structured message is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Apart from the main message, the `payload` field supports custom fields in key-value
    pair format.
  prefs: []
  type: TYPE_NORMAL
- en: It should be emphasized that the log message content is created in a Lambda
    expression, not as parameters. It’s optimal because the logging framework can
    choose not to execute the Lambda expression if this message has a lower log level
    than the configuration.
  prefs: []
  type: TYPE_NORMAL
- en: On the contrary, values that are passed in the log function as parameters are
    evaluated before the logging framework decides to use them. This may have a performance
    impact if we were to log very detailed information in a low log level such as
    TRACE.
  prefs: []
  type: TYPE_NORMAL
- en: Contextual logging, or Mapped Diagnostic Context (MDC)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Contextual logging**, also known as **Mapper Diagnostic Context** (**MDC**),
    aims to group or correlate log messages with the use of IDs (for example user
    ID, request ID, session ID, and so on). It highlights the fact that these log
    messages belong to the wider business context or process. This helps engineers
    identify and diagnose issues by going through a small set of log messages under
    the same context.'
  prefs: []
  type: TYPE_NORMAL
- en: This contextual data can also be used for monitoring and alerting. For example,
    it’s possible to monitor user activities by session ID to understand actions that
    are also performed together in a session.
  prefs: []
  type: TYPE_NORMAL
- en: Contextual logging can also cut through layers of abstraction in the log messages.
    There might be logging in the service layer, and the repository layer can be grouped
    by the contextual data.
  prefs: []
  type: TYPE_NORMAL
- en: Contextual logging is also compatible with structured logging. Contextual data
    is added as custom fields to the log messages within the scope so that these log
    messages can be grouped and analyzed.
  prefs: []
  type: TYPE_NORMAL
- en: 'Extending from the example provided for structured logging, Kotlin Logging
    provides a `withLoggingContext` function to facilitate MDC:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: The `withLoggingContext` function accepts multiple key-value pairs as the contextual
    data. In this example, `session` is added as the contextual data. The Lambda expression
    that follows defines the scope of the context, so all the function invocations
    in the Lambda expression will automatically have the contextual data added as
    custom fields to the structured log messages.
  prefs: []
  type: TYPE_NORMAL
- en: 'Optionally, the contextual data can be surfaced in the content of log messages
    by adding the contextual field in the log format:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'As a result, the JSON string log message is enhanced with contextual data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: The `session` field is automatically added to all messages that are logged inside
    the scope by the `withLoggingContext` function. This approach also separates the
    concern of logging contextual data from the main application logic. This contextual
    data doesn’t need to be passed into any function that’s invoked inside the scope.
  prefs: []
  type: TYPE_NORMAL
- en: There are wider scopes on how to centralize and aggregate data for monitoring
    and auditing purposes. We’re going to cover these next.
  prefs: []
  type: TYPE_NORMAL
- en: Centralizing and aggregating data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Previously, we discussed the challenges of auditing and monitoring distributed
    systems, one of which is the data that’s scattered across multiple places. It’s
    common to have a business process perceived as a unit but executed in multiple
    services and devices in distributed systems.
  prefs: []
  type: TYPE_NORMAL
- en: In this scenario, the auditing and monitoring data only makes sense when we
    can aggregate it into a centralized place for consolidation and analysis.
  prefs: []
  type: TYPE_NORMAL
- en: Centralized audit trail aggregation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let’s revisit the real-life example of villagers exchanging services and imagine
    that we need to aggregate auditing and monitoring data from numerous services.
    There are three services: **Household service**, **Contract service**, and **Notification
    service**. The need to aggregate audit trails would warrant a new generic subdomain
    service that collects all events that happened in other services. The new service,
    **Audit service**, and its interactions with other services are depicted in *Figure
    11**.1*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.1 – An example of Audit service interactions](img/B21737_11_1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.1 – An example of Audit service interactions
  prefs: []
  type: TYPE_NORMAL
- en: '**Audit service** consumes all events generated by the four other services.
    It’sresponsible for understanding these events, transforming them into standard
    data structures, and persisting them into permanent storage for queries in the
    future.'
  prefs: []
  type: TYPE_NORMAL
- en: This interaction pattern doesn’t require other services to know the existence
    of **Audit service**, reducing coupling or dependencies. Other services may need
    to change code just to inform consumers of what’s happened in their domain but
    without the burden of auditing requirements.
  prefs: []
  type: TYPE_NORMAL
- en: Alternative approach
  prefs: []
  type: TYPE_NORMAL
- en: The alternative approach would be to have other services imperatively inform
    **Audit service**, usually by calling a **REST endpoint**. This would make other
    services depend on **Audit service**. It’s also more complex for synchronous REST
    communication to provide the same reliability guarantees compared to asynchronous
    events. Now, all other services are aware of auditing requirements, which is considered
    a leak in the bounded context of auditing. So, this isn’t a recommended approach.
  prefs: []
  type: TYPE_NORMAL
- en: Audit data structure unification
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The downside of this approach is that **Audit service** must know the schema
    of all auditable events of all services. There are a lot of dependencies to manage
    in **Audit service**.
  prefs: []
  type: TYPE_NORMAL
- en: There’s a workaround for this problem. If the system can be aligned to adopt
    a standard envelope of all events, then the auditing fields are defined at the
    envelope level, while domain-specific fields are defined at the content level.
  prefs: []
  type: TYPE_NORMAL
- en: Having said that, it’s still essential to capture the domain-specific fields
    as part of the audit trail. These fields can be stored in their native formats
    without transformation. This transformation will only be needed when retrieving
    the data.
  prefs: []
  type: TYPE_NORMAL
- en: Linking related audit trails using IDs
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The ability to link related audit trails is paramount in reporting a complete
    business journey. This is typically implemented by generating a **correlation
    ID** for the entry point service or any other component that the distributed system
    needs to associate with related audit events. The events may not necessarily be
    part of the same request or transaction.
  prefs: []
  type: TYPE_NORMAL
- en: Correlation IDs are useful for troubleshooting and understanding the relationships
    between different components in a distributed system within a business journey,
    even if they’re not directly part of the same request flow.
  prefs: []
  type: TYPE_NORMAL
- en: Discoverability of event topics
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In a large distributed system, having to keep track of new event topics to
    be consumed by **Audit service** could be an exhausting effort. Ideally, **Audit
    service** should be able to discover and dynamically consume event topics. There
    are several ways to achieve this:'
  prefs: []
  type: TYPE_NORMAL
- en: Use service discovery mechanisms, such as service registries or service meshes,
    to discover the available event topics or event streams.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use a centralized event catalog, which can be in the form of a standalone service,
    or just a resource such as a last-value queue that can be accessed by **Audit
    service**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use messaging brokers. Some (for example, RabbitMQ and Kafka) provide APIs to
    discover event topics.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use configuration management tools such as Spring Cloud Config or Kubernetes
    as they provide APIs that can be used to look up event topics.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Once event topics have been looked up dynamically, as well as the standard envelope,
    **Audit service** can automatically consume and persist events in a dedicated
    database for audit reporting.
  prefs: []
  type: TYPE_NORMAL
- en: Example of an audit trail event
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Combining all the key aspects of audit trails that we discussed previously,
    we can come up with an example of the audit trail as a Kotlin data class. The
    most important element of an audit trail is the actor involved in the event:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: The `Actor` class uses a UUID as the tokenized identifier. While it typically
    represents a human user, it can sometimes be a scheduled trigger or an external
    system that kicks off a business journey. The type of actors (for example, user,
    external system, or scheduler) is captured by the `type` field. The involvement
    of the actor is captured by the `involvement` field – for example, “executed by,”
    “on behalf of,” and so on.
  prefs: []
  type: TYPE_NORMAL
- en: 'They use the `String` type in contrast to enumeration for two reasons:'
  prefs: []
  type: TYPE_NORMAL
- en: Adding a new enum value isn’t backward compatible
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Removing an existing enum value isn’t forward compatible
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Having it as a plain string ensures it can always be parsed to construct a full
    audit trail from the beginning of time, knowing that changes in values might be
    introduced in the future.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another important element is the resources involved:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Each resource is identified by a UUID, but it can just be a plain string. The
    resource also comes up as a `type` field, which can be the name of an aggregate,
    entity, or value object (for example, “household,” “contract,” and so on). It’s
    also useful to capture to which application the resource belongs. This information
    is captured as `application ID` (for example, “household service”). If the resource
    is versioned, then that’s also captured.
  prefs: []
  type: TYPE_NORMAL
- en: 'From these two data classes, the event envelope data class can be defined as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: It starts with an event ID as a UUID type and unique identifier. The session
    ID is captured to correlate activities that happened in the same login session.
    There’s a correlation ID that links multiple business activities together. The
    timestamp of the event is captured as the `happenedAt` field. The `action` field
    captures what initiates the business journey, while the `outcome` field captures
    the result as the event occurs.
  prefs: []
  type: TYPE_NORMAL
- en: 'The envelope uses the `Actor` class in two ways: it initiates the business
    journey and sets other actors that are involved in this event. A null set is treated
    the same as an empty set. The `Resource` class follows the same pattern in that
    there’s a main resource and other resources.'
  prefs: []
  type: TYPE_NORMAL
- en: The content of the event makes use of the generic `E` type as there will be
    many forms of events under the envelope.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, there’s a generic list of differences between the main resources before
    and after the event. A Kotlin data class can be expressed as a JSON object, and
    there are open source libraries that can generate a list in JSON Patch format
    given two JSON objects. Then, the list of differences can be represented by a
    data class – that is, `Difference`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: This class has four fields. The `op` field represents the data operation types
    such as “add,” “replace,” or “delete.”
  prefs: []
  type: TYPE_NORMAL
- en: The `path` field is the path of the field as if it were a JSON object – for
    example, */party/0/householdName*. The values that are changed before and after
    the event are captured as `fromValue` and `toValue`, respectively.
  prefs: []
  type: TYPE_NORMAL
- en: This audit trail envelope is just one example, and each organization should
    have an envelope that suits its needs. Next, we’ll turn our attention to monitoring
    data collection and aggregation.
  prefs: []
  type: TYPE_NORMAL
- en: Monitoring data collection and aggregation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Monitoring tools use a hugely different approach to collect their data. They
    use multiple methods to collect data from various sources, such as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Agents or daemons**: Small software components called agents are installed
    on the systems being monitored. These agents collect data and send it to a central
    monitoring server.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**System-level metrics**: These agents can collect various metrics, such as
    CPU usage, memory usage, disk I/O, network traffic, and more.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Application-level metrics**: Applications can log messages in the format
    so that they can be accounted for as a metric, or applications can submit the
    metric numbers directly to the monitoring tool. For example, a Kotlin/JVM application
    can use **Java Management Extensions** (**JMX**) to expose resource usage, application
    data, configuration, and performance metrics. JMX can be accessed as **Managed
    Beans** (**MBeans**) and can also be integrated with third-party monitoring tools
    for visualization and alert purposes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Log file collection**: These agents can listen to the system standard output
    and system error output. These agents can also tail the log files and send them
    to the monitoring data source. The log messages can also be directly submitted
    to a data source, such as Elastic Store, for aggregation purposes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Agentless**: By using standard network protocols, it’s possible to collect
    monitoring data, particularly network monitoring data, without installing an agent.
    For example, **Window Management Instrumentation** (**WMI**) provides an operating
    system interface where notifications and device-related information from the nodes
    are enabled. Another example is an extra node in a multicast UDP network that
    captures network metrics to be sent to the monitoring tool.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**API integration**: Some monitoring middleware software uses direct API integrations
    with services, applications, and cloud platforms. It can go both ways: either
    the node being monitored provides an API to expose monitoring data, such as Spring
    Actuator, or the monitoring tool provides an API for nodes to submit monitoring
    data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`measureTimeMillis`) and another for nanosecond precision (`measureNanoTime`):'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '**Trace IDs and span IDs**: A **trace ID** is a unique identifier that represents
    an end-to-end business process or request as it flows through a distributed system.
    It’s used to group all the individual spans (see the following paragraph) that
    are part of the distributed transaction or request. Trace IDs allow us to understand
    the complete journey of a request as it moves across multiple services, components,
    and systems.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'A **span ID** is a unique identifier for a single operation or unit of work
    within a distributed transaction or request. Spans represent individual steps
    or operations that are performed as part of a larger trace, such as an HTTP request,
    a database query, or a function call. Spans are hierarchical and can be nested
    within a trace to represent the different components, services, or processes involved
    in handling a single request. The relationship between trace IDs and span IDs
    is shown in *Figure 11**.2*:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 11.2 – Trace IDs and span IDs in a real-world example](img/B21737_11_2.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 11.2 – Trace IDs and span IDs in a real-world example
  prefs: []
  type: TYPE_NORMAL
- en: Here, one request is coming from the mobile application through **Contract Service**
    to amend a contract, while **Trace ID 215** and **Span ID 12** are assigned to
    this request. **Contract Service** requests household information from **Household
    Service** while processing the request. This means that **Household Service**
    is involved in processing this request, as indicated by **Trace ID 215** but a
    different span value – that is, **Span ID 13**. **Contract Service** notifies
    **Notification Service** to send emails to the affected households, so **Notification
    Service** is also involved in this request, using the same trace – that is, **Trace
    ID 215** – but a new span – that is, **Span** **ID 14**.
  prefs: []
  type: TYPE_NORMAL
- en: With many third-party monitoring tools on the market (for example, **Elastic
    Slack** (**ELK**), Splunk, Datadog, Kibana, Prometheus, Grafana, New Relic, Jaeger,
    and others) and various methods in collecting data, it’s recommended to avoid
    the vendor lock-in issue. It may become too expensive to consider other monitoring
    tools if the system is integrated with the monitoring tools using proprietary
    methods.
  prefs: []
  type: TYPE_NORMAL
- en: OpenTelemetry (OTel)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**OpenTelemetry** (**OTel**) is a community-driven open source framework that
    aims to standardize the way we collect, process, and export observability data
    from applications. It provides a set of APIs, libraries, agents, and instrumentation
    tools that can support various programming languages and frameworks. This interoperability
    makes it possible to trace and monitor applications that use different technologies,
    and we can monitor the system holistically.'
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, it’s cheaper to migrate from one monitoring tool to another given
    they all use OTel as a standard, and thus we aren’t locked into using only one
    vendor.
  prefs: []
  type: TYPE_NORMAL
- en: 'Setting up OTel begins with using its libraries. This is shown in the following
    code, which uses the Gradle Kotlin DSL:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'The next step is to configure the `tracer` and `span` processors:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding code defines an endpoint to export telemetric data to an `Tracer`
    object is created to be used in the traceable process. Let’s look at how this
    object is used in starting and ending a span:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: This example `main()` function starts a span with a custom attribute added to
    provide contextual information. If the process succeeds, the span is acknowledged
    and ended. Otherwise, the span records the exception that has been captured.
  prefs: []
  type: TYPE_NORMAL
- en: It’s important to note that the monitoring APIs are designed to not throw errors
    that would otherwise interfere with the actual process. In this example, the code
    will run even if the OTLP server can’t be reached.
  prefs: []
  type: TYPE_NORMAL
- en: This data will be exported to a monitoring tool for further usage, something
    we’re going to cover in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Metrics, visualization, and dashboards
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Since monitoring data is centralized and aggregated, a monitoring tool can start
    using this data for many purposes. For example, heartbeat messages and regular
    health checks of applications provide an uptime ratio per application as a metric.
    This metric can be visualized in a dashboard that operators and engineers can
    observe.
  prefs: []
  type: TYPE_NORMAL
- en: We must create intuitive visualizations and dashboards that provide a clear,
    at-a-glance understanding of the distributed system’s health, performance, and
    overall status.
  prefs: []
  type: TYPE_NORMAL
- en: The metrics that are measured and visualized on dashboards can be grouped into
    two categories.
  prefs: []
  type: TYPE_NORMAL
- en: '**Service-level metrics**: Known as **service-level indicators** (**SLIs**),
    these metrics measure the reliability, availability, latency, and performance
    of a system at the service level. It focuses on the **Quality of Service** (**QoS**)
    provided to users and external systems.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Apart from the common metrics, such as CPU utilization, network latency, memory
    used, and disk space utilization, metrics that are part of the **service-level
    objective** (**SLO**) and **service-level agreement** (**SLA**) should be highlighted
    in the dashboard. These are sensitive metrics that could affect customer satisfaction,
    relationships with external entities, and the reputation of the organization.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: A typical service-level metric is the response time to a frequently used feature.
    Application response time is likely part of the SLO or SLA and should be measured
    and visualized continuously.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: SLA versus SLO versus SLI
  prefs: []
  type: TYPE_NORMAL
- en: A SLA is a formal contract between a service provider and a customer that defines
    the expected level of service, including the specific performance metrics that
    are guaranteed and penalties for not meeting the agreement.
  prefs: []
  type: TYPE_NORMAL
- en: A SLO is a specific and measurable goal that defines the target level of the
    service. It sets the performance standards that the service provider aims to achieve.
  prefs: []
  type: TYPE_NORMAL
- en: A SLI is a metric that’s used to measure the performance of a service, in particular
    against SLOs. It provides the data needed to determine whether the SLOs are being
    met.
  prefs: []
  type: TYPE_NORMAL
- en: '**Business-level metrics**: Business-level metrics focus on patterns and usage
    that should bring awareness to the business. For example, an e-commerce system
    would be interested in monitoring how many new users have signed up in the system.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Business-level metrics are often compared against the defined **key performance
    indicators** (**KPIs**), which are used to demonstrate how effectively an organization
    achieves its **objectives and key** **results** (**OKRs**).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The **objective** part of OKR is a qualitative and visionary goal that may not
    be measurable. However, the **key results** are measurable and usually set up
    regularly.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'In this example of users signing up for the e-commerce system, the objective
    can be to “*sign up as many active purchasing users as possible.*” This objective
    can be translated into the following key results:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Sign up 30% of new users in the **third** **quarter** (**Q3**)
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Ensure 80% of new users stay active in the last 30 days in Q3
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Ensure 50% of new users purchase at least one item in the system in the last
    30 days in Q3
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: These key results are missions within the boundary of time. They’re measurable
    goals that aim to inspire bold goals.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'On the other hand, KPIs continuously measure performance. To support the aforementioned
    OKRs, the following KPIs need to be measured:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The number of users signed up in the last 3 months (that is, new users)
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: The number of new users that logged in to the system in the last 30 days
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: The number of new users who bought at least one item in the last 30 days
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: The number can be collected and aggregated from either application log messages
    or from persistent databases directly.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: An example of comprehensive metrics – DORA
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Measuring metrics can be an anti-pattern if there’s a way to game the numbers
    but not improve anything. For example, if the metrics are only about service uptime,
    then it’s possible to have 100% uptime for services that can’t perform any operation
    other than answering health checks.
  prefs: []
  type: TYPE_NORMAL
- en: It’s important to have a comprehensive suite of metrics to close this loophole.
    If multiple metrics measure various aspects of the subject, gaming one metric
    would skew the others and therefore be impossible to hide. In this section, we’re
    going to run through an example of comprehensive metrics and how they avoid cheating.
  prefs: []
  type: TYPE_NORMAL
- en: '**DevOps Research and Assessment** (**DORA**) metrics are a set of KPIs to
    ensure the effectiveness and efficiency of software development and delivery processes.
    These metrics help organizations understand their DevOps performance and identify
    areas for improvement. The four primary DORA metrics are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Deployment frequency**: How often a production release has succeeded. A higher
    frequency indicates a higher velocity and responsive development process.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Lead time for changes**: The time taken between committing code to production.
    Shorter lead times represent a more efficient development pipeline.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Change failure rate**: The percentage of deployments that cause a failure
    in production. Lower rates indicate more stable and reliable releases.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Mean time to recovery (MTTR)**: The average time taken to recover from a
    failure in production. Faster recovery times indicate better incident response
    and resilience.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Any attempt to game one of these metrics would be detected by another. For instance,
    if development skips running tests, the lead time for change will decrease, but
    the change failure rate will increase due to lack of testing.
  prefs: []
  type: TYPE_NORMAL
- en: 'The DORA team has also developed **SPACE** metrics, which provide a holistic
    perspective of engineering productivity in addition to software delivery efficiency.
    Let’s see what SPACE stands for:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Satisfaction**: This is a quantitative and qualitative measurement of how
    satisfied engineers are with their work, work-life balance, and tools'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Performance**: This specifies the quality, effectiveness, and impact of the
    software that’s been delivered'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Activity**: The volume of activities that have contributed to the completion
    of work – for example, the number of commits and pull requests'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Communication and collaboration**: This involves evaluating the effectiveness
    of team meetings, cross-team cooperation, and collaborative tools'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Efficiency**: This measures how time, effort, and tools are effectively utilized
    for desired outcomes, delivery, and waste reduction'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: SPACE metrics are designed to cover many angles of team productivity, as well
    as to avoid any metric from being manipulated by having other metrics detect it.
    For instance, having excessive meetings might have boosted the volume of activity,
    but the lack of effectiveness will be caught by evaluating communication and collaboration.
  prefs: []
  type: TYPE_NORMAL
- en: DORA and SPACE are complementary and can be measured at the same time to provide
    an all-rounded insight into the health of the team and its delivery of software
    products.
  prefs: []
  type: TYPE_NORMAL
- en: Good metrics should come as a comprehensive suite to provide a greater perspective
    of the organization’s performance.
  prefs: []
  type: TYPE_NORMAL
- en: Automated alerting and incident management
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Having a visual dashboard that shows metrics is nice, but when it comes to detecting
    system faults and raising alerts, an organization can’t rely on human eyes. There
    should be automated alerts and a well-defined workflow of incident management
    so that the organization can recover the system as quickly as possible.
  prefs: []
  type: TYPE_NORMAL
- en: We must establish mechanisms for real-time alerting and incident management
    so that we can rapidly respond and resolve problems that arise in the distributed
    system.
  prefs: []
  type: TYPE_NORMAL
- en: 'Monitoring tools allow the organization to trigger alerts under various conditions:'
  prefs: []
  type: TYPE_NORMAL
- en: Resource utilization is too high (for example, more than 90% CPU usage over
    10 minutes)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The given metric has exceeded the threshold (for example, there were more than
    20 HTTP responses with status code `400` in the last 5 minutes)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: When security threats or anomalies are detected, such as unauthorized access
    attempts
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A bespoke error log pattern is detected (for example, an error log message such
    as “Unable to authorize payment” has been detected)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The workflow for incident management varies in every organization. Some organizations
    have dedicated round-the-clock support teams that respond to incidents, while
    others have engineers to act as support persons on a rotational basis. Additionally,
    some organizations have three levels of escalation in case a major incident can’t
    be solved immediately.
  prefs: []
  type: TYPE_NORMAL
- en: There are no golden incident management procedures, but there are principles
    of incident management that should be considered.
  prefs: []
  type: TYPE_NORMAL
- en: '**Establish and document the incident management workflow**: The workflow needs
    to be defined and documented so that the people involved in incident management
    have a process to follow.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Implement communication channels**: It’s recommended to have a dedicated
    instant messaging channel for each incident so that you have relevant and focused
    collaboration among people. Emails and phone calls should be used for notification
    purposes because they don’t have a well-structured conversation format. Other
    people joining later in the investigation process will find it difficult to follow.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Moreover, the instant messaging channel has built-in timestamps and participant
    identifications, which are useful for compiling the communication section of an
    incident report.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Document the journey for each incident**: It’s important to document each
    incident to capture the findings of the problem, the troubleshooting journey,
    the resolution of the problem, and the communication during the incident. This
    is useful for internal improvement, audit, and regulatory requirements. The incident
    report should also be standardized to allow for comparisons and further analysis.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Conduct follow-up meetings**: There are three other known names for this
    type of meeting: **after-action review** (**AAR**), post-mortem, and autopsy meeting.
    The purpose of this meeting is to review and replay the incident, identify what
    was learned from this incident, and discuss preventative measures and any potential
    improvements (processes, communication, tooling, and so on).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The action items from this meeting are prioritized in the backlog of the responsible
    teams and are linked to the incident to motivate the change.
  prefs: []
  type: TYPE_NORMAL
- en: 'An example workflow for incident management is shown in *Figure 11**.3*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.3 – An example workflow for incident management](img/B21737_11_3.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.3 – An example workflow for incident management
  prefs: []
  type: TYPE_NORMAL
- en: 'In this diagram, multiple sources can report an incident that occurred. The
    support person is informed by the incident management tool via email, phone, instant
    message, or a phone application. The support person triages the incident by finding
    the answers to the following questions:'
  prefs: []
  type: TYPE_NORMAL
- en: Is it an actual incident or just a false alarm?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Which business area is impacted?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Who’s impacted by this incident?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How severely is the business area impacted?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Which team is responsible for the impacted business area?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Does it need to be fixed immediately?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If the incident turns out to be a false alarm, the incident is resolved. If
    it’s an actual incident but doesn’t require an immediate fix, then the incident
    will be picked up by the responsible team the next working day.
  prefs: []
  type: TYPE_NORMAL
- en: If the incident is major or substantial, then a second-level support person
    from the responsible team is involved to start the investigation immediately.
    During this stage, the investigation could escalate, depending on the progress
    of the investigation. Sometimes, another team needs to be involved, or a big decision
    needs to be made by upper management. Once the fix has been applied and verified,
    the incident is resolved.
  prefs: []
  type: TYPE_NORMAL
- en: If the system is mission-critical, it’s worth considering an enterprise incident
    management system that supports escalation policies, rotational support management,
    communication channels, automatic reporting, and backlog ticket integration.
  prefs: []
  type: TYPE_NORMAL
- en: Improvements in incident management are often made after an incident has occurred.
    It’s important for an organization to continuously learn and improve its incident
    management process.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we walked through the importance of auditing and monitoring.
    We emphasized the importance of measuring systems to avoid organizations going
    into the vicious cycle of opinion-based decision-making. A few exceptions of not
    needing auditing and monitoring were mentioned.
  prefs: []
  type: TYPE_NORMAL
- en: We also identified a few challenges when auditing and monitoring distributed
    systems. After highlighting the challenges we faced, we started to cover the key
    aspects of auditing and monitoring.
  prefs: []
  type: TYPE_NORMAL
- en: The data that’s captured for auditing and monitoring is different. A sample
    of the audit trail was demonstrated by Kotlin code so that we could cover the
    various types of data available for monitoring.
  prefs: []
  type: TYPE_NORMAL
- en: Next, the best practices for application-level logging were demonstrated through
    the use of sample code and a few logging frameworks. The techniques of structured
    logging and contextual logging were covered.
  prefs: []
  type: TYPE_NORMAL
- en: Afterward, we moved on to the aspect of centralizing and aggregating auditing
    and monitoring data. The approach of the standard envelope and discoverable topics
    for audit trails were presented. We also mentioned multiple approaches for collecting
    monitoring data.
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, we identified two levels of metrics: the service level and the business
    level. We covered how a qualitative goal can be translated into quantitative measurable
    metrics and used **DORA** metrics as an example of a comprehensive suite of metrics
    to prevent the gaming of metrics.'
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we discussed the aspects of automated alerting and incident management.
    We presented a sample workflow of incident management to illustrate the importance
    of appropriate tooling, effective communication, and documentation.
  prefs: []
  type: TYPE_NORMAL
- en: The next chapter will cover the performance and scalability aspects of software
    systems.
  prefs: []
  type: TYPE_NORMAL
