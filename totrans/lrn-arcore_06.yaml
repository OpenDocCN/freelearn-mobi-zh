- en: Understanding the Environment
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解环境
- en: 'Augmented reality applications are all about enhancing or augmenting the user''s
    reality. In order to do this, we as AR app developers need a set of tools capable
    of understanding the user''s environment. As we saw in the last chapter, ARCore
    uses **visual-inertial odometry** (**VIO**) to identify objects and features in
    the environment, which it can then use to obtain a pose of the device and track
    motion. However, this technology can also help us identify objects and their pose
    using the same toolkit. In this chapter, we will explore how we can use the ARCore
    API to better understand the user''s environment. Here''s a quick overview of
    the main topics we will cover in this chapter:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 增强现实应用程序都是关于增强或扩展用户的现实。为了做到这一点，作为 AR 应用程序开发者，我们需要一套能够理解用户环境的工具。正如我们在上一章中看到的，ARCore
    使用 **视觉惯性里程计**（**VIO**）来识别环境中的对象和特征，然后它可以利用这些信息来获取设备的姿态并跟踪运动。然而，这项技术也可以帮助我们使用相同的工具包来识别对象及其姿态。在本章中，我们将探讨如何使用
    ARCore API 更好地理解用户的环境。以下是本章我们将涵盖的主要主题的简要概述：
- en: Tracking the point cloud
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 跟踪点云
- en: Meshing and the environment
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 网格化和环境
- en: Interacting with the environment
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与环境交互
- en: Drawing with OpenGL ES
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 OpenGL ES 绘制
- en: Shader programming
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 着色器编程
- en: If you have not downloaded the source code from GitHub, you will need to do
    so for this chapter. Of course, you will also need to have completed the setup
    and installation of Android covered in [Chapter 2](c5c4b444-3342-457a-b756-266772b70d06.xhtml),
    *ARCore on Android*.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你还没有从 GitHub 下载源代码，你需要为这一章这样做。当然，你还需要完成 [第 2 章](c5c4b444-3342-457a-b756-266772b70d06.xhtml)
    中涵盖的 Android 设置和安装，即 *ARCore on Android*。
- en: Tracking the point cloud
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 跟踪点云
- en: 'As we discussed, motion tracking in ARCore is done by identifying and tracking
    recognizable features around the user. It then uses those points with the device''s
    orientation and accelerometer sensors to keep its tracking updated. Without doing
    this, the ability to track accurately quickly falls apart. Additionally, we gain
    the benefit of now tracking multiple points that ARCore identifies as object points.
    Let''s see an example of what these tracking points look like by starting up the
    sample ARCore Android app again. Follow the given steps to get started:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们讨论的那样，ARCore 中的运动跟踪是通过识别和跟踪用户周围的可见特征来完成的。然后，它使用这些点以及设备的方向和加速度计传感器来保持跟踪更新。如果不这样做，准确跟踪的能力会迅速下降。此外，我们还获得了跟踪
    ARCore 识别为对象点的多个点的优势。让我们通过再次启动示例 ARCore Android 应用程序来查看这些跟踪点的外观。按照以下步骤开始：
- en: Open Android Studio. If you haven't opened any other projects, then it should
    immediately load the Android ARCore sample project. If not, load the project in
    the `Android/arcore-android-sdk/samples/java_arcore_hello_ar` folder.
  id: totrans-10
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开 Android Studio。如果你还没有打开其他项目，那么它应该会立即加载 Android ARCore 示例项目。如果不是这样，请在 `Android/arcore-android-sdk/samples/java_arcore_hello_ar`
    文件夹中加载项目。
- en: 'Open the `HelloArActivity.java` file and scroll down to the `OnDrawFrame` method,
    as shown in the following excerpt:'
  id: totrans-11
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开 `HelloArActivity.java` 文件，并向下滚动到 `OnDrawFrame` 方法，如下面的摘录所示：
- en: '![](img/3134f94f-df62-41e5-bd03-25269bbb5463.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/3134f94f-df62-41e5-bd03-25269bbb5463.png)'
- en: Opening the HelloArActivity.java file in Android Studio
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Android Studio 中打开 HelloArActivity.java 文件
- en: '`OnDrawFrame` is the render method, exactly like the `update` function we have
    seen in the web example. This method is called every frame, generally around 60
    frames per second in the typical 3D app. We also call 60 fps as the frame rate.
    Frame rates will vary depending on how much your code performs each frame. Therefore,
    we want our `render` function and the code inside to be as fast as possible. We
    will talk more about performance and rendering in [Chapter 11](e7c0bdd1-e380-4498-af5a-fe9e627eb6cb.xhtml),
    *Performance Tips and Troubleshooting*.'
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`OnDrawFrame` 是渲染方法，就像我们在网络示例中看到的 `update` 函数一样。这个方法每帧被调用一次，在典型的 3D 应用程序中，通常每秒大约
    60 帧。我们也将 60 fps 称为帧率。帧率将根据你每帧执行的操作量而变化。因此，我们希望我们的 `render` 函数和其中的代码尽可能快。我们将在
    [第 11 章](e7c0bdd1-e380-4498-af5a-fe9e627eb6cb.xhtml) 中更多地讨论性能和渲染，*性能提示和故障排除*。'
- en: The first line in this method, starting with `GLES20.glClear`, clears the render
    buffer and prepares for drawing.
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在此方法的第一行，从 `GLES20.glClear` 开始，清除渲染缓冲区并准备绘图。
- en: Depending on the 3D platform you are working with, you may or may not have to
    worry about specific details such as clearing render buffers. Unity, for instance,
    hides many of these details away from the developer, which can be good and bad.
    Just understand that all 3D platforms will generally follow the same principals.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 根据你正在使用的3D平台，你可能不需要担心一些特定的细节，比如清除渲染缓冲区。例如，Unity会隐藏许多这些细节，对开发者来说这可能既有好的一面也有不好的一面。只需理解所有3D平台通常都会遵循相同的原理。
- en: 'Scroll down a bit to just inside the `try` block and add the following line:'
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 向下滚动一点，直到`try`块内部，并添加以下行：
- en: '[PRE0]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '`Frame` represents the current AR view captured from the device''s camera.
    We get access to an instance of `frame` by calling `mSession.update()`; `mSession`,
    which is initialized earlier, represents our ARCore session service.'
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`Frame`代表从设备摄像头捕获的当前AR视图。我们通过调用`mSession.update()`来获取`frame`的实例；`mSession`是在之前初始化的，代表我们的ARCore会话服务。'
- en: '`Frame` also exposes a number of helper methods; scroll down until you see
    the following lines:'
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`Frame`还公开了一些辅助方法；向下滚动直到你看到以下行：'
- en: '[PRE1]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Starting with `mPointCloud.update()`, this call gets the visible points in the
    current `frame`. Then, `mPointCloud.draw()` draws the points based on the cloud's
    pose, using the current view (`viewmtx`) and projection (`projmtx`) matrices.
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从`mPointCloud.update()`开始，这个调用获取当前`frame`中的可见点。然后，`mPointCloud.draw()`根据云的姿态绘制点，使用当前的视图（`viewmtx`）和投影（`projmtx`）矩阵。
- en: View and projection matrices represent the camera or combined scene view. With
    `three.js`, this was handled for us. Likewise, when we get to Unity, we won't
    need to worry about setting these matrices either.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 视图和投影矩阵代表相机或组合场景视图。使用`three.js`时，这些由我们处理。同样，当我们到达Unity时，我们也不需要担心设置这些矩阵。
- en: Connect your device to your machine, either through USB or remotely. Then, build
    and run the app on your device. Pay particular attention to the drawing of the
    point cloud.
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将你的设备连接到你的机器，无论是通过USB还是远程连接。然后，在你的设备上构建并运行应用。特别注意点云的绘制。
- en: Note how the number of points increases the longer you hold the device in one
    orientation. These points represent those identifiable and recognizable feature
    points used for tracking and interpreting the environment. Those are the same
    points that will help us identify objects or surfaces in the environment. In the
    next section, we will look at how surfaces are identified and rendered.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，当你保持设备在一个方向上更长的时间时，点的数量会增加。这些点代表用于跟踪和解释环境的可识别和可识别的特征点。这些点将帮助我们识别环境中的物体或表面。在下一节中，我们将探讨如何识别和渲染表面。
- en: Meshing and the environment
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 网格化和环境
- en: 'So, being able to identify features or corners of objects is really just the
    start of what we would like to know about the user''s environment. What we really
    want to do is use those feature points to help us identify planes, surfaces, or
    known objects and their pose. ARCore identifies planes or surfaces automatically
    for us through a technique called **meshing**. We have already seen how meshing
    works numerous times in the advanced samples, when ARCore tracks surfaces. Now,
    before we get ahead of ourselves, let''s picture what a point cloud and mesh look
    like in 3D, with the following diagram:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，能够识别物体的特征或角点实际上只是我们想要了解用户环境信息的起点。我们真正想要做的是利用这些特征点来帮助我们识别平面、表面或已知物体及其姿态。ARCore通过一种称为**网格化**的技术自动为我们识别平面或表面。我们已经多次在高级示例中看到网格化是如何工作的，当ARCore跟踪表面时。现在，在我们自己领先之前，让我们通过以下图表来想象一下点云和网格在3D中的样子：
- en: '![](img/bb4166b5-8609-4c8f-b6c2-6a9ccd0bdfa6.jpg)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![网格化和环境](img/bb4166b5-8609-4c8f-b6c2-6a9ccd0bdfa6.jpg)'
- en: Point cloud and mesh in 3D
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 3D中的点云和网格
- en: If you pay attention to the diagram, you will see an inset figure showing a
    polygon and the ordered set of vertices that comprise it. Note how the order of
    points goes counterclockwise. Yes, the order in which we join points makes a difference
    to the way a surface is facing when a mesh is lit and shaded. When a scene is
    rendered we only see surfaces that face the camera. Surfaces pointing away from
    the camera are removed or back-face culled. The order in which we join points
    is called winding and isn't something you have to worry about unless you plan
    to create meshes manually.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你注意观察图示，你会看到一个嵌入的图形，展示了一个多边形及其组成的有序顶点集。注意点的顺序是逆时针的。是的，我们连接点的顺序会影响网格光照和着色时的表面朝向。当场景渲染时，我们只能看到面向摄像机的表面。远离摄像机的表面会被移除或背面裁剪。我们连接点的顺序被称为绕行，除非你计划手动创建网格，否则你不必担心这个问题。
- en: 'Meshing is the process of taking a collection of feature points and constructing
    a mesh from it. The generated mesh is then often shaded and rendered into the
    scene. If we run the sample right now and watch, we will see the surfaces or plane
    meshes being generated and placed by ARCore. How about we open up the Android
    sample project again in Android Studio to see where this meshing occurs:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 网格化是将一组特征点组合起来并从中构建网格的过程。生成的网格随后通常会被着色并渲染到场景中。如果我们现在运行这个示例并观察，我们会看到 ARCore 生成的表面或平面网格被生成并放置。我们何不再次在
    Android Studio 中打开 Android 示例项目，看看网格化发生在哪里：
- en: Ensure that your code is open to where we left off last time. You should be
    looking at the lines with `mPointCloud`.
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确保你的代码是开放的，以便我们上次离开的地方。你应该正在查看带有 `mPointCloud` 的行。
- en: 'Scroll down just a little until you see this block of code:'
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 向下滚动一点，直到你看到这段代码块：
- en: '[PRE2]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: This block of code just loops through the trackables of type **Plane** (a flat
    mesh) identified in the session. When it identifies a tracked plane, of the correct
    type, it hides the loading message and breaks out of the loop.
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这段代码块只是遍历会话中识别出的类型为 **Plane**（一个平面网格）的跟踪对象。当它识别出一个正确类型的跟踪平面时，它会隐藏加载信息并跳出循环。
- en: 'Then, it renders any planes it identifies with this line:'
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，它将识别出的任何平面渲染成这条线：
- en: '[PRE3]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The `planeRenderer` helper class is for drawing planes. It uses the `drawPlanes`
    method to render any of the identified planes the ARCore session has identified
    using the view and projection matrices. You will notice it passes all the planes
    in through a call to `getAllTrackables(Plane.class)`.
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`planeRenderer` 辅助类用于绘制平面。它使用 `drawPlanes` 方法渲染 ARCore 会话通过视图和投影矩阵识别出的任何识别出的平面。你会注意到它通过调用
    `getAllTrackables(Plane.class)` 将所有平面传递进去。'
- en: Put your cursor on `drawPlanes` and type *Ctrl *+ *B* (*command* + *B* on Mac)
    to go to the definition.
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将光标放在 `drawPlanes` 上，输入 *Ctrl *+ *B* (*command* + *B* 在 Mac 上) 以跳转到定义。
- en: Now you should see the `drawPlanes` method in the `PlaneRenderer.java` file—don't
    panic. Yes, there is a lot of scary code here, which, thankfully, is already written
    for us. As an exercise, just scroll through and read the code. We don't have time
    to go through it in depth, but reading through this code will give you more insight
    into the rendering process.
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，你应该能在 `PlaneRenderer.java` 文件中看到 `drawPlanes` 方法——不要慌张。是的，这里有很多令人害怕的代码，幸运的是，这些代码已经为我们写好了。作为一个练习，只需滚动并阅读代码。我们没有时间深入分析，但阅读这段代码将使你对渲染过程有更深入的了解。
- en: From the menu, select Run - Run 'HelloArActivity'. Now, as the app runs, pay
    special attention to the way the surfaces are rendered and how you can interact
    with them.
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从菜单中选择运行 - 运行 'HelloArActivity'。现在，当应用程序运行时，请特别注意表面的渲染方式以及你如何与之交互。
- en: Okay, now we understand how surfaces are created and rendered. What we also
    need to understand is how we interact with those surfaces or other objects in
    the environment.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，现在我们了解了表面是如何创建和渲染的。我们还需要了解如何与环境中的这些表面或其他对象交互。
- en: Interacting with the environment
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 与环境交互
- en: 'We know that ARCore will provide us with identified feature points and planes/surfaces
    it recognizes around the user. From those identified points or planes, we can
    attach virtual objects. Since ARCore keeps track of these points and planes for
    us, as the user moves objects, those that are attached to a plane remain fixed.
    Except, how do we determine where a user is trying to place an object? In order
    to do that, we use a technique called **ray casting**. Ray casting takes the point
    of touch in two dimensions and casts a ray into the scene. This ray is then tested
    against other objects in the scene for collisions. The following diagram shows
    how this works:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 我们知道ARCore会为我们提供用户周围识别的特征点和平面/表面。从这些识别的点或平面，我们可以附加虚拟对象。由于ARCore为我们跟踪这些点和平面，因此当用户移动对象时，附加到平面上的对象保持固定。但是，我们如何确定用户试图放置对象的位置呢？为了做到这一点，我们使用一种称为**射线投射**的技术。射线投射将触摸点在二维空间中的点投射到场景中。然后，该射线被用于测试场景中其他对象的碰撞。以下图表显示了这是如何工作的：
- en: '![](img/cfe88118-9755-4b72-831f-e7fe6063e945.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![](img/cfe88118-9755-4b72-831f-e7fe6063e945.png)'
- en: Example of ray casting from device screen to 3D space
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 从设备屏幕到3D空间的射线投射示例
- en: 'You, of course, have likely already seen this work countless times. Not only
    the sample app, but virtually every 3D application uses ray casting for object
    interaction and collision detection. Now that we understand how ray casting works,
    let''s see how this looks in code:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，你可能已经看到过无数次这样的工作了。不仅是在示例应用中，几乎所有3D应用都使用射线投射进行对象交互和碰撞检测。现在我们了解了射线投射是如何工作的，让我们看看它在代码中的样子：
- en: Open up Android Studio, the sample project, and the `HelloArActivity.java` file.
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开Android Studio，示例项目和`HelloArActivity.java`文件。
- en: 'Scroll down to the following block of code:'
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 滚动到以下代码块：
- en: '[PRE4]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Read through the comments and pay attention to the highlighted lines of code.
    The first highlighted line starts a loop based on the number of hits detected
    in the scene using `frame.hitTest(tap)`. That call is doing the ray casting to
    determine what objects may be hit by the tap. A **tap** represents the screen
    touch in 2D.
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 阅读注释并注意高亮显示的代码行。第一行高亮显示的代码基于在场景中使用`frame.hitTest(tap)`检测到的击中次数开始循环。那个调用正在进行射线投射以确定哪些对象可能被点击。**点击**代表二维空间中的屏幕触摸。
- en: The next highlighted line is inside the `if` statement that checks which of
    the ARCore recognized planes are touched. If there is a hit, we first check that
    the number of `anchors` is less than 20, where each anchor represents an attachment
    point. Then we add a new `Anchor` to the collection of `anchors` `ArrayList`,
    with a reference to a new anchor using `hit.createAnchor` .
  id: totrans-52
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 下一个高亮显示的行在检查哪个ARCore识别的平面被触摸的`if`语句内部。如果有击中，我们首先检查`anchors`的数量是否小于20，其中每个锚点代表一个附加点。然后，我们使用`hit.createAnchor`向`anchors`
    `ArrayList`集合中添加一个新的`Anchor`，并使用对新锚点的引用。
- en: 'Scroll down some more to the following block of code in `onDrawFrame`:'
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 向下滚动一些，直到`onDrawFrame`中的以下代码块：
- en: '[PRE5]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Take a quick read through the code. The first highlighted line starts by looping
    through the `anchor` in the `anchors` list. We then check whether the anchor is
    being tracked; if it is, we get its pose in the second highlighted line. Then,
    we draw our `virtualObject` (Andy) in the last lines of code. Note that in this
    case, we are also drawing shadows.
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 快速阅读一下代码。第一行高亮显示的代码首先遍历`anchors`列表中的`anchor`。然后，我们检查该锚点是否正在被跟踪；如果是，我们在第二行高亮显示的代码中获取其姿态。然后，我们在代码的最后几行中绘制我们的`virtualObject`（安迪）。注意，在这种情况下，我们还在绘制阴影。
- en: 'Change the first line of code to match the following:'
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将第一行代码更改为以下内容：
- en: '[PRE6]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: This change will double the size of Andy. Run the app in your device and wait
    for some surfaces to appear. Then, touch the screen to drop Andy. He should now
    look double the size.
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 此更改将使安迪的大小加倍。在您的设备上运行应用，等待一些表面出现。然后，触摸屏幕放下安迪。现在，他看起来是原来的两倍大小。
- en: Touch for gesture detection
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 触摸进行手势检测
- en: 'So, that covers simple interactions. How about we add another gesture to allow
    the user to clear all the attachment points and thus remove the Andy robot from
    the scene. Follow along the given steps to add another touch gesture:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，这涵盖了简单的交互。我们再添加一个手势，允许用户清除所有附加点，从而从场景中移除安迪机器人。按照以下步骤添加另一个触摸手势：
- en: 'Scroll to the following section of code:'
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 滚动到以下代码部分：
- en: '[PRE7]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The preceding section of code is in the `onCreate` method of the `HelloArActivity`.
    It first sets up `gestureDetector` for interpreting the selected touch events.
    Then, we set a listener with `setOnTouchListener` in order to capture touch events
    and send them to the gesture detector. Just remember that the listener listens
    for the touch, and the gesture detector interprets the type of touch. So what
    we want to do is capture another form of gesture from the user.
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 上述代码位于`HelloArActivity`的`onCreate`方法中。它首先为解释选定的触摸事件设置了`gestureDetector`。然后，我们通过`setOnTouchListener`设置一个监听器来捕获触摸事件并将它们发送到手势检测器。只需记住，监听器监听触摸，而手势检测器解释触摸的类型。所以我们要做的是捕获用户另一种形式的触摸手势。
- en: 'Add the following code right after the highlighted section:'
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在高亮部分之后立即添加以下代码：
- en: '[PRE8]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'That sends our event to a new method, `onLongPressDown`. Let''s add this new
    method just below the other gesture handling method by adding the following code:'
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这将我们的事件发送到新的方法`onLongPressDown`。让我们在其他的处理手势的方法下面添加这个新方法，代码如下：
- en: '[PRE9]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: All that happens inside `onLongPressDown` is the collection of `anchors`, `anchors` is
    cleared. By clearing the `anchors`, we clear the attachment points and thus any
    rendering of Andy.
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`onLongPressDown`内部发生的一切只是收集`anchors`，`anchors`被清除。通过清除`anchors`，我们清除了附着点，因此Andy的任何渲染都将消失。
- en: Save the file, connect your device, and run the sample. Try placing a few big
    Andy's around the scene. Then, use the new long press gesture to remove them.
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 保存文件，连接您的设备，并运行示例。尝试在场景周围放置几个大型的Andy。然后，使用新的长按手势来移除它们。
- en: Good, now we have a basic understanding of how we can interact with the environment.
    In the next section, we will cover some basics of OpenGL ES, the 3D rendering
    framework we are using for Android.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，现在我们基本了解了如何与环境交互。在下一节中，我们将介绍OpenGL ES的一些基础知识，这是我们用于Android的3D渲染框架。
- en: Drawing with OpenGL ES
  id: totrans-71
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用OpenGL ES进行绘图
- en: 'OpenGL ES or just GLES is the trimmed down mobile version of OpenGL. OpenGL
    is a low-level and powerful 2D and 3D drawing API similar to DirectX. Since it
    is a low-level library, it does require significant knowledge of 2D/3D maths.
    Again, for our purposes, we will avoid most of the nasty math and just modify
    some of the drawing code to change the way the sample app functions. What we will
    do is modify the sample app to change the way objects are drawn. Load up Android
    Studio with the sample project and let''s get started:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: OpenGL ES或简称GLES是OpenGL的精简版移动版本。OpenGL是一个类似于DirectX的低级且强大的2D和3D绘图API。由于它是一个低级库，因此确实需要大量的2D/3D数学知识。再次强调，为了我们的目的，我们将避免大多数复杂的数学，只是修改一些绘图代码来改变示例应用程序的功能。我们将修改示例应用程序，改变对象绘制的方式。加载Android
    Studio中的示例项目，让我们开始吧：
- en: 'Scroll down to the bottom of `PointCloudRenderer.java` and look at the following
    section of code identified in the following screen excerpt:'
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 滚动到`PointCloudRenderer.java`的底部，查看以下屏幕摘录中标识的代码部分：
- en: '![](img/3a74943b-eabf-4290-982a-0c1e5cd97cbf.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/3a74943b-eabf-4290-982a-0c1e5cd97cbf.png)'
- en: PointCloudRenderer.java open on the draw method
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在`PointCloudRenderer.java`中打开draw方法
- en: Now the code is straightforward, but a lot of what is going on assumes that
    the developer has a good foundation in 3D maths and graphic rendering. We don't
    have time to go through every step, but, essentially, all that the code is doing
    is drawing the identified point cloud features (those blue points).
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在代码很简单，但其中很多内容都假设开发者有很好的3D数学和图形渲染基础。我们没有时间逐一解释每个步骤，但本质上，代码所做的只是绘制标识的点云特征（那些蓝色点）。
- en: When we get to the chapters on Unity, you may start wondering why someone would
    ever put themselves through the pain of writing an AR app with OpenGL ES. That's
    a good question. Rendering realistic 3D graphics is all about speed and performance.
    While Unity does an excellent job at rendering, it still is just another layer
    of software on top of OpenGL ES. This means that Unity would typically run slower
    than its native OpenGL ES counterpart. How much slower, really depends on what
    you are trying to do.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们到达Unity章节时，你可能会开始想知道为什么有人会愿意忍受编写OpenGL ES AR应用程序的痛苦。这是一个好问题。渲染逼真的3D图形完全是关于速度和性能。虽然Unity在渲染方面做得很好，但它仍然是OpenGL
    ES之上的另一层软件。这意味着Unity通常会比其本地的OpenGL ES版本运行得慢。具体慢多少，取决于你试图做什么。
- en: 'Take a look at the identified line in the following excerpt, as shown:'
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查看以下摘录中标识的行，如图所示：
- en: '[PRE10]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: This line sets the color of the rendered point cloud. It does this by normalizing
    the RGB color values of `31.0`, `188.0`, and `210.0` by dividing them by `255.0`,
    thus creating a uniform or normalized color vector of values from 0 to 1. With
    the last value of `1.0` representing the alpha or transparency, where `1.0` means
    the color is **opaque** and `0.0` means it is **transparent**.
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这行代码设置了渲染点云的颜色。它是通过将`31.0`、`188.0`和`210.0`的RGB颜色值除以`255.0`来归一化这些值的，从而创建一个从0到1的均匀或归一化颜色向量。最后一个值`1.0`代表alpha或透明度，其中`1.0`表示颜色**不透明**，而`0.0`表示它**透明**。
- en: 'Let''s experiment a little by changing that line of code to the following:'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们通过将那行代码更改为以下内容进行一点实验：
- en: '[PRE11]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Next, we will change the size of points we draw so that they are clearly visible,
    by changing the following line of code:'
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将改变我们绘制的点的尺寸，以便它们清晰可见，通过更改以下行代码：
- en: '[PRE12]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Save the file, connect up your device, and then deploy and run the app. As the
    app runs, note the color of the points now. Is it what you expected?
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 保存文件，连接您的设备，然后部署并运行应用程序。当应用程序运行时，注意现在点的颜色。这是您预期的吗？
- en: Now, we can clearly see how and where the feature points are being identified.
    However, we still don't get a lot of information from the point data. What if
    we color the points based on their distance to the viewer? This will allow us
    to visualize our environment point cloud with some depth information. Doing this
    in a low-level API such as OpenGL ES to manually subset points by color will require
    substantial code changes. Fortunately, we can even go lower and write a program
    called a **shader** to change the color of the point just before we draw it. We
    will take a dive in to shader programming in the next section.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以清楚地看到特征点是如何以及在哪里被识别的。然而，我们仍然从点数据中得不到很多信息。如果我们根据点到观察者的距离给点着色会怎样？这将使我们能够以一些深度信息可视化我们的环境点云。在像OpenGL
    ES这样的低级API中手动通过颜色子集点将需要大量的代码更改。幸运的是，我们甚至可以更进一步，编写一个名为**着色器**的程序，在绘制点之前改变点的颜色。我们将在下一节深入探讨着色器编程。
- en: Shader programming
  id: totrans-87
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 着色器编程
- en: Shader programming is probably one of the most difficult and low-level development
    tasks you can do as a graphics programmer. It requires an excellent knowledge
    of 3D math and the graphics rendering process. Also, writing good shaders is a
    skill that can take years to master. So why are we covering this in a book that
    covers fundamentals? Simply put, coding a good shader may be difficult, but it
    is also extremely rewarding, and it's a skillset that is essential to any serious
    3D programmer.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 着色器编程可能是作为图形程序员你能做的最困难且最底层的发展任务之一。它需要卓越的3D数学和图形渲染过程的知识。此外，编写好的着色器是一项可能需要数年才能掌握的技能。那么，为什么我们要在一本介绍基础知识的书中介绍这个？简单地说，编写一个好的着色器可能很困难，但它也是极其有益的，而且这是一项对于任何严肃的3D程序员来说必不可少的技能集。
- en: We will be using shaders throughout the rest of this book for many things. If,
    at this point, you are starting to feel overwhelmed, then take a break and study
    some 3D math or jump ahead a chapter. Sometimes, you just need time for things
    to sink in before you get that eureka moment.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在本书的其余部分使用着色器来完成许多事情。如果你现在开始感到不知所措，那么请休息一下，学习一些3D数学或跳到下一章。有时候，你需要时间让事情沉淀下来，才能有那种“啊哈”的顿悟时刻。
- en: A shader program runs directly on the **graphic processing unit** (**GPU**)
    of the device or computer. If the device doesn't have a GPU, then the program
    is executed on the CPU, which is a much slower process. After all, the GPU has
    been optimized to run shader code and do it extremely well. In fact, virtually
    all 3D rendering done on the GPU runs the shader code. When we use Unity, a much
    higher-level game engine, we will still write our own shaders because of the power
    and flexibility it gives us.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 着色器程序直接在设备或计算机的**图形处理单元**（**GPU**）上运行。如果设备没有GPU，则程序在CPU上执行，这是一个速度慢得多的过程。毕竟，GPU已经针对运行着色器代码进行了优化，并且执行得非常好。实际上，几乎在GPU上进行的所有3D渲染都运行着色器代码。当我们使用Unity这样的高级游戏引擎时，我们仍然会编写自己的着色器，因为它给我们提供了强大的功能和灵活性。
- en: 'So, what does a shader program look like? The following is an example of a
    shader written in the **OpenGL Shading Language** (**GLSL**):'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，着色器程序看起来是什么样子？以下是一个用**OpenGL着色语言**（**GLSL**）编写的着色器示例：
- en: '[PRE13]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: This is the shader program we use for rendering our point cloud points or vertices.
    Specifically, this shader is responsible for rendering a single vertex for each
    call to `main`, and it's called a vertex shader. Later in the rendering process,
    after the 3D scene is flattened to a 2D image with the vertex shaders, we have
    the opportunity to run a fragment or pixel shader. A fragment shader is run for
    every pixel/fragment that needs to be rendered.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们用于渲染点云点或顶点的着色器程序。具体来说，这个着色器负责在每次调用`main`时渲染单个顶点，它被称为顶点着色器。在渲染过程的后期，在3D场景通过顶点着色器被展平成2D图像之后，我们有运行片段或像素着色器的机会。片段着色器是为需要渲染的每个像素/片段运行的。
- en: Shader programs come in a few variations, but since they all derive from a C
    language and share so many similar functions, switching from one language to another
    isn't as difficult as you think. We will, in fact, learn some basics of the GLSL
    and the form used in Unity called **High Level Shading Language** (**HLSL**),
    which has its roots in DirectX.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 着色器程序有多种变体，但既然它们都源自C语言并且共享许多相似的功能，从一种语言切换到另一种语言并不像你想的那么困难。实际上，我们将学习一些GLSL的基础知识以及Unity中使用的称为**高级着色语言**（**HLSL**）的形式，它起源于DirectX。
- en: 'If you look in the `main` function, you will see we are setting three variables:
    `v_Color`, `gl_Position`, and `gl_PointSize`. Those variables are global and just
    determine the color, size, and position of the vertex. The first line sets the
    color to an input variable—`u_Color`. Then, the position is calculated by multiplying
    the `u_ModelViewProjection` matrix with a new vector representing the position.
    That operation converts our vertex from world space to screen space. Finally,
    we set the point size with another input—`u_PointSize`.'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你查看`main`函数，你会看到我们设置了三个变量：`v_Color`、`gl_Position`和`gl_PointSize`。这些变量是全局的，仅用于确定顶点的颜色、大小和位置。第一行将颜色设置为输入变量——`u_Color`。然后，通过将`u_ModelViewProjection`矩阵与表示位置的新的向量相乘来计算位置。这个操作将我们的顶点从世界空间转换为屏幕空间。最后，我们使用另一个输入——`u_PointSize`来设置点的大小。
- en: 'What we want to do is modify that shader program so that it colorizes the points
    based on the distance from the user. Before we do that, though, let''s take a
    look at how the shader gets those inputs. Open up Android Studio to `PointCloudRenderer.java`
    and follow along:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 我们想要做的是修改这个着色器程序，使其根据用户距离来着色点。不过，在我们这样做之前，先看看着色器是如何获取这些输入的。打开Android Studio中的`PointCloudRenderer.java`文件，并按照以下步骤操作：
- en: 'Scroll down to bottom of the `createOnGUIThread` method and look for the following
    lines:'
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 滚动到`createOnGUIThread`方法的底部，查找以下行：
- en: '[PRE14]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Those lines of code set up our shader input positions. What we are doing here
    is determining the indexes we need for injecting data into the array buffer we
    pass to the shader. We need to add another input, so add the following line at
    the end of the preceding code snippet:'
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这些代码行设置了我们的着色器输入位置。我们在这里所做的就是确定我们需要用于将数据注入传递给着色器的数组缓冲区的索引。我们需要添加另一个输入，所以请在前面代码片段的末尾添加以下行：
- en: '[PRE15]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'This line adds another input variable called `u_FurthestPoint`. We need to
    calculate the furthest point from the user (camera) in order to colorize the points
    on a gradient. Before we do that, go back to the top of the file and declare the
    following new variables under the line identified:'
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这行代码添加了一个名为`u_FurthestPoint`的另一个输入变量。我们需要计算用户（相机）到最远点的距离，以便在渐变上着色点。在此之前，回到文件顶部，并在识别的行下面声明以下新变量：
- en: '[PRE16]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Remember that `furthestPoint` is an index to the variable and `furthestPointLength`
    will be used to hold the distance to the furthest point.
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 记住`furthestPoint`是一个变量的索引，而`furthestPointLength`将用于存储到最远点的距离。
- en: 'Scroll down to the `update` method and enter the following code after the identified
    line:'
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 滚动到`update`方法，在识别的行之后输入以下代码：
- en: '[PRE17]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: This code first sets our minimum distance (`1`) to `mFurthestPointLength`. Then,
    we check whether there are any observed points. If there are, we loop through
    the points in the point cloud. In the loop, we use the `get` method to index into
    the point buffer and extract the `x`, `y`, and `z` of the points. This allows
    us to measure the length of the vector with `x`, `y`, and `z` of the point. You
    make recognize the equation as the Pythagorean theorem, but in 3 dimensions rather
    than the 2 you may be used to. We then check whether this new length (distance)
    is greater than the current furthest length with `Math.max`. Keep in mind that
    this code is run in the `update` method and thus executed every rendered frame.
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这段代码首先将我们的最小距离（`1`）设置为`mFurthestPointLength`。然后，我们检查是否有任何观测到的点。如果有，我们遍历点云中的点。在循环中，我们使用`get`方法索引到点缓冲区并提取点的`x`、`y`和`z`。这使得我们可以用点的`x`、`y`和`z`来测量向量的长度。你可能认出这个方程是勾股定理，但是在三维空间中，而不是你习惯的二维空间中。然后我们检查这个新的长度（距离）是否大于当前的最长长度，使用`Math.max`。请注意，这段代码在`update`方法中运行，因此每帧渲染都会执行。
- en: 'We calculate the distance between two points in 3D space using the following
    formulae:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用以下公式计算三维空间中两点之间的距离：
- en: '![](img/266792db-feb1-4454-86bb-0a0ca4a6ecfd.png)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![](img/266792db-feb1-4454-86bb-0a0ca4a6ecfd.png)'
- en: 'Since our camera (user) is the origin, we can assume that one of our points
    is (0,0,0), which is equal to this:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们的相机（用户）是原点，我们可以假设我们的一个点是（0,0,0），这等于以下内容：
- en: '![](img/8e4e34c9-fcd7-40b0-94e6-901180fd4ed4.png)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8e4e34c9-fcd7-40b0-94e6-901180fd4ed4.png)'
- en: 'This becomes the following:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 这变成了以下内容：
- en: '![](img/b0d0b8bd-d35b-4570-9293-3af04453ac62.png)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b0d0b8bd-d35b-4570-9293-3af04453ac62.png)'
- en: 'Scroll down to the `draw` method and add the following code beneath the identified
    line:'
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 滚动到`draw`方法，并在指定的行下面添加以下代码：
- en: '[PRE18]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: This call sets the `furthestPointLength` that we calculated in the `update`
    method to the shader program.
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这个调用将我们在`update`方法中计算的`furthestPointLength`设置到着色器程序中。
- en: Editing the shader
  id: totrans-116
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 编辑着色器
- en: 'Okay, so that''s all the Java code we need to write in order to calculate and
    set our new distance variable. Next, we want to open up the shader program and
    modify the code for our needs. Follow the given steps to modify the shader program:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，这就是我们为了计算和设置新的距离变量而需要编写的所有Java代码。接下来，我们想要打开着色器程序并修改代码以满足我们的需求。按照以下步骤修改着色器程序：
- en: 'Open the `point_cloud_vertex.shader` file under the `res/raw` folder, as shown:'
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`res/raw`文件夹下打开`point_cloud_vertex.shader`文件，如图所示：
- en: '>![](img/680efd8c-2119-4b27-bfaf-adef5eae725f.png)'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '>![](img/680efd8c-2119-4b27-bfaf-adef5eae725f.png)'
- en: Opening point_cloud_vertex.shader
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 打开`point_cloud_vertex.shader`
- en: 'Make the highlighted code changes, as follows:'
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按照以下方式对高亮显示的代码进行更改：
- en: '[PRE19]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: The first line of code is new. All we are doing is taking the length of the
    `a_Position` vector, determining its length or distance to the camera, and then
    normalizing that value between 0 and 1\. The second line then creates a new `vec4`
    for color based on our calculations of the `t` variable. This new vector represents
    the color in the form **red blue green alpha** (**RGBA**), where alpha is set
    to a constant of `1.0`.
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 代码的第一行是新的。我们只是获取`a_Position`向量的长度，确定其长度或到相机的距离，然后将该值归一化到0和1之间。第二行根据我们对`t`变量的计算创建一个新的`vec4`来表示颜色。这个新向量代表以**红蓝绿alpha**（**RGBA**）形式存在的颜色，其中alpha被设置为常量`1.0`。
- en: 'Save the file, connect your device, and build and run the app on your device.
    You should now see the cloud points colorized by distance to the camera, as follows:'
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 保存文件，连接您的设备，并在设备上构建和运行应用程序。现在，你应该会看到按到相机的距离着色的云点，如下所示：
- en: '![](img/03cccfa8-878f-4ce2-ae57-bd1f10574958.png)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![](img/03cccfa8-878f-4ce2-ae57-bd1f10574958.png)'
- en: Screenshot of colored point cloud points by depth
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 按深度着色的点云点截图
- en: Imagine if we had to write Java code in order to do the same colorization of
    the points. We would certainly need a lot more code than what we wrote. Also,
    any Java code we used would certainly be much slower than a shader. Now, for our
    example, the app's performance is less critical, but when you develop a real AR
    app, you will want to squeeze all the performance you can; that's why our discussion
    and knowledge of shaders is so important.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下，如果我们不得不编写Java代码来完成相同颜色的点着色。我们肯定需要比我们写的代码多得多的代码。此外，我们使用的任何Java代码肯定比着色器慢得多。现在，对于我们的示例，应用程序的性能不太关键，但当你开发一个真正的AR应用程序时，你将希望榨取所有可用的性能；这就是为什么我们的讨论和对着色器的了解如此重要的原因。
- en: Exercises
  id: totrans-128
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 练习
- en: 'The following exercises are meant to test your skills and the knowledge you
    just earned in order to build on the work we just completed. Complete the following
    exercises on your own:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 以下练习旨在测试你的技能和刚刚获得的知识，以便在我们刚刚完成的工作上继续前进。请在自己的设备上完成以下练习：
- en: Change the color of the tracking line from blue to red, or another color.
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将跟踪线的颜色从蓝色改为红色，或另一种颜色。
- en: Replace the straight line segments with a `SplineCurve`. Hint, you will need
    to track more than one previous position.
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将直线段替换为`SplineCurve`。提示：你需要跟踪多个之前的位置。
- en: Make the cube and/or audio follow the user along the tracked path. Hint—you
    can use another `setInterval` timer function to move the box along the path every
    1.1 seconds (1100 ms).
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让立方体和/或音频沿着跟踪路径跟随用户。提示——你可以使用另一个`setInterval`定时器函数，每1.1秒（1100毫秒）沿着路径移动盒子。
- en: Summary
  id: totrans-133
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: We began this chapter by first reviewing some concepts on environment tracking
    and exploring how ARCore keeps track of the environment. Then, we moved on to
    meshing and how it is used to generate planes and surfaces. From there, we moved
    on to interacting with the environment, where we saw how a touch gesture is interpreted
    and converted into a position in a 3D scene. After that, we learned some basics
    about OpenGL ES and how our point cloud is rendered. We then took a deep dive
    and introduced the low-level rendering process of shaders. With this, we then
    modified the point cloud vertex shader in order to colorize the points by distance.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从回顾环境跟踪的一些概念开始本章，探讨了ARCore如何跟踪环境。然后，我们转向网格化以及它是如何用于生成平面和表面的。从那里，我们转向与环境交互，我们看到触摸手势是如何被解释并转换为3D场景中的位置的。之后，我们学习了OpenGL
    ES的一些基础知识以及我们的点云是如何渲染的。然后，我们深入探讨了着色器的低级渲染过程。有了这个，我们就修改了点云顶点着色器，以便根据距离着色点。
- en: Lighting is a critical element to the whole illusion of augmented reality. In
    the next chapter, we will dive back into Unity and learn about light estimation.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 灯光是增强现实整体错觉的关键元素。在下一章中，我们将再次深入Unity，学习关于光估计的内容。
