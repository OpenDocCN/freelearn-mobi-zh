["```kt\nmkdir ARCore\ncd ARCore\n```", "```kt\ngit clone https://github.com/google-ar/arcore-unity-sdk.git ARCoreML\n```", "```kt\nusing System.Linq; //add after other using's\n\npublic class Neuron\n{\n  private static readonly System.Random Random = new System.Random();\n  public List<Synapse> InputSynapses;\n  public List<Synapse> OutputSynapses;\n  public double Bias;\n  public double BiasDelta;\n  public double Gradient;\n  public double Value;\n}\n```", "```kt\npublic static double GetRandom()\n{\n return 2 * Random.NextDouble() - 1;\n}\n```", "```kt\npublic Neuron()\n{\n  InputSynapses = new List<Synapse>();\n  OutputSynapses = new List<Synapse>();\n  Bias = GetRandom();\n}\n\npublic Neuron(IEnumerable<Neuron> inputNeurons) : this()\n{\n  foreach (var inputNeuron in inputNeurons)\n  {\n    var synapse = new Synapse(inputNeuron, this);\n    inputNeuron.OutputSynapses.Add(synapse);\n    InputSynapses.Add(synapse);\n  }\n}\n```", "```kt\npublic virtual double CalculateValue()\n{\n  return Value = Sigmoid.Output(InputSynapses.Sum(a => a.Weight *  \n                                a.InputNeuron.Value) + Bias);\n}\n\npublic double CalculateError(double target)\n{\n  return target - Value;\n}\n\npublic double CalculateGradient(double? target = null)\n{\n  if (target == null)\n    return Gradient = OutputSynapses.Sum(a =>    \n    a.OutputNeuron.Gradient * a.Weight) * Sigmoid.Derivative(Value);\n    return Gradient = CalculateError(target.Value) * Sigmoid.Derivative(Value);\n}\n\npublic void UpdateWeights(double learnRate, double momentum)\n{\n  var prevDelta = BiasDelta;\n  BiasDelta = learnRate * Gradient;\n  Bias += BiasDelta + momentum * prevDelta;\n  foreach (var synapse in InputSynapses)\n  {\n    prevDelta = synapse.WeightDelta;\n    synapse.WeightDelta = learnRate * Gradient * synapse.InputNeuron.Value;\n    synapse.Weight += synapse.WeightDelta + momentum * prevDelta;\n  }\n}\n```", "```kt\n} // end of Neuron class definition\npublic class Synapse\n{\n  public Neuron InputNeuron;\n  public Neuron OutputNeuron;\n  public double Weight;\n  public double WeightDelta;\n  public Synapse(Neuron inputNeuron, Neuron outputNeuron)\n  {\n    InputNeuron = inputNeuron;\n    OutputNeuron = outputNeuron;\n    Weight = Neuron.GetRandom();\n  }\n}\n\npublic static class Sigmoid\n{\n  public static double Output(double x)\n  {\n    return x < -45.0 ? 0.0 : x > 45.0 ? 1.0 : 1.0 / (1.0 +    \n    Mathf.Exp((float)-x));\n  }\n  public static double Derivative(double x)\n  {\n    return x * (1 - x);\n  }\n}\npublic class DataSet\n{\n  public double[] Values;\n  public double[] Targets;\n  public DataSet(double[] values, double[] targets)\n  {\n    Values = values;\n    Targets = targets;\n  }\n}\n```", "```kt\npublic class NeuralNet\n{\n  public double LearnRate;\n  public double Momentum;\n  public List<Neuron> InputLayer;\n  public List<Neuron> HiddenLayer;\n  public List<Neuron> OutputLayer;\n\n}  //be sure to add ending brace\n```", "```kt\npublic NeuralNet(int inputSize, int hiddenSize, int outputSize, \n              double? learnRate = null, double? momentum = null)\n{\n  LearnRate = learnRate ?? .4;\n  Momentum = momentum ?? .9;\n  InputLayer = new List<Neuron>();\n  HiddenLayer = new List<Neuron>();\n  OutputLayer = new List<Neuron>();\n  for (var i = 0; i < inputSize; i++){\n    InputLayer.Add(new Neuron());\n  }\n\n  for (var i = 0; i < hiddenSize; i++){\n    HiddenLayer.Add(new Neuron(InputLayer));\n  }\n\n  for (var i = 0; i < outputSize; i++){\n    OutputLayer.Add(new Neuron(HiddenLayer));\n  }\n}\n```", "```kt\npublic void Train(List<DataSet> dataSets, int numEpochs)\n{\n  for (var i = 0; i < numEpochs; i++)\n  {\n    foreach (var dataSet in dataSets)\n    {\n      ForwardPropagate(dataSet.Values);\n      BackPropagate(dataSet.Targets);\n    }\n  }\n}\n\npublic void Train(List<DataSet> dataSets, double minimumError)\n{\n  var error = 1.0;\n  var numEpochs = 0;\n  while (error > minimumError && numEpochs < int.MaxValue)\n  {\n    var errors = new List<double>();\n    foreach (var dataSet in dataSets)\n    {\n      ForwardPropagate(dataSet.Values);\n      BackPropagate(dataSet.Targets);\n      errors.Add(CalculateError(dataSet.Targets));\n    }\n    error = errors.Average();\n    numEpochs++;\n  }\n}\n```", "```kt\nprivate void ForwardPropagate(params double[] inputs)\n{\n  var i = 0;\n  InputLayer.ForEach(a => a.Value = inputs[i++]);\n  HiddenLayer.ForEach(a => a.CalculateValue());\n  OutputLayer.ForEach(a => a.CalculateValue());\n}\n\nprivate void BackPropagate(params double[] targets)\n{\n  var i = 0;\n  OutputLayer.ForEach(a => a.CalculateGradient(targets[i++]));\n  HiddenLayer.ForEach(a => a.CalculateGradient());\n  HiddenLayer.ForEach(a => a.UpdateWeights(LearnRate, Momentum));\n  OutputLayer.ForEach(a => a.UpdateWeights(LearnRate, Momentum));\n}\n```", "```kt\npublic double[] Compute(params double[] inputs)\n{\n  ForwardPropagate(inputs);\n  return OutputLayer.Select(a => a.Value).ToArray();\n}\n\nprivate double CalculateError(params double[] targets)\n{\n  var i = 0;\n  return OutputLayer.Sum(a => Mathf.Abs((float)a.CalculateError(targets[i++])));\n}\n```", "```kt\n[RequireComponent(typeof(AudioSource))]\npublic class EnvironmentalScanner : MonoBehaviour  //before me\n```", "```kt\npublic NeuralNet net;\npublic List<DataSet> dataSets;\n\nprivate float min = float.MaxValue;\nprivate float maxRange = float.MinValue;\nprivate float[] inputs;\nprivate double[] output;\nprivate double temp;\nprivate bool warning;\nprivate AudioSource audioSource;\nprivate double lastTimestamp;\n\npublic void Awake()\n{ \n    int numInputs, numHiddenLayers, numOutputs;\n    numInputs = 1; numHiddenLayers = 4; numOutputs = 1;\n    net = new NeuralNet(numInputs, numHiddenLayers, numOutputs);\n    dataSets = new List<DataSet>();\n}\n```", "```kt\nvoid Start()\n{ \n  dataSets.Add(new DataSet(new double[]{ 1,.1,0.0}, new double[] { 0.0,1.0,1.0 } ));\n  net.Train(dataSets, .001);\n  audioSource = GetComponent<AudioSource>();\n}\n```", "```kt\nvoid Update()\n{\n  if (warning)\n  { \n    audioSource.Play();\n  }\n  else\n  {\n    audioSource.Stop();\n  }\n  // Do not update if ARCore is not tracking.\n  if (Frame.TrackingState != FrameTrackingState.Tracking)\n  {\n    return;\n  }\n\n  min = float.MaxValue; \n  PointCloud pointCloud = Frame.PointCloud;\n  if (pointCloud.PointCount > 0 && pointCloud.Timestamp > lastTimestamp)\n  {\n  lastTimestamp = pointCloud.Timestamp;\n  //find min\n    for (int i = 0; i < pointCloud.PointCount; i++)\n    {\n      var rng = Mathf.Clamp01((pointCloud.GetPoint(i)- transform.parent.parent.transform.position).magnitude);\n      min = Mathf.Min(rng, min);\n    }\n\n    //compute output\n    output = net.Compute(new double[] { (double)min });\n    if(output.Length > 0)\n    {       \n      warning = output[0] > .001;\n    }\n    else\n    {\n      warning = false;\n    }\n  }  \n}\n```", "```kt\npublic void Train(List<DataSet> dataSets, double minimumError)\n{\n  var error = 1.0;\n  var numEpochs = 0;\n  while (error > minimumError && numEpochs < int.MaxValue)\n  { \n    var errors = new List<double>();\n    foreach (var dataSet in dataSets)\n    {\n      ForwardPropagate(dataSet.Values);\n      BackPropagate(dataSet.Targets);\n      errors.Add(CalculateError(dataSet.Targets));\n    }\n    error = errors.Average();\n    numEpochs++;\n  }\n}\n```", "```kt\nprivate void BackPropagate(params double[] targets)\n{\n    var i = 0;\n    OutputLayer.ForEach(a => a.CalculateGradient(targets[i++]));\n    HiddenLayer.ForEach(a => a.CalculateGradient());\n    HiddenLayer.ForEach(a => a.UpdateWeights(LearnRate, Momentum));\n    OutputLayer.ForEach(a => a.UpdateWeights(LearnRate, Momentum));\n}\n```", "```kt\npublic double CalculateGradient(double? target = null)\n{\n  if (target == null)\n    return Gradient = OutputSynapses.Sum(a => a.OutputNeuron.Gradient * a.Weight) * Sigmoid.Derivative(Value);\n\n  return Gradient = CalculateError(target.Value) * Sigmoid.Derivative(Value);\n}\n```", "```kt\npublic double CalculateError(double target)\n{\n    return target - Value;\n}\n```", "```kt\npublic void UpdateWeights(double learnRate, double momentum)\n{\n    var prevDelta = BiasDelta;\n    BiasDelta = learnRate * Gradient;\n    Bias += BiasDelta + momentum * prevDelta;\n\n    foreach (var synapse in InputSynapses)\n    {\n        prevDelta = synapse.WeightDelta;\n        synapse.WeightDelta = learnRate * Gradient *         \n                               synapse.InputNeuron.Value;\n        synapse.Weight += synapse.WeightDelta + momentum * prevDelta;\n    }\n}\n```", "```kt\npublic void Awake()\n{ \n  int numInputs, numHiddenLayers, numOutputs;\n  numInputs = 25; numHiddenLayers = 13; numOutputs = 1;\n  net = new NeuralNet(numInputs, numHiddenLayers, numOutputs);\n  dataSets = new List<DataSet>();\n  normInputs = new double[numInputs];\n}\n```", "```kt\nprivate void Train()\n{ \n  net.Train(dataSets, 100);\n  trained = dataSets.Count > 10;\n}\n```", "```kt\npublic void TrainNetwork(float expected)\n{\n  this.expected = expected;\n  training = true;\n}\n```", "```kt\nif (training)\n{ \n  dataSets.Add(new DataSet(normInputs, new double[] { expected }));\n  training = false;\n  Train();\n}\n```", "```kt\nfor (int i = 0; i < normInputs.Length; i++)\n{\n  if (i < pointCloud.PointCount)\n  {\n    //normalize the inputs\n    normInputs[i] = inputs[i] / max;\n  }\n  else\n  {\n    normInputs[i] = 0;\n  }\n}\n```", "```kt\nmkdir TensorFlow\ncd TensorFlow\n```", "```kt\ngit clone https://github.com/tensorflow/tensorflow\n```", "```kt\ndef nativeBuildSystem = 'none'\n```"]