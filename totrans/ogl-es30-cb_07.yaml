- en: Chapter 7. Textures and Mapping Techniques
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following recipes:'
  prefs: []
  type: TYPE_NORMAL
- en: Applying texture with UV mapping
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Efficient rendering with ETC2 compressed texture format
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Applying multiple textures
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing Skybox with seamless cube mapping
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing reflection and refraction with environment mapping
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing render to texture with Frame Buffer Objects
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing terrain with displacement mapping
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing bump mapping
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter will shed some light on textures, which is a very interesting part
    of the 3D computer graphics study. Texturing is a technique by which the surface
    of a 3D mesh model is painted with static images. In our previous chapter, we
    described the procedural and image texturing technique. The former uses a special
    algorithm to calculate the colors of the fragments in order to generate specific
    patterns. On the other hand, the latter one uses static images, which are wrapped
    onto the 3D mesh or geometry.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter is all about image texturing that explains its various applications
    in the field of 3D computer graphics. We will begin this chapter with a simple
    recipe that demonstrates the UV mapping to render a texture on the 2D planar surface;
    moving ahead from single texture, you will learn how to apply multiple textures
    on 3D objects. OpenGL ES 3.0 has introduced many new features. Among these, nonpower
    of two (NPOT) texture support, ETC2/EAC texture compression support, and seamless
    cube mapping are explained in detail in this chapter, with the help of a few practical
    recipes. In the later sections of this chapter, we will implement the environment
    mapping recipes to simulate the reflection and refraction behavior on the surface
    of objects. The chapter will continue to explain an effective technique called
    render to texture; this allows you to render scenes to user-defined texture buffers.
    Further, we will discuss the displacement mapping technique, which can be used
    to render a geographical terrain; the last recipe in this chapter will discuss
    the bump mapping technique, which is used to produce a high quality, detailed
    surface using a low polygon mesh.
  prefs: []
  type: TYPE_NORMAL
- en: Applying texture with UV mapping
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A texture is basically an image represented by a chunk of memory in the computer;
    this memory contains color information in the form of red (R), green (G), blue
    (B), and alpha (A) component; each component is represented as a series of bits/bytes,
    depending on the format of the type of texture.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this recipe, we will create a simple square and apply texture to it; three
    things are required for texture mapping:'
  prefs: []
  type: TYPE_NORMAL
- en: An image first needs to be loaded into the OpenGL ES texture memory with the
    help of texture objects.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A texture is mapped to the geometry using texture coordinates.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use texture coordinates to get the corresponding color from texture in order
    to apply it on the surface of the geometry.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The GLPI framework allows to load **Portable Network Graphics** (**PNG**) image
    files using a high-level abstracted class called `.png` image, which is derived
    from image; this class loads the `.png` image and stores image metrics in the
    class, such as name, dimensions, raw bits, and OpenGL ES texture name (ID). Internally,
    this class uses `libpng`, which is a platform-independent library that allows
    you to parse `.png` images.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The following procedure describes the steps to render geometry with the `.png`
    image texture:'
  prefs: []
  type: TYPE_NORMAL
- en: The `libpng` library is available under the `GLPLFramework` folder; this book
    will use version 1.5.13 of `libpng`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**iOS**: On iOS, this library needs to be added to the project. In Xcode, under
    your project, you can include this library using **File** | **Add to <Project
    Name>**.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Android**: For Android, `libpng` can be compiled as a shared library called
    `GLPipng`; for this, create `Android.mk` in the `libpng` folder and add the following
    code:'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: 'This makefile (`<GLPIFramework>/libpng/Android.mk`) needs to be included in
    the makefile main project (`SimpleTexture/Android/JNI/ Android.mk`) and the following
    line must be included in order to compile it in the makefile of your main project:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The generated shared library called `GLPipng` must be added to the project,
    as given in the following code:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'In order to read or write files on the external storage, your app must acquire
    the system permissions:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
- en: Beginning with Android 4.4, these permissions are not required if you're reading
    or writing only files that are private to your app.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a `SimpleTexture` class derived from `Model`; inside the constructor
    of this class, use the `PngImage` class member variable image to load an image:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The `PngImage::loadImage()` is responsible for loading an image and assigning
    a unique name to the loaded texture, which is provided by OpenGL ES to recognize
    a texture uniquely in the system.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Syntax**:'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '| Variable | Description |'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_TB
- en: '| --- | --- |'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_TB
- en: '| `fileName` | This is the name of the image file that needs to be loaded.
    |'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_TB
- en: '| `generateTexID` | This is the Boolean value that decides whether the image
    needs a unique name ID or not. If the Boolean value is `true`, then the loaded
    image is assigned with a unique ID and if the Boolean value is `false`, no ID
    is assigned to the image. The default value of this parameter is Boolean `true`.
    |'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_TB
- en: '| `target` | This specifies the target to which the texture needs to be bound.
    The possible targets are `GL_TEXTURE_2D`, `GL_TEXTURE_3D, GL_TEXTURE_2D_ARRAY`,
    or `GL_TEXTURE_CUBE_MAP`. The default value of this parameter is `GL_TEXTURE_2D`.
    |'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_TB
- en: '**Code**: The working code for the `loadImage` function of the `PngImage` class
    is as follows:'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: The `loadImage` function parses the specified image filename and stores the
    read image buffer in the `bitraw` class member of `PngImage`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The unique texture name is generated using the `glGenTexture` OpenGL ES API.
    This API generates a number of unused names in textures as specified by `n`. This
    name exists in the form of an unsigned integer ID; the generated ID is stored
    in the `texID` PngImage's member variable.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Syntax**:'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '| Variable | Description |'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_TB
- en: '| --- | --- |'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_TB
- en: '| `n` | This specifies the number of texture names to be generated |'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_TB
- en: '| `textures` | This specifies an array of unused generated texture names |'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_TB
- en: 'Consider the following code:'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: 'Bind the generated `texID` into a specified target using `glBindTexture`; this
    API of OpenGL ES 3.0 specifies the pipeline and what kind of texture it needs
    to manage. For example, the following code mentions that the current state of
    OpenGL ES contains a 2D type texture:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This API is very important to be called to perform any operation on a texture;
    it binds the correct texture name to OpenGL ES, which allows you to perform any
    texture operation on it.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Syntax**:'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '| Variable | Description |'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_TB
- en: '| --- | --- |'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_TB
- en: '| `target` | This specifies the target to which the texture is bound. This
    must be either `GL_TEXTURE_2D`, `GL_TEXTURE_3D`, `GL_TEXTURE_2D_ARRAY`, or `GL_TEXTURE_CUBE_MAP`.
    |'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_TB
- en: '| `texture` | This specifies an array of unused generated texture names. |'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_TB
- en: 'Load the image in the OpenGL ES texture memory using the `glTexImage2D` OpenGL
    ES 3.0 API:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The syntax of the `glTexImage2D` API describing each parameter is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Syntax**:'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '| Variable | Description |'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_TB
- en: '| --- | --- |'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_TB
- en: '| `target` | This specifies the target to which the texture is bound. |'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_TB
- en: '| `level` | This is the level of detail number for mipmapping. |'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_TB
- en: '| `internalFormat` | This specifies the number of components in the texture.
    For example, this recipe uses an image with four components (red, green, blue,
    and alpha). Therefore, the format will be `GL_RGBA`. |'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_TB
- en: '| `width` | This specifies the width of the texture; the new version of OpenGL
    ES 3.0 supports 2048 texels for all implementations. |'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_TB
- en: '| `height` | This specifies the height of the texture; the new version of OpenGL
    ES 3.0 supports 2048 texels for all implementations. |'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_TB
- en: '| `border` | This value must be 0. |'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_TB
- en: '| `format` | This specifies the pixel data format; for this recipe, it''s `GL_RGBA`.
    |'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_TB
- en: '| `type` | This specifies the data type of the pixel data; in this recipe,
    all components used 8 bits unsigned integer. Therefore, the type must be `GL_UNSIGNED_BYTE`.
    |'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_TB
- en: '| `data` | This is a pointer to the image parsed data. |'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_TB
- en: 'Create a vertex shader file called `SimpleTexutreVertex.glsl` and add the following
    code; this shader file receives the vertex and texture coordinate information
    from the OpenGL ES program; the received texture coordinates are further sent
    to the fragment shader for texture sampling purposes:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Similarly, create a shader file called `SimpleTexureFragment.glsl`; this is
    responsible for receiving the texture coordinate from the vertex shader and the
    texture image. The texture is received in sampler2D, which is a built-in data
    type in GLSL to access texture in the shader. Another GLSL API texture is used
    to retrieve the fragment color; this API accepts the texture and texture coordinate
    as an argument:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define the geometry vertices of the square and texture coordinates to map the
    texture on the geometry:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '![How to do it...](img/5527OT_07_01.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Note
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
- en: A single texture is always represented in the UV coordinate system from (0.0,
    0.0) bottom-left to (1.0, 1.0) top-right. If the texture coordinates goes beyond
    these dimensional ranges, then the special wrapping rule can be applied to control
    texture wrapping. For more information, refer to the *There's more…* section in
    this recipe.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The OpenGL ES shader accesses loaded images using texture units; texture units
    are pieces of hardware that have access to images. Each texture unit has an ID
    that ranges from `0` to `GL_MAX_COMBINED_TEXTURE_IMAGE_UNITS -1`. In order to
    make a texture unit active, use `glActiveTexture`. In the current recipe, the
    loaded texture is made accessible to the shader through texture unit 0 (`GL_TEXTURE0`).
    Bind the texture to this texture unit:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Send the texture unit ID to the fragment shader using a `glUniform1i`. In the
    fragment shader, the `Tex1` uniform variable receives this information; query
    the location of this uniform variable in order to provide the texture unit information.
    Note that `0` here is the texture unit number, not the handle of the texture:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Set the minification, magnification, and wrapping behavior on the texture using
    `glTexParameterf`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Use the current shader program and send the vertex and texture coordinate information
    to the shader to render geometry:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The GLPI framework provides a high-level PNG image parsing class called `PNGImage`;
    it internally uses the `libpng` library to parse PNG files and stores vital information
    in a local data structure. This class generates texture objects, binds them with
    an OpenGL state machine, and loads the image buffer data in it.
  prefs: []
  type: TYPE_NORMAL
- en: OpenGL ES supports texture through texture objects; these texture objects are
    prepared using the `glGenTextures` API within the `loadImage` function. This API
    generates a texture object behind the curtains and returns the (`texID`) unique
    name ID. OpenGL ES is a state machine; therefore, before applying any operation
    on a texture, it needs to set it as a current texture; this can be achieved using
    `glBindTexture`. This API will bind the `texID` to the current OpenGL ES state
    as current texture, which allows the OpenGL ES state machine to apply all texture-related
    operations to the current texture object.
  prefs: []
  type: TYPE_NORMAL
- en: 'The OpenGL ES loads the texture in the form of an image buffer in its texture
    memory; this information is provided through `glTexImage2D`, which specifies the
    format of the image to the underlying programmable pipeline. The `glActiveTexture`
    API is used to bind the texture with a texture unit; the texture units in OpenGL
    ES are meant to access textures in the fragment shader. In our recipe, the loaded
    texture is attached to texture unit `0` (`GL_TEXTURE0`). The fragment uses a uniform
    `Sampler2D` data type that contains the handle of texture unit through which the
    texture is attached. The `glUniform1i` is used to send information to the sampler
    `Tex1` variable in the fragment shader:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: The vertex shader has two generic attributes, namely, `VertexPosition` and `VertexTexCoord`,
    which receive the vertex coordinates and the texture coordinates. Per-vertex texture
    coordinates (received in the vertex shader) are sent to the fragment shader using
    `TexCoord`.
  prefs: []
  type: TYPE_NORMAL
- en: The fragment shader is responsible for sampling the texture; sampling is a process
    of selecting a desire `texel` using texture coordinates; this `texel` provides
    the color information that needs to be applied to the corresponding pixel in the
    primitive. It uses the incoming per-vertex generic attribute called `TexCoord`
    to retrieve texture coordinates and a texture handle in the sampler2D. Texture
    handles allow you to access the texture from the OpenGL ES texture memory to be
    used in shaders to perform the sampling operation. The shading language provides
    a texture for sampling purposes; it uses the texture handle, which is `0` for
    this recipe, and the `TexCoord` texture coordinate.
  prefs: []
  type: TYPE_NORMAL
- en: '![How it works...](img/5527OT_07_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: There's more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we will discuss the various built-in filtering and wrapping
    techniques available in the OpenGL ES 3.0 pipeline. These techniques are applied
    through `glTexParamterf`, `glTexParameteri`, `glTexParameterf`, `glTexParameteriv`,
    or `glTexParameterfv` by specifying various symbolic constants.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Unlike texture, coordinates have the UV coordinate system; the sampling texels
    have a convention of the ST coordinate system, where S corresponds to the horizontal
    axis and T corresponds to the vertical axis. This can be used to define the filtering
    and wrapping behavior along S and T in the sampling process.
  prefs: []
  type: TYPE_NORMAL
- en: Filtering
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The texture filtering technique allows you to control the appearance of the
    texture quality; sometimes, at correct depth, one texel corresponds to exactly
    one pixel on screen. However, in other cases, mapping a smaller texture on to
    a bigger geometry may cause the texture to appear stretched (magnification). Similarly,
    in the vice versa case, many texels are shader by a few pixels (minification).
  prefs: []
  type: TYPE_NORMAL
- en: 'This type of situation is called minification and magnification. Let''s look
    at them in detail:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Minification**: This occurs when many texels exist for a few screen pixels.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Magnification**: This occurs when many screen pixels exist for a few texels.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In order to deal with minification and magnification, OpenGL ES 3.0 provides
    the following two types of filtering techniques:'
  prefs: []
  type: TYPE_NORMAL
- en: '`GL_NEAREST`: This uses the pixel color closest to texture coordinates'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`GL_LINEAR`: This uses the weighted average of four surrounding pixels closest
    to texture coordinates![Filtering](img/5527OT_07_03.jpg)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: OpenGL ES 3.0 provides `GL_TEXTURE_MAG_FILTER` and `GL_TEXTURE_MIN_FILTER` as
    symbolic constants, which can be used in `glTexParamterf` as a parameter to specify
    the filtering technique on magnification and minification respectively.
  prefs: []
  type: TYPE_NORMAL
- en: Wrapping
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'One obvious question that comes to mind is what happens when the range of texture
    mapping is greater than 1.0; the OpenGL ES 3.0 sampling allows three types of
    wrapping mode:'
  prefs: []
  type: TYPE_NORMAL
- en: '`GL_REPEAT`: This produces repeating patterns'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`GL_MIRRORED_REPEAT`: This produces a repeating pattern where adjacent texture
    is mirrored'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`GL_CLAMP_TO_EDGE`: This produces border edges pixels that are repeated'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following image uses 2 x 2 texture coordinates and demonstrates the use
    of wrapping modes:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Wrapping](img/5527OT_07_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: MIP mapping
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This is a texture mapping technique that improves the visual output by reducing
    the aliasing effect and increases the performance of the system by reducing the
    texture bandwidth. MIP mapping uses precalculated versions as a texture (where
    each texture is half of the resolution of the previous one). An appropriate texture
    is selected at runtime according to how far away the viewer is.
  prefs: []
  type: TYPE_NORMAL
- en: 'Textures can be viewed from a far or near viewer''s distance; this changes
    the shape and size of the texture that causes the texture to undergo the minification
    and magnification artefacts. These artefacts can be minimized using the previously
    mentioned filters, but the effective result can only be produced if the texture
    size scales in a factor of half or double; beyond these scales, the filter may
    not produce pleasing results. The MIP mapping improves the quality by picking
    the correct resolution based on the viewer''s distance from the given texture.
    Not only does it improve the quality of the image by minimizing the minification/magnification
    artefacts, but it also increases the performance of the system by picking a correct
    resolution texture instead of using the full resolution image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![MIP mapping](img/5527OT_07_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The `glGenerateMipmap` API can be used to generate mipmaps.
  prefs: []
  type: TYPE_NORMAL
- en: '**Syntax**:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: '| Variable | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| `target` | This specifies the target type to which the texture mipmaps are
    going to generate and bound. The target must be either of `GL_TEXTURE_2D`, `GL_TEXTURE_3D`,
    `GL_TEXTURE_2D_ARRAY`, or `GL_TEXTURE_CUBE_MAP`. |'
  prefs: []
  type: TYPE_TB
- en: The generated mipmaps can be bound to a particular level of depth using the
    `glTexImage2D` API; the second parameter of this API can be used to specify the
    level of detail. Refer to step 2 under *How to do it…* section of current recipe
    to see the full description of the `glTexImage2D` API.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Refer to the *Procedural texture shading with texture coordinates* recipe in
    [Chapter 6](ch06.html "Chapter 6. Working with Shaders"), *Working with Shaders*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Applying multiple textures*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Efficient rendering with the ETC2 compressed texture*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Efficient rendering with the ETC2 compressed texture
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For many reasons, compressed texture is desirable over uncompressed textures;
    the major benefit is reduced memory footprint on the device, smaller size of the
    downloadable application, and an increase in performance. The OpenGL ES 3.0 specifications
    made it compulsory for all vendors to support ETC2 and EAC texture compression
    formats. Prior to this, in OpenGL ES 2.0, texture compression was not standard,
    as a result of which various hardware specific extensions were evolved. Developers
    have to support programs of various extensions in order to achieve texture compression
    on different types of devices.
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we will demonstrate ETC2, which is very famous among different
    texture compression schemes. ETC stands for **Ericson Texture Compression**, which
    is a lossy texture compression technique; this scheme supports both RGB and RGBA
    formats. Additionally, this recipe also demonstrates the new feature of OpenGL
    ES 3.0, which is capable of loading the **nonpower of two** (**NPOT**) texture.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The ETC2 compressed texture can be stored in two types of file formats, that
    is, KTX and `PKM`. The `KTX` file format is a standard Khronos Group compression
    format, which stores multiple textures under a single file; for example, mipmaps
    in `KTX` require only one file to contain all mipmapped textures. On the other
    hand, `PKM` is a very simple file format that stores each compressed texture as
    a separate file. Therefore, in case of mipmaps, it will generate multiple files.
    For this recipe, we will use the `PKM` file format. It consists of a header and
    is followed by the payload; the following c structure declaration describes the
    header:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: OpenGL ES 3.0 supports compressed textures using the `glCompressedTexImage2D`
    API.
  prefs: []
  type: TYPE_NORMAL
- en: '**Syntax**:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: Except the `internalFormat` and `imageSize`, most of the parameters are similar
    to glTexImage2D, which was described in the first recipe. The former is a format
    of the compressed texture and the latter specifies the image size, which is specifically
    calculated using formula. For example, in this recipe, the `internalFormat` is
    a `GL_COMPRESSED_RGB8_PUNCHTHROUGH_ALPHA1_ETC2` format, which is an RGBA. The
    `imageSize` is calculated using the *ceil(width/4) * ceil(height/4) * 8* formula,
    where width and height are the image dimensions.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: For more information on the internal formation and image size calculations,
    refer to OpenGL ES 3.0 reference pages at [https://www.khronos.org/opengles/sdk/docs/man3/html/glCompressedTexImage2D.xhtml](https://www.khronos.org/opengles/sdk/docs/man3/html/glCompressedTexImage2D.xhtml).
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Perform the following steps to program compressed textures; you can refer to
    the `CompressedTexture` sample recipe of this chapter. In this recipe, we will
    render a compressed image on to a square plane:'
  prefs: []
  type: TYPE_NORMAL
- en: This recipe reuses our first `SimpleTexture`; there is no change in the vertex
    or fragment shader; the code to render the square geometry has also been reused.
    For more information, refer to *Applying texture with UV mapping*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In order to process the compressed PKM format image, the GLPI framework provides
    a high-level helper class called `CompressImage`. This class is responsible for
    loading the compressed PKM image using the `loadImage` function. The compressed
    image can be loaded using the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'In `CompressedImage::loadImage`, open the compressed image and read the header
    bytes specified by the ETC2 header specification mentioned previously:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Convert read bytes to the Big Endian format:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Calculate the size of the compressed image as per the specified formula mentioned
    in the *Getting ready* section of this recipe; use it to read the payload image
    buffer:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Generate and bind the `texID` named texture and use `glCompressedTexImage2D`
    to load the compressed texture image buffer:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The `CompressedTexture` class helps in loading the PKM format ETC2 compressed
    texture images. The PKM file format is simple; the header `ETC2Header` size is
    16 bytes long and the payload is variable. The first four bytes of the header
    must be PKM and the next two bytes must be `20` to ensure the ETC2 scheme. The
    format provides the internal format of the compressed image, the next two bytes
    provide the padded dimension of the image, and the last two each byte represents
    the original dimension of the image in pixels. The internal format helps to identify
    the correct formula to calculate the size of the image:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: Finally, the compressed texture is loaded using the `glCompressedTexImage2D`
    OpenGL ES 3.0 API; this API will also provide a table reference for all compressed
    internal formats, which is very helpful to know the image size calculation formula,
    as mentioned in the preceding code. Refer to the previous recipe for more information
    on texture rendering using UV texture coordinates.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There are a variety of texture compression tools available that can be used
    for texture compression; among them, the famous tools are PVRtexTool, Mali GPU
    Texture Compression Tool, and so on. You can use them to compress a desired image
    into the PKM format.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Applying texture with UV mapping*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Applying multiple textures
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The multitexturing allows you to apply more than one texture on a given geometry
    to produce many interesting results; modern graphics allow you to apply multiple
    textures on to geometry by means of texture units. In this recipe, you will learn
    how to make use of multiple texture units in order to implement multitexturing.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This recipe is similar to our first recipe, that is, `SimpleTexture`. The only
    difference is that we will use more than one texture. Instead of using the 2D
    plane geometry, we will use a 3D cube. Additionally, there are some changes required
    in the fragment shader. We will discuss this in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This section will discuss all the important changes made to support multiple
    textures:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Modify the fragment shader to support two given textures simultaneously; these
    two textures are referenced using the `TexFragile` and `Texwood` handles:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a function called `loadMultiTexture`, which will be responsible for
    loading multiple textures in the `MultipleTexture` class; it must be called after
    the loading and compilation of the shader programs. In this function, query the
    location of `TexFragile` and `Texwood` uniform sampler variables:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Activate the texture unit `1` and load the `fragile.png` image using the PngImage''s
    class and the `loadImage` function. This takes care of creating the named texture
    ID and binds it to the current OpenGL ES state. Internally, this API uses `glGenTextures`,
    `glBindTexture`, and `glTexImage2D` to load the image; this wrapper API makes
    the job of loading images easy:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Set the texture filtering and wrapping properties:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Using the `TEX` location of `TexFragile`, send the texture unit information
    to the shader using the `glUniform1i` API. The Fragile.png texture can be accessed
    using texture unit `1`; therefore, send `1` as parameter in the `glUniform1i`
    API:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Similarly, for the second texture, that is, wooden.png, follow the same procedure
    mentioned from the third to the fifth steps:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The fragment shader uses two samplers, namely `TexFragile` and `TexWood`; these
    are used to access texture images in the shader. It stores the handle of texture
    units; therefore, it's very important to query their locations from the fragment
    shader and is stored in the `TEX` and `TEX1`. Texture images are loaded in the
    OpenGL texture memory using the `PngImage::loadImage` function. For single or
    multiple textures, it's compulsory to activate texture units so that they become
    available in the shader program; the texture unit is made active using the `glActiveTexture`
    API. It accepts the handle of the texture unit as an argument. Refer to the next
    section for more information on texture units.
  prefs: []
  type: TYPE_NORMAL
- en: The texture unit 1 is activated for the first texture object (`fragile.png`)
    and a corresponding uniform variable is set with `1` using `glUniform1i(TEX1,
    1)`. Similarly, the second texture unit (`woodenBox.png`) is activated and its
    corresponding uniform variable `TEX1` is set to value `2`. There is no special
    change required for the vertex shader because it sets clip coordinates for the
    incoming position and shares texture coordinates with the fragment shader. The
    fragment shader utilizes these texture coordinates for texture sampling from the
    available two textures; the sampling provides two color values stored in the `TextureFragile`
    and `TextureWood`; these colors are mixed together with the help of the mix GLSL
    API to produce mixed color effect; this API takes three parameters as an input.
    The first two parameters specifies the colors that need to be mixed together,
    whereas the third parameter specifies the proportion of the colors in which these
    need to be mixed.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Texture units can be thought of as buffers that contain texture information
    and the number of texture units fixed; the number is very specific to the hardware
    implementation of the OpenGL ES 3.0\. This number can be checked by using the
    `GL_MAX_COMBINED_TEXTURE_IMAGE_UNITS` macro. The texture object is not directly
    bound with the shader program. Instead, they are bound to the index of the texture
    unit.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following figure, the texture memory shows 16 texture units. Out of
    these, only three seem unoccupied (blue in color) and the rest of them are utilized
    by various texture images. Texture units are uniquely recognized by their index;
    these can be accessed in the shader program directly, thereby giving a unique
    capability of multitexturing. Texture units 1 and 2 are accessed in the fragment
    shader to produce the desired output, as shown in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![There''s more...](img/5527OT_07_11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Implementing Skybox with seamless cube mapping
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Cube mapping is a texturing technique used in 3D graphics to fill the background
    of a scene with a given set of images. This technique reduces the number of objects
    required to draw a scene in order to make the scene look populated (the scene
    looks bigger). It is commonly used in gaming to render sky horizons, rooms, mountains,
    day/night effect, reflection, and refraction.
  prefs: []
  type: TYPE_NORMAL
- en: A cube map is achieved by wrapping six sets of images on six faces of the cube;
    these images perfectly stitch with each other on the edges. In the cube mapping
    technique, the viewer or camera is always in the center of the cube. When camera
    displaces in the 3D space, the cubes are also displaced with respect to it. This
    way, the camera never reaches close to any face of the cube and creates an illusion
    of a horizon that always remains at the same distance from the viewer.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This recipe uses six images named bottom, top, left, right, front, and back
    for each face of the cube to be mapped on, as shown in the following image. When
    these images are wrapped around the cube and viewed from inside, it produces an
    illusion of the sky environment. So far, we have already learned the mapping of
    texture on to a given geometry in our previous recipes using the UV texture coordinate
    mapping. However, OpenGL ES provides a special mapping called cube mapping; this
    mapping makes the job easier to wrap images to a cube-shaped geometry.
  prefs: []
  type: TYPE_NORMAL
- en: 'Creating the cube map in OpenGL ES 3.0 is simple:'
  prefs: []
  type: TYPE_NORMAL
- en: Create a texture object using `glGenTexture`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Bind the texture using the `glBindTexture` API with the `GL_TEXTURE_CUBE_MAP`
    argument. This will help the OpenGL ES to understand the type of texture it needs
    to store.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Load six images in the OpenGL ES texture memory, using `glTexImage2D` with `GL_CUBE_MAP_{POSITIVE,
    NEGATIVE}_{X, Y, Z}` as the target parameter:![Getting ready](img/5527OT_07_07.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This section will describe the practical steps required to implement this recipe:'
  prefs: []
  type: TYPE_NORMAL
- en: Create a class called Skybox to render cube geometry; you can reuse the *Efficient
    rendering with Vertex Buffer Object* recipe from [Chapter 2](ch02.html "Chapter 2. OpenGL
    ES 3.0 Essentials"), *OpenGL ES 3.0 Essentials*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Implement the vertex and fragment shader, as given in the following code. For
    cube mapping, we require the vertex information in the fragment shader. Therefore,
    each incoming per-vertex needs to be shared with the fragment shader:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '| Vertex shader | Fragment shader |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| --- | --- |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '|'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '|'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '|'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Create a function called `createCubeMap` in the `Skybox` class and call the
    following function after the shaders are loaded and compiled:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'In the `createCubeMap` function, make the texture unit `1` active; this allows
    you to access the cube map texture from the fragment shader:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The `createCubeMap` function first loads six images using `PngImage:: loadImage`.
    This function creates the texture objects into the OpenGL ES texture memory. Only
    the first image needs to send with the `true` value in the second argument; this
    parameter will tell the function to generate the named texture (an ID is given
    to the texture object). The rest of the images will use the same texture name
    (ID); therefore, the rest must be sent with a `false` argument. If the image appears
    at the right-hand side corner of the cube box and (`Right.png`) is located at
    the positive *x* axis, then use `GL_TEXTURE_CUBE_MAP_POSITIVE_X` as the fourth
    argument. Similarly, for other images, use the appropriate argument, as shown
    in the preceding code.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Set linear filtering for the minification/magnification and wrapping scheme.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Query the location of the `CubeMapTexture` uniform sampler from the fragment
    shader and set the handle of texture unit as `1`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Render the scene using the `Skybox::Render` function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The cubemap texturing requires six sets of 2D images; these images are mapped
    to the six faces of the cube geometry. Select a texture unit and make it active.
    In the present case, its texture unit is `1` (`GL_TEXTURE1`). Load the image using
    `PngImage::loadImage`; this function is called in the `Skybox::InitModel`. After
    the shaders are loaded, it accepts three arguments. The first argument specifies
    the image file to be loaded and the second argument decides whether to create
    a texture object or not. For example, in the case of cubemap, only the first image
    is required to create a texture object; the remaining images will share the same
    texture object. The final argument specifies the face to which the image belongs
    to in the cubemap. In this function, it creates a texture object using `glGenTexture`
    and bounds it using `glBindTexture` with the `GL_TEXTURE_CUBE_MAP` parameter.
    The `glTexImage2D` API will allocate the necessary storage space for all textures;
    this API accepts important parameters, such as `GL_TEXTURE_CUBE_MAP_POSITIVE_X`,
    `GL_TEXTURE_CUBE_MAP_NEGATIVE_X`, and so on and helps OpenGL ES to know what texture
    to apply on which surface. Share the cubemap texture stored in the texture unit
    `1` to the fragment shader.
  prefs: []
  type: TYPE_NORMAL
- en: In order to render the cubes, we have reused the *Efficient rendering with Vertex
    Buffer Object* recipe, [Chapter 2](ch02.html "Chapter 2. OpenGL ES 3.0 Essentials"),
    *OpenGL ES 3.0 Essentials*. The rendering process takes place in the `Render()`
    function, the cube is scaled in order to fill up the screen and the culling and
    depth testing should be disabled.
  prefs: []
  type: TYPE_NORMAL
- en: From the shader's perspective, cube vertices are received in the vertex shader;
    these are shared to the fragment shader in the form of the position vector as
    the origin is at (0.0, 0.0, 0.0). The position vector turns out to be the same
    as vertex positions. This vertex position in the fragment shader is used for sampling
    purposes where the texture API is provided with the sampler and vertex position;
    it returns the corresponding color of the fragment.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Implementing reflection and refraction with environment mapping*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Refer to the *Efficient rendering with Vertex Buffer Object* recipe in [Chapter
    2](ch02.html "Chapter 2. OpenGL ES 3.0 Essentials"), *OpenGL ES 3.0 Essentials*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing reflection and refraction with environment mapping
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Environment mapping is a simple yet effective and efficient technique that
    allows you to map the surrounding environment effect to render 3D objects. There
    are two ways in which environment mapping can be used: reflection and refraction.
    In the former technique, rendered objects are mapped with the reflection of the
    surroundings, which shows the reflection of the surrounding view of objects. However,
    in the latter case, objects mapped with the refraction allow you to see through
    objects. These environment mapping techniques require cube mapping that we programmed
    in the previous recipe Skybox with seamless cube mapping. In this recipe, we will
    implement the reflection and refraction environment mapping.'
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For this recipe, we can reuse the *Implementing Skybox with seamless cube mapping*
    recipe and *Rendering the wavefront OBJ mesh model* recipes in [Chapter 5](ch05.html
    "Chapter 5. Light and Materials"), *Working with Meshes*. The former recipe does
    not require any special changes. However, we will program a new shader for the
    latter case.
  prefs: []
  type: TYPE_NORMAL
- en: 'Reflection is a phenomenon in which light/wave changes its direction when it
    interacts with other mediums. As a result, it bounces back to the same medium
    from which it was coming from. The angle of incidence of the light is always equal
    to the angle of reflection after bouncing, as shown in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Getting ready](img/5527OT_07_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Refraction is a phenomenon that bends the direction of the wave/light through
    the transmission medium in which it is traveling. The reason for this bending
    is the difference between the optical densities of these two mediums. For example,
    a straw in a glass of water appears bent because light travels at different speeds
    in the given medium/material, such as air and water. This characteristic of the
    medium or material that affects the speed of light is called the refractive index.
    The refractive index of a medium tells us how fast the light travels in a given
    medium; it's the ratio of the speed of light in vacuum (c) to the speed of light
    in that medium (v), *n=c/v*, therefore, the bending of the light is determined
    by its refractive index.
  prefs: []
  type: TYPE_NORMAL
- en: Snell's law gives the relation between the refractive index and the direction
    of propagation. Mathematically, *n1.sinθ1 = n2.sinθ2*. As per this law, the ratio
    of the sine angle of incidence and refraction (*sinθ1/sinθ2*) is equivalent to
    the opposite ratio of refractive index of the mediums (*n2/n1*).
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this section, you will learn the step-by-step procedure to program environment
    mapping for reflection and refraction:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The surrounded environment required in environment mapping is created using
    the cube mapped Skybox from the previous recipe in this chapter. Inside the Skybox
    simple 3D waveform, objects are rendered (refer to the *Rendering the wavefront
    OBJ mesh model* recipe [Chapter 5](ch05.html "Chapter 5. Light and Materials"),
    *Working with Meshes*). Add the `Skybox` and the `ObjLoader` model in the `createModels`
    function and include the required headers:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The Skybox model is responsible for rendering the Skybox environment using the
    cube mapped texture; there is no change required for shader programs. The cube
    mapped texture is stored in the texture unit `1`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The ObjLoader model renders mesh objects and uses the texture unit `1` (containing
    the cube mapped texture) to apply the reflection and refraction mapping.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Define new shader programs (`ReflectionVertex.glsl`) for the vertex shader:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Use the following code reflection mapping fragment shader in `ReflectionFragment.glsl`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Similarly, for refraction, reuse the preceding reflection shader and define
    a uniform float variable for the refraction index called `RefractIndex`. Additionally,
    replace the GLSL `reflect` API with the refract API and rename the `reflectedDirection`
    with `refractedDirection`:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Create `RefractionFragment.glsl` and reuse the code from `ReflectionFragment.glsl`;
    the only change required is renaming the incoming shared attribute called `reflectedDirection`
    with `refractedDirection`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Load and compile the shader in the `ObjLoader::InitModel` function and initialize
    all uniform variables required by the reflection and refraction shaders. Set the
    current texture in `CubeMap` from the texture unit `1` as it contains the cube
    mapped texture. Note that this texture unit was loaded from the Skybox model class:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The working model of the reflection and refraction environment mapping is very
    similar; both use the cube map texturing to produce the reflection and refraction
    effect. The following image shows the logic behind this working model. Here, the
    top view of the cube map is represented with a green rectangle and all the labeled
    edges are faces of the cube. The camera position is depicted by an eye, which
    looks toward the sphere direction that are placed inside the cube map Skybox.
    Each vertex position produces an incident ray from the camera position, which
    is used with the normal vector at the vertex position to calculate the reflected
    vector. This reflected vector is used with the cube-mapped texture to look up
    the corresponding texel. For example, in the following image, the vertex v1, v2,
    and v3 after reflection corresponds to the right, back and left face of the cube
    map. Similarly, refracted rays correspond to the front face of the cube map:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How it works...](img/5527OT_07_09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The reflected and refracted positional vector is calculated in the vertex shader;
    these vectors are shared with the fragment shader, where the cubemap texture is
    used to look up the texel for the corresponding texture.
  prefs: []
  type: TYPE_NORMAL
- en: Now, we know that the working of the environment mapping is at a higher level;
    let's understand the code for reflection environment mapping. The vertex shader
    calculates the world position of each vertex position (`VertexPosition`) and normal
    vector (Normal) in the world coordinate using the model matrix (`MODELMATRIX`)
    and stores it in `worldCoordPosition` and `worldCoordNormal` respectively. The
    incident ray for each vector with respect to camera position is calculated and
    stored in the `incidenceRay`. The OpenGL ES shading language provides a high level
    `reflect()` API to calculate the reflected vector. This API takes an incident
    ray, normal vector, and returns the reflected vector.
  prefs: []
  type: TYPE_NORMAL
- en: '**Syntax**:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: '| Variable | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| `I` | This is the incidence ray from coming from source to destination |'
  prefs: []
  type: TYPE_TB
- en: '| `N` | This is the normal of the surface |'
  prefs: []
  type: TYPE_TB
- en: '| `Return` | This is the reflected vector given by *I - 2.0 * dot(N, I) *N*
    |'
  prefs: []
  type: TYPE_TB
- en: The reflected vector is shared with the fragment shader using an out variable
    called reflected direction. The fragment shader uses this vector to find the corresponding
    texel in the cube map using the `texture()` API.
  prefs: []
  type: TYPE_NORMAL
- en: '![How it works...](img/5527OT_07_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Similarly, the refraction is calculated using the `refract()` GLSL API; unlike
    the reflect API, this accepts an additional parameter called refract index of
    the material and returns the refracted vector.
  prefs: []
  type: TYPE_NORMAL
- en: '**Syntax**:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: '| Variable | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| `I` | This is the incidence ray from coming from source to destination |'
  prefs: []
  type: TYPE_TB
- en: '| `N` | This is the normal of the surface |'
  prefs: []
  type: TYPE_TB
- en: '| `RI` | This is the refractive index of the medium |'
  prefs: []
  type: TYPE_TB
- en: '| `Return` | This is the refracted vector |'
  prefs: []
  type: TYPE_TB
- en: The refracted vector is shared with the fragment shader using `refractedDirection`.
    The texel color is calculated for the corresponding fragment.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Implementing Skybox with seamless cube mapping*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Refer to the *Rendering the wavefront OBJ mesh model* recipe in [Chapter 4](ch04.html
    "Chapter 4. Working with Meshes"), *Working with Meshes*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing render to texture with Frame Buffer Objects
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: OpenGL ES renders a scene on framebuffer; this framebuffer is called the default
    framebuffer. A framebuffer consist of various buffers, such as color, depth, and
    the stencil buffer. **Frame Buffer Objects** (**FBO**) allows you to create user-defined
    framebuffers, which can be used to render scenes on non-default framebuffers.
    The rendered scene on the nondefault framebuffer can be used as a texture to map
    objects. In this recipe, we will demonstrate render to texture in which a scene
    is rendered to a texture and this texture is mapped to a 2D plane surface; the
    2D plane can be rotated in a 3D space using touch gesture events.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The detailed procedure to implement the render to texture recipe using FBO
    is as follows. We will reuse the *Generating the polka dot pattern* recipe from
    [Chapter 6](ch06.html "Chapter 6. Working with Shaders"), *Working with Shaders*:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a `DemoFBO` class derived from the `Model` base class and add `SimpleTexture`
    and `ObjLoader` pointer objects; initialize these objects in the constructor of
    `DemoFBO`. For more information on dependent recipes, refer to the *See also*
    subsection in this recipe:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define the `generateTexture` function; this function is responsible for generating
    the color or depth texture depending on the (`isDepth`) Boolean argument passed
    to it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define the `GenerateFBO` and use the following code. This function is responsible
    for generating the FBO; it uses the color buffer and the depth buffer from the
    framebuffer. This recipe also contains the `GenerateFBOWithRenderBuffer` alternate
    function, which uses Render buffer''s depth buffer to create FBO. For more information,
    refer to *There''s more…* subsection in this recipe:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define the `InitModel` function and initialize the Polka dots and simple texture
    classes. Also, generate the FBO using the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'In the `Render()` function, render the polka dots in the FBO texture and map
    this texture to the 2D plane:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Shader programs can be reused completely without any changes. The only exception
    being that we rename shader from `SimpleTexture` to FBO.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The final destination of all the rendering commands in the rendering pipeline
    is the default framebuffer; OpenGL ES 3.0 provides means to create additional
    framebuffers using FBO. FBO allows you to render a scene directly to a texture,
    which can be used like any other texture for mapping purposes. It can also be
    used for post processing of a scene. Similar to the default framebuffer, FBO also
    contains color, depth, and stencil buffers; these buffers are accessed through
    the (`GL_COLOR_ATTACHMENT0..N`, `GL_DEPTH_ATTACHMENT`, `GL_STENCIL_ATTACHMENT`)
    attachment points, as shown in the following image given in the *There's more…*
    section..
  prefs: []
  type: TYPE_NORMAL
- en: First, like any other buffer object in OpenGL ES, create an FBO and bind it
    using `glGenFramebuffer` and `glBindFrameBuffer`. Use the `generateTexture` function
    and create an empty 256 x 256 color and depth buffer texture object and store
    the handles in `textureId` and `depthTextureId` respectively. The FBO implementation
    of OpenGL ES 3.0 allows one color buffer and one depth buffer, which can be attached
    to the FBO, using the `glFramebufferTexture2D` API; more color buffers may be
    defined depending on the OpenGL ES Driver implementation. This is defined via
    the macro `MAX_COLOR_ATTACHMENTS`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `glFramebufferTexture2D` API attaches the handle of the created color and
    depth buffer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: '**Syntax**:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: '| Variables | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| `target` | This specifies the framebuffer target and should be `GL_FRAMEBUFFER`,
    `GL_DRAW_FRAMEBUFFER`, or `GL_READ_FRAMEBUFFER`. |'
  prefs: []
  type: TYPE_TB
- en: '| `attachment` | This specifies the framebuffer target. For this recipe, it
    should be `GL_COLOR_ATTACHMENT0` for the color buffer and `GL_DEPTH_ATTACHMENT`
    for the depth buffer. |'
  prefs: []
  type: TYPE_TB
- en: '| `textarget` | This specifies the 2D texture target, which in the present
    case is `GL_TEXTURE_2D`. |'
  prefs: []
  type: TYPE_TB
- en: '| `texture` | This specifies the handle of the texture buffer. In the current
    recipe, it should be `textureID` for the color buffer and `depthTextureId` for
    the depth buffer. |'
  prefs: []
  type: TYPE_TB
- en: '| `level` | This specified the Mipmap level. |'
  prefs: []
  type: TYPE_TB
- en: Check the status of the created framebuffer using the `glCheckFramebufferStatus`
    API; this API must return `GL_FRAMEBUFFER_COMPLETE` if the framebuffer is created
    successfully.
  prefs: []
  type: TYPE_NORMAL
- en: Now, we have an FBO with the color and depth buffer attached; the second thing
    we need to do is to render the scene to this texture. For this, we need to redirect
    the rendering command to our FBO instead of a default framebuffer. We need to
    query the handle of the default framework using `glGetIntergerv` with the `GL_FRAMEBUFFER_BINDING`
    parameter and store it in `currentFbo`; we will use this handle to restore the
    default framebuffer once the render to texture operation is accomplished. Bind
    the rendering pipeline with the `fboID` frame buffer object handle using `glBindFramebuffer`.
    Prepare the viewport and clear the color and depth buffer of the FBO using `glViewPort`
    and `glClearColor` APIs respectively. Finally, rendering the Polka dots will redirect
    all the procedural texture-patterned meshes to our `textureId` FBO color texture
    object. After the rendering is completed, restore the default framebuffer by binding
    its handle to the rendering pipeline using `glBindFramebuffer` with `CurrentFbo`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The third important thing is to use the (`textureId`) FBO texture and apply
    it to this 2D square; this process of applying texture is similar to our first
    recipe, that is, simple texture; the only difference here is that instead of a
    static texture, we will use the FBO texture. As we have switched to the default
    buffer, we need to set the viewport and clear the color and depth buffer. Set
    the active texture unit ID to `0` using `glActiveTexture` with the `GL_TEXTURE0`
    parameter or make sure that this texture unit is the same as what is sent to the
    fragment shader. Finally, render the square geometry and see the render to texture
    in action:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How it works...](img/5527OT_07_12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Make sure that the FBO is deleted using the `glDeleteFramebuffers` API when
    it's not required by any application.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The current FBO recipe uses the depth buffer from the `Texture` object. Alternatively,
    we can also use the depth buffer of the render buffer for this purpose. The render
    buffer is a special OpenGL ES object used with the FBO that allows you to render
    off screen; it renders the scene directly to the render buffer object instead
    of a texture object. The render buffer can only store a single image in its internal
    format.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following code, we will see how we can use the render buffer''s depth
    buffer instead of using the depth buffer from the texture object; the process
    of creating an FBO object and attaching with the color buffer of texture images
    is the same as described in the previous section:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: The render buffer is created using `glGenRenderBuffers`, this API returns a
    non-zero value when a **Render** **Buffer Objects** (**RBO**) is created successfully.
    Unlike the other OpenGL ES objects also need to be bound first before using it
    with the help of the `glBindRenderBuffer` API. The created object is empty. Therefore,
    it's allocated to the memory space using the `glRenderbufferStorage` API; this
    API takes four arguments. The first argument specifies the target of the allocation
    (which is `GL_RENDERBUFFER`), the second argument is the internal format render
    buffer image (which may be a color-renderable, depth-renderable, or stencil-renderable
    format). For this recipe, we will use the depth renderable format. The last two
    parameters are used to specify the dimensions of the render buffer.
  prefs: []
  type: TYPE_NORMAL
- en: '**Syntax**:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: Finally, the `glFramebufferRenderbuffer` API helps the RBO depth buffer to attach
    to the FBO depth attachment point. The first parameter of this API specifies the
    framebuffer target, which should be `GL_FRAMEBUFFER` in this case. The second
    argument is the attachment point of the FBO; as we want to attach to the depth
    attachment point, it should be `GL_DEPTH_ATTACHMENT`. The third argument specifies
    the render buffer target and must be `GL_RENDERBUFFER`. The last argument specifies
    the handle of the `rboId` render buffer object. When RBO is no longer in need,
    it can be deleted using `glDeleteRenderbuffers`.
  prefs: []
  type: TYPE_NORMAL
- en: '**Syntax**:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: '![There''s more...](img/5527OT_07_13.jpg)'
  prefs: []
  type: TYPE_IMG
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Applying* *texture* *with UV mapping*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Refer to the *Generating the polka dot pattern* recipe in [Chapter 6](ch06.html
    "Chapter 6. Working with Shaders"), *Working with Shaders*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing terrain with displacement mapping
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The displacement map technique modifies the surface of a geometric shape using
    procedural texture or texture image. This recipe uses the texture image called
    height maps to implement a geographical terrain surface on a 2D plane. A height
    map is a grayscale image where each texel stores the elevation information in
    the range of 0.0 to 1.0 (white is mapped to 1.0 and black is mapped to 0.0). The
    2D plane is represented by a set of vertices arranged in a grid fashion; the elevation
    information for each vertex in this 3D grid space is read from the height map.
    This recipe uses another texture image, which is used to map the grass texture
    on the generated terrain, to make it more realistic.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Perform the following steps to implement the displacement mapping height field
    recipe:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a `HeightField` class and declare the following member variables in
    it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Define the parameterize constructor; the first argument specifies the parent
    of the `HeightField` class, the next two parameters define the dimensions of the
    terrain, and the final two parameters specify the row and column used to create
    the vertex grid for the terrain plane.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'In this function, load the `HeightMap.png` and `grass.png` textures for the
    displacement mapping and texture mapping respectively; this will generate two
    texture objects. We are interested only in the front face of the terrain; the
    total number of faces will be the product of the rows and columns. Allocate the
    memory space for the total number of vertices (`v`), normals (`n`), texture coordinates
    (`tex`), and populate them with their respective information. Calculate vertex
    coordinates using the dimension argument; the normal information is assumed to
    be a positive unit vector along the *y* axis for each vertex. Assign texture coordinates
    for each vertex in the grid plane. Finally, use this populated buffer information
    to generate the VBO and IBO:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'In the `initModel` function, link and compile the vertex and fragment shader.
    Activate texture units and bind it with the height map and grass texture objects.
    The height map texture is used by the vertex shader to read the elevation information
    for each vertex. However, the grass texture is used in the fragment shader to
    paint the geometric surface. The vertex shader uses a `heightFactor` uniform variable
    to control the elevation value for each vertex:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create the `HeightFldVertex.glsl` vertex shader and add the following code.
    In this shader, use texture coordinates and read the elevation information for
    each vertex from the height map texture stored in the `HeightMapTexture`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Similarly, for the `HeightFldFragment.glsl` fragment shader, add the following
    code. Make use of texture coordinates and map the grass texture from the `ImageGrassTexture`
    texture unit to the surface of the terrain:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'In the `Renderer.cpp`, add the `HeightField` model, as shown in the following
    code; the model is `5` units in horizontal and vertical dimensions and contains
    `50` rows and columns:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The following image shows the working of displacement mapping that renders
    the dummy geographical terrain. In this simple example, we assumed the terrain
    plane with dimension as 1 x 1 units with three rows and columns, resulting in
    a 3 x 3 vertex grid. Vertex positions are calculated in such a way that the origin
    always resides in the center; all vertex elevations by default are at 0.0\. The
    vertex shader is responsible for calculating the elevation for each given vertex
    using the gray scale height map texture. This texture is loaded and accessed using
    the `HeightMapTexture` texture unit (image part **A**), the height information
    is read using the `TexCoords` texture coordinate (image part **D**) from the height
    map and is assigned to elevation coordinates (image part **B: H0**, **H1\. . .
    H8**). Finally, the output of the displacement mapping looks like part **C**,
    as shown in the following image. This is the screenshot of the practical recipe,
    in which the terrain is 5 x 5 wide and contains 50 x 50 rows and columns.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the fragment shader, the grass image texture is applied to the surface of
    the terrain geometry with the help of a simple texture mapping technique; this
    makes the geometry more realistic. The image parts **D**, **E**, and **F** show
    the output of the fragment shader:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How it works...](img/5527OT_07_14.jpg)'
  prefs: []
  type: TYPE_IMG
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Refer to the *Efficient rendering with Vertex Buffer Object* recipe in [Chapter
    2](ch02.html "Chapter 2. OpenGL ES 3.0 Essentials"), *OpenGL ES 3.0 Essentials*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Refer to the *Managing VBO with Vertex Array Objects* recipe in [Chapter 3](ch03.html
    "Chapter 3. New Features of OpenGL ES 3.0"), *New Features of OpenGL ES 3.0*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing bump mapping
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The bump mapping technique is a very efficient technique as compared to displacement
    mapping. This technique is also used to add depth details or elevations to the
    surface of the geometry. However, this depth or elevation is fake. The geometry
    vertices do not undergo any change in the elevation. Instead, it uses the light
    illumination to simulate the depth appearance on a smooth surface. Light illumination
    uses the vertex normal information stored in normal maps to add depth. Like height
    maps, which store the height or elevation information, the normal map stores normal
    information. The idea in normal maps is to avoid calculation of normal maps for
    each triangular face; these can be sampled from the texture.
  prefs: []
  type: TYPE_NORMAL
- en: The designer responsible for designing mesh models first create a very high
    polygon (100,000+) mesh model, then they create a normal map out of it in an image
    file. Finally, they reduced the high-resolution model to a low polygon mesh (between
    3000 and 5000 depends). Depth details are applied at runtime to the low poly mesh
    using a normal map, which results in a similar appearance like the high poly mesh.
    Therefore, bump mapping is used to add high details in a low poly mesh model.
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we will implement an earth globe, which makes use of the normal
    map to produce the bump mapping effect; this makes the 3D depth information more
    obvious on the globe surface.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In order to implement this recipe, we need two textures. The first texture contains
    the color information to apply texture on the geometric surface. The second texture
    is the normal map of the first texture. There are many tools available to generate
    normal maps, such as CrazyBump, GIMP, PixPlant, Photoshop plugins, XNormals, and
    so on.
  prefs: []
  type: TYPE_NORMAL
- en: '![Getting ready](img/5527OT_07_15.jpg)'
  prefs: []
  type: TYPE_IMG
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The step-by-step instructions to implement bump mapping are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Load the `sphere.obj` with `ObjLoader::LoadMesh()`; this function uses the `OBJMesh`
    class to load the mesh data. This recipe requires the tangent information from
    the loaded mesh in order to implement the bump mapping; this is automatically
    calculated by the `OBJMesh` class with the help of the `CalculateTangents` function.
    For more information on this function and mathematics calculations, refer to the
    *There's more…* section of this recipe.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Load the `earthcolor.png` earth texture and its normal (`earthnormal.png`) to
    create texture objects in the `ObjLoader::initModel`, as shown in previous recipes.
    Attach and bind these two texture objects to the texture unit `0` and `1` respectively
    so that they become available to the shader programs.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Create the `BumpVertex.glsl` and add the following code snippet; this code
    is responsible for calculating the bi-normal tangent (`B`) with the help of the
    cross product of normal (`N`) and tangent (`T`). All these vertex parameters are
    in the tangent space; these must be normalized and stored as a 3x3 tangent space
    matrix represented by (`[Tx, Bx, Nx]`, `[Ty, By, Ny]`, and `[Tz, Bz, Nz]`). This
    is used to convert the eye space to a tangent space. The `eyecoord` in the present
    case is converted to the tangent space and shared with the fragment shader:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create the `BumpFragment.glsl` and use the following code; the fragment shader
    coverts the light direction from eye coordinates to the tangent space; this is
    helpful in calculating the diffuse and specular intensity:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The bump map requires two texture files. The first texture file contains color
    information and is used in the diffuse shading. The second texture is called the
    normal map, which contains the normal information for the geometry; this information
    is helpful for specular shading. Both these textures are loaded and stored in
    texture units in order to make it accessible to the shader.
  prefs: []
  type: TYPE_NORMAL
- en: 'Bump mapping heavily relies on the tangent information calculated in the `ObjMesh`
    class when the mesh is loaded. For more information on the tangent calculation,
    refer to the next section in this recipe. The tangents that are calculated are
    stored within the mesh VBO and are available to the vertex shader unlike other
    vertex attributes. In the vertex shader, this information in conjunction with
    the normal information helps to calculate per-vertex bi-tangent vectors. Once
    the normal (N), tangent (T), and bi-tangent (B) vectors are available, they are
    normalized and used to create a tangent space matrix, as shown in the following
    figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How it works...](img/5527OT_07_16.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The obtained tangent space matrix (`tangentSpace`) is multiplied with the eye
    coordinates of the `VertexPosition` to yield tangent space eye coordinates (`eyeCoord`).
    These are then shared with the fragment shader, along with the tangent space matrix
    and the `TexCoords` texture coordinates.
  prefs: []
  type: TYPE_NORMAL
- en: In the fragment shader, the image texture and normal texture are sampled using
    texture coordinates and are stored in the `texColor` and `normalMap`. It's necessary
    to change the normal map values from the range `[0, 1]` to `[-1, 1]`. Once changed,
    these two texture values are then sent to the `GouraudShading`. In this function,
    the light direction for each vertex is calculated and multiplied with the `tangentSpace`
    in order to transform into the tangent space. This modified `normalizeLightVec`
    and `eyeCoord` are then used to calculate diffuse and specular illumination components
    in the same way we calculated in the Gouraud shading technique. For more information
    on this technique, refer to [Chapter 5](ch05.html "Chapter 5. Light and Materials"),
    *Light and Materials*.
  prefs: []
  type: TYPE_NORMAL
- en: '![How it works...](img/5527OT_07_17.jpg)'
  prefs: []
  type: TYPE_IMG
- en: There's more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The normal map used in the bump mapping technique stores normal information
    of the geometry with respect to some default direction when normal map was generated.
    When this texture is mapped on the geometry and used for rendering purposes, it
    may generate incorrect results because not all faces of the geometry have the
    same direction as the mapped normal map. Therefore, the normal map needs to be
    manipulated on the fly at runtime, depending on the direction of the face, which
    is done using tangent planes. In the `ObjMesh` class, this tangent plane is calculated
    using `OBJMesh::CalculateTangents`; the tangent plane consists of Tangent (T)
    and BiTangent (B) vectors.
  prefs: []
  type: TYPE_NORMAL
- en: A tangent is a vector that touches a curved surface at a given point; there
    could be too many tangents at a given point. Hence, it's very important to choose
    the correct tangent. Therefore, we want our tangent space to be aligned in such
    a way that **X** direction corresponds to the **U** direction of texture coordinates
    and **Y** direction corresponds to the **V** direction of texture coordinates.
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider a scenario where there is a triangle with vertices P[0], P[1], and
    P[2] and corresponding texture coordinates as (U[0], V[0]), (U[1], V[1]), and
    (U[2], V[2]), the following image explains the calculation of the tangent space
    (see the equations). This gives the un-normalized Tangent (T) and BiTangent (B)
    for the triangle face created using P[0], P[1], and P[2]. In order to calculate
    the tangent for a given vertex, take the average tangents of all triangle faces
    that share this vertex:'
  prefs: []
  type: TYPE_NORMAL
- en: '![There''s more...](img/5527OT_07_18.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The preceding pictorial illustration and given equations in it, the tangent
    information is calculated in the `OBJMesh` class, as shown in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Refer to the *Gouraud shading – the per-vertex shading technique* recipe in
    [Chapter 5](ch05.html "Chapter 5. Light and Materials"), *Light and Materials*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Refer to the *Rendering the wavefront OBJ mesh model* recipe in [Chapter 4](ch04.html
    "Chapter 4. Working with Meshes"), *Working with Meshes*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
