- en: Designed for Concurrency
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we'll discuss the most common concurrency design patterns,
    implemented with coroutines, and how coroutines can synchronize their execution.
  prefs: []
  type: TYPE_NORMAL
- en: Concurrent design patterns help us to manage many tasks at once. Yeah, I know,
    that's what we did in the last chapter. That's because some of those design patterns
    are already built into the language.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we'll briefly cover design patterns and other concurrent design
    patterns that you'll need to implement by yourself, with little effort.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will be covering the following topics in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Active Object
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deferred value
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Barrier
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Scheduler
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pipelines
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fan out
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fan in
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Buffered channels
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Unbiased select
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mutex
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Select on close
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sidekick channel
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deferred channel
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Active Object
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This design pattern allows a method to be executed in a safe way on another
    thread. Guess what else is being executed on another thread?
  prefs: []
  type: TYPE_NORMAL
- en: 'You''re totally right: `actor()`.'
  prefs: []
  type: TYPE_NORMAL
- en: So, it's one of those design patterns that is already built into the language.
    Or, to be precise, into one of the accommodating libraries.
  prefs: []
  type: TYPE_NORMAL
- en: We've already seen how to send data to `actor()`. But how do we receive data
    from it?
  prefs: []
  type: TYPE_NORMAL
- en: 'One way is to supply it with a channel for output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Remember to close the output channel when you're done.
  prefs: []
  type: TYPE_NORMAL
- en: Testing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To test the **Active Object** pattern, we''ll launch two jobs. One will send
    data to our actor:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'And another will wait for output on the outbound channel:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Deferred value
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We've already met deferred values in [Chapter 8](part0196.html#5QTE80-6704093aa34748cfa77c54bdc1a20dc7), *Threads
    and Coroutines*, in the *Returning results* section. `Deferred` is the result
    of the `async()` function, for example. You may also know them as *Futures* from
    Java or Scala, or as *Promises* from JavaScript.
  prefs: []
  type: TYPE_NORMAL
- en: Interestingly enough, Deferred is a **Proxy** design pattern that we've met
    in previous chapters.
  prefs: []
  type: TYPE_NORMAL
- en: Much as the Kotlin `Sequence` is very similar to the Java8 `Stream`, Kotlin
    Deferred is very similar to Java Future. You'll rarely need to create your own
    Deferred. Usually, you would work with the one returned from `async().`
  prefs: []
  type: TYPE_NORMAL
- en: 'In cases where you do need to return a placeholder for a value that would be
    evaluated in the future, you can do it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: This code will print `OK` half of the time, and throw `RuntimeException` the
    other half of the time.
  prefs: []
  type: TYPE_NORMAL
- en: Make sure that you always complete your deferred. It is usually a good idea
    to wrap any code containing deferred into a `try...catch` block.
  prefs: []
  type: TYPE_NORMAL
- en: 'It is also possible to cancel a deferred if you''re no longer interested in
    its results. Simply call `cancel()` on it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Barrier
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Barrier design pattern provides us with the means to wait for multiple concurrent
    tasks before proceeding further. A common use case is composing objects from different
    sources.
  prefs: []
  type: TYPE_NORMAL
- en: 'Take, for example, the following class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Assume that we're fetching name, `catchphrase`, and number. This `catchphrase`
    is being repeated from three different sources.
  prefs: []
  type: TYPE_NORMAL
- en: 'The most basic way would be to use `CountDownLatch`, as we did in some of the
    previous examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'You''ll notice that the order of the async tasks completing is changing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'But in the end, we always print the same result:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: But this solution brings a lot of problems. We need to work with mutable variables
    and either set defaults for them or use nulls.
  prefs: []
  type: TYPE_NORMAL
- en: Also, this would work as long as we use closures. What if our functions were
    longer than a few lines?
  prefs: []
  type: TYPE_NORMAL
- en: CountDownLatch
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We could pass them the latch, of course. The latch, which we''ve already seen
    a couple of times, allows one thread to wait until the other threads have completed
    working:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: But it's not a clear separation of concerns. Do we really want to specify how
    this function should be synchronized?
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s have a second take:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Just a reminder, `fun getRepeats() = async { ... }` has nothing magical in
    it. Its longer equivalent is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'We can call our code to get the same results as before:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: But we can improve it further by using our old friend, data class.
  prefs: []
  type: TYPE_NORMAL
- en: Data class as Barrier
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now our data class is the Barrier:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'The additional benefit of data classes as Barriers is the ability to destructure
    them easily:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: This works well if the type of data we receive from different asynchronous tasks
    is widely different. In this example, we receive both `String` and `Int`.
  prefs: []
  type: TYPE_NORMAL
- en: In some cases, we receive the same types of data from different sources.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, let''s ask Michael (our canary product owner), Jake (our barista),
    and me who our favorite movie character is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'In that case, we can use a list to gather the results:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Scheduler
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This is another concept we discussed briefly in [Chapter 8](part0196.html#5QTE80-6704093aa34748cfa77c54bdc1a20dc7),
    *Threads and Coroutines*, in the *Starting a coroutine* section.
  prefs: []
  type: TYPE_NORMAL
- en: Remember how our `launch()` or `async()` could receive `CommonPool`?
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s an example to remind you that you could specify it explicitly:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: This `CommonPool` is a Scheduler design pattern in a bad disguise. Many async
    tasks may be mapped to the same Scheduler.
  prefs: []
  type: TYPE_NORMAL
- en: 'Run the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'What is interesting is the fact that the same coroutine is picked up by different
    threads:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'You can also specify the context as `Unconfined`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'This will run the coroutine on the main thread. It prints:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'You can also inherit context from your parent coroutine:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Note though, that running in the same context doesn't mean that we run on the
    same thread.
  prefs: []
  type: TYPE_NORMAL
- en: 'You may ask yourself: what''s the difference between inheriting the context
    and using `Unconfined`? We''ll discuss this in detail in the next section.'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding contexts
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To understand different contexts, let''s look at the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: Instead of `yield()`, we're using the `delay()` function, which also suspends
    the current coroutine.
  prefs: []
  type: TYPE_NORMAL
- en: 'But the output compared to `yield()` is different:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: After calling `delay()` for the first time, the coroutine has switched context,
    and as a result, threads.
  prefs: []
  type: TYPE_NORMAL
- en: For that reason, using `Unconfined` is not recommended for CPU-intensive tasks
    or tasks that need to run on a particular thread, such as UI rendering.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can also create your own thread pool for coroutines to run on:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'It prints:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: If you create your own thread pool, make sure that you either release it with
    `close()` or reuse it, since creating a new thread pool and holding to it is expensive
    in terms of resources.
  prefs: []
  type: TYPE_NORMAL
- en: Pipelines
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In our `StoryLand`, the same lazy architect, me, is struggling with a problem.
    Back in [Chapter 4](part0112.html#3APV00-6704093aa34748cfa77c54bdc1a20dc7), *Getting
    Familiar with Behavioral Patterns*, we wrote an HTML page parser. But it depends
    on whether somebody already fetched the pages to parse for us. It is also not
    very flexible.
  prefs: []
  type: TYPE_NORMAL
- en: What we would like is for one coroutine to produce an infinite stream of news,
    and for others to parse that stream in steps.
  prefs: []
  type: TYPE_NORMAL
- en: 'To start working with DOM, we''ll need a library, such as `kotlinx.dom`*. *If
    you''re using **Gradle**, make sure you add the following lines to your `build.gradle`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: Now, to the task at hand.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we would like to fetch news pages once in a while. For that, we''ll
    have a producer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: We use `shuffled()` here so the order of the list elements won't be the same
    all the time.
  prefs: []
  type: TYPE_NORMAL
- en: The `isActive` flag will be true as long as the coroutine is running and hasn't
    been canceled. It is good practice to check this property in loops that may run
    for a long time, so they could be stopped between iterations.
  prefs: []
  type: TYPE_NORMAL
- en: Each time we receive new titles, we send them downstream.
  prefs: []
  type: TYPE_NORMAL
- en: Since tech news isn't updated very often. We can check for updates only once
    in a while, using `delay()`. In the actual code, the delay would probably be minutes,
    if not hours.
  prefs: []
  type: TYPE_NORMAL
- en: 'The next step is creating **Document Object Model** (**DOM**) out of those
    raw strings containing HTML. For that we''ll have a second producer, this one
    receiving a channel that connects it to the first one:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: We can use the `for` loop to iterate over the channel as long as more data is
    coming. This is a very elegant way of consuming data from a channel.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this producer, we finally make use of the DOM parser we imported a while
    ago. We also introduced an extension function on `String` for our convenience:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'That''s because `parseXml()` expects `InputSource` as its input. Basically,
    this is an **Adapter** design pattern in action:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: We're looking for the headers, hence `getElementsByTagName("H1")`. For each
    header found, and there may be more than one, we get its text with `textContent`.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we're sending each header from each page to the next in line.
  prefs: []
  type: TYPE_NORMAL
- en: Establishing a pipeline
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now, to establish our pipeline:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'We have the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: A pipeline is a great way to break a long process into smaller steps. Note that
    each producing coroutine is a pure function, so it's also easy to test and reason
    about.
  prefs: []
  type: TYPE_NORMAL
- en: The entire pipeline could be stopped by calling `cancel()` on the first coroutine
    in line.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can achieve an even nicer API by using the extension functions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'Then we can call our code like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: Kotlin really excels at creating expressive and fluent APIs.
  prefs: []
  type: TYPE_NORMAL
- en: The fan-out design pattern
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What if the amount of work at different steps in our pipeline is very different?
  prefs: []
  type: TYPE_NORMAL
- en: For example, it takes a lot more time to fetch the HTML than to parse it. Or
    what if we don't have a pipeline at all, just a lot of tasks we would like to
    distribute between coroutines.
  prefs: []
  type: TYPE_NORMAL
- en: That's where the fan-out design pattern kicks in. The number of coroutines may
    read from the same channel, distributing the work.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can have one coroutine produce some results:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'And have a function that would create a coroutine that reads those results:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'This allows us to generate an arbitrary number of consumers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: The fan-out design pattern allows us to efficiently distribute the work across
    a number of coroutines, threads, and CPUs.
  prefs: []
  type: TYPE_NORMAL
- en: The fan-in design pattern
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It would be great if our coroutines could always make decisions by themselves. But
    what if they need to return some results from the computation to another coroutine?
  prefs: []
  type: TYPE_NORMAL
- en: The opposite of **fan-out** is the **fan-in** design pattern. Instead of multiple
    coroutines reading from the same channel, multiple coroutines can write their
    results to the same channel.
  prefs: []
  type: TYPE_NORMAL
- en: 'Imagine that you''re reading news from two prominent tech resources: `techBunch`
    and `theFerge`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Each resource produces the values at its own pace, and sends them over a channel:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'By providing them with the same channel, we can combine their results:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: Combining the fan-out and fan-in design patterns is a good base for **Map**/**Reduce**
    algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: To demonstrate that, we'll generate 10,000,000 random numbers and compute the
    maximum number among them by dividing this task multiple times.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, to generate the list of 10,000,000 random integers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: Managing workers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now we''ll have two types of workers:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The divide worker will receive the list of numbers, determine the biggest number
    in the list, and send it over to the output channel:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'The collector will listen to this channel and each time a new sub-max number
    arrives, will decide whether it''s the all-time biggest:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we only need to establish those channels:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: Note that in this case, we don't gain performance benefits, and naive `numbers.max()`
    would produce better results. But the more data you need to collect, the more
    useful this pattern becomes.
  prefs: []
  type: TYPE_NORMAL
- en: Buffered channels
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Up until now, all the channels that we used had a capacity of exactly one element.
  prefs: []
  type: TYPE_NORMAL
- en: 'This means that if you write to this channel but no one reads from it, the
    sender will be suspended:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: This code doesn't print anything because the coroutine is waiting for someone
    to read from the channel.
  prefs: []
  type: TYPE_NORMAL
- en: 'To avoid that, we can create a buffered channel:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: Now suspension will occur only when the channel capacity is reached.
  prefs: []
  type: TYPE_NORMAL
- en: 'It prints:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'Since `produce()` and `actor()` are also backed up by a channel, we can make
    it buffered too:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: Unbiased select
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the most useful ways to work with channels is the `select {}` clause
    we saw in [Chapter 8](part0196.html#5QTE80-6704093aa34748cfa77c54bdc1a20dc7), *Threads
    and Coroutines*, in the *Producers* section.
  prefs: []
  type: TYPE_NORMAL
- en: But select is inherently biased. If two events happen at the same time, it will
    select the first clause.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following example, we''ll have a producer that sends five values with
    a very short delay:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'We''ll create three such producers and see the results:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'We run this code five times. Here are some of the results:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, `A` almost always wins, while `C` is always third. The more
    `repeats` you set, the larger the bias gets.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now let''s use `selectUnbiased` instead:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'The results of the first five executions may look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: Not only are the numbers distributed more evenly now, but all clauses have an
    equal chance of being selected.
  prefs: []
  type: TYPE_NORMAL
- en: Mutexes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Also known as mutual exclusions, mutexes provide a means to protect a shared
    state.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s start with same, old, dreaded counter example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: As you've probably guessed, this prints anything but the result of `10*100`.
    Totally embarrassing.
  prefs: []
  type: TYPE_NORMAL
- en: 'To solve that, we introduce a mutex:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: Now our example always prints the correct number.
  prefs: []
  type: TYPE_NORMAL
- en: This is good for simple cases. But what if the code within the critical section
    (that is, between `lock()` and `unlock()`) throws an exception?
  prefs: []
  type: TYPE_NORMAL
- en: 'Then we''ll have to wrap everything in `try...catch`, which is not very convenient:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'Exactly for that purpose, Kotlin also introduces `withLock()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: Selecting on close
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Reading from a channel using `select()` is nice until it gets closed.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can see an example of that problem here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: Although the numbers add up, we may often receive `ClosedReceiveChannelException`
    running this code. That's because the second producer has fewer items, and as
    soon as it finishes, it will close its channel.
  prefs: []
  type: TYPE_NORMAL
- en: To avoid that, we can use `onReceiveOrNull`, which will return a nullable version
    at the same time. Once the channel gets closed, we'll receive `null` in our `select`.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can handle this null value in any way we want, for example, by making use
    of the `elvis` operator:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: 'Using that knowledge, we can drain both channels by skipping the null results:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: Sidekick channel
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Up until now, we've only discussed the usages of `select` as a receiver. But
    we can also use `select` to send items to another channel.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s look at the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: We have a superhero and their sidekick as two actors. Since the superhero is
    more experienced, it usually takes them less time to beat the villain they're
    facing.
  prefs: []
  type: TYPE_NORMAL
- en: But in some cases, they still have their hands full, so a sidekick needs to
    step in.
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ll throw five villains at the pair with a few delays, and see how they
    fare:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: 'It prints:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: Notice that the type parameter for this select refers to what is returned from
    the block, and not what is being sent to the channels.
  prefs: []
  type: TYPE_NORMAL
- en: That's the reason we use `Pair<String, String>` here.
  prefs: []
  type: TYPE_NORMAL
- en: Deferred channel
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The more you work with coroutines, the more you'll get used to await results.
    At some point, you'll start sending deferred values over channels.
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ll start by creating 10 async tasks. The first will delay for a long time,
    and others we delay for a short time:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: We'll put all those results into a buffered channel.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we can read from this channel, and be using a second `select` block, and
    await the results:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that the resulting time is of the slowest task:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: You can also use `onAwait()` as a stop signal for another channel.
  prefs: []
  type: TYPE_NORMAL
- en: 'For that, we''ll create an async task that will complete in 600 ms:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: 'And, as in the previous example, we''ll send 10 deferred values over the buffered
    channel:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: 'Then we''ll wait for either a new value or a notification that the channel
    should be closed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: This prints only six values out of ten, as expected, stopping after 600 ms have
    passed.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we covered various design patterns related to concurrency in
    Kotlin. Most of them are based on coroutines, channels, deferred values, or a
    combination.
  prefs: []
  type: TYPE_NORMAL
- en: '**Pipeline**, **fan-in**, and **fan-out** help distribute work and collect
    the results. **Deferred values** are used as placeholders for something that would
    resolve at a later time. **Schedulers** help us manage resources, mainly threads
    that back up the coroutines. **Mutexes** and **Barriers** help control that concurrency.'
  prefs: []
  type: TYPE_NORMAL
- en: Now you should understand the `select` block and how it can be combined with
    channels and deferred values efficiently.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we'll discuss Kotlin's idioms, best practices, and some
    of the anti-patterns that emerged with the language.
  prefs: []
  type: TYPE_NORMAL
