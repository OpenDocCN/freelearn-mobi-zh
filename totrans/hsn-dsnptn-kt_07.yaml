- en: Staying Reactive
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Once we're familiar with functional programming and its building blocks, we
    can start discussing reactive programming concepts. While it's not coupled with
    functional programming (you can be reactive while writing object-oriented or procedural
    code, too), it's still better to discuss after learning about functional programming
    and its foundation.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Reactive principles
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reactive extension
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reactive principles
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So, what is reactive programming?
  prefs: []
  type: TYPE_NORMAL
- en: It's summarized nicely by the reactive manifesto: [https://www.reactivemanifesto.org](https://www.reactivemanifesto.org).
  prefs: []
  type: TYPE_NORMAL
- en: 'To cite it, reactive programs are:'
  prefs: []
  type: TYPE_NORMAL
- en: Responsive
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Resilient
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Elastic
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Message-driven
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To understand these four topics, let's imagine 10 people standing in a line
    for a cashier. Each one of them can see only the person in front, but not how
    many people are in the line ahead of that person or what the cashier is doing.
    Do you have this picture in your mind? Let's start then.
  prefs: []
  type: TYPE_NORMAL
- en: Responsiveness
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Would you stand in that line for the cashier?
  prefs: []
  type: TYPE_NORMAL
- en: That depends on the urgency and how much time you have. If you're in a hurry,
    you'll probably leave empty-handed before reaching the cash register.
  prefs: []
  type: TYPE_NORMAL
- en: That's a system being unresponsive to you. You're often in the same situation
    when reaching a call center of one of the service providers by phone. You're asked
    to wait on the line, and you wait. But, more often than not, a nice automatic
    voice tells you how many people are waiting on the same line ahead of you or even
    how much time you'll have to wait.
  prefs: []
  type: TYPE_NORMAL
- en: In both cases, the result is the same. You've wasted your time waiting in line
    or on the line. But the second system was responsive to your needs, and you could
    make decisions based on that.
  prefs: []
  type: TYPE_NORMAL
- en: Resiliency
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's continue to resiliency. You're waiting on the line for 10 minutes, then
    the line drops. Or, you reached one of the customer care representatives, but
    they hang up on you by mistake. How often does that happen? That's the system
    not being resilient to failures. Or, you've waited in line for half an hour to
    see a doctor, when they suddenly leave the office and go to a golf club, asking
    you to come back tomorrow. That's a system that wasn't responsive in the face
    of failure.
  prefs: []
  type: TYPE_NORMAL
- en: 'The reactive manifesto discusses various ways to achieve resiliency:'
  prefs: []
  type: TYPE_NORMAL
- en: Delegation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Replication
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Containment
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Isolation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Delegation is when the doctor comes out of their office and tells you, *I can't
    see you* *today, but knock on the other door; they'll see to you soon*.
  prefs: []
  type: TYPE_NORMAL
- en: Replication is for a clinic to always have two doctors available, just in the
    event that one of them miss their favorite team playing this evening. It relates
    to elasticity, which we'll discuss in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Containment and isolation are usually discussed together. What if you actually
    don't need to see the doctor? Maybe you only need a prescription from them. Then,
    you could leave them a message (we'll discuss message-passing soon, as it's also
    an important part of reactiveness) and they'll send you a recipe when they're
    between games. You decoupled yourself from seeing a doctor. It also provided you
    with isolation from the doctors' failures or problems. What you didn't know is
    that, while printing your recipe, their computer crashed twice and they were really
    stressed about that. But because you weren't in front of them, they kept that
    to themselves.
  prefs: []
  type: TYPE_NORMAL
- en: Elasticity
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So, in the previous section, we discussed replication. To prevent failures,
    our clinic always has two doctors available. Maybe the second doctor served some
    patients, or maybe they were just patiently waiting for the first doctor to leave
    for their football game to start working.
  prefs: []
  type: TYPE_NORMAL
- en: But, what would happen to that resilient system if suddenly there is a flu epidemic
    or a band of rabid squirrels starts attacking citizens in the nearby park? Two
    doctors won't be able to handle all of the patients and then, again, we have a
    problem with resiliency.
  prefs: []
  type: TYPE_NORMAL
- en: But what if we had a supply of retired doctors sitting in their homes playing
    mahjong? Certainly, we could call them to come and help bandage all of those squirrel
    victims. And after they were all properly treated, the doctors could return to
    their mahjong.
  prefs: []
  type: TYPE_NORMAL
- en: That's a system being elastic depending on the workload.
  prefs: []
  type: TYPE_NORMAL
- en: Elasticity builds on scalability. We could treat all of those patients because
    each doctor could work independently. But what if all of the bandages were stored
    in a single box? Then it would create a bottleneck, with all of those doctors
    standing around waiting for the next pack of bandages.
  prefs: []
  type: TYPE_NORMAL
- en: Message-driven
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This is also referred to as *asynchronous message passing*. So, we saw in the
    *Resiliency* section that if you could leave a message for the doctor, it may
    make the system more resilient.
  prefs: []
  type: TYPE_NORMAL
- en: What if all of the patients would only leave messages? Then each doctor could
    prioritize them or batch-process those messages. For example, printing all recipes
    together, instead of switching between different tasks.
  prefs: []
  type: TYPE_NORMAL
- en: In addition to loose coupling and isolation, there's also *location transparency*.
    You didn't know tha your doctor sent you this prescription while driving home
    (they snuck out of the window while you left your message). But you don't care since
    you got what you wanted.
  prefs: []
  type: TYPE_NORMAL
- en: Using messages also allows an interesting option of *backpressure*. If your
    doctor receives too many messages, they may collapse from stress. To avoid that,
    they may text you to say that you'll have to wait a bit longer to receive your
    prescription. Or, if they have a secretary, we may even ask them to do that anyway.
    Again, we're talking about delegation here, as all of those principles are correlated.
  prefs: []
  type: TYPE_NORMAL
- en: Messages are also non-blocking. After you leave the message, you don't sit there
    waiting for the doctor's response. You usually go back home, to your regular tasks.
    The ability to perform other tasks while you wait is one of the cornerstones of
    concurrency.
  prefs: []
  type: TYPE_NORMAL
- en: Reactive extension
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The rest of this chapter will be dedicated to the specific implementation of
    reactive principles in Kotlin. The predominant library in this field is RxJava.
    Since Kotlin is fully interoperable with Java libraries, RxKotlin is only a thin
    wrapper over the original RxJava. Hence, we'll discuss it as if these are one
    and the same library, and highlight the differences, if any.
  prefs: []
  type: TYPE_NORMAL
- en: As soon as we start talking about RxJava, you'll recognize it's built upon the **Observer**
    design pattern we discussed in [Chapter 4](part0112.html#3APV00-6704093aa34748cfa77c54bdc1a20dc7),
    *Getting Familiar with Behavioral Patterns*.
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ll start by adding the following dependency to our Gradle project:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Currently, this is the latest version of RxJava2, but when you read this chapter,
    there will probably ba a more recent version already. Feel free to use it.
  prefs: []
  type: TYPE_NORMAL
- en: 'You may remember that the pattern consists of two objects:'
  prefs: []
  type: TYPE_NORMAL
- en: '`publisher`: Produces data'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`subscriber`: Consumes data'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In RxJava, publishers are called `Observable`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code will create our first publisher:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'To start consuming those numbers, we can supply a lambda to the `subscribe()`
    function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'There are other functions available on `Observable` that you''ll immediately
    recognize: `map()` and `filter()`, for example. Those are the same functions that
    are available on regular arrays in Kotlin:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: OK, this is nice, but we've already discussed collections and streams in sequences
    in the previous chapter. Why do it again?
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s look at the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'This code will wait for five milliseconds before terminating and it will print
    the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: This is unexpected. `Sleeping` was the last line in the code, but it's printed
    first. Then notice that `P2` is printed before `P1` sometimes if you run this
    example more than once. And sometimes, it's `P1` before `P2`, much like in the
    code. What's going on here?
  prefs: []
  type: TYPE_NORMAL
- en: That's asynchronicity in action. We need `Thread.sleep()` here to allow our
    listeners to run for some time, otherwise, our program would terminate. And when
    they're called, it doesn't matter where in the actual code they were placed.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we'll use `Thread.sleep()` and `CountDownLatch` a lot to demonstrate
    how asynchronism works. In a real-life application, you should never use `Thread.sleep`.
    If you're still not familiar with `CountDownLatch,` don't worry, we'll explain
    how it works the first time we stumble upon it, in the *Flowables* section.
  prefs: []
  type: TYPE_NORMAL
- en: Well, that's how the Observer design pattern behaves, naturally. But with Observer,
    there's also an option to unsubscribe. How do we achieve it here?
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s replace the second listener with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: A call to `subscribe()` returns a `Disposable`. When you no longer want to receive
    updates, you can call `dispose()` on it, which is synonymous with *unsubscribe*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Your output may look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'What if we were to create our own `Observable`, with its own specific logic?
    There''s a `create()` method for that:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: We create an `Observable` that publishes numbers. To push a new value to all
    listeners, we use the `onNext()` method. We notify the listeners that there's
    no more data with `onComplete()`. Finally, if an error occurrs, we can call `onError()`,
    supplying the exception as an argument.
  prefs: []
  type: TYPE_NORMAL
- en: 'You''ll notice that if we try to actually call `onError()`, we''ll get an exception:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: That's because we use the shorthand form with the lambda listener.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we want to handle errors correctly, we also need to supply *error handler*
    as a second argument:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'There''s also a third parameter, which is the `onComplete` handler:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: In our examples, we'll rarely use error handlers since our code is very basic.
    But you should always provide them in real applications.
  prefs: []
  type: TYPE_NORMAL
- en: Hot Observable
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Hot `Observable` is a term we'll use a lot in this chapter, as opposed to cold
    `Observable`. All Observable we discussed before was cold. That meant they knew
    everything that happened from the beginning of time, and each time somebody asked
    them politely, they could repeat the whole history. Hot `Observable` only know
    what happens now. Think of the weather forecast and weather history, for example.
    The weather forecast is hot—you'll get the current weather, let's say every minute.
    The weather history is cold–you can get the whole history of weather changes,
    if you care about it. If you still don't get this concept, don't worry too much.
    We have half of the chapter ahead of us to cover it.
  prefs: []
  type: TYPE_NORMAL
- en: 'As you''ve probably noticed, up until now, all of our subscribers always got
    all the data, no matter when they subscribed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'But that''s not always the case. More often, we have the data source coming
    from outside and not created each time by the `publisher`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Here, instead of creating the list inside, we have a reference to its iterator.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s see how the following code behaves now:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'We have two subscribers, as before. Up until now, all subscribers executed
    on the same thread we were running. For this example, we assigned them a separate
    thread each. That would allow us to simulate operations that are running for some
    time: 10 ms, in this case. To specify on which thread subscriber should run, we
    use `subscribeOn()`. `Schedulers` is an utility class, much like `Executors` from
    Java 5\. In this case, it will assign a new thread for each listener.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The output may look something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Notice that if every consumer received all the data previously, now the second
    subscriber will never receive numbers 1-5.
  prefs: []
  type: TYPE_NORMAL
- en: After the second subscriber is connected, only one of them will receive the
    data each time.
  prefs: []
  type: TYPE_NORMAL
- en: What if we want to publish data to all of the subscribers simultaneously?
  prefs: []
  type: TYPE_NORMAL
- en: Multicast
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There''s a `publish()` method for that:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: We again create a somewhat *hot* `Observable`, but this time we specify that
    it will run on a separate thread with `observeOn()`. We also use the `publish()`
    method, which turns our `Observable` into `ConnectableObservable`.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we simply subscribe to this type of `Observable`, nothing will happen. We
    need to tell it when to start running. We use that with the `connect()` method.
    Since the `connect()` method is blocking, we''ll execute it from a separate thread
    for this example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we''ll let publisher work for a few milliseconds, then connect our first
    listener:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'After some more time, we connect a second listener, and allow them to finish:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s see the output now, as it''s quite interesting:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Of course, having this `connect()` is not always comfortable.
  prefs: []
  type: TYPE_NORMAL
- en: 'For that reason, we have a method called `refCount()`, which turns our `ConnectableObservable`
    back into a regular `Observable`. It will keep a reference count of the subscribers,
    and dispose of the subscriptions only after all subscribers have done so, too:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'And if calling `publish().refCount()` is too cumbersome, there''s also the `share()`
    method that does exactly that:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Subject
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The easiest way to understand `Subject` is that `Subject = Observable + Observer`.
  prefs: []
  type: TYPE_NORMAL
- en: 'On the one hand, it allows others to `subscribe()` to it. On the other, it
    can `subscribe` to other `Observable`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'The following code prints six lines, three for each subscriber:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: Note that we didn't use `publish()` on our `dataSource`, so it's cold. Cold
    means that each time somebody subscribes to this source, it will begin sending
    data anew. The hot `Observable`, on the other hand, doesn't have all the data,
    and will only send what it has from this moment on.
  prefs: []
  type: TYPE_NORMAL
- en: For that reason, we need to first connect all the listeners, and only then begin
    to listen to the `dataSource`.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we''re using a hot `dataSource`, we can switch the calls:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: As in the previous section, we use `connect()` to tell `dataSource` when to
    start emitting data.
  prefs: []
  type: TYPE_NORMAL
- en: ReplaySubject
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In addition to `PublishSubject`, which we discussed in the previous section,
    there are other subjects available. To understand how `ReplaySubject` works, let''s
    see first the following example with `PublishSubject`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'This prints the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: Clearly, some events are lost for good.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s replace `PublishSubject` with `ReplaySubject` and examine the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'The following output will be printed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: With `ReplaySubject`, no events are lost. You can see from the output, though,
    that until some point, events aren't multicast, even when there is more than one
    `subscriber`. Instead, for each `subscriber`, `ReplaySubject` performs a kind
    of catch-up of what it missed until now.
  prefs: []
  type: TYPE_NORMAL
- en: 'The benefits of this approach are clear. We converted what seems to be a *hot*
    `Observable` into something quite *cold*. But there are also limitations. By using `ReplaySubject.create`,
    we produce an unbounded subject. If it tries to record too many events, we will
    simply run out of memory. To avoid that, we can use the `createWithSize()` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'It creates the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, now our subject remembers fewer items, so the earliest events
    are lost.
  prefs: []
  type: TYPE_NORMAL
- en: BehaviorSubject
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Imagine a situation when you have a stream of updates every minute. You want
    to display the latest value you received, then keep updating it when new data
    comes in. You can use `ReplaySubject` with a size of one. But there''s also `BehaviorSubject`
    exactly for this case:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: AsyncSubject
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This is a strange `subject` since, unlike the others, it doesn't update its
    subscribers. So, what is it good for?
  prefs: []
  type: TYPE_NORMAL
- en: 'What if you wanted to have a very basic functionality, simply updating a screen
    with the latest value and never refreshing it again until the screen is closed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'Be careful, though. Since `AsyncSubject` waits for the sequence to complete,
    if the sequence is infinite, it will never call its subscribers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: SerializedSubject
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It's important not to call the `onNext()`/`onComplete()`/`onError()` methods
    from different threads, as it will make the calls non-serializable.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is a **Proxy** of sorts around any regular `subject`, which synchronizes
    calls to the unsafe methods. You can wrap any `subject` with `SerializedSubject`
    using the `toSerialized()` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: Flowables
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In all previous examples, we emitted data using `Observable` or `subject`, which
    also extends `Observable`, and it worked out pretty well.
  prefs: []
  type: TYPE_NORMAL
- en: But our listeners weren't doing much. What if they were to do something more
    substantial?
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s see the following example. We''ll produce a lot of unique strings:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: We're using `CountDownLatch` so the main thread will be able to wait until we
    finish. In addition, we're also printing how much time it took to emit 100,000
    events. This will be useful later.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the `subscribe()` method, we would repeat those strings 1,000 times:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: '`AtomicInteger` is used to count the number of processed events in a thread-safe
    way.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We''re obviously consuming more slowly than we''re producing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: But the interesting point is that, after some period, the producing time will
    increase dramatically.
  prefs: []
  type: TYPE_NORMAL
- en: 'That''s the point when we start to run out of memory. Let''s now replace our
    `Observable` with `Flowable`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, instead of passing only a lambda, we also pass a second argument,
    which is `BackpressureStrategy`. What happens is that, behind the scenes, `Flowable`
    has a bounded buffer. This is very similar to how we could make `ReplaySubject`
    bounded. The second argument is telling `Flowable` what should happen if this
    buffer limit is reached. In this case, we're asking it to throw away those events.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we should check the final part of our output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: First, note that we didn't get stuck at any point. Actually, the pace of our
    production is constant.
  prefs: []
  type: TYPE_NORMAL
- en: Second, you should note that although we *produced* 10,000,000 events, we *consumed*
    only 2.8 million. All other events were dropped.
  prefs: []
  type: TYPE_NORMAL
- en: But we didn't run out of memory, which is the great benefit of `Flowable`.
  prefs: []
  type: TYPE_NORMAL
- en: If you do want `Flowable` to behave like `Observable`, you can specify `BackpressureStrategy.BUFFER`,
    and see that it begins to stutter around the same lines.
  prefs: []
  type: TYPE_NORMAL
- en: 'As a general guideline, use `Flowable` when as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: You plan to emit more than 1,000 items (some may say 10,000)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You're reading a file
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You're querying a database
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You have some network streaming to do
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Use `Observable` as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: You have a limited amount of data you plan to emit.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You deal with user input. Humans aren't as quick as they think they are and
    don't produce many events.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'You care about the performance of the flow: `Observable` are simpler, thus
    faster.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When we used the lambda expression, we didn't notice much difference between
    `Flowable` and `Observable`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Instead, now we''ll replace it with an anonymous class and see what benefits
    this approach provides:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: That's obviously a lot more code. We need to implement four methods now.
  prefs: []
  type: TYPE_NORMAL
- en: What interests us the most is the `onSubscribe()` method. Here, we receive a
    new object called `Subscription` and store it in a property.
  prefs: []
  type: TYPE_NORMAL
- en: 'For now, we''ll drop the fancy code that we were using in our listener before,
    and simply print every new string we receive:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: Huh? That's strange. Our listener doesn't print anything.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s go to our `onSubscribe` and modify it a bit:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: '`Subscription` has a method called `request()`, which receives the number of
    items we''re willing to take.'
  prefs: []
  type: TYPE_NORMAL
- en: You can run the code again to see that now our subscriber prints the first 100
    strings, then goes silent again.
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ve already discussed the `BackpressureStrategy.DROP` and `BackpressureStrategy.BUFFER`
    strategies. Let''s now focus on the `BackpressureStrategy.MISSING` strategy. The
    name is a bit confusing; *custom* would be better. We''ll see why in a moment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'And we''ll go back to `onNext()`, which actually does something:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: So, we're back to repeating strings. And after we finish with each, we ask our
    `Flowable` to provide the next one with `subscription.request(1)`.
  prefs: []
  type: TYPE_NORMAL
- en: Quickly enough, though, we receive `MissingBackpressureException`.
  prefs: []
  type: TYPE_NORMAL
- en: That's because we specified the `BackpressureStrategy.MISSING` strategy, and
    didn't specify the size of the buffer.
  prefs: []
  type: TYPE_NORMAL
- en: 'To fix that, we''ll use the `onBackpressureBuffer()` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: That postponed the problem, but we still crash with `MissingBackpressureException`.
  prefs: []
  type: TYPE_NORMAL
- en: 'What we need in this case is not to *create* a `Flowable`, but to *generate*
    it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: Note that, unlike `create()`, `generate()` receives a lambda that represents
    *a single action*. For that reason, we cannot have loops inside it. Instead, we
    store our state, if any, outside.
  prefs: []
  type: TYPE_NORMAL
- en: 'The output looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: Take note of how much slower the production is now. That's because we wait for
    our consumer to process the event before supplying the next batch.
  prefs: []
  type: TYPE_NORMAL
- en: Holding state
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Having those values captured in a closure may seem a bit ugly. There''s a more
    functional alternative, but it''s quite hard to grasp. Generate can receive two
    functions instead of one:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: Well, that's a mouthful. Let's try to understand what's going on there.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first initial state is `() -> State`. In our case, the state can be represented
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: We don't pass an instance of `CountDownLatch` to our function for the sake of
    simplicity. You'll soon understand why.
  prefs: []
  type: TYPE_NORMAL
- en: So, our first argument is the `() -> State` function, which has no parameters
    and returns a `State`. Now, the second argument should be a function, that is, `(State,
    Emitter<T>) -> State`. In our case, we emit strings, so our function is `(State,
    Emitter<String>) -> State`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Since this is all a bit confusing not only to us but also to the Kotlin compiler,
    we specify exactly what types of functions those are, `Callable<State>` and `BiFunction<State,
    Emitter<String>, State>`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, sometimes purely functional code is much more complex. Luckily
    for us, Kotlin allows us to chose different approaches for different situations.
  prefs: []
  type: TYPE_NORMAL
- en: FlowableProcessor
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Much like any `Subject` is an `Observer` and `Observable` at the same time,
    any `FlowableProcessor` is a `Flowable` that is both a `Publisher` and `Subscriber`.
  prefs: []
  type: TYPE_NORMAL
- en: 'To understand this statement, let''s take the example of `ReplaySubject` and
    rewrite it using `ReplayProcessor`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: Any `Observable` can be converted to `Flowable` using the `toFlowable()` method.
    As with any `Flowable`, we need to specify which strategy to use. In our case,
    we use `BackpressureStrategy.DROP`.
  prefs: []
  type: TYPE_NORMAL
- en: 'As you can see, `Flowable` supports the `publish()` method, the same as `Observable`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'Instead of creating `ReplaySubject`, we create `ReplayProcessor`, which also
    supports size limiting:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is practically the same:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: But in case of big input, we now have backpressure to protect us.
  prefs: []
  type: TYPE_NORMAL
- en: Batching
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Sometimes, slowing the producer is not possible. So, are we back to the original
    problem, of either dropping some events or running out of memory? Luckily, Rx
    still has a few tricks up its sleeve. It is often more efficient to process data
    in batches. We've already discussed such a case in the previous chapter. For that,
    we can specify `buffer()` for our `subseriber`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Buffer has three flavors. The first one is batch-per-size:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: 'It outputs the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'The second is the batch-per-time interval. Imagine we have a screen with a
    screen that displays the latest news, and new updates arrive every few seconds.
    But for us, it''s fine to refresh the view only once every five seconds:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: 'It outputs the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: 'The third flavor allows us to become dependent on another `Observable`. We''ll
    batch until it asks us to flush the data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: 'It outputs the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: Throttling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Throttling on the consumer side is similar to dropping on the producer side.
    But it can be applied not only to `Flowable`, but also to `Observable`.
  prefs: []
  type: TYPE_NORMAL
- en: 'You specify the time interval, and each time get only one element, either the
    first or last one, in that interval:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: Execute this example a few times and you will see that you get different results.
    Throttling is highly sensitive to timing.
  prefs: []
  type: TYPE_NORMAL
- en: '`throttleFirst()` outputs `[8, 11, 15, 17, 21]` because it received the following
    windows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: Notice that `[22]` is throttled and never printed.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s see what happens when we use `throttleLast()`, instead:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: '`throttleLast()` outputs `[10, 13, 16, 19, 22]` because it received the following
    windows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: Again, `[22]` is throttled and never printed.
  prefs: []
  type: TYPE_NORMAL
- en: Throttling is the last resiliency tool we'll discuss in this chapter, but it's
    probably one of the most useful ones.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we learned about the main benefits of reactive systems. Such
    systems should be responsive, resilient, elastic, and driven by messaging.
  prefs: []
  type: TYPE_NORMAL
- en: We also discussed the Java 9 Reactive Streams API and its most popular implementation,
    which is Rx.
  prefs: []
  type: TYPE_NORMAL
- en: Now you should better understand the difference between cold and hot `Observable`.
    A cold `Observable` starts working only when someone subscribes to it. A hot `Observable`,
    on the other hand, always emits events, even if nobody is listening.
  prefs: []
  type: TYPE_NORMAL
- en: We also discussed the concept of backpressure, implemented with `Flowable`.
    It allows for a feedback mechanism between the producer and consumer.
  prefs: []
  type: TYPE_NORMAL
- en: In addition, you should be familiar with the notion of multicasting using subjects.
    It allows us to send the same message to multiple listeners.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we discussed some resilience mechanisms, such as buffering and throttling,
    that allow us to accumulate or drop messages, in case we're unable to process
    them in time.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we'll start discussing threads, a concept that should be
    familiar to you if you come from a Java background, and coroutines, which are
    lightweight threads introduced in Kotlin 1.1.
  prefs: []
  type: TYPE_NORMAL
