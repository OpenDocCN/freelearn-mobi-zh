- en: '10'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '10'
- en: Idempotency, Replication, and Recovery Models
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 幂等性、复制和恢复模型
- en: 'Distributed systems are very common in modern software architectures. The challenges
    of ensuring data consistency, fault tolerance, and availability become critical.
    This chapter is going to cover three key concepts that help address these challenges:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 分布式系统在现代软件架构中非常普遍。确保数据一致性、容错性和可用性的挑战变得至关重要。本章将涵盖三个关键概念，有助于解决这些挑战：
- en: Idempotency
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 幂等性
- en: Replication
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 复制
- en: Recovery models
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 恢复模型
- en: '**Idempotency** is a fundamental non-functional system property that ensures
    operations can be executed safely and repeatedly without causing unintended side
    effects. In a distributed system, network failures and system crashes are common.
    Idempotency is essential for maintaining data integrity and consistency. By designing
    operations to be idempotent, engineers can build more resilient and fault-tolerant
    systems that can recover from partial failures without compromising the overall
    system state.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '**幂等性**是一个基本的非功能性系统属性，它确保操作可以安全且重复地执行，而不会产生意外的副作用。在分布式系统中，网络故障和系统崩溃是常见的。幂等性对于维护数据完整性和一致性至关重要。通过设计幂等操作，工程师可以构建更具有弹性和容错性的系统，能够在部分故障的情况下恢复，而不会损害整体系统状态。'
- en: '**Replication**, on the other hand, is a technique that’s used to improve the
    availability and durability of data in distributed systems. By maintaining multiple
    copies of data across different nodes, replication provides redundancy and helps
    ensure that the system can continue to operate even if one or more nodes fail.
    However, replication introduces its own set of challenges, such as ensuring consistency
    between replicas and efficiently managing the replication process.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，**复制**是一种用于提高分布式系统中数据可用性和持久性的技术。通过在不同节点上维护数据的多个副本，复制提供了冗余，并有助于确保即使在某个或多个节点失败的情况下，系统仍能继续运行。然而，复制引入了自己的挑战，例如确保副本之间的一致性以及高效地管理复制过程。
- en: Finally, **recovery models** define the strategies and mechanisms that are used
    to restore the state of a distributed system after a failure or disruption. These
    models can range from simple backup-and-restore approaches to more sophisticated
    techniques. Choosing the right recovery model is crucial for building resilient
    distributed systems that can weather unexpected events and maintain high levels
    of availability and responsiveness.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，**恢复模型**定义了在故障或中断后用于恢复分布式系统状态的策略和机制。这些模型可以从简单的备份和恢复方法到更复杂的技术。选择正确的恢复模型对于构建能够应对意外事件并保持高可用性和响应性的弹性分布式系统至关重要。
- en: In this chapter, we’ll explore each of these topics in greater depth, discussing
    their underlying principles, trade-offs, and best practices for applying them
    in real-world distributed applications. After this chapter, you should be able
    to implement idempotency, replication, and recovery models at a level suitable
    for your system.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将更深入地探讨这些主题，讨论其基本原理、权衡以及在实际分布式应用中应用的最佳实践。在本章之后，你应该能够以适合你系统的水平实现幂等性、复制和恢复模型。
- en: Technical requirements
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'You can find the code files used in this chapter on GitHub: [https://github.com/PacktPublishing/Software-Architecture-with-Kotlin/tree/main/chapter-10](https://github.com/PacktPublishing/Software-Architecture-with-Kotlin/tree/main/chapter-10)'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在GitHub上找到本章使用的代码文件：[https://github.com/PacktPublishing/Software-Architecture-with-Kotlin/tree/main/chapter-10](https://github.com/PacktPublishing/Software-Architecture-with-Kotlin/tree/main/chapter-10)
- en: Idempotency
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 幂等性
- en: Idempotency is a concept in software engineering that refers to the non-functional
    property of operations that can be performed multiple times while still having
    the same effect as performing it only once. In other words, an idempotent operation
    can be safely repeated without side effects. Let’s cover a short scenario where
    idempotency is required.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 幂等性是软件工程中的一个概念，它指的是操作的非功能性属性，可以在执行多次的情况下仍然保持与只执行一次相同的效果。换句话说，幂等操作可以安全地重复执行而不会产生副作用。让我们来看一个需要幂等性的简短场景。
- en: A use case where idempotency is required
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一个需要幂等性的用例
- en: Imagine that we’re building an online banking application. A key capability
    is **Transfer Funds**, in which a user transfers money from one account to another.
    This capability is a fundamental yet critical part of the system, and it needs
    to be implemented in a way that ensures the integrity and reliability of the user’s
    financial transactions.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 想象我们正在构建一个在线银行应用程序。一个关键功能是**转账**，其中用户将资金从一个账户转移到另一个账户。这个功能是系统的基础且至关重要的部分，需要以确保用户财务交易完整性和可靠性的方式实现。
- en: If the **Transfer Funds** operation isn’t idempotent, then the user could accidentally
    click the **Transfer** button multiple times, and the system would execute the
    transfer operation multiple times, resulting in an unintended debit from the source
    account and a corresponding credit to the destination account.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 如果**转账**操作不具有幂等性，那么用户可能会不小心多次点击**转账**按钮，系统会多次执行转账操作，从而导致源账户不预期的扣款和目标账户相应的贷记。
- en: Most mature user interfaces can avoid this situation by blocking the button
    once it’s pushed until a response is received. However, there are also API integrations
    that require idempotency.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数成熟的用户界面可以通过在收到响应前阻止按钮被按下，来避免这种情况。然而，也有一些API集成需要幂等性。
- en: This result isn’t intended by the user, and it has multiple consequences. First,
    if the user has insufficient funds from the second and subsequent transfer, the
    user will have overdraft funds and be subject to interest charges. Second, these
    incidents trigger user complaints and can result in the potential involvement
    of financial regulatory bodies. Not only the user experience but also the unintended
    side effect results in reputational damage to the bank.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 这种结果并不是用户所期望的，它有多重后果。首先，如果用户在第二次及以后的转账中资金不足，用户将会有透支资金，并可能被收取利息。其次，这些事件会触发用户投诉，并可能导致金融监管机构的潜在介入。这不仅会影响用户体验，还会导致银行声誉受损。
- en: To prevent these issues, the **Transfer Funds** operation should be designed
    to be idempotent. This means that no matter how many times the user clicks the
    **Transfer Funds** button, the system will only execute the transfer once, ensuring
    that the final state of the accounts is correct and matches the user’s intent.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 为了防止这些问题，**转账**操作应该被设计成具有幂等性。这意味着无论用户点击**转账**按钮多少次，系统都只会执行一次转账，确保账户的最终状态是正确的，并且与用户的意图相匹配。
- en: Key aspects of idempotency
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 幂等性的关键方面
- en: 'Idempotency is an important concept in software development, particularly in
    the context of distributed systems, APIs, and data processing pipelines. Here
    are some key aspects of idempotency:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 幂等性是软件开发中的一个重要概念，尤其是在分布式系统、API和数据处理管道的背景下。以下是幂等性的几个关键方面：
- en: '**Constant outcomes**: An idempotent operation always produces the same result,
    regardless of how many times it’s executed. If an operation isn’t idempotent,
    each subsequent execution might produce a different outcome.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**恒定结果**：幂等性操作总是产生相同的结果，无论执行多少次。如果一个操作不具有幂等性，每次后续执行可能会产生不同的结果。'
- en: '**Error handling and retries**: Idempotency helps in handling errors and retries
    gracefully. If an operation fails, the system can safely retry the operation without
    causing unintended side effects.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**错误处理和重试**：幂等性有助于优雅地处理错误和重试。如果一个操作失败，系统可以安全地重试操作，而不会造成不预期的副作用。'
- en: '**Data consistency**: Idempotent operations ensure data consistency by preventing
    accidental data modifications or duplications, which can occur when retrying non-idempotent
    operations.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据一致性**：幂等性操作通过防止在重试非幂等性操作时意外修改或重复数据，确保数据一致性。'
- en: '**Scalability and reliability**: Idempotency is crucial in distributed systems,
    where multiple instances of an application may be processing the same request
    concurrently. Idempotent operations allow the system to scale and handle failures
    without compromising data integrity.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可扩展性和可靠性**：在分布式系统中，幂等性至关重要，因为可能存在多个应用程序实例同时处理相同的请求。幂等性操作允许系统进行扩展并处理故障，而不会损害数据完整性。'
- en: Let’s cover a few practical scenarios where idempotency can be applied.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们探讨一些可以应用幂等性的实际场景。
- en: Scenario 1 – evolutionary database migration script
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 场景1 – 数据库迁移脚本
- en: Evolutionary databases aim to create database systems that can evolve and adapt
    to changes over time. They aren’t defined by static and rigid models. The database
    schema is defined by incremental changes that build the target schema.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 进化数据库旨在创建可以随着时间的推移而演变和适应变化的数据库系统。它们不是由静态和僵化的模型定义的。数据库模式是通过增量更改构建目标模式的。
- en: 'Consider Flyway, an open source database migration tool. The incremental changes
    are specified by SQL scripts:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑 Flyway，这是一个开源的数据库迁移工具。增量更改由 SQL 脚本指定：
- en: '[PRE0]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'For simplicity’s sake, let’s assume that the `V1` script only contains the
    following statement for creating a table:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简化起见，让我们假设 `V1` 脚本只包含以下创建表的语句：
- en: '[PRE1]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The `CREATE` SQL statement will create a new table called `HOUSEHOLD` if it
    doesn’t already exist. Otherwise, an error will be reported and the `V1` script
    will fail. In other words, it isn’t idempotent, and repeated executions don’t
    have the same outcome. Here’s an idempotent version of the script:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 如果 `CREATE` SQL 语句中不存在名为 `HOUSEHOLD` 的新表，它将创建该表。否则，将报告错误，并且 `V1` 脚本将失败。换句话说，它不是幂等的，重复执行不会产生相同的结果。以下是脚本的幂等版本：
- en: '[PRE2]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The `IF NOT EXIST` syntax ensures the table is created if it doesn’t exist,
    or nothing is performed if the table already exists. The outcome is the same in
    either case, which is that the `HOUSEHOLD` table exists in the database.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '`IF NOT EXISTS` 语法确保如果表不存在，则创建该表，如果表已存在，则不执行任何操作。在两种情况下结果相同，即数据库中存在 `HOUSEHOLD`
    表。'
- en: 'The execution of the `V2` script will add a new column to this table as a non-null
    column. Some database vendors support clever SQL statements that create a non-null
    column and populate values in the same statement. For the sake of this argument,
    let’s assume that this isn’t supported. We’ve resorted to the classic approach
    of adding a nullable column, populating the value, and then setting the column
    to non-null. Like the modified `V1` script, we can make it idempotent:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 执行 `V2` 脚本将向该表添加一个新列作为非空列。一些数据库供应商支持创建非空列并在同一语句中填充值的巧妙 SQL 语句。为了这个论点，让我们假设这不被支持。我们求助于经典的添加可空列、填充值然后设置列为非空的方法。就像修改后的
    `V1` 脚本一样，我们可以使其幂等：
- en: '[PRE3]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The `IF EXISTS` syntax ensures that the table or columns will be altered if
    they exist, or nothing is performed if they don’t. The outcome is the same and
    therefore it’s idempotent. The classic guideline would have suggested that the
    `ALTER TABLE` is DDL and `UPDATE` is DML. This was suggested because DDL is immediately
    committed while DML requires an explicit commit. However, with idempotency, this
    is no longer an issue as each statement can be repeated to produce the same outcome.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '`IF EXISTS` 语法确保如果表或列存在，则将对其进行修改，如果不存在，则不执行任何操作。结果相同，因此它是幂等的。经典的指导方针会建议 `ALTER
    TABLE` 是 DDL（数据定义语言），而 `UPDATE` 是 DML（数据操作语言）。这是建议这样做的原因是 DDL 会立即提交，而 DML 需要显式提交。然而，由于幂等性，这不再是问题，因为每个语句都可以重复执行以产生相同的结果。'
- en: Scenario 2 – create/update operations
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 场景 2 – 创建/更新操作
- en: Using the real-life example of villagers exchanging services, there’s a business
    case to ensure households are kept in the system record. However, the household
    users don’t know if the household has already been persisted.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 以村民交换服务的现实生活为例，有一个业务案例来确保家庭记录保持在系统记录中。然而，家庭用户不知道家庭记录是否已经被持久化。
- en: A CRUD-based system may define create and update as two independent operations.
    These operations are well-suited as users want the household records to persist
    regardless of whether they exist. There could have been a network outage, so users
    may not know if their previous requests were successful.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 基于CRUD（创建、读取、更新、删除）的系统可能将创建和更新定义为两个独立的操作。这些操作非常适合用户，因为用户希望无论记录是否存在，家庭记录都应持久化。可能发生了网络中断，因此用户可能不知道他们的先前请求是否成功。
- en: In other words, users want an operation that can be repeated and yet generate
    the same outcome. They need an idempotent operation to ensure the household records
    have been stored, despite whether they already exist.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，用户希望一个可以重复执行且产生相同结果的操作。他们需要一个幂等操作来确保即使记录已存在，家庭记录也已存储。
- en: 'This operation is often referred to as **upsert**, which means **update or
    insert**. The key characteristics of an upsert operation are as follows:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 这种操作通常被称为 **upsert**，即 **更新或插入**。upsert 操作的关键特征如下：
- en: '**Idempotent**: It can be executed repeatedly with the same outcome. If the
    record already exists, the record is updated; if the record doesn’t exist, the
    record is created.'
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**幂等性**: 它可以重复执行而结果相同。如果记录已存在，则更新记录；如果记录不存在，则创建记录。'
- en: '**Atomic**: The operation is executed in a transaction of serialized isolation.
    This means the operation was either completed or it didn’t happen.'
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**原子性**: 操作在序列化隔离的事务中执行。这意味着操作要么完成，要么未发生。'
- en: '**Option 1 – pessimistic**: The pessimistic approach would check if the record
    already exists or not to determine whether it’s an update or a create operation.'
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**选项 1 – 悲观锁**: 悲观的方法会检查记录是否存在，以确定是更新操作还是创建操作。'
- en: '**Option 2 – optimistic**: The optimistic approach would assume the record
    either exists or not and perform an update or create operation, respectively.
    If the update operation hasn’t found the record, it switches to the create operation.
    Alternatively, if the create operation fails due to a unique constraint violation,
    it switches to the update operation.'
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**选项 2 – 乐观锁**: 乐观的方法会假设记录要么存在，要么不存在，并分别执行更新或创建操作。如果更新操作未找到记录，则切换到创建操作。或者，如果创建操作由于违反唯一约束而失败，则切换到更新操作。'
- en: 'Here’s an example of the upsert operation for a household in an SQL statement.
    It’s implementing the optimistic approach:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一个 SQL 语句中家庭上插操作（upsert operation）的示例。它实现了乐观方法：
- en: '[PRE4]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: This SQL statement attempts to insert a new household record. If the record
    doesn’t exist, a new row is inserted. If the execution hits a duplicate key violation,
    it becomes an update operation to `name` and `email`.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 此 SQL 语句尝试插入一个新的家庭记录。如果记录不存在，则插入新行。如果执行过程中遇到重复键违反，则变为更新 `name` 和 `email` 的操作。
- en: 'If this operation is exposed as an external API – that is, as a REST endpoint
    – the contract can be expressed in the following ways:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 如果此操作公开为外部 API（即作为 REST 端点），则合同可以用以下方式表达：
- en: '`GET`: Multiple invocations of the `GET` endpoint shall return the same result,
    given the system state remains unchanged.'
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`GET`: 在系统状态保持不变的情况下，`GET` 端点的多次调用应返回相同的结果。'
- en: '`PUT`: The `PUT` endpoint implies creating a new resource or replacing a representation
    of the household with the request payload.'
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`PUT`: `PUT` 端点意味着创建新资源或用请求有效负载替换家庭表示。'
- en: '`DELETE`: The `DELETE` endpoint intends to remove the resource, regardless
    of whether it already exists. If the resource isn’t found, then it should return
    a successful **Hypertext Transfer Protocol** (**HTTP**) status code.'
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`DELETE`: `DELETE` 端点旨在删除资源，无论该资源是否存在。如果未找到资源，则应返回成功的 **超文本传输协议** (**HTTP**)
    状态码。'
- en: The HTTP method itself doesn’t bring idempotency. For example, if the response
    payload of the `GET` endpoint contains the current time or random values, then
    multiple invocations don’t return the same result, and therefore it’s not idempotent.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: HTTP 方法本身并不保证幂等性。例如，如果 `GET` 端点的响应有效负载包含当前时间或随机值，那么多次调用不会返回相同的结果，因此它不是幂等的。
- en: The `POST` and `PATCH` endpoints aren’t defined as idempotent. The `POST` endpoint
    in REST architecture implies the request to create a resource and assumes the
    resource was absent. The `PATCH` endpoint assumes the resource already exists
    so that the resource can be partially updated.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '`POST` 和 `PATCH` 端点未定义为幂等。REST 架构中的 `POST` 端点意味着创建资源的请求，并假设资源不存在。`PATCH` 端点假设资源已存在，以便可以部分更新资源。'
- en: HTTP methods
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: HTTP 方法
- en: HTTP defines a few methods to categorize the request to perform an action on
    a resource. The `GET` method is a read-only operation that returns data from the
    server. The `POST` method creates resources in a server. The `PUT` method replaces
    or creates a resource. The `PATCH` method partially updates an existing resource.
    The `DELETE` method removes a resource from the server. The `HEAD` method returns
    the header of the resource without the body content. The `OPTIONS` method describes
    the options to communicate with the specific resource. Finally, the `TRACE` method
    is a diagnosis operation that echoes the final receipt of the request to provide
    information for troubleshooting.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: HTTP 定义了几种方法来对请求进行分类，以便在资源上执行操作。`GET` 方法是一种只读操作，从服务器返回数据。`POST` 方法在服务器上创建资源。`PUT`
    方法替换或创建资源。`PATCH` 方法部分更新现有资源。`DELETE` 方法从服务器删除资源。`HEAD` 方法返回资源的头部信息，但不包含正文内容。`OPTIONS`
    方法描述了与特定资源通信的选项。最后，`TRACE` 方法是一种诊断操作，通过回显请求的最终接收情况来提供故障排除信息。
- en: Scenario 3 – processing events in sequence
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 场景 3 – 按顺序处理事件
- en: Something that consumes events from a stream or a topic usually takes an event
    one at a time and processes them sequentially. If the sequence of events that’s
    processed is important, then there’s a need to gracefully process events in the
    face of duplication and out of sequence.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，从流或主题中消费事件的东西一次处理一个事件，并按顺序处理它们。如果处理的事件序列很重要，那么就需要优雅地处理重复和顺序错误的事件。
- en: There are two levels where an event sequence could be compromised. The first
    level is the transport level, where the offset of the last consumed event is reset
    to older events due to network issues, partition changes, or consumer group changes.
    The second level is the application level and is where the publisher has sent
    older events.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 事件序列可能受到损害的两个级别是传输级别和应用级别。第一个级别是传输级别，由于网络问题、分区更改或消费者组更改，最后消费事件的偏移量被重置为较旧的事件。第二个级别是应用级别，这是发布者发送较旧事件的地方。
- en: Application-level deduplication at the consumer level could handle event sequences
    being compromised at the transport or application level. However, that would require
    publishers to provide sequential information on each event. This could be a sequence
    number on the event or a timestamp where an event occurred.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在消费者级别进行应用级去重可以处理在传输或应用级别受损的事件序列。然而，这要求发布者为每个事件提供顺序信息。这可以是事件上的序列号，或者事件发生的时间戳。
- en: The consumer can maintain the last processed sequence number or timestamp per
    publisher. If the consumer receives an event where the sequence number is lower
    than the last to be processed, or where the timestamp is older than the last to
    be processed, then the consumer skips this event until a newer event is received.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 消费者可以维护每个发布者的最后处理序列号或时间戳。如果消费者收到一个序列号低于最后处理序列号的事件，或者时间戳早于最后处理时间戳的事件，那么消费者将跳过此事件，直到收到新的事件。
- en: 'Here’s an example implementation of an event listener that prevents older events
    from being processed:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一个事件监听器的示例实现，该监听器防止处理较旧的事件：
- en: '[PRE5]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Here, `HouseholdEventListener` keeps the timestamp of the last processed event.
    The incoming events from Kafka have a header field, `kafka_eventTime`, that’s
    provided by the publisher. The value is when the event occurred, not when the
    event was published.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，`HouseholdEventListener` 保存了最后处理事件的戳记。来自 Kafka 的传入事件有一个头部字段，`kafka_eventTime`，由发布者提供。该值是事件发生的时间，而不是事件发布的时间。
- en: The first event process wouldn’t perform any timestamp check. Subsequently,
    the listener would skip processing if the event timestamp from the header is earlier
    than the last processed timestamp. This indicates that the incoming event is old
    and can be skipped.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个事件处理不会执行任何时间戳检查。随后，如果事件头部的时间戳早于最后处理的时间戳，监听器将跳过处理。这表明传入的事件是旧的，可以跳过。
- en: If the event isn’t skipped and has finished processing, the last processed timestamp
    is updated, and the event is acknowledged by the Kafka broker. The listener is
    now ready to consume another event.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 如果事件没有被跳过并且已经完成处理，则最后处理的时间戳将被更新，并且事件将通过 Kafka 代理进行确认。现在，监听器已准备好消费另一个事件。
- en: In a production system, the last processed time should be persisted in the database
    and be in the same transaction where business processing takes place. The last
    processed time should be restored when the listener starts. This would allow the
    listener to resume its consumption of events after a restart.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在生产系统中，最后处理的时间应该持久化到数据库中，并且应该在业务处理发生的同一事务中。当监听器启动时，应该恢复最后处理的时间。这将允许监听器在重启后继续消费事件。
- en: This implementation illustrates how a consumer can detect an older event with
    the help of the publisher. The older event isn’t processed, and the consumer can
    keep the last processed timestamp as an offset to verify the next event.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 这个实现说明了消费者如何在发布者的帮助下检测到较旧的事件。较旧的事件不会被处理，消费者可以将最后处理的时间戳作为偏移量来验证下一个事件。
- en: To extend to this example, the timestamp of the last processed event can be
    persisted in a database so that the value is restored after a restart.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 为了扩展到这个例子，最后处理事件的戳记可以持久化到数据库中，以便在重启后恢复值。
- en: Scenario 4 – the multiple bounded context saga
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 场景4 – 多个边界上下文的故事
- en: A **saga** is a pattern in **domain-driven design** (**DDD**) that involves
    distributed transactions. The challenge is to maintain data consistency across
    multiple bounded contexts.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '**故事**是**领域驱动设计**（**DDD**）中的一种模式，它涉及分布式事务。挑战是在多个边界上下文中保持数据一致性。'
- en: Let’s use our bank transfer example, where we need idempotent operations to
    ensure the fund is only transferred once and only once. The banking phone application
    intends to send a request to the backend service.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们以我们的银行转账为例，其中我们需要幂等操作来确保资金只被转账一次，并且只被转账一次。银行手机应用程序打算向后端服务发送请求。
- en: However, there are multiple backend services involved in this operation. First,
    there’s **Transfer Service**, which validates the request.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这个操作涉及多个后端服务。首先，有**转账服务**，它验证请求。
- en: Once validated, it needs to reserve the amount in the withdrawing account until
    the transfer has been completed. This is done by another service called **Account
    Service**.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦验证，它需要保留提款账户中的金额，直到转账完成。这是通过另一个名为**账户服务**的服务完成的。
- en: '**Account Service** orchestrates reserving funds by moving funds from a customer
    account to the corporate account. Later, it orchestrates adding funds by moving
    funds from the corporate account to a customer account. This is done by communicating
    with the legacy **Core** **Banking System**.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '**账户服务**通过将资金从客户账户转移到企业账户来协调预留资金。稍后，它通过与企业账户到客户账户的资金转移来协调增加资金。这是通过与遗留的**核心**
    **银行系统**通信来完成的。'
- en: Once the funds have been reserved, **Transfer Service** can request the second
    part of the transfer by moving the funds from the corporate account to the customer
    account. The request is handled by **Account Service**, which communicates with
    the legacy **Core Banking System** to transfer the funds. Once this has been acknowledged
    and completed by **Core Banking System**, **Account Service** returns the result
    to **Transfer Service** and thus completes the transfer.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦资金被预留，**转账服务**可以通过将资金从企业账户转移到客户账户来请求转账的第二部分。请求由**账户服务**处理，它与遗留的**核心银行系统**通信以转账资金。一旦**核心银行系统**确认并完成转账，**账户服务**将结果返回给**转账服务**，从而完成转账。
- en: 'This interaction is demonstrated in *Figure 10**.1*:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 这种交互在*图10.1*中得到了演示：
- en: '![Figure 10.1 – Example sequence for a bank transfer](img/B21737_10_1.jpg)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![图10.1 – 银行转账示例](img/B21737_10_1.jpg)'
- en: Figure 10.1 – Example sequence for a bank transfer
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.1 – 银行转账示例序列
- en: Making the whole transfer operation idempotent is complex because transactions
    are distributed among services. Moreover, we need a way to identify that the user
    only wants the transfer funds once, despite multiple attempts from the banking
    application.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 使整个转账操作具有幂等性是复杂的，因为事务分布在多个服务中。此外，我们需要一种方法来识别用户只想转账一次，尽管银行应用程序有多次尝试。
- en: Often, some parts of the system are legacy systems that may not be enhanced
    so easily. In this case, let’s assume **Core Banking System** can’t take the idempotency
    key in the request.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 通常情况下，系统的一些部分可能是遗留系统，可能无法轻易增强。在这种情况下，让我们假设**核心银行系统**无法在请求中接受幂等键。
- en: Let’s explore how each component involved in this process can work toward idempotency.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们探讨每个参与此过程的组件如何努力实现幂等性。
- en: Banking application
  id: totrans-85
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 银行应用程序
- en: The first step should be the banking application generating an **idempotency
    key**, which can identify multiple attempts belonging to the same user intent.
    Ideally, the idempotency key should be carried to all services involved.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步应该是银行应用程序生成一个**幂等键**，它可以识别属于同一用户意图的多个尝试。理想情况下，幂等键应该携带到所有相关的服务中。
- en: Transfer Service
  id: totrans-87
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 转账服务
- en: '**Transfer Service** can cache these idempotency keys for a certain period.
    Within that period, the same idempotency keys are treated as duplicated requests.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '**转账服务**可以缓存这些幂等键一段时间。在这段时间内，相同的幂等键被视为重复请求。'
- en: To avoid consistency issues under concurrent requests, many systems use explicit
    locks to ensure the requests of the same idempotency keys are processed only one
    at a time, across multiple instances.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免并发请求下的不一致性问题，许多系统使用显式锁来确保相同幂等键的请求在多个实例中一次只处理。
- en: The service can decide to skip the remaining interactions with other services
    and return the response that was sent previously to the banking service. This
    approach is OK if we are sure the remaining services have acknowledged completion
    of the request.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 服务可以选择跳过与其他服务的剩余交互，并返回之前发送给银行服务的响应。如果我们确信剩余的服务已经确认了请求的完成，这种方法是可以接受的。
- en: If, for example, there was a timeout when **Transfer Service** communicated
    with **Account Service**, then it may be sensible to repeat the interaction with
    **Account Service**. This allows the operation to be repaired and continue until
    completion. This approach also assumes that **Account Service** can handle duplicated
    requests in an idempotent manner.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果**转账服务**与**账户服务**通信时出现超时，那么重复与**账户服务**的交互可能是合理的。这允许操作得到修复并继续完成。这种方法还假设**账户服务**可以以幂等的方式处理重复请求。
- en: Account Service
  id: totrans-92
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 账户服务
- en: 'In this operation, **Account Service** provides two functionalities: reserve
    funds and add funds. To be able to identify duplicate requests, the idempotency
    keys should be persisted alongside the records related to holding and moving funds.'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个操作中，**账户服务**提供两个功能：储备资金和增加资金。为了能够识别重复请求，幂等键应该与持有和移动资金的记录一起持久化。
- en: When **Account Service** handles the requests of reserving or adding funds,
    it must check whether duplicate requests already exist by using the idempotency
    keys. If they do, **Account Service** returns the response from the records, as
    if it had been processed this time.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 当**账户服务**处理储备或增加资金的请求时，它必须通过使用幂等键来检查是否存在重复请求。如果存在，**账户服务**将返回记录中的响应，就像这次已经处理过一样。
- en: If the reserve fund request is rejected by **Core Banking System** due to insufficient
    funds, **Account Service** needs to roll back the operation by reversing the fund
    back to the withdrawal account.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 如果由于资金不足，**核心银行系统**拒绝储备资金请求，**账户服务**需要通过将资金反向退回到提款账户来回滚操作。
- en: Like **Transfer Service**, there should be some form of explicit locking to
    ensure only one request for a given idempotency key is processed at a time across
    multiple instances.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 与**转账服务**类似，应该有一种形式的显式锁定，以确保在多个实例中一次只处理给定幂等键的一个请求。
- en: Core Banking System
  id: totrans-97
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 核心银行系统
- en: '**Core Banking System** is a legacy system that doesn’t support idempotency.
    It isn’t able to take idempotency keys or process them. Since **Account Service**
    is the service that communicates with **Core Banking System**, **Account Service**
    should persist the response from **Core Banking System** together with the corresponding
    idempotency key.'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '**核心银行系统**是一个不支持幂等的遗留系统。它无法接受或处理幂等键。由于**账户服务**是与**核心银行系统**通信的服务，**账户服务**应该将**核心银行系统**的响应与相应的幂等键一起持久化。'
- en: If the record of the response already exists with the idempotency key, **Account
    Service** skips communication with **Core Banking System** and uses the previously
    persisted response from **Core Banking System** to complete the process.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 如果响应记录已经存在且带有幂等键，**账户服务**将跳过与**核心银行系统**的通信，并使用之前持久化的**核心银行系统**的响应来完成流程。
- en: This is getting complex as there could be a timed-out request for **Core Banking
    System**. **Account Service** doesn’t know whether **Core Banking System** has
    processed the transfer or not. **Account Service** would need to query the recent
    transaction history to identify the previous request to **Core Banking System**,
    either success or failure, to recover and resume the transfer operation. Otherwise,
    retrying may still result in an inconsistent state.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 这变得复杂了，因为可能会有对**核心银行系统**的请求超时。**账户服务**不知道**核心银行系统**是否已处理了转账。**账户服务**需要查询最近的交易历史以识别之前对**核心银行系统**的请求，无论是成功还是失败，以便恢复并继续转账操作。否则，重试可能仍然会导致不一致的状态。
- en: Sometimes, this recovery may even involve manual correction, which is error-prone.
    You can see when a process can’t be idempotent as it becomes substantially more
    complex, inefficient, and expensive.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，这种恢复甚至可能涉及手动纠正，这容易出错。你可以看到当过程变得复杂得多、效率低下且成本高昂时，它就无法保持幂等性。
- en: With that, we’ve run through four scenarios where idempotency is required, and
    we’ve explored multiple approaches for these scenarios. Now, let’s delve into
    a concept related to idempotency – replication.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这些，我们已经探讨了需要幂等性的四个场景，并探索了这些场景的多种方法。现在，让我们深入研究与幂等性相关的一个概念——复制。
- en: Replication
  id: totrans-103
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 复制
- en: '**Replication** serves as a safeguard against potential failures, allowing
    the system to maintain continuity of service even when individual components malfunction
    or become unavailable.'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '**复制**作为对潜在故障的防护措施，即使在个别组件出现故障或不可用的情况下，系统也能保持服务的连续性。'
- en: This aspect of replication has a close relationship with recovery, which will
    be covered later in this chapter. In short, some replication techniques can prevent
    system downtime, which requires recovery. Also, some replication techniques enable
    and enhance recovery processes.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 复制的这一方面与恢复密切相关，将在本章后面讨论。简而言之，一些复制技术可以防止系统停机，这需要恢复。还有一些复制技术可以启用并增强恢复过程。
- en: Another aspect of replication is that it can improve system performance by distributing
    load to multiple nodes, as well as by allowing the system to scale based on traffic.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 复制的另一个方面是，它可以通过将负载分配到多个节点以及允许系统根据流量进行扩展来提高系统性能。
- en: The copy of the data or running instances is usually called a *replica*. There
    are many areas where replication is applicable. Let’s take a look.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 数据或运行实例的副本通常被称为*副本*。有许多领域可以应用复制。让我们看看。
- en: Data redundancy
  id: totrans-108
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据冗余
- en: Multiple replicas are distributed across different nodes or servers. If one
    node fails, the data can still be accessed from the replicated copies on other
    nodes. It also prevents data loss if some nodes become permanently unavailable.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 多个副本分布在不同的节点或服务器上。如果一个节点失败，数据仍然可以从其他节点上的复制副本中访问。它还防止了某些节点永久不可用时的数据丢失。
- en: This redundancy ensures that the overall system can continue to function, even
    if some nodes or components are unavailable.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 这种冗余确保了即使某些节点或组件不可用，整体系统也能继续运行。
- en: This can apply to relational databases, NoSQL databases, durable message brokers,
    distributed object caches, and nodes in **peer-to-peer** (**P2P**) networks.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 这可以应用于关系数据库、NoSQL数据库、耐用的消息代理、分布式对象缓存以及**对等网络**（**P2P**）中的节点。
- en: Service redundancy
  id: totrans-112
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 服务冗余
- en: Having the running service instances of the system distributed and replicated
    brings a few key benefits.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 系统的运行服务实例分布和复制带来了一些关键的好处。
- en: First, requests can be routed to the most available and responsive replica,
    reducing the risk of overloading a single node and improving overall system performance.
    This load balancing helps maintain availability by preventing bottlenecks and
    ensuring that the system can handle increased traffic or workloads.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，请求可以被路由到最可用和响应最快的副本，从而降低单个节点过载的风险，并提高整体系统性能。这种负载均衡有助于通过防止瓶颈并确保系统可以处理增加的流量或工作量来维持可用性。
- en: Second, it enables the system to scale out by adding more replicas or instances
    as demand increases. This horizontal scalability allows the system to handle higher
    loads and maintain availability as the number of requests or resources required
    grows.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 第二，它使得系统可以通过增加更多副本或实例来扩展，以满足需求增加。这种水平扩展性使得系统可以处理更高的负载，并在请求或所需资源数量增加时保持可用性。
- en: Moreover, if a primary node becomes unavailable, the system can automatically
    failover to a secondary or backup replica, ensuring a seamless transition.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，如果主节点变得不可用，系统可以自动故障转移到次要或备份副本，确保无缝过渡。
- en: The secondary replica can take over the workload, maintaining service continuity
    and high availability.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 次要副本可以接管工作负载，保持服务连续性和高可用性。
- en: Replication also facilitates faster recovery as the system can restore services
    by promoting a healthy replica to become the new primary.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 复制还促进了更快的恢复，因为系统可以通过提升一个健康的副本成为新的主副本来恢复服务。
- en: It’s also common for data and services to be replicated across multiple geographical
    locations and data centers. This practice can improve availability in the event
    of regional failures or disasters. If one data center or region experiences an
    outage, the system can continue to operate using the replicas in other locations,
    ensuring that the service remains available to users.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 数据和服务在多个地理位置和数据中心之间进行复制也很常见。这种做法可以在区域故障或灾难发生时提高可用性。如果一个数据中心或区域发生故障，系统可以使用其他位置的副本继续运行，确保服务对用户始终可用。
- en: CAP theorem
  id: totrans-120
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: CAP 定理
- en: Let’s look at a couple of replication and recovery models that we should discuss.
    They cater to various levels of consistency, availability performance, and scalability
    non-functional requirements.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看我们应该讨论的几个复制和恢复模型。它们满足各种一致性、可用性和可扩展性非功能性要求的不同级别。
- en: 'According to the **CAP theorem**, also known as **Brewer’s theorem**, it’s
    impossible for a distributed system to provide all three of the following non-functional
    properties simultaneously:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 根据 **CAP 定理**，也称为 **Brewer 定理**，分布式系统无法同时提供以下三个非功能性属性：
- en: '**Consistency (C)**: All nodes in the system have the same data at the same
    time. Consistency ensures that the data is always in a valid state'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**一致性 (C)**: 系统中的所有节点在相同时间拥有相同的数据。一致性确保数据始终处于有效状态'
- en: '**Availability (A)**: Every request receives a non-error response, but there’s
    no guarantee that it contains the most recent data'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可用性 (A)**: 每个请求都会收到一个非错误响应，但无法保证它包含最新的数据'
- en: '**Partition tolerance (P)**: The system continues to operate despite arbitrary
    message loss or failure of part of the system'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分区容错性 (P)**: 即使发生任意消息丢失或系统部分故障，系统仍能继续运行'
- en: The theorem states that when communication between nodes fails, a distributed
    system can only satisfy two of the three properties (C, A, or P) at the same time.
    This is known as the **CAP trade-off**.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 该定理指出，当节点间的通信失败时，分布式系统只能在三个属性（C、A 或 P）中同时满足两个。这被称为 **CAP 权衡**。
- en: The history of the CAP theorem
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: CAP 定理的历史
- en: The CAP theorem was proposed by Eric Brewer in 2000 during the Symposium on
    **Principles of Distributed Computing** (**PODC**). The theorem was later proved
    by Seth Gilbert and Nancy Lynch of Massachusetts Institute of Technology in 2002,
    in their paper *Brewer’s Conjecture and the Feasibility of Consistent, Available,
    Partition-Tolerant* *Web Services*.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: CAP 定理由 Eric Brewer 在 2000 年的 **分布式计算原理研讨会**（**PODC**）上提出。该定理后来由麻省理工学院的 Seth
    Gilbert 和 Nancy Lynch 在 2002 年通过他们的论文 *Brewer 的猜想与一致、可用、分区容错 Web 服务可行性* 得到证明。
- en: 'The three possible choices are as follows:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 可能的选择有以下三种：
- en: '**Consistency and partition tolerance (CP)**: The system sacrifices availability
    to uphold strong consistency in the face of a network partition. This is common
    in traditional database systems, such as relational databases.'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**一致性和分区容错性 (CP)**: 在面对网络分区的情况下，系统牺牲可用性以保持强一致性。这在传统数据库系统中很常见，例如关系数据库。'
- en: '**Availability and partition tolerance (AP)**: The system remains available
    but forgoes maintaining consistency during network failure. This is common in
    NoSQL databases.'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可用性和分区容错性 (AP)**: 在网络故障期间，系统保持可用但放弃维护一致性。这在 NoSQL 数据库中很常见。'
- en: '**Consistency and availability (CA)**: The system offers both consistency and
    availability, but this is only possible in a fully connected system with no network
    partitions. In practice, it rarely happens, and the system must choose between
    consistency and availability.'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**一致性和可用性 (CA)**: 系统提供一致性和可用性，但这仅在无网络分区的完全连接系统中才可能。在实践中，这种情况很少发生，系统必须在一致性和可用性之间做出选择。'
- en: Although there are three combinations, the choice is more fluid and situational.
    For example, a system may be initially AP, but as more nodes fail, it may fall
    back to a single node running with CA.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然有三种组合，但选择更为灵活和情境化。例如，一个系统最初可能是 AP，但随着更多节点的故障，它可能回退到单个节点运行 CA。
- en: The CAP theorem is a concept that helps developers understand the trade-offs
    they need to make when designing a distributed system. It’s an important consideration
    when you’re choosing the appropriate data storage and processing solutions for
    a particular application.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: CAP 定理是一个帮助开发者理解在设计分布式系统时需要做出的权衡的概念。当您为特定应用程序选择适当的数据存储和处理解决方案时，这是一个重要的考虑因素。
- en: When exploring these models, it’s important to understand and discover the non-functional
    properties your system should aim for. Not all models are suitable for all systems.
    It’s about finding the most suitable models based on your needs and anticipated
    scenarios.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 在探索这些模型时，理解并发现系统应追求的非功能性属性非常重要。并非所有模型都适用于所有系统。这关乎根据您的需求和预期场景找到最合适的模型。
- en: Model 1 – primary-secondary
  id: totrans-136
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型 1 – 主从
- en: 'The **primary-secondary** (also known as **single-leader**) replication has
    a **Primary** node (the “leader”) that handles all write operations and replicates
    data changes to the **Secondary** nodes (the “followers”). Single-leader replication
    is demonstrated in *Figure 10**.2*:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '**主从**（也称为**单领导者**）复制有一个**主节点**（“领导者”），它处理所有写操作并将数据更改复制到**从节点**（“追随者”）。单领导者复制在*图
    10.2*中展示：'
- en: '![Figure 10.2 – Primary-secondary replication](img/B21737_10_2.jpg)'
  id: totrans-138
  prefs: []
  type: TYPE_IMG
  zh: '![图 10.2 – 主从复制](img/B21737_10_2.jpg)'
- en: Figure 10.2 – Primary-secondary replication
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.2 – 主从复制
- en: Read and write operations
  id: totrans-140
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 读和写操作
- en: The **Primary** node is responsible for all write operations. Whether the **Primary**
    or **Secondary** nodes should serve read operations has a profound impact on system
    quality attributes such as consistency, throughput, availability, and resilience.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '**主节点**负责所有写操作。**主节点**或**从节点**是否应该处理读操作对系统质量属性，如一致性、吞吐量、可用性和弹性，有深远的影响。'
- en: If the **Primary** node serves all read operations, then the **Secondary** nodes
    can be either cold backup or hot standby. Cold backup implies the **Secondary**
    nodes aren’t running but the data files are being replicated. Hot standby implies
    the **Secondary** nodes are up but not serving any request.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 如果**主节点**处理所有读操作，那么**从节点**可以是冷备份或热备用。冷备份意味着**从节点**没有运行，但数据文件正在复制。热备用意味着**从节点**已启动，但未处理任何请求。
- en: This setup provides strong consistency, but serving both read and write operations
    means the **Primary** node takes all the load. This increases resource consumption
    and makes it more challenging to achieve high performance. Moreover, if the **Primary**
    node fails, it may take some time for the cold backup to start up and cause an
    outage. The hot standby would have better availability as the **Secondary** nodes
    are already running, but all read requests to the failed primary node are still
    impacted. This will cause a “blip” until one of the **Secondary** nodes becomes
    the **Primary** node.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 这种设置提供了强一致性，但服务读和写操作意味着**主节点**承担所有负载。这增加了资源消耗，并使得实现高性能更具挑战性。此外，如果**主节点**失败，冷备份启动可能需要一些时间，并可能导致中断。热备用由于**从节点**已经运行，因此具有更好的可用性，但所有对失败主节点的读请求仍然受到影响。这将导致“波动”，直到其中一个**从节点**成为**主节点**。
- en: If **Secondary** nodes serve read requests, the throughput of read operations
    is increased. More nodes are available to handle read requests. If some of the
    **Secondary** nodes fail, others can continue to operate. This approach comes
    with the trade-off of potential inconsistency issues. Imagine if one of the **Secondary**
    nodes failed to connect to the **Primary** node; this **Secondary** node would
    have outdated data but still performs a read operation and provides outdated data,
    something that’s inconsistent with other nodes.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 如果**从节点**处理读请求，读操作的吞吐量会增加。有更多节点可用于处理读请求。如果某些**从节点**失败，其他节点可以继续运行。这种方法带来的权衡是可能的不一致性问题。想象一下，如果其中一个**从节点**未能连接到**主节点**；这个**从节点**将拥有过时的数据，但仍然执行读操作并提供过时数据，这与其他节点不一致。
- en: Replication
  id: totrans-145
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 复制
- en: 'When you’re replicating data changes from the **Primary** node to **Secondary**
    nodes, you have two options: synchronous or asynchronous replication. An example
    sequence diagram of the synchronization process is shown in *Figure 10**.3*:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 当您从**主节点**复制数据变更到**辅助节点**时，您有两个选项：同步或异步复制。同步过程的示例序列图显示在*图10.3*中：
- en: '![Figure 10.3 – Primary-secondary synchronization – synchronous (left)/asynchronous
    (right)](img/B21737_10_3.jpg)'
  id: totrans-147
  prefs: []
  type: TYPE_IMG
  zh: '![图10.3 – 主-辅助同步 – 同步（左侧）/异步（右侧）](img/B21737_10_3.jpg)'
- en: Figure 10.3 – Primary-secondary synchronization – synchronous (left)/asynchronous
    (right)
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.3 – 主-辅助同步 – 同步（左侧）/异步（右侧）
- en: This diagram is split vertically into two approaches. On the left-hand side,
    we have synchronous replication. Here, a write request is sent to the primary
    node. The primary node updates the data in its local storage but doesn’t commit
    the transaction. Then, it sends the data change to all secondary nodes.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 此图垂直分为两种方法。在左侧，我们有同步复制。在这里，写请求被发送到主节点。主节点更新其本地存储中的数据，但不提交事务。然后，它将数据变更发送到所有辅助节点。
- en: This is a blocking and synchronous process where the primary node waits for
    responses from all secondary nodes. If all responses are successful, then the
    primary node commits the transaction and flushes the changes to local storage.
    Finally, a response is returned to the original requester. The synchronized approach
    maintains strong data consistency across all nodes at the cost of higher latency
    due to synchronous communication between the primary and secondary nodes.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个阻塞和同步的过程，其中主节点等待所有辅助节点的响应。如果所有响应都成功，则主节点提交事务并将更改刷新到本地存储。最后，将响应返回给原始请求者。同步方法通过主节点和辅助节点之间的同步通信，以更高的延迟为代价，在所有节点上维护强数据一致性。
- en: On the right-hand side, after the primary node completes the write request,
    the data change is committed to local storage, and the response is returned to
    the requester. The data changes are synchronized in the background without blocking.
    This is either done as a scheduled background process or as an event that’s published
    to the secondary nodes. This approach has reduced latency as replication isn’t
    required to return a response. However, it introduces scenarios where data could
    be inconsistent.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 在右侧，主节点完成写请求后，数据变更被提交到本地存储，并将响应返回给请求者。数据变更在后台同步，不会阻塞。这可以通过计划的后台进程完成，或者作为发布给辅助节点的事件。这种方法减少了延迟，因为不需要复制来返回响应。然而，它引入了可能出现数据不一致的场景。
- en: If the communication between the primary and some secondary nodes fails, some
    of the secondary nodes will have the latest data and some won’t. Meanwhile, all
    secondary nodes serve read operations that return different versions of the same
    data.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 如果主节点与某些辅助节点之间的通信失败，一些辅助节点将拥有最新数据，而另一些则不会。同时，所有辅助节点都执行返回相同数据不同版本的读操作。
- en: The risk of inconsistency can be mitigated by stamping the data with a version
    number or timestamp. Any outdated data can be spotted and then skipped.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 通过在数据上标注版本号或时间戳可以减轻不一致的风险。任何过时的数据都可以被发现并跳过。
- en: The requester can also have a sticky connection with the secondary nodes serving
    read requests. The data that’s returned to the requester will change in tandem
    with the secondary node. This provides some level of reliability that a request
    won’t get one version of the data, and then get an older version.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 请求者也可以与处理读请求的辅助节点保持粘性连接。返回给请求者的数据将与辅助节点同步变化。这提供了一定程度的可靠性，即请求不会得到一个版本的数据，然后得到一个更早的版本。
- en: Failover
  id: totrans-155
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 备用
- en: If the primary node fails, one of the secondary nodes needs to become the primary
    node. The new primary node can be determined by the round-robin rule, or a potentially
    more complex leader election algorithm.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 如果主节点失败，其中一个辅助节点需要成为主节点。新的主节点可以通过轮询规则确定，或者通过可能更复杂的领导者选举算法。
- en: If data is replicated asynchronously, losing a primary node may result in losing
    the latest data. This happens if the primary node has updated its local storage
    and returned the result, but then fails before it can notify secondary nodes.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 如果数据是异步复制的，丢失主节点可能会导致丢失最新数据。这种情况发生在主节点已更新其本地存储并返回结果，但在通知辅助节点之前失败。
- en: It’s even worse if the failed primary node gets backed up but loses the connection
    to some of the secondary nodes. Here, a new primary node may have been assigned.
    We now have a split-brain situation where there are two primary nodes, and secondary
    nodes are fragmented. This usually requires manual intervention to shut down one
    of the primary nodes and reconnect all secondary nodes to the one primary node.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 如果失败的主节点被备份但失去了与一些从节点的连接，情况会更糟。在这种情况下，可能已经分配了一个新的主节点。我们现在有一个分裂脑的情况，有两个主节点，从节点是碎片化的。这通常需要手动干预来关闭一个主节点，并将所有从节点重新连接到单一的主节点。
- en: Primary-secondary replications are commonly used in highly available databases
    and message brokers.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 主从复制在高度可用的数据库和消息代理中常用。
- en: Model 2 – partitioned and distributed
  id: totrans-160
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型2 – 分区和分布式
- en: '**Partitioned and distributed** (known as **multi-leader**) replication distributes
    data management into partitions. It allows multiple nodes to serve requests at
    the same time. These nodes replicate the changes to the other nodes, enabling
    higher write throughput and availability.'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '**分区和分布式**（也称为**多主**）复制将数据管理分布到分区中。它允许多个节点同时处理请求。这些节点将更改复制到其他节点，从而实现更高的写入吞吐量和可用性。'
- en: 'It’s typically used when data and services are replicated across multiple geographical
    locations, often in different data centers or cloud regions. This provides availability
    and resilience against regional failures or disasters. This is illustrated in
    *Figure 10**.4*:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 通常在数据和服务跨多个地理位置复制时使用，通常在不同的数据中心或云区域。这提供了对区域故障或灾难的可用性和弹性。这在*图10.4*中有所说明。4*：
- en: '![Figure 10.4 – Partitioned and distributed replication](img/B21737_10_4.jpg)'
  id: totrans-163
  prefs: []
  type: TYPE_IMG
  zh: '![图10.4 – 分区和分布式复制](img/B21737_10_4.jpg)'
- en: Figure 10.4 – Partitioned and distributed replication
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.4 – 分区和分布式复制
- en: Requests are geographically partitioned so that users of a given region can
    access the corresponding services in that region. Within this region, this partitioned
    and distributed replication can behave exactly like primary-secondary replication,
    where primary nodes serve write requests and secondary nodes serve read requests.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 请求在地理上分区，以便给定区域的用户可以访问该区域对应的服务。在这个区域内，这种分区和分布式复制可以表现得像主从复制一样，其中主节点处理写请求，从节点处理读请求。
- en: Across regions, an additional synchronization process occurs so that the data
    in one region is copied to another. Some data is fully partitioned and regional,
    which means that all requests for the data are served within the designated region
    in normal circumstances. Some data is shared and may need to be fully replicated.
    This introduces the need to resolve conflicts if it’s updated in both regions.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 在区域之间，发生额外的同步过程，以便一个区域的数据被复制到另一个区域。一些数据是完全分区和区域化的，这意味着在正常情况下，所有对数据的请求都在指定的区域内得到服务。一些数据是共享的，可能需要完全复制。这引入了在两个区域都更新时解决冲突的需求。
- en: 'This setup is more complex compared to primary-secondary replication. However,
    it can be justified if there are non-functional requirements such as the following:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 与主从复制相比，这种设置更为复杂。然而，如果存在如下非功能性需求，则可以证明其合理性：
- en: Serve requests coming from multiple geographic regions
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 服务来自多个地理区域的请求
- en: Recover in the face of total data center failure
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 面对数据中心完全故障时进行恢复
- en: Decouple from a particular cloud provider architecturally and operationally
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在架构和操作上从特定的云服务提供商解耦
- en: Support offline operations
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持离线操作
- en: Support collaborative update operations
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持协作更新操作
- en: On the other hand, it will become difficult to uphold strong consistency if
    the same data across multiple regions can’t be updated at the same time.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，如果多个区域中的相同数据不能同时更新，将难以保持强一致性。
- en: If a data center has failed, requests for the corresponding partition should
    be routed to the running data center. Data that hasn’t been replicated in the
    running data center would be lost. In this situation, clients may need to roll
    back to the last replicated state.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 如果数据中心已经失败，对应分区的请求应该被路由到运行中的数据中心。在运行中的数据中心尚未复制的数据库将会丢失。在这种情况下，客户端可能需要回滚到最后一次复制的状态。
- en: Resolving write conflicts and avoiding lost updates
  id: totrans-175
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 解决写冲突和避免丢失更新
- en: Partitioned and distributed replication requires some mechanisms to resolve
    write conflicts in which the same piece of data is updated simultaneously, and
    perhaps differently. Let’s illustrate the resolution of write conflicts with a
    real-life example.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 分区式和分布式复制需要一些机制来解决同时更新同一份数据并可能不同的情况。让我们用一个现实生活中的例子来说明写冲突的解决。
- en: Imagine that each household in a village has a record of its name and a contact
    email address. The *Whittington* household has a record in the repository with
    an email address of *info@whittington.com*.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下，一个村庄中的每一户都有一个其名称和联系电子邮件地址的记录。*Whittington* 家庭在存储库中有一个记录，其电子邮件地址为 *info@whittington.com*。
- en: This record is exposed to two different clients. Each client has read the email
    address, *info@whittington.com*. One client has updated the email address to *query@whittington.com*,
    while the other one has updated it to *contact@whittington.com*. The two clients
    attempt to update the value in the repository by providing their updated ones.
    The repository is going to receive the write requests from these two clients.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 此记录被暴露给两个不同的客户端。每个客户端都读取了电子邮件地址，*info@whittington.com*。一个客户端已将电子邮件地址更新为 *query@whittington.com*，而另一个客户端已将其更新为
    *contact@whittington.com*。两个客户端试图通过提供它们的更新值来更新存储库中的值。存储库将接收这两个客户端的写请求。
- en: 'Both clients determine the new value based on the current value they receive:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 两个客户都根据他们收到的当前值确定新值：
- en: '**Client A**: Update the current email address from *info@whittington.com*
    to *query@whittington.com*'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**客户 A**：将当前电子邮件地址从 *info@whittington.com* 更新为 *query@whittington.com*'
- en: '**Client B**: Update the current email address from *info@whittington.com*
    to *contact@whittington.com*'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**客户 B**：将当前电子邮件地址从 *info@whittington.com* 更新为 *contact@whittington.com*'
- en: If Client A requests an update earlier than Client B does, then the process
    of updating the email address to *query@whittington.com* would be lost. This is
    because Client B almost immediately overwrote the value with *contact@whittington.com*
    without knowing Client A had also requested an update. This problem is called
    the **lost** **update** problem.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 如果客户 A 请求更新早于客户 B，那么将电子邮件地址更新为 *query@whittington.com* 的过程将会丢失。这是因为客户 B 几乎立即用
    *contact@whittington.com* 覆盖了该值，而不知道客户 A 也请求了更新。这个问题被称为 **丢失** **更新** 问题。
- en: This problem is typically solved by having a version number or timestamp on
    the data. If an incoming request update is identified as older than the one in
    the system record, then it’s safe to skip the update. Having a monotonic increasing
    version number is a preferred method compared to timestamps due to the risk that
    the system clock on each machine can be different.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，通过在数据上添加版本号或时间戳来解决此问题。如果传入的请求更新被识别为比系统记录中的更新更旧，那么可以安全地跳过更新。与时间戳相比，单调递增的版本号是一个更受欢迎的方法，因为每个机器的系统时钟可能不同。
- en: 'We can model this situation with the following data class:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以用以下数据类来模拟这种情况：
- en: '[PRE6]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Here, the `Household` class has a `version` field as an integer. This will
    be used for comparison during the update operation. There’s also a repository
    class for `Household` to handle the update request. Here’s the scenario simulated
    in code:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，`Household` 类有一个整型的 `version` 字段。这将在更新操作期间用于比较。还有一个用于处理更新请求的 `Household`
    存储库类。以下是代码中模拟的场景：
- en: '[PRE7]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'First, a `household` record is created as a version, after which there are
    two updates based on it:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，创建一个作为版本的 `household` 记录，之后基于它有两个更新：
- en: '[PRE8]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: In this situation, we would expect the second update to be skipped because it
    was based on version zero. The second update would require refreshing the `household`
    record to version one and computing the potential update.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们预计第二次更新将被跳过，因为它基于版本零。第二次更新将需要刷新 `household` 记录到版本一，并计算潜在的更新。
- en: 'A version check should be in place in the repository to prevent the lost update
    problem. Here’s an example implementation:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 存储库中应实施版本检查，以防止丢失更新问题。以下是一个示例实现：
- en: '[PRE9]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The `HouseholdRepository` class holds a `ConcurrentMap` interface that uses
    the household name as the key. The `create` function makes use of the atomic `putIfAbsent`
    function to ensure the value won’t be overwritten by mistake:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: '`HouseholdRepository` 类持有 `ConcurrentMap` 接口，使用家庭名称作为键。`create` 函数利用原子的 `putIfAbsent`
    函数来确保值不会被错误地覆盖：'
- en: '[PRE10]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The `update` function checks that the updated value must be one version higher
    than the existing value by using the atomic `computeIfPresent` function:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: '`update`函数通过使用原子的`computeIfPresent`函数检查更新的值必须比现有值高一个版本：'
- en: '[PRE11]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'For completeness, there’s also a `get` function so that we can get what’s kept
    in the map after the run:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 为了完整性，还有一个`get`函数，这样我们可以在运行后获取存储在映射中的内容：
- en: '[PRE12]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The output of the program is as follows:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 程序的输出如下：
- en: '[PRE13]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: This means the second update is skipped.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着第二次更新被跳过了。
- en: Model 3 – quorum-based replication
  id: totrans-202
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型3 – 基于多数派复制
- en: '**Quorum-based** (also known as **leaderless**) **replication** requires nodes
    to agree on the state of the data before committing a write operation. This ensures
    consistency and availability, even if some nodes have failed.'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: '**基于多数派**（也称为**无领导者**）**复制**要求节点在提交写入操作之前就数据的状态达成一致。这确保了即使某些节点失败，也能保持一致性和可用性。'
- en: 'The key difference of quorum-based replication is the lack of a primary node,
    a leader, or a central coordinator. Instead, the data is decentralized and distributed
    among the nodes in the cluster:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 基于多数派复制的关键区别在于没有主节点、领导者或中央协调者。相反，数据是去中心化并在集群中的节点之间分布式存储：
- en: '![Figure 10.5 – Quorum-based replication](img/B21737_10_5.jpg)'
  id: totrans-205
  prefs: []
  type: TYPE_IMG
  zh: '![图10.5 – 基于多数派复制](img/B21737_10_5.jpg)'
- en: Figure 10.5 – Quorum-based replication
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.5 – 基于多数派复制
- en: A write operation is only considered successful if it’s acknowledged by the
    majority (quorum) of the participating nodes in the system. This quorum requirement
    ensures that a write is only committed if it’s been replicated to enough nodes,
    making the system resilient to individual node failures.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 只有当写入操作被系统中参与节点的多数（多数派）确认时，才被认为是成功的。这个多数派要求确保只有当写入操作被复制到足够的节点时，才会提交，这使得系统对单个节点故障具有弹性。
- en: 'The quorum size is typically set to at least more than half of the total nodes,
    ensuring that even if some fail, the system can still make progress and maintain
    a consistent state. The data that’s synchronized among the nodes is versioned
    for a couple of reasons:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 多数派的大小通常设置为至少超过总节点数的一半，确保即使某些节点失败，系统仍可以继续前进并保持一致状态。同步到节点之间的数据出于以下几个原因进行了版本化：
- en: The data synchronization process needs to identify an older version of the data,
    as well as increment the version to indicate an update
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据同步过程需要识别旧版本的数据，以及增加版本号以指示更新
- en: Clients can read the version to understand whether the data that’s received
    is outdated
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 客户端可以读取版本以了解接收到的数据是否过时
- en: For example, in a five-node cluster, a quorum size of three would be required
    for a write operation to succeed. This way, the system can tolerate the failure
    of up to two nodes without compromising data consistency.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在五个节点的集群中，写入操作要成功，需要三个节点的多数派。这样，系统可以容忍多达两个节点的故障，而不会损害数据一致性。
- en: Since all the nodes have the same state, there’s no actual failover mechanism.
    Instead, each request would need to be able to remove duplicated or older responses.
    This can be done if the data is versioned.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 由于所有节点具有相同的状态，实际上没有实际的故障转移机制。相反，每个请求都需要能够删除重复或旧响应。如果数据是分版本的，则可以这样做。
- en: Quorum-based replication is commonly used in distributed databases, key-value
    stores, P2P networks, blockchains, and coordination services, where maintaining
    strong consistency and availability in the face of node failures is of utmost
    importance.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 基于多数派复制在分布式数据库、键值存储、P2P网络、区块链和协调服务中常用，在这些服务中，在节点故障的情况下保持强一致性和可用性至关重要。
- en: Comparing the three replication models
  id: totrans-214
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 比较三种复制模型
- en: 'Choosing the appropriate replication mode in a database or data system depends
    on several factors, including non-functional requirements regarding consistency,
    availability, performance, and fault tolerance. Here’s a summary and use case
    for each model:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据库或数据系统中选择适当的复制模式取决于几个因素，包括与一致性、可用性、性能和容错性相关的非功能性需求。以下是每种模型的摘要和用例：
- en: '| **Primary-Secondary** | **Partitioned** **and Distributed** | **Quorum-Based**
    |'
  id: totrans-216
  prefs: []
  type: TYPE_TB
  zh: '| **主从** | **分区和分布式** | **基于多数派** |'
- en: '| Strong consistency | Eventual consistency | Configurable consistency |'
  id: totrans-217
  prefs: []
  type: TYPE_TB
  zh: '| 强一致性 | 最终一致性 | 可配置一致性 |'
- en: '| Simple and easy to maintain | Increased complexity | Complex quorum maintenance
    |'
  id: totrans-218
  prefs: []
  type: TYPE_TB
  zh: '| 简单且易于维护 | 增加的复杂性 | 复杂的多数派维护 |'
- en: '| Low tolerance for data loss | Challenges in conflict resolution | Fault tolerance
    |'
  id: totrans-219
  prefs: []
  type: TYPE_TB
  zh: '| 对数据丢失的低容忍度 | 冲突解决挑战 | 容错性 |'
- en: '| Performance is limited by the capacity of the leader and replication lag
    | Performance is limited by the capacity of the leader and replication lag | Additional
    latency to achieve consensus for each changeHigher resource usage |'
  id: totrans-220
  prefs: []
  type: TYPE_TB
  zh: '| 性能受限于领导者容量和复制延迟 | 性能受限于领导者容量和复制延迟 | 为每个变更实现共识的额外延迟 | 资源使用量更高 |'
- en: '| Less available | Highly available; load balancer options are available |
    Depends on the number of nodes available |'
  id: totrans-221
  prefs: []
  type: TYPE_TB
  zh: '| 可用性较低 | 高可用性；提供负载均衡器选项 | 取决于可用节点的数量 |'
- en: '| Single point of failure | No single point of failure | No single point of
    failure |'
  id: totrans-222
  prefs: []
  type: TYPE_TB
  zh: '| 存在单点故障 | 没有单点故障 | 没有单点故障 |'
- en: '| Suitable for traditional databases and systems that read more often than
    write (for example, content management systems) | Suitable for systems spread
    across different regions and collaborative applications | Suitable for distributed
    data stores and critical systems that aren’t latency-sensitive |'
  id: totrans-223
  prefs: []
  type: TYPE_TB
  zh: '| 适用于传统数据库和读操作多于写操作的系统（例如，内容管理系统） | 适用于跨不同地区分布的系统以及协作应用 | 适用于分布式数据存储和不需要低延迟的关键系统
    |'
- en: The failover mechanism is part of the recovery process, but it focuses on shifting
    the workload to other running nodes. Recovery also covers bringing up nodes that
    weren’t running. These approaches will be covered in the next section.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 故障转移机制是恢复过程的一部分，但它的重点是将工作负载转移到其他正在运行的节点。恢复还包括启动未运行的节点。这些方法将在下一节中介绍。
- en: Recovery
  id: totrans-225
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 恢复
- en: The recovery process of a system heavily relies on accessible data replicas,
    except stateless systems. This implies that the recovery approach heavily relies
    on the replication approach.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 系统的恢复过程高度依赖于可访问的数据副本，除了无状态系统。这意味着恢复方法高度依赖于复制方法。
- en: Snapshots and checkpoints
  id: totrans-227
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 快照和检查点
- en: The most common approach for recovery is to have a snapshot of the last known
    system state. Periodically saving the state of the distributed system is known
    as **checkpointing**.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 最常见的恢复方法是保存最后已知系统状态的快照。定期保存分布式系统状态的过程称为 **检查点**。
- en: In the event of a failure, the system can be rolled back to the last known good
    checkpoint to restore the system to a consistent state. Data that didn’t persist
    in the snapshot will be lost. The amount of data loss would depend on how often
    the snapshots are taken.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 在发生故障的情况下，系统可以回滚到最后一个已知的好检查点，以将系统恢复到一致状态。未在快照中持久化的数据将会丢失。数据丢失的数量将取决于快照的频率。
- en: Change logs
  id: totrans-230
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 变更日志
- en: A system state can also be restored by replaying the change logs of all operations
    and transactions within the distributed system.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 通过重放分布式系统内所有操作和事务的变更日志，也可以恢复系统状态。
- en: It’s common to recover distributed systems using a combination of checkpoints
    and change logs. This is similar to the event sourcing recovery method mentioned
    in [*Chapter 9*](B21737_09.xhtml#_idTextAnchor307), where an aggregate is stored
    by replaying all related events.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 使用检查点和变更日志的组合恢复分布式系统是常见的做法。这与在 [*第9章*](B21737_09.xhtml#_idTextAnchor307) 中提到的基于事件源恢复方法类似，其中通过重放所有相关事件来存储聚合。
- en: This approach helps recover from failures by replaying the missed or lost operations.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法通过重放遗漏或丢失的操作来帮助从故障中恢复。
- en: Re-route and re-balance
  id: totrans-234
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 重新路由和重新平衡
- en: After a node is brought up, it needs to create or join a network of nodes. Requests
    may need to be re-routed and partitions may need to be re-balanced.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 启动节点后，它需要创建或加入一个节点网络。可能需要重新路由请求并重新平衡分区。
- en: This may also trigger the election of a new primary node. Consensus protocols
    such as **Raft** ([https://raft.github.io/](https://raft.github.io/)) and **Paxos**
    ([https://www.microsoft.com/en-us/research/publication/part-time-parliament/](https://www.microsoft.com/en-us/research/publication/part-time-parliament/))
    may be used to coordinate the actions of the other nodes, ensuring the system
    remains operational even when individual nodes fail.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 这也可能触发新主节点的选举。可以使用如 **Raft** ([https://raft.github.io/](https://raft.github.io/))
    和 **Paxos** ([https://www.microsoft.com/en-us/research/publication/part-time-parliament/](https://www.microsoft.com/en-us/research/publication/part-time-parliament/))
    这样的共识协议来协调其他节点的操作，确保系统在个别节点失败的情况下仍能保持运行。
- en: Case study – Raft leader election
  id: totrans-237
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 案例研究 – Raft 领导者选举
- en: 'To demonstrate the details of recovery, we’re going to walk through a simplified
    **Raft** leader election process, as demonstrated in *Figure 10**.5*:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 为了展示恢复的细节，我们将通过一个简化的 **Raft** 领导者选举过程进行说明，如图 *10.5* 所示：
- en: '![Figure 10.6 – Node state transition in Raft leader election](img/B21737_10_6.jpg)'
  id: totrans-239
  prefs: []
  type: TYPE_IMG
  zh: '![图10.6 – Raft领导者选举中的节点状态转换](img/B21737_10_6.jpg)'
- en: Figure 10.6 – Node state transition in Raft leader election
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.6 – Raft领导者选举中的节点状态转换
- en: Raft uses primary-secondary replication in which the primary node replicates
    data changes to all secondary nodes. The primary node keeps an integer called
    **Terms**; this number increments for each election. Each request that’s received
    by the primary node is stamped by Terms.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: Raft使用主从复制，其中主要节点将数据更改复制到所有次要节点。主要节点保持一个名为**Terms**的整数；这个数字在每次选举时增加。每个被主要节点接收到的请求都会被**Terms**标记。
- en: The primary node broadcasts heartbeat messages to all secondary nodes. They’re
    like pulses to keep announcing that the primary node has been up.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 主要节点向所有次要节点广播心跳消息。它们就像脉冲一样，不断宣布主要节点已经启动。
- en: When a secondary node hasn’t received heartbeat messages over the configured
    time, it becomes a candidate and calls other secondary nodes to vote for itself.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 当一个次要节点在配置的时间内没有收到心跳消息时，它将成为一个候选人并要求其他次要节点为自己投票。
- en: Other secondary nodes can either accept or reject their votes. When a candidate
    has been accepted by receiving the most votes, they become the primary node, and
    others revert to followers.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 其他次要节点可以接受或拒绝他们的投票。当一个候选人在获得最多投票后得到接受，他们将成为主要节点，其他人则恢复为跟随者。
- en: 'This mechanism happens concurrently and means there will be conflicts to resolve:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 这种机制是并发发生的，意味着将会有冲突需要解决：
- en: '**Conflicting elections**: Conflicting elections can happen if the timed-out
    configurations for heartbeat messages are the same among all secondary nodes.
    This can be avoided by randomizing the timed-out configuration in each node. Moreover,
    if there are ties of conflicting elections, all elections are called off, after
    which another election can be called.'
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**冲突选举**：如果所有次要节点的心跳消息超时配置相同，则可能会发生冲突选举。可以通过在每个节点中随机化超时配置来避免这种情况。此外，如果有冲突选举的平局，则取消所有选举，之后可以再次进行选举。'
- en: '**Multiple leaders**: If a part of the network is disconnected from another,
    we can end up with a split-brain situation, where each inter-connected portion
    starts its own election. Since the majority should be more than half of the total
    number of nodes, only one part can reach majority votes and elect a leader.'
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**多个领导者**：如果网络的一部分与另一部分断开连接，我们可能会遇到脑裂情况，其中每个相互连接的部分开始自己的选举。由于大多数应该超过节点总数的半数，只有一个部分可以达到多数票并选举出一个领导者。'
- en: If the original leader is in the smaller part of the split network, there will
    be multiple leaders when the whole network has recovered. At this point, the value
    *Terms* can be used to make the original leader step down because the new leader
    will have a higher term value than the original.
  id: totrans-248
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果原始领导者位于网络分裂的小部分中，当整个网络恢复时，将会有多个领导者。在这种情况下，可以使用*Terms*的值让原始领导者下台，因为新领导者的term值将高于原始领导者。
- en: '**Outdated candidates**: Some secondary nodes could be behind others in replication
    but would still call for an election and put themselves as candidates. If one
    of them became the primary node, its outdated data became the source of truth,
    and some updates could be lost.'
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**过时候选人**：一些次要节点可能在复制上落后于其他节点，但仍然会要求进行选举并将自己作为候选人。如果其中之一成为主要节点，其过时的数据将成为真相的来源，并且一些更新可能会丢失。'
- en: To avoid this situation, the secondary nodes will reject candidates whose Terms
    are lower than other candidates, and whose data isn’t up to date. A candidate
    who has outdated data can be spotted by the number of items in the change log.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免这种情况，次要节点将拒绝那些Terms值低于其他候选人且数据未更新的候选人。可以通过变更日志中的项目数量来识别具有过时数据的候选人。
- en: Summary
  id: totrans-251
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: 'In this chapter, we covered three topics: idempotency, replication, and recovery.
    First, we discussed four scenarios where idempotency is useful and how it can
    be achieved with reference implementation.'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们讨论了三个主题：幂等性、复制和恢复。首先，我们讨论了幂等性有用的四种场景以及如何通过参考实现来实现。
- en: Then, we briefly mentioned how to replicate data and services. We brought up
    the CAP theorem, in which trade-offs need to be considered for each system. We
    also delved into three models of replication, namely primary-secondary, partitioned
    and distributed, and quorum-based.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们简要介绍了如何复制数据和服务的步骤。我们提到了CAP定理，其中每个系统都需要考虑权衡。我们还深入探讨了三种复制模型，即主从复制、分区和分布式复制以及基于法定人数的复制。
- en: Finally, we covered some common mechanisms of recovery, outlining how a newly
    launched node can become operational in the context of distributed systems.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们讨论了一些常见的恢复机制，概述了在分布式系统中一个新启动的节点如何成为可操作的。
- en: In the next chapter, we’ll cover the audit and monitoring aspects of a distributed
    system.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将讨论分布式系统的审计和监控方面。
