<html><head></head><body><div class="chapter" title="Chapter&#xA0;11.&#xA0;Anti-aliasing Techniques"><div class="titlepage"><div><div><h1 class="title"><a id="ch11"/>Chapter 11. Anti-aliasing Techniques</h1></div></div></div><p>In this chapter, we will cover the following recipes:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Understanding the sampling rate technique</li><li class="listitem" style="list-style-type: disc">Understanding the post processing technique</li><li class="listitem" style="list-style-type: disc">Implementing fast approximate anti-aliasing</li><li class="listitem" style="list-style-type: disc">Implementing adaptive anti-aliasing</li><li class="listitem" style="list-style-type: disc">Implementing an antialiased circle geometry</li></ul></div><div class="section" title="Introduction"><div class="titlepage"><div><div><h1 class="title"><a id="ch11lvl1sec92"/>Introduction</h1></div></div></div><p>Anti-aliasing is a technique in <a id="id842" class="indexterm"/>computer graphics that improves the quality of the rendered image or video output displayed on the screen by minimizing jagged lines or the stair-step case effect. The raster screen is composed of hundreds of tiny square pixels arranged in a grid format. These pixels are sampled during the image rasterization process according to the shape of the geometry. Basically, the cause of anti-aliasing is the point sampling. These samples are represented by rectangular pixels, which are not sufficient to produce curved shapes. Edges in the image, which are round (not horizontal or vertical), are responsible for this stair-step case effect as it ends up coloring pixels like a stair arrangement. The aliasing problem is not much noticeable when an image or scene is still, but as soon as they are in motion, jagged edges are highly visible. The following image shows the rendering of an infinite detailed isosceles right triangle (<span class="strong"><strong>A</strong></span>). The rasterization stage performs the sampling and displays it on the screen with limited sampling grid. Clearly, the stair-step case effect is easily visible on the hypotenuse (<span class="strong"><strong>B</strong></span>). However, the edges of the base and perpendicular are aligned with horizontal and vertical grid pixels (<span class="strong"><strong>C</strong></span>), thereby causing no jagged edges.</p><p>However, as soon as the triangle rotates, all edges will show the aliased effect:</p><div class="mediaobject"><img src="graphics/5527OT_11_01.jpg" alt="Introduction"/></div><p>The anti-aliasing takes samples from nearby or background pixels and blends them with the color of the edge pixel to generate a smooth approximation such that it minimizes the stair-step case effect and makes the edges appear smooth.</p><p>Anti-aliasing can be caused from other various factors, such as specular highlights, shadows boundaries, geometry outlines, and so on, resulting in a rapid change in the color frequencies.</p><p>Anti-aliasing techniques can be categorized into two types: sampling rate and post processing techniques.</p></div></div>
<div class="section" title="Understanding the sampling rate technique"><div class="titlepage"><div><div><h1 class="title"><a id="ch11lvl1sec93"/>Understanding the sampling rate technique</h1></div></div></div><p>In sampling rate technique, an increase in the amount of the sample rate in a pixel is used to decide the color of the pixel based on samples. This includes techniques, such as Super Sample Anti-aliasing (SSAA), Multi Sample Anti-aliasing (MSAA), Coverage Sampling Anti-aliasing (CSAA), which is usually driven on GPU hardware.</p><div class="section" title="How to do it..."><div class="titlepage"><div><div><h2 class="title"><a id="ch11lvl2sec303"/>How to do it...</h2></div></div></div><p>This section is a bit different from the rest of the <span class="emphasis"><em>How to do it...</em></span> sections that we followed in the chapters. In this, we will discuss the various sampling rate techniques mentioned previously and the procedural difference between each of them. Let's discuss them in detail.</p><p><span class="strong"><strong>Super Sample Anti-aliasing</strong></span> (<span class="strong"><strong>SSAA</strong></span>): <a id="id843" class="indexterm"/>This technique<a id="id844" class="indexterm"/> is also known as <span class="strong"><strong>Full-Scene Anti-Aliasing</strong></span> (<span class="strong"><strong>FSAA</strong></span>). Here, the<a id="id845" class="indexterm"/> scene is first rendered to higher resolution and then downsampled to its original resolution by taking <a id="id846" class="indexterm"/>the average of its neighboring pixels. <a id="id847" class="indexterm"/>For <a id="id848" class="indexterm"/>example, if a given scene needs to be rendered to a resolution of 1920 x 1080, it's <a id="id849" class="indexterm"/>first rendered to a higher resolution of 3840 x 2160 on an off screen surface and downsampled. The <a id="id850" class="indexterm"/>off screen surface is four times bigger, resulting in 2 x 2 samples per pixels <a id="id851" class="indexterm"/>when downsized to its original resolution. The logic of FSAA is simple and results in fine quality, but it all comes at a very high computational cost because it requires all pixels to be available with the color and depth information per sample. This technique was available in early <a id="id852" class="indexterm"/>video cards and is no longer widely used in real time applications due to its tremendous computation cost.</p><p><span class="strong"><strong>Accumulation Buffer</strong></span> (<span class="strong"><strong>AA</strong></span>): This technique is similar to the FSAA, but here the buffers are used with the same resolution and with more bits of color than the desired image. In order to produce the same 2 x 2 <a id="id853" class="indexterm"/>sample per pixel, four image buffers are created where each image view is moved half a pixel along the <span class="emphasis"><em>x</em></span> or y axis as needed. These images are then summed up in the GPUs accumulation buffer and averaged to produce the anti-aliased output. The modern GPUs hardware does not have accumulation buffers. Instead, this can be performed using fragment shaders. The precision used in the pixel shader must be higher (10 to 16 bits per channel) to store the accumulated resultant color. The 8 bit precision may result in color banding artifact when blending is performed.</p><p><span class="strong"><strong>Multi-Sampling Anti-aliasing</strong></span> (<span class="strong"><strong>MSAA</strong></span>): The large computational cost of SSAA results in the advent of MSAA. This technique produces lower acceptable quality, but it saves tremendous <a id="id854" class="indexterm"/>computation cost and has become the number one choice of GPU hardware vendors for a long time. Multisample takes more than one sample in the computation process for a given pixel in a single pass. There exists various pixel sampling schemes, as shown in the following image:</p><div class="mediaobject"><img src="graphics/5527OT_11_02.jpg" alt="How to do it..."/></div><p>The sample rate may vary depending on the rate of the change in color frequencies. Cases such as shadows and geometry edges show a higher variation. Therefore, it requires more samples to process better results. The shading is computed from each fragment only once, which makes it faster than SSAA. For each sample, the corresponding color and depth information is stored separately.</p><p>The following image shows 1x and 4x sampling schemes. In the former case, the sampling position is <a id="id855" class="indexterm"/>not sufficient to overlap with the green triangle, thereby resulting in pixels that are colored in white. However, in the latter case, two out of four sampling locations are successfully in the geometry. Therefore, the interpolated resultant color falls in between these two colors, the extreme right-hand side image shows a shade bar of the 4x sampling scheme:</p><div class="mediaobject"><img src="graphics/5527OT_11_03.jpg" alt="How to do it..."/></div><p><span class="strong"><strong>Coverage Sampling Anti-aliasing</strong></span> (<span class="strong"><strong>CSAA</strong></span>): This technique is an improved version compared to MSAA. MSAA stores the color and depth information separately for each sample. However, this storage is unnecessary and can be completely avoided. The CSAA technique takes advantage<a id="id856" class="indexterm"/> of this drawback and avoids separate storages for the color and depth information; it uses an index-based approach. In this, each subpixel or sample stores an index to the fragment shader to which it's associated. All fragments are stored in a table format, which contains the color and depth information. Each fragment is identified by its unique index.</p></div></div>
<div class="section" title="Understanding the post processing technique"><div class="titlepage"><div><div><h1 class="title"><a id="ch11lvl1sec94"/>Understanding the post processing technique</h1></div></div></div><p>In this type of technique, a scene is rendered to an off screen surface and processed with anti-aliasing algorithms. The process output is split up on the on screen surface. This type of anti-aliasing includes AMD's Morphological Filtering (MLAA), Fast Approximate Anti-aliasing (FXAA), Subpixel Morphological Anti-aliasing (SMAA), and so on.</p><div class="section" title="How to do it..."><div class="titlepage"><div><div><h2 class="title"><a id="ch11lvl2sec304"/>How to do it...</h2></div></div></div><p>In this, we will discuss the various post processing techniques mentioned earlier.</p><p><span class="strong"><strong>Fast Approximate Anti-aliasing</strong></span> (<span class="strong"><strong>FXAA</strong></span>): FXAA is a post-processing filtering technique. This filter primarily does two things: it first detects edges and then applies the blurring algorithm to<a id="id857" class="indexterm"/> aliased edges. Like previous techniques, which are hardware dependent, FXAA can be highly useful for cases where anti-aliasing options are limited. FXAA gives very good performance. It's faster compared to MSAA and SSAA, making it a preferred choice for the gaming industry. This technique works in the image space. Therefore, it can be used in any case, such as the forward rendered image or the deferred rendered image:</p><div class="mediaobject"><img src="graphics/5527OT_11_04.jpg" alt="How to do it..."/></div><p><span class="strong"><strong>Forward rendering</strong></span>: This is the traditional path of the rendering execution model, where the geometry is first fed to the vertex shader followed by the fragment shader. Finally, the processed visual is<a id="id858" class="indexterm"/> rendered to the target. This whole procedure consists of four steps:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">The geometry is computed.</li><li class="listitem">Material characteristics, such as normals, bidirectional tangents, and so on, are defined.</li><li class="listitem">The direction of the incident light is computed.</li><li class="listitem">Object surfaces and light interactions are computed.</li></ol></div><p><span class="strong"><strong>Deferred rendering</strong></span>: In the deferred rendering technique, the first two steps are separated from the last two steps, performing each of these in discrete stages of the rendering pipeline. Here, the scene<a id="id859" class="indexterm"/> is divided into two passes. The first pass is never used to perform any kind of shading. However, during this pass, the vital information required for shading is gathered (position, normals, material, and depth) in a set of textures and used in the second pass where the direct and indirect light information is computed to light the objects.</p></div></div>
<div class="section" title="Implementing fast approximate anti-aliasing"><div class="titlepage"><div><div><h1 class="title"><a id="ch11lvl1sec95"/>Implementing fast approximate anti-aliasing</h1></div></div></div><p>There are two very important factors in anti-aliasing: performance and quality. A good anti-aliasing technique must be fast and should produce acceptable quality results. FXAA stands very positive on<a id="id860" class="indexterm"/> these aspects. It's faster compared to MSAA, which provides roughly 25 percent reduction in performance overhead compared to the SSAA technique. This works in the same resolution as the texture, which eliminates extra overhead similar to other techniques, where the texture has scaled to a higher resolution and then downsampled.</p><p>FXAA works on the specific details of an image; it systematically detects the stair-step case effect in the given image and blurs it out. Stair-steps are recognized with an edge detection algorithm. Therefore, the quality of edge detection and blurring algorithm are very important factors here. An incorrect algorithm may miss important edges or detect incorrect edges, which may produce an unpleasant quality after blurring.</p><div class="section" title="Getting ready"><div class="titlepage"><div><div><h2 class="title"><a id="ch11lvl2sec305"/>Getting ready</h2></div></div></div><p>In this recipe, we will implement the FXAA technique. Let's understand this implementation at a higher level.</p><p>The FXAA technique first renders a scene to an off screen surface using the <span class="strong"><strong>Frame Buffer Objects</strong></span> (<span class="strong"><strong>FBO</strong></span>). Like <a id="id861" class="indexterm"/>other screen space-based techniques, which operates a full scene, the FXAA technique can be run on selective areas that requires anti-aliasing. FXAA is implemented as a postprocessing shader. It detects edges in the rendered scene on the basis of the pixel luminosity. The detected edges are then smoothed out using their gradient. Both these<a id="id862" class="indexterm"/> processing are done under a single pass.</p><p>This recipe is like any other postprocessing recipe:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Create a FBO with the required dimensions.</li><li class="listitem">Create a scene and render it to the FBO off screen surface.</li><li class="listitem">Apply the FXAA technique in a single pass to the FBO-textured scene.<div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note64"/>Note</h3><p>In this recipe, we will describe the third step, where we will implement the FXAA algorithm in the fragment shader. For more information on post screen techniques, refer to <a class="link" href="ch09.html" title="Chapter 9. Postscreen Processing and Image Effects">Chapter 9</a>, <span class="emphasis"><em>Postscreen Processing and Image Effects</em></span>.</p></div></div></li></ol></div></div><div class="section" title="How to do it..."><div class="titlepage"><div><div><h2 class="title"><a id="ch11lvl2sec306"/>How to do it...</h2></div></div></div><p>The following code implements the FXAA technique algorithm in the fragment shader; this fragment shader operates on an off screen scene texture image:</p><div class="informalexample"><pre class="programlisting">#version 300 es
precision mediump float;

in vec2             TexCoord;      // Texture coordinates
uniform sampler2D   Tex1;          // FBO texture
uniform float       ScreenCoordX;  // X Screen Coordinate
uniform vec2        FBS;          // Frame Buffer Size
layout(location = 0) out vec4   outColor;

// Calculates the luminosity of a sample.
float FxaaLuma(vec3 rgb) {return rgb.y * (0.587/0.299) + rgb.x;}

void main() {
        float FXAA_SPAN_MAX     = 8.0;
    float FXAA_REDUCE_MUL   = 1.0/8.0;
    float FXAA_REDUCE_MIN   = 1.0/128.0;

    // Sample 4 texels including the middle one.
    // Since the texture is in UV coordinate system, the Y is
    // therefore, North direction is –ve and south is +ve.
    vec3 rgbNW = texture(Tex1,TexCoord+(vec2(-1.,-1.)/FBS)).xyz;
    vec3 rgbNE = texture(Tex1,TexCoord+(vec2(1.,-1.)/FBS)).xyz;
    vec3 rgbSW = texture(Tex1,TexCoord+(vec2(-1.,1.)/FBS)).xyz;
    vec3 rgbSE = texture(Tex1,TexCoord+(vec2(1.,1.)/FBS)).xyz;
    vec3 rgbM  = texture(Tex1,TexCoord).xyz;
    
    float lumaNW = FxaaLuma(rgbNW);   // Top-Left
    float lumaNE = FxaaLuma(rgbNE);   // Top-Right
    float lumaSW = FxaaLuma(rgbSW);   // Bottom-Left
    float lumaSE = FxaaLuma(rgbSE);   // Bottom-Right
    float lumaM  = FxaaLuma(rgbM);    // Middle
    
      // Get the edge direction, since the y components are inverted
      // be careful to invert the resultant x
       vec2 dir;
    dir.x = -((lumaNW + lumaNE) - (lumaSW + lumaSE));
    dir.y =  ((lumaNW + lumaSW) - (lumaNE + lumaSE));
    
      // Now, we know which direction to blur, 
      // But far we need to blur in the direction? 
      float dirReduce = max((lumaNW + lumaNE + lumaSW + lumaSE) * 
      (0.25 * FXAA_REDUCE_MUL),FXAA_REDUCE_MIN);
      float rcpDirMin = 1.0/(min(abs(dir.x),abs(dir.y))+dirReduce);
    
      dir = min(vec2( FXAA_SPAN_MAX,  FXAA_SPAN_MAX), max(vec2(-
      FXAA_SPAN_MAX,-FXAA_SPAN_MAX), dir*rcpDirMin))/FBS;
    
      vec3 rgbA = (1.0/2.0)*(texture(Tex1, TexCoord.xy + dir *
      (1.0/3.0 - 0.5)).xyz + texture(Tex1, TexCoord.xy 
      + dir * (2.0/3.0 - 0.5)).xyz);
      vec3 rgbB = rgbA * (1.0/2.0) + (1.0/4.0) * (texture(Tex1, 
      TexCoord.xy + dir * (0.0/3.0 - 0.5)).xyz + texture
      (Tex1, TexCoord.xy + dir * (3.0/3.0 - 0.5)).xyz);
    
      float lumaB    = FxaaLuma(rgbB);
      float lumaMin   = min(lumaM, min(min(lumaNW, lumaNE),
      min(lumaSW, lumaSE)));
      float lumaMax    = max(lumaM, max(max(lumaNW, lumaNE), 
      max(lumaSW, lumaSE)));

      if((lumaB &lt; lumaMin) || (lumaB &gt; lumaMax)){
        outColor = vec4(rgbA, 1.0);
      }else{
        outColor = vec4(rgbB, 1.0);
      }
}</pre></div></div><div class="section" title="How it works..."><div class="titlepage"><div><div><h2 class="title"><a id="ch11lvl2sec307"/>How it works...</h2></div></div></div><p>The FXAA technique uses an interesting property of the human eye, which is luminosity or color brightness; our eyes are highly sensitive to it. Human eyes are very much capable of noticing the<a id="id863" class="indexterm"/> slightest change in luminosity. Detecting edges with color brightness works with almost all types of aliasing effect, such as specular or geometric aliasing. Luminosity or grayscale provides the brightness level in an image; it's helpful in detecting light and dark regions in the image space. The sharp transition in luminosity between two samples hints at the presence of an edge.</p><p>The FXAA filter implemented in this recipe takes five samplings around the current texel and analyzes these for the presence of an edge. The following image shows a triangle whose hypotenuse is suffering from the stair-step case effect (<span class="strong"><strong>A</strong></span>). A certain section of its edge is processed with the FXAA filter to perform the anti-aliasing (<span class="strong"><strong>B</strong></span>). This filter takes five samples and coverts them to luminous texels for edge-detection (<span class="strong"><strong>C</strong></span>). This information is used by the blurring algorithm to blur the color intensity based on neighboring samples (<span class="strong"><strong>D</strong></span>):</p><div class="mediaobject"><img src="graphics/5527OT_11_05.jpg" alt="How it works..."/></div><p>The <code class="literal">FBS</code> contains the size of the current off screen surface texture (FBO) and its reciprocal gives the dimension of a unit texel. This unit texel is added to the current texel (<span class="strong"><strong>M</strong></span>) in various directions (top, bottom, left, and right) to produce new sampling texels <span class="strong"><strong>NW</strong></span> (top-left), <span class="strong"><strong>NE</strong></span> (top-right), <span class="strong"><strong>SW</strong></span> (bottom-left), and SE (bottom-right) around the center texel (<span class="strong"><strong>M</strong></span>). As the UV coordinate system has the inverted <span class="strong"><strong>Y</strong></span> direction compared to the Cartesian coordinate system, we need to invert the North and South directions. As a result, you can see a negative sign for the north and south components:</p><div class="informalexample"><pre class="programlisting">vec3 rgbNW = texture(Tex1,TexCoord+(vec2(-1.,-1.)/FBS)).xyz;
vec3 rgbNE = texture(Tex1,TexCoord+(vec2( 1.,-1.)/FBS)).xyz;
vec3 rgbSW = texture(Tex1,TexCoord+(vec2(-1., 1.)/FBS)).xyz;
vec3 rgbSE = texture(Tex1,TexCoord+(vec2( 1., 1.)/FBS)).xyz;
vec3 rgbM  = texture(Tex1,TexCoord).xyz;</pre></div><p>The <code class="literal">FXAALuma</code> function calculates the luminous weight for NW, NE, SW, SE and M samples as shown<a id="id864" class="indexterm"/> in the next image; these weights are used to find the direction of the blur.</p><div class="informalexample"><pre class="programlisting">   float lumaNW = FxaaLuma(rgbNW);    // Top-Left
   float lumaNE = FxaaLuma(rgbNE);     // Top-Right
   float lumaSW = FxaaLuma(rgbSW);     // Bottom-Left
   float lumaSE = FxaaLuma(rgbSE);     // Bottom-Right
   float lumaM  = FxaaLuma(rgbM);      // Middle</pre></div><p>The following image gives the formula to calculate the direction of the edge. If the result is a nonzero magnitude for the <span class="emphasis"><em>x</em></span> and <span class="emphasis"><em>y</em></span> component, an edge exists. As you can see, the directional formula determines the components of the edge direction along the <span class="emphasis"><em>x</em></span> and <span class="emphasis"><em>y</em></span> axis. Now, using this information, blurring can be performed in a specific direction:</p><div class="mediaobject"><img src="graphics/5527OT_11_06.jpg" alt="How it works..."/></div><p>You may have noticed that the direction of <span class="emphasis"><em>x</em></span> is inverted (negative). This is because the inverted signs used for north and south components are mentioned in the preceding code:</p><div class="informalexample"><pre class="programlisting">dir.x = -((lumaNW + lumaNE) - (lumaSW + lumaSE)); //Inverted
dir.y =  ((lumaNW + lumaSW) - (lumaNE + lumaSE));</pre></div><p>We have got the direction. Now, we have to determine how far we should blur it in the given direction. In order to find the distance, we roughly normalized the direction vector in such a way that the smallest components become unity. For this, the magnitude of this direction vector (<code class="literal">rcpDirMin</code>) can be calculated taking the reciprocal of the smallest component directional vector. Now, the resultant is undefined if there occurs a divide by zero condition. For this, a delta component is added. We called this as reduced direction (<code class="literal">dirReduce</code>):</p><div class="informalexample"><pre class="programlisting">float rcpDirMin = 1.0/(min(abs(dir.x),abs(dir.y))+dirReduce);</pre></div><p>The reduced direction calculation is pretty much easy; it's the maximum value of the product of the <code class="literal">FXAA_REDUCE_MUL</code> constant and the average value of all luminous intensities and the <code class="literal">FXAA_REDUCE_MIN</code> constant. These constants are very much dependent on the user observation. Therefore, it can be defined as uniforms to allow these experiments:</p><div class="informalexample"><pre class="programlisting">float dirReduce = max((lumaNW + lumaNE + lumaSW + lumaSE) * 
                     (0.25 * FXAA_REDUCE_MUL),FXAA_REDUCE_MIN);</pre></div><p>The unit directional<a id="id865" class="indexterm"/> vector can be calculated as <code class="literal">dir = dir * rcpDirMin</code>, but there is another problem here. What if the resultant product is very large. This will produce texels, which are far away from the current texel. We certainly don't want this because we are only interested in texels located nearby. So, we need to clamp the spanning of this resultant directional vector to some limited range using the following path. The <code class="literal">FXAA_SPAN_MAX</code> is a constant (8.0). The division of the result with FBS gives us the direction of the texture space for a unit texel in the UV direction:</p><div class="informalexample"><pre class="programlisting">dir = min(vec2( FXAA_SPAN_MAX,  FXAA_SPAN_MAX), max(vec2(-
              FXAA_SPAN_MAX,-FXAA_SPAN_MAX), dir*rcpDirMin))/FBS;</pre></div><p>Now, we have the directional magnitude for blurring purposes. To perform the blur, take two samples along the same direction of the edge. The first sample, <code class="literal">rgbA</code> uses one-sixth of the forward (<span class="emphasis"><em>dir * (2.0/3.0 - 0.5)</em></span>) and backward (<span class="emphasis"><em>dir *(1.0/3.0 - 0.5)</em></span>) direction (<span class="emphasis"><em>dir</em></span>) to calculate two samples from the <code class="literal">Tex1</code> texture. The resultant intensity is reduced by half:</p><div class="informalexample"><pre class="programlisting">vec3 rgbA = (1.0/2.0)*(texture(Tex1, TexCoord.xy + dir *
            (1.0/3.0 - 0.5)).xyz + texture(Tex1, TexCoord.xy 
             + dir * (2.0/3.0 - 0.5)).xyz);</pre></div><p>Similarly, the other sample, namely, <code class="literal">rgbB,</code> also comprises of two inner samples, which are half in the forward (<span class="emphasis"><em>dir * (3.0/3.0 - 0.5)</em></span>) and backward (<span class="emphasis"><em>dir * (0.0/3.0 - 0.5</em></span>) direction from the current texel. Here, the resultant intensity is reduced by one-fourth and mixed with the resultant of <code class="literal">rgbA</code>. As the intensity of <code class="literal">rgbA</code> is already reduced by half, it's further reduced to one-fourth before mixing it with the resultant sampling vectors:</p><div class="informalexample"><pre class="programlisting">   vec3 rgbB = rgbA * (1.0/2.0) + (1.0/4.0) * (texture(Tex1, 
   TexCoord.xy + dir * (0.0/3.0 - 0.5)).xyz + texture
   (Tex1, TexCoord.xy + dir * (3.0/3.0 - 0.5)).xyz);</pre></div><p>These two sample vectors (<code class="literal">rgbA</code> and <code class="literal">rgbB</code>) are used to perform a test to check if the sampled texture is too far. For this, we calculate the minimum and maximum luminosity from the given samples in <code class="literal">lumaMin</code> and <code class="literal">lumaMax</code>. Similarly, compute the luminosity for <code class="literal">lumaB</code> and store it in the <code class="literal">rgbB</code> variable:</p><div class="informalexample"><pre class="programlisting">   float lumaB     = FxaaLuma(rgbB);
   float lumaMin   = min(lumaM, min(min(lumaNW, lumaNE),
   min(lumaSW, lumaSE)));
   float lumaMax    = max(lumaM, max(max(lumaNW, lumaNE), 
   max(lumaSW, lumaSE)));</pre></div><p>If the luminosity of <code class="literal">rgbB</code> is less than the minimum luminosity or greater than the maximum one, clearly, it's outside the expected range of the luminosity that we sampled. In this case, we <a id="id866" class="indexterm"/>will color the current fragment with <code class="literal">rgbA</code>, which is much closer to the sampled directed edge. On the other hand, if the luminosity range is within the expected range, use the <code class="literal">rgbB</code> color:</p><div class="informalexample"><pre class="programlisting">if((lumaB &lt; lumaMin) || (lumaB &gt; lumaMax)){
       outColor = vec4(rgbA, 1.0);
   }else{
       outColor = vec4(rgbB, 1.0);
}</pre></div></div><div class="section" title="There's more..."><div class="titlepage"><div><div><h2 class="title"><a id="ch11lvl2sec308"/>There's more...</h2></div></div></div><p>In this section, we will discuss the advantages and disadvantage of using FXAA:</p><p><span class="strong"><strong>Advantages</strong></span>:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">FXAA is <a id="id867" class="indexterm"/>faster compared to MSAA and yet consumes less memory.</li><li class="listitem" style="list-style-type: disc">This technique works in the image space as a filter. Therefore, it's easy to integrate it into the shader and does not require a highly computational cost.</li><li class="listitem" style="list-style-type: disc">FXAA smoothens edges that are produced by alpha-blended textures and those resulted from fragment shader effects. It works on any technique, such as forward images or defer-rendered images.</li><li class="listitem" style="list-style-type: disc">The cost of anti-aliasing is independent of the cost of rendering a scene. Therefore, the executional time for anti-aliasing a complex scene with millions of vertices and hundreds of texture is the same as a simple one, which contains a few hundred vertices with a handful of textures.</li><li class="listitem" style="list-style-type: disc">The FXAA technique can be combined with other postprocessing filtering techniques. This will completely remove the extra cost of the anti-aliasing pass.</li><li class="listitem" style="list-style-type: disc">If the information is available ahead of time to know which parts of the scene are going to be anti-aliased, using features, such as scissor testing, viewport information, the FXAA can be applied to selected regions.</li></ul></div><p><span class="strong"><strong>Disadvantages</strong></span>:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">It requires a<a id="id868" class="indexterm"/> good quality edge detection algorithm; a poor quality algorithm may miss some of the edges that need to be aliased.</li><li class="listitem" style="list-style-type: disc">Similarly, a good blurring algorithm needs to blur correct results.</li><li class="listitem" style="list-style-type: disc">It does not handle the temporal anti-aliasing.<div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note65"/>Note</h3><p>Temporal anti-aliasing causes the rendering objects to hop to appear to jump instead of giving an impression of smoothly moving objects towards them. The reason behind this kind of behavior is the rate at which the scene is sampled; the sampling rate is much lower compared to the transformation speed of objects in the scene. In order to avoid temporal anti-aliasing effects, the sampling rate of a scene must be at least twice as high as the fastest moving object.</p></div></div></li></ul></div></div><div class="section" title="See also"><div class="titlepage"><div><div><h2 class="title"><a id="ch11lvl2sec309"/>See also</h2></div></div></div><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Refer to the <span class="emphasis"><em>Procedural texture shading with texture coordinates</em></span> recipe in <a class="link" href="ch06.html" title="Chapter 6. Working with Shaders">Chapter 6</a>, <span class="emphasis"><em>Working with Shaders</em></span></li><li class="listitem" style="list-style-type: disc">Refer to the <span class="emphasis"><em>Implementing render to texture with Frame Buffer Objects</em></span> recipe in <a class="link" href="ch07.html" title="Chapter 7. Textures and Mapping Techniques">Chapter 7</a>, <span class="emphasis"><em>Textures and Mapping Techniques</em></span></li></ul></div></div></div>
<div class="section" title="Implementing adaptive anti-aliasing"><div class="titlepage"><div><div><h1 class="title"><a id="ch11lvl1sec96"/>Implementing adaptive anti-aliasing</h1></div></div></div><p>The adaptive anti-aliasing mitigates the aliasing effects caused during the implementation of procedural shaders. As procedural shaders are programmed to produce dynamic textures, transition from the low to high frequency is very much known to the programmer, as they are the<a id="id869" class="indexterm"/> one to program it. For example, the polka dot recipe implementation generates dot patterns using a circle or sphere computational logic. It paints the fragment shader with one type of color if it falls inside the circle; otherwise, it uses the background color. In this case, the programmer knows very well that the transition from one color to another will be very sharp. This is where adaptive anti-aliasing is useful. It avoids such sharp color transitions by interpolating colors between two colors. These sharp transitions can be made smoother using many built-in shading language APIs, such as smooth, mix, and clamp.</p><p>In this recipe, we will produce an animated strip pattern and remove the aliasing effects on the strip edges by implementing an anti-aliasing procedural texture.</p><div class="section" title="How to do it..."><div class="titlepage"><div><div><h2 class="title"><a id="ch11lvl2sec310"/>How to do it...</h2></div></div></div><p>Use the<a id="id870" class="indexterm"/> following fragment shader to implement the adaptive anti-aliasing:</p><div class="informalexample"><pre class="programlisting">#version 300 es
precision mediump float;

// Reuse Phong shading light and material properties.
uniform float  Time;

// Flag to enable and disable Adaptive anti-aliasing
uniform int     EnableAdaptiveAA;

layout(location = 0) out vec4 FinalColor;

vec3 PhongShading{
   // Reuse Phong shading code.
}

in float objectY;
float Frequency = 6.0; // Controls number of stripes

// Reference: OpenGL Shading Language by Randi J Rost
void main() {
    if(gl_FragCoord.x &lt; ScreenCoordX+1.0 
             &amp;&amp; gl_FragCoord.x &gt; ScreenCoordX-1.0){
        FinalColor = vec4(1.0, 0.0, 0.0, 1.0);
        return;
    }
    
    float offset    = Time;

    // GENERATE fractional value 0.0, 0.1, ........, 0.9
    float sawtooth  = fract((objectY+offset) * Frequency);
    
    // Produce values in the range between [-1, 1]
    float triangle  = 2.0 * sawtooth - 1.0;
    
    // Produce continuous range from [ 1.0 ... 0.0 ... 1.0 ]
    triangle        = abs(triangle);
    float dp        = length(vec2 (dFdx(objectY+offset),
                                          dFdy(objectY+offset)));
    float edge      = dp * Frequency * 4.0;
    float square    = 0.0;

    // Show the difference between aliased and anti-aliased.
    if (gl_FragCoord.x &lt; ScreenCoordX){
        square      = step(0.5, triangle);
    }
    else{
        square      = smoothstep(0.5-edge, 0.5 + edge, triangle);
    }
    
    FinalColor = vec4 (vec3 (square)*PhongShading(), 1.0);
}</pre></div></div><div class="section" title="How it works..."><div class="titlepage"><div><div><h2 class="title"><a id="ch11lvl2sec311"/>How it works...</h2></div></div></div><p>This recipe implements animated horizontal strip patterns. It uses the vertical component of object <a id="id871" class="indexterm"/>coordinates to produce this pattern. The object coordinates of the 3D mesh model on which the pattern is to be generated are passed on to the vertex shader, where it's shared with the fragment shader in the <code class="literal">objectY</code> variable. The vertical component of these object coordinates are added with the <code class="literal">offset</code> variable. The offset variable is a function of time. This animates the strip pattern by displacing it from its last position to some new position each time a new frame is rendered. These strip patterns will animate continuously from the top to bottom direction.</p><p>The <code class="literal">Frequency</code> variable controls the number of strips on an object. It is multiplied with object coordinates to scale its range. The <code class="literal">fract()</code> API of the shading language produces a decimal number ranging form 0.0 to 0.9, producing a pattern (<span class="strong"><strong>A</strong></span>) that resembles a sawtooth. Multiplying these values with two and subtracting by one, we get a function that restricts the range between -1.0 and 1.0 (<span class="strong"><strong>B</strong></span>). Finally, taking these absolute values produces a positive continuous range that varies from 1.0 to 1.0 (<span class="strong"><strong>C</strong></span>), which are stored in the triangle variable:</p><div class="mediaobject"><img src="graphics/5527OT_11_07.jpg" alt="How it works..."/></div><p>The strip pattern produces using the GLSL step API. This API returns 0.0 if the triangle is smaller than 0.5 and 1.0 if bigger, as show in the following figure (<span class="strong"><strong>D</strong></span>):</p><div class="mediaobject"><img src="graphics/5527OT_11_08.jpg" alt="How it works..."/></div><p>The output produced by the <code class="literal">step</code> API is shown in the following image (refer to the left-hand side of the red line). Clearly, aliased effects can be seen easily because output values switch from 0.0 to 1.0 and vice versa directly. This aliasing effect can be removed using an alternate API of GLSL called <code class="literal">smoothstep</code>. This API takes two parameters as an input value and <a id="id872" class="indexterm"/>performs the interpolation between the two. It avoids a sharp transition and interpolates a smooth range, as shown in the preceding image (<span class="strong"><strong>E</strong></span>). Two input parameters in the <code class="literal">smoothstep</code> API are functions of the partial derivatives of the object coordinates along the <span class="emphasis"><em>x</em></span> and <span class="emphasis"><em>y</em></span> components:</p><div class="mediaobject"><img src="graphics/5527OT_11_09.jpg" alt="How it works..."/></div></div><div class="section" title="See also"><div class="titlepage"><div><div><h2 class="title"><a id="ch11lvl2sec312"/>See also</h2></div></div></div><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Refer to the <span class="emphasis"><em>Procedural texture shading with texture coordinates</em></span> recipe in <a class="link" href="ch06.html" title="Chapter 6. Working with Shaders">Chapter 6</a>, <span class="emphasis"><em>Working with Shaders</em></span></li><li class="listitem" style="list-style-type: disc"><span class="emphasis"><em>Implementing an anti-aliased circle geometry</em></span></li></ul></div></div></div>
<div class="section" title="Implementing an anti-aliased circle geometry"><div class="titlepage"><div><div><h1 class="title"><a id="ch11lvl1sec97"/>Implementing an anti-aliased circle geometry</h1></div></div></div><p>A circle is a very common geometric shape that is widely used across a variety of computer graphics application, such as rendering statistics with pie graphs, drawing sign boards, animating dot patterns, and so on. In this recipe, we will implement an antialiased circle geometry with the help of texture coordinates and make it smoother using the adaptive anti-aliasing technique from the previous recipe.</p><p>One way to implement the<a id="id873" class="indexterm"/> antialiased circle geometry is to generate a set of vertices along the circumference of the circle, where every two consecutive vertices are connected to the center vertex (origin), creating a triangular slice. Several such slices are required to create the skeleton of the circle, as shown in the following image. When these vertices are rendered with the triangle primitive, they produce a filled circle pattern. The smoothness of the produced circle shape is highly dependent on the number of vertices used along the circumference. The use of more vertices may degrade its performance as we try to achieve smoother edges along the circumference.</p><p><span class="strong"><strong>Advantages</strong></span>:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">As the circle geometry<a id="id874" class="indexterm"/> is represented with the vertices itself, the collision detection and pick test will be highly accurate.</li></ul></div><p><span class="strong"><strong>Disadvantages</strong></span>:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">More and more vertices <a id="id875" class="indexterm"/>are required for smoother edges. Eventually, this comes at a cost of more performance overhead.</li><li class="listitem" style="list-style-type: disc">By default, the edges of the circle are not anti-aliasing. Such geometric techniques may be very complex in terms of implementation.</li><li class="listitem" style="list-style-type: disc">Changes in the dimension of the geometry may surface the aliased edges:<div class="mediaobject"><img src="graphics/5527OT_11_10.jpg" alt="Implementing an anti-aliased circle geometry"/></div></li></ul></div><p>In an alternate, we can use procedural shaders to produce circular geometries with the help of texture coordinates. One thing to note here is that the circle geometry produced in this technique is not a really a circle; it's a fake geometry that only comprises of four vertices. Irrespective of how big the circle is, it always uses the same number of vertices (4) to<a id="id876" class="indexterm"/> render a circle shape.</p><p>The basic principle of this technique is very simple. It uses four vertices to create a square and produces a perfect logical circle inscribed in it. Fragments that fall inside this circle are colored and the rest are masked by the alpha channel.</p><p>The circumference or edges<a id="id877" class="indexterm"/> of the circle are made smoother by processing it with the adaptive anti-aliasing technique. Here, a small portion along the circumference is interpolated from inside to outside to produce a smooth gradient.</p><div class="section" title="Getting ready"><div class="titlepage"><div><div><h2 class="title"><a id="ch11lvl2sec313"/>Getting ready</h2></div></div></div><p>Let's take a look at the high level implementation of this recipe:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Create a quad with vertices, as shown in the following image. The center of the quad must be at the origin (0.0, 0.0, 0.0).</li><li class="listitem">Assign each vertex with a texture coordinate as follows. As per the texture coordinate convention, the origin always exists at the bottom-left part of the quad:<div class="mediaobject"><img src="graphics/5527OT_11_11.jpg" alt="Getting ready"/></div></li><li class="listitem">Specify the winding of vertices in an anticlockwise direction (<span class="strong"><strong>V0</strong></span> &gt; <span class="strong"><strong>V1</strong></span> &gt; <span class="strong"><strong>V2</strong></span> &gt; <span class="strong"><strong>V3</strong></span>).</li><li class="listitem">In the fragment shader, subtract each texture coordinate with a half vector along the UV direction. This will displace the origin from the bottom-left to the center of the quad.</li><li class="listitem">Check each fragment distance from the displaced origin. If the current fragment is inside the outer radius range (say 0.5), then paint it with the required color; otherwise, alpha blend the fragment with the background color.</li><li class="listitem">For anti-aliasing, take another radii called inner radius with a value smaller than the outer radii (say 0.4) and interpolate the color value based on the weight calculated from the position of the fragment texture coordinate inside the region<a id="id878" class="indexterm"/> between the inner and outer radii [0.4 0.5].</li></ol></div></div><div class="section" title="How to do it..."><div class="titlepage"><div><div><h2 class="title"><a id="ch11lvl2sec314"/>How to do it...</h2></div></div></div><p>Here are the steps to understand the step-by-step implementation of this recipe:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Create a class called <code class="literal">Circle</code> in <code class="literal">Circle.h</code>/<code class="literal">.cpp</code>.</li><li class="listitem">In the class constructor, define the vertex and texture coordinate in the vertices and <code class="literal">texCoords</code> variables respectively:<div class="informalexample"><pre class="programlisting">   glm::vec2 texCoords[4] = {
       vec2(0.0f, 0.0f),vec2(0.0f, 1.0f),
        vec2(1.0f, 0.0f), vec2(1.0f, 1.0f)
    };
    memcpy(texCoordinates, texCoords, sizeof(glm::vec2)*4);

    glm::vec3 tempVtx[4] = {
        vec3( -0.5f, -0.5f, 0.0f), vec3( -0.5f,  0.5f, 0.0f),
        vec3(  0.5f, -0.5f, 0.0f), vec3(  0.5f,  0.5f, 0.0f)
    };
    memcpy(vertices, tempVtx, sizeof(glm::vec3)*4);</pre></div></li><li class="listitem">Create the vertex shader file called <code class="literal">AACircleVertex.glsl</code>:<div class="informalexample"><pre class="programlisting">#version 300 es

// Vertex information
layout(location = 0) in vec3  VertexPosition;
layout(location = 1) in vec2  VertexTexCoord;

out vec2 TexCoord;

uniform mat4 ModelViewProjectMatrix;

void main( void ) {
    TexCoord = VertexTexCoord;
    gl_Position = ModelViewProjectMatrix *
                   vec4(VertexPosition,1.0);
}</pre></div></li><li class="listitem">Similarly, create <code class="literal">AACircleFragment.glsl</code> and add the following code:<div class="informalexample"><pre class="programlisting">#version 300 es
precision mediump float;
// Texture coordinates
in vec2 TexCoord;
 
uniform vec3        PaintColor;     // circle color
uniform float       InnerRadius;    // inside radius
uniform float       OuterRadius;    // outside radius
layout(location = 0) out vec4   outColor;

void main() {
   float weight = 0.0f;
    // Displace the texture coordinate wrt 
    // hypothetical centered origin
    float dx     = TexCoord.x - 0.5;
    float dy     = TexCoord.y - 0.5;

    // Calculate the distance of this transformed 
    // texture coordinate from Origin.
    float length = sqrt(dx * dx + dy * dy);
    
    // Calculate the weights
    weight = smoothstep(InnerRadius, OuterRadius, length );

    outColor = mix( vec4(PaintColor, 1.0), 
                   vec4(PaintColor, 0.0), weight);
}</pre></div></li><li class="listitem">Define the scene<a id="id879" class="indexterm"/> in the <code class="literal">NativeTemplate.cpp</code>, as shown in the following code:<div class="informalexample"><pre class="programlisting">Renderer*       graphicsEngine; // Graphics Engine
Scene*          scene;          // Scene object
Circle*         circle;
Camera* camera;
bool GraphicsInit(){
    // Create rendering engine
    graphicsEngine  = new Renderer();

    // Create the scene
    scene = new Scene("MeshScene", graphicsEngine);
    
    // Create camera and added to the scene
    camera = new Camera("Camera1", scene);
    camera-&gt;SetClearBitFieldMask(GL_COLOR_BUFFER_BIT | 
                                 GL_DEPTH_BUFFER_BIT);
    camera-&gt;SetPosition(glm::vec3 (0.00000, 0.0, 2.00000));
    camera-&gt;SetTarget(glm::vec3 (0.0, 0.0,0.0));
    
    // Create a new circle shape object    
    circle = new Circle(scene, NULL, None);
    circle-&gt;SetName(std::string("My Circle"));

    scene-&gt;addModel(circle);
    graphicsEngine-&gt;initializeScenes();
    return true;
}

bool GraphicsResize( int width, int height ){
    // Create the view port
    camera-&gt;Viewport(0, 0, width, height);
    graphicsEngine-&gt;resize(width, height);
    return true;
}

bool GraphicsRender(){
    // Rotate the circle
    circle-&gt;Rotate(1.0, 1.0, 1.0, 1.0);
    graphicsEngine-&gt;render();
    return true;
}</pre></div></li></ol></div></div><div class="section" title="How it works..."><div class="titlepage"><div><div><h2 class="title"><a id="ch11lvl2sec315"/>How it works...</h2></div></div></div><p>This recipe mainly consists of two parts: the creation of the circle and smoothening the edges of the created<a id="id880" class="indexterm"/> circle. In the first part, the geometry is defined to create a base shape. The base shape is made up of four vertices to create a perfect square. These vertices are shared with the vertex shader to produce eye coordinates. Each of the vertex contains associated texture coordinates that are also passed on to the vertex shader and shared with the fragment shader. The fragment shader controls the shaded region of the perfect square in such a way that it appears as a perfect circle. All this is done using the texture coordinate manipulation. The following image shows the incoming texture coordinates mapped on the square geometry (<span class="strong"><strong>A</strong></span>). As you can see, the origin in the first image appears in the bottom-left corner. This origin is logically moved to the center part of the square (<span class="strong"><strong>B</strong></span>) by subtracting the texture coordinate with half the total dimension of the texture coordinate span in the UV direction.</p><p>This way, all texture coordinates get displaced with respect to the new origin in the center of the square:</p><div class="informalexample"><pre class="programlisting"> float dx = TexCoord.x - 0.5;
 float dy = TexCoord.y - 0.5;</pre></div><p>The distance of the displaced texture coordinate is calculated and checked against the circle radii. If it's<a id="id881" class="indexterm"/> smaller than the given radii, it means that it's inside the circle and needs to be painted with <code class="literal">PaintColor</code>. The inner part will be colored with alpha 1.0 to appear solid. If the distance of the current fragment texture coordinate appears outside the given radius, then it's colored with alpha 0.0. This will make the outer part of the circle disappear:</p><div class="mediaobject"><img src="graphics/5527OT_11_12.jpg" alt="How it works..."/></div><p>The second part of this technique makes the edges soft by processing it through adaptive anti-aliasing. For this, two radii (<code class="literal">InnerRadius</code> and <code class="literal">OuterRadius</code>) are used, as shown in the preceding image (<span class="strong"><strong>C</strong></span>). Fragments that fall under the band of these two radii are interpolated for their color values on the basis of the weights obtained from the position of the texture coordinate in this band:</p><div class="informalexample"><pre class="programlisting">weight    = smoothstep( innerRadius, outerRadius, length );
outColor  = mix( vec4(paintColor, 1.0), 
            vec4(paintColor, 0.0), weight);</pre></div><div class="mediaobject"><img src="graphics/5527OT_11_13.jpg" alt="How it works..."/></div><p>This technique has some pros and cons:</p><p><span class="strong"><strong>Pros</strong></span>:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">This technique is<a id="id882" class="indexterm"/> highly performance efficient.</li><li class="listitem" style="list-style-type: disc">This technique produces high quality circle shapes with smooth edges.</li><li class="listitem" style="list-style-type: disc">Edge sharpness can be adjusted at runtime.</li><li class="listitem" style="list-style-type: disc">The border of the circle can be rendered.</li><li class="listitem" style="list-style-type: disc">Scaling does not effect the quality of the image. It can be adaptive.</li></ul></div><p><span class="strong"><strong>Cons</strong></span>:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">This technique cannot perform the <a id="id883" class="indexterm"/>collision detection or pick test with high accuracy.</li><li class="listitem" style="list-style-type: disc">This technique produces high quality shapes with smooth edges.</li></ul></div></div><div class="section" title="See also"><div class="titlepage"><div><div><h2 class="title"><a id="ch11lvl2sec316"/>See also</h2></div></div></div><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Refer to the <span class="emphasis"><em>Creating a circular pattern and making them revolve</em></span> recipe in <a class="link" href="ch06.html" title="Chapter 6. Working with Shaders">Chapter 6</a>, <span class="emphasis"><em>Working with Shaders</em></span></li><li class="listitem" style="list-style-type: disc"><span class="emphasis"><em>Implementing adaptive anti-aliasing</em></span></li></ul></div></div></div></body></html>