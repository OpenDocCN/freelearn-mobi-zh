- en: '*Chapter 10*: Making Smarter Apps with Core ML'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第 10 章*：使用 Core ML 制作更智能的应用'
- en: Over the past few years, machine learning has gained in popularity. However,
    it has never been easy to implement in mobile applications—that is, until Apple
    released the **Core ML** framework as part of iOS 11\. Core ML is Apple's solution
    to all of the problems that developers at the company have run into themselves
    while implementing machine learning for iOS. As a result, Core ML should have
    the fastest, most efficient implementations for working with sophisticated machine
    learning models, through an interface that is as simple and flexible as possible.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去的几年里，机器学习越来越受欢迎。然而，在移动应用中实现它一直不容易——直到苹果在 iOS 11 中发布了 **Core ML** 框架。Core
    ML 是苹果针对公司开发者在为 iOS 实现机器学习时遇到的所有问题而提供的解决方案。因此，Core ML 应该为处理复杂的机器学习模型提供最快、最有效的实现，通过尽可能简单和灵活的接口。
- en: 'In this chapter, you will learn what machine learning is, how it works, and
    how you can use trained machine learning models in your apps. You will also learn
    how you can use Apple''s **Vision framework** to analyze images, and you''ll see
    how it integrates with Core ML for powerful image detection. Lastly, you''ll learn
    how to use the new **Create ML** tool to train your models, how to deploy your
    models to the cloud, and how to encrypt them for security. You will learn about
    these topics in the following sections:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你将学习机器学习是什么，它是如何工作的，以及你如何在你的应用中使用训练好的机器学习模型。你还将学习如何使用苹果的 **Vision 框架**分析图像，并了解它如何与
    Core ML 集成以实现强大的图像检测。最后，你将学习如何使用新的 **Create ML** 工具来训练你的模型，如何将你的模型部署到云端，以及如何加密它们以确保安全。你将在以下部分学习这些主题：
- en: Understanding machine learning and Core ML
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解机器学习和 Core ML
- en: Combining Core ML and computer vision
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 结合 Core ML 和计算机视觉
- en: Training your own models with Create ML
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Create ML 训练自己的模型
- en: Updating models remotely with Model Deployment
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用模型部署远程更新模型
- en: Encrypting Core ML models
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 加密 Core ML 模型
- en: By the end of this chapter, you will be able to train and use your Core ML models
    to make the apps you build more intelligent and compelling.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，你将能够训练和使用你的 Core ML 模型，使你构建的应用更加智能和引人入胜。
- en: Technical requirements
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: The code bundle for this chapter includes three starter projects called `TextAnalyzer`,
    `ImageAnalyzer`, and `TextAnalyzerCloud`. It also includes a playground file named
    `Create ML.playground`.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的代码包包括三个起始项目，分别称为 `TextAnalyzer`、`ImageAnalyzer` 和 `TextAnalyzerCloud`。它还包括一个名为
    `Create ML.playground` 的游乐场文件。
- en: 'The code for this chapter can be found here: [https://github.com/PacktPublishing/Mastering-iOS-14-Programming-4th-Edition/tree/master/Chapter%2010%20-%20Core%20ML](https://github.com/PacktPublishing/Mastering-iOS-14-Programming-4th-Edition/tree/master/Chapter%2010%20-%20Core%20ML).'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的代码可以在以下链接找到：[https://github.com/PacktPublishing/Mastering-iOS-14-Programming-4th-Edition/tree/master/Chapter%2010%20-%20Core%20ML](https://github.com/PacktPublishing/Mastering-iOS-14-Programming-4th-Edition/tree/master/Chapter%2010%20-%20Core%20ML).
- en: Understanding machine learning and Core ML
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解机器学习和 Core ML
- en: Machine learning and Core ML go hand in hand, but they're not quite the same.
    Machine learning is all about teaching a machine how it can recognize, analyze,
    or apply certain things. The result of all this teaching is a trained model that
    can be used by Core ML to analyze specific inputs and produce an output based
    on the rules that were established during the training phase.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习和 Core ML 密不可分，但它们并不完全相同。机器学习的一切都是关于教会机器如何识别、分析或应用某些事物。所有这些教学的结果是一个训练好的模型，可以被
    Core ML 使用来分析特定的输入，并根据训练阶段建立的规则产生输出。
- en: Before you learn about Core ML, it's good to obtain some knowledge about machine
    learning to make sure you're familiar with some of the terms that are used, and
    so you know what machine learning is.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在学习 Core ML 之前，了解一些机器学习的知识是很好的，这样你可以熟悉一些使用的术语，并了解机器学习是什么。
- en: Understanding what machine learning is
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解机器学习是什么
- en: A lot of developers will hear about machine learning, deep learning, or neural
    networks at some point in their careers. You may have already heard about these
    topics. If you have, you know that machine learning is a complex field that requires
    particular domain knowledge. However, machine learning is becoming more prominent
    and popular by the day, and it is used to improve many different types of applications.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 许多开发者在职业生涯的某个阶段都会听说机器学习、深度学习或神经网络。你可能已经听说过这些话题。如果你已经了解，你会知道机器学习是一个复杂的领域，需要特定的领域知识。然而，机器学习正变得越来越突出和受欢迎，它被用于改进许多不同类型的应用。
- en: 'For instance, machine learning can be used to predict what type of content
    a particular user might like to see in a music app based on the music that they
    already have in their library, or to automatically tag faces in photos to connect
    them to people in the user''s contact list. It can even be used to predict costs
    for specific products or services based on past data. While this might sound like
    magic, the flow for creating machine learning experiences like these can be split
    roughly into two phases:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，机器学习可以用来根据用户在音乐库中已有的音乐预测他们可能在音乐应用中喜欢看到的内容，或者自动标记照片中的面孔，将它们与用户联系人列表中的人联系起来。它甚至可以根据历史数据预测特定产品或服务的成本。虽然这可能听起来像魔法，但创建类似这些机器学习体验的流程大致可以分为两个阶段：
- en: Training a model
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练模型
- en: Using inference to obtain a result from the model
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用推理从模型中获取结果
- en: Large amounts of high-quality data must be collected to perform the first step.
    If you're going to train a model that should recognize cats, you will need a large
    number of pictures of cats. You must also collect images that do not contain cats.
    Each image must then be appropriately tagged to indicate whether the image includes
    a cat or not.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 必须收集大量高质量的数据来执行第一步。如果你打算训练一个应该能够识别猫的模型，你需要大量猫的图片。你还必须收集不包含猫的图片。然后，每张图片都必须适当标记，以表明图片是否包含猫。
- en: If your dataset only contains images of cats that face towards the camera, the
    chances are that your model will not be able to recognize cats from a sideways
    point of view. If your dataset does contain cats from many different sides, but
    you only collected images for a single breed or with a solid white background,
    your model might still have a tough time recognizing all cats. Obtaining quality
    training data is not easy, yet it's essential.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的数据集只包含朝向摄像头的猫的图片，那么你的模型可能无法从侧面识别猫。如果你的数据集确实包含来自许多不同角度的猫，但你只收集了单一品种或背景为纯白色的图片，那么你的模型可能仍然很难识别所有猫。获得高质量的训练数据并不容易，但它是至关重要的。
- en: During the training phase of a model, you must provide a set of inputs that
    are of the highest quality possible. The smallest mistake could render your entire
    dataset worthless. Collecting big amounts of high-quality data to train a model
    is a tedious task. It also takes a lot of time. Certain complex models could take
    a couple of hours to crunch all the data and train themselves.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在模型的训练阶段，你必须提供一组尽可能高质量的输入。最小的错误可能会导致你的整个数据集变得毫无价值。收集大量高质量数据以训练模型是一项繁琐的任务。这也需要花费大量时间。某些复杂的模型可能需要几个小时来处理所有数据并自行训练。
- en: A trained model comes in several types. Each type of model is suitable for a
    different kind of task. For instance, if you are working on a model that can classify
    specific email messages as spam, your model might be a so-called **support vector
    machine**. If you're training a model that recognizes cats in pictures, you are
    likely training a **neural network**.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 训练好的模型有多种类型。每种类型的模型都适用于不同类型的任务。例如，如果你正在开发一个可以分类特定电子邮件消息是否为垃圾邮件的模型，你的模型可能是一个所谓的**支持向量机**。如果你正在训练一个在图片中识别猫的模型，你很可能在训练一个**神经网络**。
- en: Each model comes with its pros and cons, and each model is created and used
    differently. Understanding all these different models, their implications, and
    how to train them is extremely hard, and you could likely write a book on each
    kind of model.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 每个模型都有其优缺点，每个模型都是不同地创建和使用的。理解所有这些不同的模型、它们的含义以及如何训练它们是非常困难的，你可能会为每种类型的模型写一本书。
- en: In part, this is why Core ML is so great. Core ML enables you to make use of
    pre-trained models in your own apps. On top of this, Core ML standardizes the
    interface that you use in your own code. This means that you can use complex models
    without even realizing it. Let's learn more about Core ML, shall we?
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在一定程度上，这就是为什么 Core ML 如此出色的原因。Core ML 允许你在自己的应用中使用预训练的模型。在此基础上，Core ML 标准化了你在自己代码中使用的接口。这意味着你可以使用复杂的模型，甚至都不必意识到这一点。让我们更深入地了解
    Core ML，好吗？
- en: Understanding Core ML
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解 Core ML
- en: Due to the complex nature of machine learning and using trained models, Apple
    has built Core ML to make incorporating a trained model as straightforward as
    possible. On top of this, another goal was to ensure that whenever you implement
    machine learning using Core ML, your implementation is as fast and energy-efficient
    as possible. Since Apple has been enhancing iOS with machine learning for a couple
    of years now, they have loads of experience of implementing complex models in
    apps.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 由于机器学习的复杂性和使用训练模型，苹果公司构建了 Core ML，以便将集成训练模型的过程尽可能简化。除此之外，另一个目标是确保你使用 Core ML
    实现机器学习时，你的实现尽可能快且节能。由于苹果公司已经将机器学习增强到 iOS 中有几年时间了，他们在应用中实现复杂模型方面积累了丰富的经验。
- en: If you have ever researched machine learning, you might have come across cloud-based
    solutions. Typically, you send a bunch of data to a cloud-based solution, and
    the result is passed back as a response to your request. Core ML is very different,
    since the trained model lives on the device, instead of in the cloud. This means
    that your user's data never has to leave the device, which is very good for your
    user's privacy. Also, having your trained model on the device means that no internet
    connection is required to use Core ML, which saves both time and precious data.
    And since there is no potential bottleneck regarding response latency, Core ML
    is capable of calculating results in real time.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你曾经研究过机器学习，你可能遇到过基于云的解决方案。通常情况下，你会发送一些数据到基于云的解决方案，结果作为对请求的响应返回。Core ML 非常不同，因为训练模型存在于设备上，而不是在云中。这意味着你的用户数据永远不需要离开设备，这对用户的隐私非常有利。此外，将训练模型放在设备上意味着使用
    Core ML 不需要互联网连接，这节省了时间和宝贵的数据。而且由于没有潜在的响应延迟瓶颈，Core ML 能够实时计算结果。
- en: In the previous section, you learned that there are several types of trained
    models. Each type of model is used slightly differently, so if you were to implement
    machine learning in your app manually, you would have to write different wrappers
    around each of the different models your app uses. Core ML makes sure that you
    can use each type of model without even being aware of this in your app; they
    all share the same programming interface. A Core ML model is domain-agnostic.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，你了解到存在几种类型的训练模型。每种类型的模型使用方式略有不同，所以如果你要在应用中手动实现机器学习，你将不得不为应用使用的每种不同模型编写不同的包装器。Core
    ML 确保你可以在应用中无需意识到这一点的情况下使用每种类型的模型；它们都共享相同的编程接口。Core ML 模型是领域无关的。
- en: To be domain-agnostic, all trained models that you use with Core ML must be
    in a particular format. Since machine learning already has a vibrant community
    with several popular formats, Apple has made sure that the most popular models
    can be easily converted to Apple's own `.mlmodel` format. Let's see how to obtain
    `.mlmodel` files for you to use in your own apps.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 要实现领域无关性，你使用 Core ML 的所有训练模型都必须采用特定的格式。由于机器学习已经有一个充满活力的社区和几种流行的格式，苹果公司确保最流行的模型可以轻松转换为苹果自己的
    `.mlmodel` 格式。让我们看看如何获取用于你自己在应用中使用的 `.mlmodel` 文件。
- en: Obtaining Core ML models
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 获取 Core ML 模型
- en: There are two ways to obtain a model for you to use in your apps. The simplest
    way is to find an existing `.mlmodel` file. You can find several ready-to-use
    `.mlmodel` files on Apple's machine learning website, at [https://developer.apple.com/machine-learning/](https://developer.apple.com/machine-learning/).
    This website contains several of the most popular models. At the time of writing,
    most of these models are focused on recognizing the dominant objects in an image,
    and chances are that you have different needs for your app.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 获取用于你应用中的模型有两种方式。最简单的方式是找到一个现有的 `.mlmodel` 文件。你可以在苹果的机器学习网站上找到几个现成的 `.mlmodel`
    文件，网址为 [https://developer.apple.com/machine-learning/](https://developer.apple.com/machine-learning/)。这个网站包含了几种最受欢迎的模型。在撰写本文时，这些模型大多数都专注于识别图像中的主要对象，而且你很可能对你的应用有不同的需求。
- en: If you're looking for something that hasn't already been converted by Apple,
    you can try to look in several places online for a pre-converted `.mlmodel` file,
    or you can convert an existing model you have found online. Apple has created
    converters for several popular machine learning formats, such as `.mlmodel` file
    are written in Python, and they ship as part of Xcode. If your needs do not fit
    the converters that Apple provides, you can extend the **toolchain**, since the
    conversion tools are open source. This means that everybody can add their own
    converters or tweak existing converters.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您正在寻找 Apple 尚未转换的内容，您可以在网上几个地方尝试寻找预转换的 `.mlmodel` 文件，或者您可以将您在网上找到的现有模型进行转换。Apple
    为几种流行的机器学习格式创建了转换器，例如 `.mlmodel` 文件是用 Python 编写的，并且作为 Xcode 的一部分提供。如果您的需求不符合 Apple
    提供的转换器，您可以扩展 **toolchain**，因为转换工具是开源的。这意味着每个人都可以添加自己的转换器或调整现有的转换器。
- en: Converting Core ML models using Apple's tools can usually be done with a couple
    of lines of Python. Writing a good conversion script does typically involve a
    little bit of domain knowledge in the area of machine learning, because you'll
    need to make sure that the converted model works just as well as the original
    model.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Apple 的工具转换 Core ML 模型通常只需几行 Python 代码。编写一个良好的转换脚本通常需要一点机器学习领域的专业知识，因为您需要确保转换后的模型与原始模型一样有效。
- en: Once you have obtained a Core ML model for your app, either by converting one
    or finding an existing one, you're ready to add it to your project and begin using
    it. Let's see how to do this next.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您为您的应用程序获得了 Core ML 模型，无论是通过转换还是找到现有的模型，您就可以将其添加到项目中并开始使用它。让我们看看如何进行下一步。
- en: Using a Core ML model
  id: totrans-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用 Core ML 模型
- en: Applications can utilize Core ML for many different purposes. One of these purposes
    is text analysis. You can use a trained model to detect whether a particular piece
    of text has a positive or negative sentiment. To implement a feature like this,
    you can use a trained and converted Core ML model.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 应用程序可以利用 Core ML 实现许多不同的目的。其中之一是文本分析。您可以使用训练好的模型来检测特定文本是正面还是负面情绪。要实现这样的功能，您可以使用训练和转换后的
    Core ML 模型。
- en: The code bundle for this chapter includes a project named `@IBAction`, named
    `analyze()`. The project folder also contains a file called `SentimentPolarity.mlmodel`.
    This file is a trained Core ML model that analyzes the sentiment associated with
    a certain text. Drag this file into Xcode to add the Core ML model to your project.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的代码包包括一个名为 `@IBAction` 的项目，名为 `analyze()`。项目文件夹还包含一个名为 `SentimentPolarity.mlmodel`
    的文件。此文件是一个分析与特定文本相关的情绪的训练好的 Core ML 模型。将此文件拖入 Xcode 以将 Core ML 模型添加到您的项目中。
- en: 'After adding the model to your project, you can click it in the **Project Navigator**
    to see more information about the model, as illustrated in the following screenshot:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在将模型添加到您的项目后，您可以在**项目导航器**中点击它，以查看有关模型的更多信息，如下面的截图所示：
- en: '![Figure 10.1 – Model metadata'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.1 – 模型元数据'
- en: '](img/Figure_10.01_B14717.jpg)'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](img/Figure_10.01_B14717.jpg)'
- en: Figure 10.1 – Model metadata
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.1 – 模型元数据
- en: 'You can see that this model was provided by **Vadym Markov** under the **MIT**
    license. If you click the **Predictions** tab (see the preceding screenshot),
    you can find out which **Input** and **Output** you can expect this model to work
    with:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以看到，这个模型是由**Vadym Markov**在**MIT**许可下提供的。如果您点击**预测**选项卡（见前面的截图），您可以找到这个模型可以与之配合的**输入**和**输出**：
- en: '![Figure 10.2 – Input and output of the model'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.2 – 模型的输入和输出'
- en: '](img/Figure_10.02_B14717.jpg)'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](img/Figure_10.02_B14717.jpg)'
- en: Figure 10.2 – Input and output of the model
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.2 – 模型的输入和输出
- en: 'You can see in this case; the `[String: Double]` type. This means that we should
    feed this model a dictionary of word counts. If you add this model to Xcode, the
    center section that lists the **Model Class** might notify you that the model
    is not part of any targets yet. If this is the case, fix it as you have done previously,
    by adding this model to your app target in the **Utilities** sidebar on the right
    side of the window.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '在这个例子中，您可以看到 `[String: Double]` 类型。这意味着我们应该向这个模型提供一个词频字典。如果您将此模型添加到 Xcode 中，中心部分列出的
    **Model Class** 可能会通知您该模型尚未属于任何目标。如果是这种情况，您可以像之前那样修复它，通过在窗口右侧的**实用工具**侧边栏中将此模型添加到您的应用程序目标中。'
- en: Now that your model has been implemented, it's time to take it for a spin. First,
    implement a method that extracts the word count from any given string. You can
    implement this using the `NLTokenizer` object from the new `NaturalLanguage` framework.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 既然你的模型已经实现，是时候让它试运行了。首先，实现一个从任何给定的字符串中提取词数的方法。你可以使用来自新`NaturalLanguage`框架的`NLTokenizer`对象来实现这一点。
- en: '`NLTokenizer` is a text analysis class that is used to split a string into
    words, sentences, paragraphs, or even whole documents. In this example, the tokenizer
    is set up to detect individual words. Implement the word count method as follows.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '`NLTokenizer`是一个用于将字符串拆分为单词、句子、段落甚至整个文档的文本分析类。在这个例子中，分词器被设置为检测单个单词。以下是如何实现词数方法的示例。'
- en: 'Add an import to the `ViewController.swift` file as follows:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 按照以下方式将导入添加到`ViewController.swift`文件中：
- en: '[PRE0]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Now add the following method to the same file:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 现在将以下方法添加到同一文件中：
- en: '[PRE1]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The previous code iterates over all the words that the tokenizer has recognized
    and stores it in a dictionary of the `[String: Double]` type. You might wonder
    why a `Double` type is used for the word count, rather than an `Int` type, since
    the word counts won''t have to deal with decimals. This is true, but the `SentimentPolarity`
    model requires its input to be a dictionary of the `[String: Double]` type, so
    you must prepare the data accordingly.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '之前的代码遍历了分词器识别的所有单词，并将它们存储在`[String: Double]`类型的字典中。你可能想知道为什么词数使用`Double`类型而不是`Int`类型，因为词数不需要处理小数。这是真的，但是`SentimentPolarity`模型要求其输入为`[String:
    Double]`类型的字典，所以你必须相应地准备数据。'
- en: 'Now that you have the code to prepare the input data for the `SentimentPolarity`
    model, let''s see how you can use this model to analyze the user''s input. Add
    the following implementation for the `analyze()` method:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你有了为`SentimentPolarity`模型准备输入数据的代码，让我们看看如何使用这个模型来分析用户的输入。为`analyze()`方法添加以下实现：
- en: '[PRE2]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: You might be surprised that this method is so short, but that's how simple Core
    ML is! First, we retrieve the `wordCount` using the method we implemented earlier.
    Then, an instance of the Core ML model is created. When you added the `SentimentPolarity`
    model to the app target, Xcode generated a class interface that abstracted away
    all complexities involving the model. Because the model is now a simple class,
    you can obtain a prediction for the sentiment of the text by calling `prediction(input:)`
    on the model instance.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会惊讶这个方法如此简短，这正是Core ML的简单之处！首先，我们使用我们之前实现的方法检索`wordCount`。然后，创建一个Core ML模型的实例。当你将`SentimentPolarity`模型添加到应用目标时，Xcode生成了一个类接口，抽象了涉及模型的所有复杂性。因为模型现在是一个简单的类，你可以通过在模型实例上调用`prediction(input:)`来获取文本情感预测。
- en: The `prediction` method returns an object that contains the processed prediction
    in the `classLabel` property, as well as an overview of all available predictions
    and how certain the model is about each option in the `classProbability` property.
    You can use this property if you want to be a bit more transparent to the user
    about the different options that the model suggested and how certain it was about
    these options.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '`prediction`方法返回一个对象，其中包含在`classLabel`属性中的处理后的预测，以及所有可用预测的概述以及模型对每个选项的确定程度在`classProbability`属性中。如果你想对用户更透明地展示模型建议的不同选项以及模型对这些选项的确定程度，可以使用这个属性。'
- en: 'Let''s see a couple of examples to demonstrate how it works. First, launch
    the app. Now write `I love rainbows` in the text area and press `I am sad on cloudy
    days`. The result now is **Your text is rated: Neg**. This time, the sentiment
    of your sentence is negative! You can try out your own ideas to see how the model
    behaves in different scenarios.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看几个示例来演示它是如何工作的。首先，启动应用。现在在文本区域中写下`我喜欢彩虹`，然后按下`我在多云的日子里感到悲伤`。现在的结果是**你的文本评分为：负**。这次，你的句子情感是负面的！你可以尝试自己的想法来查看模型在不同场景下的表现。
- en: In the last section of this chapter, you will learn how you can use `Create
    ML` to train your own natural language model to analyze texts that use domain-specific
    language relevant to your own app.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的最后部分，你将学习如何使用`Create ML`来训练你自己的自然语言模型，以分析使用与你的应用相关的特定领域语言的文本。
- en: Using Core ML to perform text analysis was quite simple. Now let's see how you
    can use computer vision together with Core ML to determine the type of object
    that exists in a particular picture.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Core ML进行文本分析相当简单。现在让我们看看如何将计算机视觉与Core ML结合使用，以确定特定图片中存在的对象类型。
- en: Combining Core ML and computer vision
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结合Core ML和计算机视觉
- en: When you're developing an app that works with photos or live camera footage,
    there are several things you might like to do using computer vision. For instance,
    it could be desirable to detect faces in an image. Or, maybe you would want to
    identify certain rectangular areas of photographs, such as traffic signs. You
    could also be looking for something more sophisticated, such as detecting the
    dominant object in a picture.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 当你开发一个处理照片或实时摄像头视频的应用时，你可能想使用计算机视觉做一些事情。例如，你可能想在图像中检测面部。或者，你可能想识别照片中的某些矩形区域，如交通标志。你也可能正在寻找更复杂的事情，比如检测图片中的主导对象。
- en: To work with computer vision in your apps, Apple has created the **Vision**
    framework. You can combine Vision and Core ML to perform some pretty sophisticated
    image recognition. Before you implement a sample app that uses dominant object
    recognition, let's take a quick look at the Vision framework, so you have an idea
    of what it's capable of and when you might like to use it.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 要在你的应用中使用计算机视觉，苹果创建了 **Vision** 框架。你可以将 Vision 和 Core ML 结合起来执行一些相当复杂的图像识别。在你实现一个使用主导对象识别的示例应用之前，让我们快速了解一下
    Vision 框架，这样你就知道它能够做什么，以及你可能在什么时候想使用它。
- en: Understanding the Vision framework
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解 Vision 框架
- en: The Vision framework is capable of many different tasks that revolve around
    computer vision. It is built upon several powerful deep learning techniques that
    enable state-of-the-art facial recognition, text recognition, barcode detection,
    and more.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: Vision 框架能够执行许多围绕计算机视觉的任务。它基于几个强大的深度学习技术，能够实现最先进的面部识别、文本识别、条形码检测等。
- en: When you use Vision for facial recognition, you get much more information than
    just the location of a face in an image. The framework can recognize several facial
    landmarks, such as eyes, noses, or mouths. All of this is possible due to the
    extensive use of deep learning behind the scenes at Apple.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 当你使用 Vision 进行面部识别时，你获得的信息远不止图像中面部位置那么简单。该框架可以识别多个面部特征，如眼睛、鼻子或嘴巴。所有这一切都得益于苹果在幕后对深度学习的广泛使用。
- en: 'For most tasks, using Vision consists of the following three stages:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 对于大多数任务，使用 Vision 包括以下三个阶段：
- en: You create a request that specifies what you want; for instance, a `VNDetectFaceLandmarksRequest`
    request to detect facial features.
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你创建一个请求来指定你想要的内容；例如，一个用于检测面部特征的 `VNDetectFaceLandmarksRequest` 请求。
- en: You set up a handler that can analyze the images.
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你设置了一个可以分析图像的处理程序。
- en: The resulting observation contains the information you need.
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 结果观察包含了你需要的信息。
- en: 'The following code sample illustrates how you might find facial landmarks in
    an image:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码示例说明了你如何在图像中找到面部特征：
- en: '[PRE3]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: For something as complex as detecting the contour of a face or the exact location
    of an eye, the code is quite simple. You set up a `handler` and a `request`. Next,
    the `handler` is asked to `perform` one or more requests. This means that you
    can run several requests on a single image.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 对于像检测面部轮廓或眼睛的确切位置这样复杂的事情，代码相当简单。你设置一个 `handler` 和一个 `request`。接下来，`handler`
    被要求执行一个或多个请求。这意味着你可以在单个图像上运行多个请求。
- en: In addition to enabling computer vision tasks like this, the Vision framework
    also tightly integrates with Core ML. Let's see just how tight this integration
    is, by adding an image classifier to the augmented-reality gallery app you have
    been working on!
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 除了启用此类计算机视觉任务外，Vision 框架还与 Core ML 紧密集成。让我们通过向你在开发的增强现实画廊应用中添加图像分类器来了解一下这种集成有多紧密！
- en: Implementing an image classifier
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实现图像分类器
- en: The code bundle for this section contains an app called **ImageAnalyzer**. This
    app uses an image picker to allow a user to select an image from their photo library
    to use it as an input for the image classifier you will implement. Open the project
    and explore it for a little bit to see what it does and how it works. Use the
    starter project if you want to follow along with the rest of this section.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 本节代码包包含一个名为 **ImageAnalyzer** 的应用。这个应用使用图像选择器允许用户从他们的照片库中选择一张图片，作为你将要实现的图像分类器的输入。打开项目并探索一下，看看它做什么以及它是如何工作的。如果你想跟随本节的其余部分，请使用启动项目。
- en: To add an image classifier, you need to have a Core ML model that can classify
    images. On Apple's machine learning website ([https://developer.apple.com/machine-learning/build-run-models/](https://developer.apple.com/machine-learning/build-run-models/)),
    there are several models available that can do image classification. An excellent
    lightweight model you can use is the **MobileNetV2** model; go ahead and download
    it from the machine learning page. Once you have downloaded the model, drag the
    model into Xcode to add it to the **ImageAnalyzer** project. Make sure to add
    it to your app target so that Xcode can generate the class interface for the model.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 要添加一个图像分类器，你需要有一个能够对图像进行分类的 Core ML 模型。在苹果的机器学习网站上 ([https://developer.apple.com/machine-learning/build-run-models/](https://developer.apple.com/machine-learning/build-run-models/))，有多个可用的模型可以进行图像分类。你可以使用的一个优秀的轻量级模型是
    **MobileNetV2** 模型；请前往机器学习页面下载它。一旦下载了模型，将其拖入 Xcode 以将其添加到 **ImageAnalyzer** 项目中。请确保将其添加到你的应用程序目标中，以便
    Xcode 可以为该模型生成类接口。
- en: 'After adding the model to Xcode, you can open it to examine the **Model Predictions**
    tab. The parameters tell you the different types of inputs and outputs the model
    will expect and provide. In the case of **MobileNetV2**, the input should be an
    image that is **224** points wide and **224** points high, as shown in the following
    screenshot:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在将模型添加到 Xcode 后，你可以打开它来检查 **模型预测** 选项卡。参数告诉你模型将期望和提供不同类型的输入和输出。在 **MobileNetV2**
    的情况下，输入应该是一个宽度为 **224** 点和高度为 **224** 点的图像，如下面的截图所示：
- en: '![Figure 10.3 – Input and output of the model'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.3 – 模型的输入和输出'
- en: '](img/Figure_10.03_B14717.jpg)'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_10.03_B14717.jpg)'
- en: Figure 10.3 – Input and output of the model
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.3 – 模型的输入和输出
- en: After generating the model, the code to use the model is very similar to the
    code used to detect facial features with Vision earlier. The most significant
    difference is that the type of request that is used is a special `VNCore MLRequest`.
    This type of request takes the Core ML model you want to use, in addition to a
    completion handler.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在生成模型后，使用该模型的代码与之前使用 Vision 检测面部特征的代码非常相似。最显著的区别是使用的请求类型是一个特殊的 `VNCore MLRequest`。这种类型的请求除了需要一个完成处理程序外，还包含你想要使用的
    Core ML 模型。
- en: When combining Core ML and Vision, Vision will take care of image scaling and
    converting the image to a type that is compatible with the Core ML model. You
    should make sure that the input image has the correct orientation. If your image
    is rotated in an unexpected orientation, Core ML might not be able to analyze
    it correctly.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 当结合 Core ML 和 Vision 时，Vision 将负责图像缩放并将图像转换为与 Core ML 模型兼容的类型。你应该确保输入图像具有正确的方向。如果你的图像以意外的方向旋转，Core
    ML 可能无法正确分析它。
- en: 'First, let''s import the `Vision` framework. Add this statement at the top
    of the `ViewController` class in the **ImageAnalyzer** project:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们导入 `Vision` 框架。在 **ImageAnalyzer** 项目的 `ViewController` 类顶部添加此语句：
- en: '[PRE4]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Now, add the following implementation for `analyzeImage(_:)` to the `ViewController`
    class:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，将以下 `analyzeImage(_:)` 实现添加到 `ViewController` 类中：
- en: '[PRE5]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The previous method takes a `UIImage` and converts it to a `CGImage`. Also,
    a `VNCore MLModel` is created, based on the `MobileNetV2` model. This particular
    model class wraps the Core ML model, so it works seamlessly with `Vision`. The
    request is very similar to the request you have seen before. In the `completionHandler`,
    the results array and first prediction of the image classifications are extracted
    and shown to the user. Every prediction made by the classifier will have a label
    that is stored in the identifier and a confidence rating with a value between
    `0` and `1` stored in the `confidence` property. Note that the value of the description
    label is set on the main thread to avoid crashes.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 之前的方法将 `UIImage` 转换为 `CGImage`。同时，基于 `MobileNetV2` 模型创建了一个 `VNCore MLModel`。这个特定的模型类封装了
    Core ML 模型，因此它可以与 `Vision` 无缝工作。请求与之前看到的请求非常相似。在 `completionHandler` 中，提取并显示给用户的结果数组和图像分类的第一预测。分类器做出的每个预测都将有一个存储在标识符中的标签和一个存储在
    `confidence` 属性中的介于 `0` 和 `1` 之间的置信度评分。请注意，描述标签的值是在主线程上设置的，以避免崩溃。
- en: 'You have already implemented two different types of Core ML models that were
    trained for general purposes. Sometimes, these models won''t be specific enough
    for your purposes. For instance, take a look at the following screenshot, where
    a machine learning model labels a certain landscape with only 32% confidence:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 您已经实现了两种不同类型的 Core ML 模型，这些模型是为了通用目的而训练的。有时，这些模型可能不足以满足您的需求。例如，看看以下截图，其中机器学习模型仅以
    32% 的置信度标记了一个特定的风景：
- en: '![Figure 10.4 – Photo analysis result'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.4 – 照片分析结果'
- en: '](img/Figure_10.04_B14717.jpg)'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_10.04_B14717.jpg)'
- en: Figure 10.4 – Photo analysis result
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.4 – 照片分析结果
- en: In the next section, you will learn how to train models for purposes that are
    specific to you and your apps by using Create ML.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，您将学习如何使用 Create ML 训练针对您和您的应用程序特定目的的模型。
- en: Training your own models with Create ML
  id: totrans-95
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Create ML 训练自己的模型
- en: As part of Xcode 10 and Apple's version of macOS, **Mojave**, they have shipped
    a tool that you can use to train your own machine learning models by adding specializations
    to existing models. This means that you can train your own natural language model
    that places certain texts in categories that you define. Or, you can train a model
    that recognizes certain product names or terms in a text that are specific to
    your application's domain.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 作为 Xcode 10 和苹果公司的 macOS 版本 **Mojave** 的一部分，他们提供了一款工具，您可以使用它通过向现有模型添加特殊化来训练自己的机器学习模型。这意味着您可以为将某些文本分类到您定义的类别中的自然语言模型进行训练。或者，您可以为识别文本中特定于您应用程序领域的某些产品名称或术语的模型进行训练。
- en: If you're building a news app, you might want to train a Core ML model that
    can automatically categorize the articles in the app. You can then use this model
    to keep track of the articles your users read, and present articles that are most
    likely to fit their interests on a dedicated page in your app.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您正在构建新闻应用程序，您可能想训练一个 Core ML 模型，该模型可以自动对应用程序中的文章进行分类。然后，您可以使用此模型跟踪用户阅读的文章，并在应用程序的专用页面上展示最有可能符合他们兴趣的文章。
- en: In this segment, you will learn how to train natural language models and how
    you can train an image recognition model based on the Vision framework. In doing
    so, you will find that creating a large and optimized training set is crucial
    when you want to train a machine learning model.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，您将学习如何训练自然语言模型，以及您如何根据 Vision 框架训练图像识别模型。在这样做的时候，您会发现，当您想要训练机器学习模型时，创建一个大型且优化的训练集至关重要。
- en: In the code bundle for this chapter, you will find a Playground called **Create
    ML**. This playground contains all the resources used for training natural language
    models.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的代码包中，您将找到一个名为 **Create ML** 的游乐场。这个游乐场包含了用于训练自然语言模型的所有资源。
- en: Training a Natural Language model
  id: totrans-100
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练自然语言模型
- en: The Natural Language framework has excellent features to analyze text with.
    Bundled with the power of machine learning models, you can perform some powerful
    operations on text. Apple has spent a lot of time training several models with
    vast amounts of data to ensure that the Natural Language framework can detect
    names, places, and more.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 自然语言框架具有分析文本的出色功能。结合机器学习模型的力量，您可以对文本执行一些强大的操作。苹果公司投入了大量时间，使用大量数据训练了几个模型，以确保自然语言框架能够检测名称、地点等。
- en: However, sometimes you might want to add your own analysis tools. To facilitate
    this, the Natural Language framework works well with Core ML and Apple's new **Create
    ML** framework. With **Create ML**, you can easily and quickly create your own
    machine learning models that you can use in your apps straight away.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，有时您可能想添加自己的分析工具。为了便于这样做，自然语言框架与 Core ML 和苹果公司的新 **Create ML** 框架配合得很好。使用
    **Create ML**，您可以轻松快速地创建自己的机器学习模型，并将其直接用于您的应用程序。
- en: 'You can use several different types of training for a Natural Language model.
    In this section, you will learn about two different models:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用多种不同的训练方式来训练自然语言模型。在本节中，您将了解两种不同的模型：
- en: A text classifier
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文本分类器
- en: A word tagger
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文本标注器
- en: 'The **text classifier** will classify a particular piece of text with a label.
    This is similar to the sentiment analysis you have implemented in the **TextAnalyzer**
    sample app. An example of an entry in your training data would look as follows:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '**文本分类器**将使用标签对特定的文本进行分类。这与您在 **TextAnalyzer** 示例应用程序中实现的情感分析类似。您的训练数据中的一个条目示例如下：'
- en: '[PRE6]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: This is a sample of a news article headline that belongs in a category labeled
    `Tech`. When you feed a large number of samples like this to your model, you could
    end up with a classifier that can apply labels to news articles based on their
    headlines. Of course, this assumes that the headlines are specific enough and
    contain enough information to train the classifier properly. In reality, you will
    find that short sentences like these will not make the best models. The sample
    Playground contains a JSON file with training data that attempts to separate news
    articles into the two categories of politics and tech. Let's see how the model
    can be trained so you can then see for yourself how accurate the model is.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个属于标签为`Tech`类别的新闻文章标题样本。当你向模型提供大量这样的样本时，你可能会得到一个能够根据文章标题为新闻文章分配标签的分类器。当然，这假设标题足够具体并且包含足够的信息来正确训练分类器。实际上，你会发现像这样的短句并不会构成最好的模型。示例Playground中包含一个包含训练数据的JSON文件，试图将新闻文章分为政治和科技两个类别。让我们看看模型是如何训练的，这样你就可以亲自看看模型的准确性如何。
- en: 'The following code trains and stores the custom Core ML model. In the playground
    file, open the `Labeller`. Check the code:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的代码训练并存储自定义Core ML模型。在playground文件中打开`Labeller`，检查代码：
- en: '[PRE7]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Training the entire model requires only a couple of lines of code. All you need
    to do is obtain your training data, create the classifier, and save it somewhere
    on your machine. You can even do some quick testing to see whether your model
    works well, from right inside the playground.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 训练整个模型只需要几行代码。你只需要获取你的训练数据，创建分类器，并将其保存在你的机器上的某个位置。你甚至可以在playground内部进行一些快速测试，看看你的模型是否工作良好。
- en: Note that the preceding code uses a `try!` statement. This is done to keep the
    code sample brief and simple. In your own apps, you should always strive for proper
    error handling to avoid surprising crashes.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，前面的代码使用了`try!`语句。这样做是为了使代码示例简短简单。在你的应用中，你应该始终努力进行适当的错误处理，以避免意外的崩溃。
- en: The string passed to the `URL(fileURLWithPath:)` initializer represents the
    location where your model will be stored. Make sure to specify the full path here,
    so, for instance, use `/Users/yourUser/Desktop/TextClassifier.mlmodel`, and not
    `~/Desktop/TextClassifier.mlmodel`. Make sure to substitute `yourUser` with your
    own username or folder.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 传递给`URL(fileURLWithPath:)`初始化器的字符串表示你的模型将被存储的位置。请确保在这里指定完整路径，例如，使用`/Users/yourUser/Desktop/TextClassifier.mlmodel`，而不是`~/Desktop/TextClassifier.mlmodel`。请确保用你的用户名或文件夹替换`yourUser`。
- en: 'The following lines of code test two different headlines to see if the model
    correctly labels them:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的代码测试了两个不同的标题，看看模型是否正确地标记了它们：
- en: '[PRE8]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: If you're happy with the results of your model, you can grab the trained model
    from the place where you saved it, and immediately add it to your Xcode project.
    From there, you can use the model like you would use any other model.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你对自己的模型结果满意，你可以从保存模型的地方获取训练好的模型，并立即将其添加到你的Xcode项目中。从那里，你可以像使用任何其他模型一样使用该模型。
- en: 'Let''s see another example of a model from the Natural Language framework.
    In this case, the model should label every word in a text to classify it as a
    certain type of word. For instance, you could train the model to recognize certain
    brand names, product names, or other words that have special meanings to your
    app. An example of some training data that you could use to train a model like
    this is the following:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看自然语言框架中模型的另一个示例。在这种情况下，模型应该为文本中的每个单词标记标签，以将其分类为某种类型的单词。例如，你可以训练模型来识别某些品牌名称、产品名称或其他对你应用有特殊意义的单词。以下是一些你可以用来训练此类模型的训练数据示例：
- en: '[PRE9]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'By collecting many samples that include the words that you want to label, your
    model will be able to not only match tags based on the word itself, but even on
    the surrounding words. Essentially, the model would be aware of the context in
    which each word is used to then determine the correct tag. Once you have collected
    enough sample data, you can train the model in a similar way as the classifier:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 通过收集包含你想要标记的单词的大量样本，你的模型不仅能够根据单词本身匹配标签，甚至可以根据周围的单词匹配标签。本质上，模型将了解每个单词被使用的上下文，然后确定正确的标签。一旦你收集了足够的样本数据，你就可以以类似分类器的方式训练模型：
- en: '[PRE10]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The amount of code to train the model hasn't changed. The only difference is
    that the previous model was based on the `MLTextClassifier` class, and the current
    model is based on `MLWordTagger`. Again, you can immediately use the trained model
    to make some predictions that you can then use to validate whether the model was
    trained properly. Providing good data and testing often are the keys to building
    a great Core ML model.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 训练模型所需的代码量并没有变化。唯一的不同是，之前的模型基于 `MLTextClassifier` 类，而当前的模型基于 `MLWordTagger`。再次强调，你可以立即使用训练好的模型进行一些预测，然后你可以使用这些预测来验证模型是否被正确训练。提供良好的数据和经常测试是构建优秀的
    Core ML 模型的关键。
- en: In addition to text analysis models, Create ML can also help you to train your
    own image recognition models. Let's see how this works next.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 除了文本分析模型之外，Create ML 还可以帮助你训练自己的图像识别模型。让我们看看这是如何工作的。
- en: Training a Vision model
  id: totrans-123
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练视觉模型
- en: In the **ImageAnalyzer** sample app, you saw that picking an image of a certain
    car would be classified as a sports car with a pretty low confidence score. You
    can train your own vision model that specializes in recognizing certain cars.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 在 **ImageAnalyzer** 示例应用中，你看到选择一张特定车型的图片会被归类为跑车，并且置信度得分相当低。你可以训练自己的视觉模型，专门用于识别某些车型。
- en: Collecting good training data for image classifiers is tough, because you have
    to make sure that you gather many pictures of your subjects from all sides and
    in many different environments. For instance, if all your car images feature cars
    that are next to trees, or on the road, the model might end up classifying anything
    with trees or a road next to it as a car. The only way to obtain a perfect training
    set is to experiment, tweak, and test.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 为图像分类器收集良好的训练数据很困难，因为你必须确保从所有侧面和许多不同的环境中收集你主题的许多图片。例如，如果你的所有汽车图像都显示汽车靠近树木或在路上，模型最终可能会将任何旁边有树木或道路的物体分类为汽车。获得完美训练集的唯一方法是实验、调整和测试。
- en: 'Training a Vision model works slightly differently from training a Natural
    Language model. You can''t use a JSON file to feed your test data to the classifier.
    So, instead, you should create folders that contain your images where the folder
    name is the label you want to apply to each image inside that folder. The following
    screenshot is an example of a training set that contains two kinds of labels:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 训练视觉模型的工作方式与训练自然语言模型略有不同。你不能使用 JSON 文件来将测试数据喂给分类器。因此，相反，你应该创建包含你的图像的文件夹，其中文件夹名称是你想要应用给该文件夹内每张图像的标签。以下截图是一个包含两种标签的训练集示例：
- en: '![Figure 10.5 – Training set of images'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.5 – 训练集图像'
- en: '](img/Figure_10.05_B14717.jpg)'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_10.05_B14717.jpg)'
- en: Figure 10.5 – Training set of images
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.5 – 训练集图像
- en: 'Once you have collected your set of training data, you can store it anywhere
    on your computer—for instance, on the desktop. You will then pass the path for
    your training data to your model training code as follows:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你收集了你的训练数据集，你可以在电脑上的任何位置存储它——例如，在桌面上。然后，你将按照以下方式将你的训练数据路径传递给你的模型训练代码：
- en: '[PRE11]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Again, you only need a couple of lines of code to train a model. That's how
    powerful Create ML is. If you want, you can quickly test your image classifier
    by dropping the `.mlmodel` file in the `MobileNetV2` classifier that you used
    before.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，你只需要几行代码就可以训练一个模型。这就是 Create ML 强大的地方。如果你想的话，可以快速测试你的图像分类器，只需将 `.mlmodel`
    文件放入之前使用的 `MobileNetV2` 分类器中。
- en: Apart from the simple ways of training models, there are certain parameters
    that you can pass to the different Create ML classifiers. If you have trouble
    training your models properly, you could tweak some of the parameters that are
    used by Create ML. For instance, you could apply more iterations to your training
    set, so the model gains a deeper understanding of the training data.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 除了简单的模型训练方法之外，你还可以向不同的 Create ML 分类器传递某些参数。如果你在正确训练模型时遇到困难，你可以调整 Create ML 使用的某些参数。例如，你可以对你的训练集应用更多的迭代，这样模型就能对训练数据有更深入的理解。
- en: As mentioned before in this chapter, machine learning is a subject that could
    span several books on its own, and even though Create ML makes training models
    straightforward and simple, it's not easy to train a robust model without any
    prior machine learning experience.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 如本章之前所述，机器学习是一个可以涵盖几本书的主题，尽管 Create ML 使模型训练变得简单直接，但如果没有任何先前的机器学习经验，要训练一个健壮的模型并不容易。
- en: Now that you have learned how to use your own trained data, in the next section,
    we are going to learn how to update your models from the cloud, without the need
    to update the app itself.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经学会了如何使用自己的训练数据，在下一节中，我们将学习如何从云中更新您的模型，而无需更新应用本身。
- en: Updating models remotely with Model Deployment
  id: totrans-136
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用模型部署远程更新模型
- en: One of the new features of iOS 14 for machine learning is the ability to keep
    collections of your models in the cloud, giving you the power to update them at
    any time without the need to update the app itself.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: iOS 14 为机器学习带来的新功能之一是能够在云中保留您的模型集合，让您能够在任何时间更新它们，而无需更新应用本身。
- en: We are going to use a project, available in the code bundle of this book, in
    order to demonstrate this new feature. The project's name is **TextAnalyzerCloud**.
    It is the same project that we used before, but this time, the model will be on
    the cloud (with a local copy as a fallback).
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用本书代码包中可用的项目来演示此新功能。该项目的名称是**TextAnalyzerCloud**。它与之前使用的项目相同，但这次模型将在云中（本地副本作为后备）。
- en: 'There are two steps involved in order to use Model Deployment in our apps:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 使用模型部署在我们的应用中涉及两个步骤：
- en: Use the Core ML API to retrieve collections of models.
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 Core ML API 检索模型集合。
- en: Prepare and deploy the model.
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 准备和部署模型。
- en: Let's implement these steps in the next subsections.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在下一小节中实现这些步骤。
- en: Using the Core ML API to retrieve collections of models
  id: totrans-143
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Core ML API 检索模型集合
- en: 'Let''s start by learning how to retrieve models that are stored in the cloud
    into your app. Open the `ViewController` class. At this point, the class just
    contains an `analyze` method that counts the words inside a `textView` and makes
    a prediction if a model exists. The class also contains some methods to display
    error and success messages to the user. Note that we have also defined the following
    property: `var model: SentimentPolarity?`.'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '让我们首先学习如何将存储在云中的模型检索到您的应用中。打开`ViewController`类。在这个阶段，该类仅包含一个`analyze`方法，该方法计算`textView`内的单词数量，并在存在模型的情况下进行预测。该类还包含一些向用户显示错误和成功消息的方法。请注意，我们已定义以下属性：`var
    model: SentimentPolarity?`。'
- en: 'In the `analyze` method, we are going to download a model from the cloud, and
    in case of failure, we will use a local modal as a fallback. Let''s modify the
    method to achieve this. Update the implementation of the `analyze` method, and
    add the following code where it says `//add code`:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 在`analyze`方法中，我们将从云中下载一个模型，如果失败，我们将使用本地模态作为后备。让我们修改该方法以实现这一点。更新`analyze`方法的实现，并在`//add
    code`处添加以下代码：
- en: '[PRE12]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Let''s review the preceding code blocks (the following numbers refer to the
    comments in the preceding code):'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回顾前面的代码块（以下数字指的是前面代码中的注释）：
- en: First, in `//1`, we are accessing the new Core ML API to retrieve a collection
    of models from our account on the Apple servers. We do that by using the `MLModelCollection.beginAccessing`
    method with an identifier for the collection (that has to match the one in the
    cloud) – in our case, we used `SentimentPolarityCollection`.
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 首先，在`//1`中，我们正在访问新的 Core ML API，从苹果服务器上的账户中检索一组模型。我们通过使用带有集合标识符的`MLModelCollection.beginAccessing`方法来实现，该标识符必须与云中的标识符匹配——在我们的例子中，我们使用了`SentimentPolarityCollection`。
- en: Next, in `//2`, we are checking the result of `beginAccessing`. If it is successful
    and we get a collection of models, we search for a specific model with an identifier
    of `SentimentPolarity` and we extract the `modelURL` from it. If we get any errors
    (such as there being no network connection), we call the `handleCollectionError`
    method to handle it properly (in our case, we inform the user with a modal).
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 接下来，在`//2`中，我们正在检查`beginAccessing`的结果。如果成功并且我们得到了一个模型集合，我们将搜索具有`SentimentPolarity`标识符的特定模型，并从中提取`modelURL`。如果出现任何错误（例如没有网络连接），我们将调用`handleCollectionError`方法来正确处理它（在我们的情况下，我们通过模态向用户通知）。
- en: Now that we have a model URL, in `//3`, we try to load it. We haven't implemented
    the `loadSentimentClassifier` method yet, but we will do it shortly. Just take
    into account that this method will try to load a model with a given remote URL,
    and it will wrap it in a `Result<SentimentPolarity, Error>` enum (to handle errors
    properly).
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 现在我们有了模型 URL，在`//3`中，我们尝试加载它。我们尚未实现`loadSentimentClassifier`方法，但我们将很快完成它。请注意，此方法将尝试加载具有给定远程
    URL 的模型，并将其包装在`Result<SentimentPolarity, Error>`枚举中（以正确处理错误）。
- en: In the last part, under comment `//4`, we inspect the `Result` from `//3`. If
    we obtained a model, we store it in the `model` property variable. We store it
    so we don't need to download the model over and over again. After storing the
    model, we use it to analyze the text. On the other hand, if we obtained an error,
    we display a message to the user to inform them about it.
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在最后一部分，在注释`//4`下，我们检查`//3`中的`Result`。如果我们获得了一个模型，我们将它存储在`model`属性变量中。我们这样做是为了避免反复下载模型。在存储模型后，我们使用它来分析文本。另一方面，如果我们获得了一个错误，我们将向用户显示一条消息，通知他们有关错误的信息。
- en: 'Now let''s add the `loadSentimentClassifier` method so the class compiles.
    Add the following method to the `ViewController`:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们添加`loadSentimentClassifier`方法，以便类可以编译。将以下方法添加到`ViewController`中：
- en: '[PRE13]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'This method receives an optional model URL as a param; that is, the URL of
    our model stored in Apple Servers. It is an optional value because when we try
    to fetch it, it can fail (for example, if the user doesn''t have an internet connection).
    Inside the method, we handle two possibilities:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 此方法接收一个可选的模型URL作为参数；即我们存储在苹果服务器上的模型的URL。它是一个可选值，因为我们尝试获取它时，可能会失败（例如，如果用户没有互联网连接）。在方法内部，我们处理两种可能性：
- en: If the URL is not nil, we use it to initialize the model with `SentimentPolarity(contentsOf:)`
    and return it inside a `Result`.
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果URL不为空，我们使用它通过`SentimentPolarity(contentsOf:)`初始化模型，并在`Result`内部返回它。
- en: 'If the URL is nil, we try to initialize the model with a local version and
    the default configuration with `SentimentPolarity(configuration: .init())`. Again,
    we return it inside `Result`.'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '如果URL为空，我们尝试使用本地版本和默认配置通过`SentimentPolarity(configuration: .init())`初始化模型。同样，我们在`Result`内部返回它。'
- en: 'With this method implemented, we have all the code necessary to load a model
    from the network and use it in our app. However, we still need to perform two
    important steps to complete the process: Prepare the model to be uploaded to the
    Apple servers in the proper format, and deploy the model to the cloud.'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 通过实现此方法，我们已经拥有了从网络加载模型并在我们的应用中使用它的所有必要代码。然而，我们还需要执行两个重要步骤来完成此过程：将模型以适当的格式准备上传到苹果服务器，并将模型部署到云端。
- en: Preparing and deploying the model
  id: totrans-158
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备和部署模型
- en: In the previous section, we created the methods to retrieve a model from the
    Apple servers and into our app. Now, we are going to prepare our local model to
    be deployed into the cloud.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我们创建了从苹果服务器检索模型并将其导入我们应用的方法。现在，我们将准备我们的本地模型以便部署到云端。
- en: 'In the project explorer, click on the file named `SentimentPolarity.mlmodel`.
    Now, go to the **Utilities** tab. You will see the following:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 在项目资源管理器中，点击名为`SentimentPolarity.mlmodel`的文件。现在，转到**实用工具**选项卡。您将看到以下内容：
- en: '![Figure 10.6 – Model Utilities tab'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 10.6 – Model Utilities tab]'
- en: '](img/Figure_10.06_B14717.jpg)'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 10.06_B14717.jpg]'
- en: Figure 10.6 – Model Utilities tab
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 10.6 – Model Utilities tab]'
- en: 'Click on **Create Model Archive**. This new option in iOS 14 will help us to
    deploy our model onto the Apple servers in the cloud. When you click it, this
    popup will appear:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 点击**创建模型存档**。iOS 14中的这个新选项将帮助我们部署我们的模型到云端的苹果服务器。当您点击它时，将出现此弹出窗口：
- en: '![Figure 10.7 – Generate Model Archive'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 10.7 – Generate Model Archive]'
- en: '](img/Figure_10.07_B14717.jpg)'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 10.07_B14717.jpg]'
- en: Figure 10.7 – Generate Model Archive
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 10.7 – Generate Model Archive]'
- en: 'For now, leave the **Encrypt Model** checkbox unchecked and click **Continue**
    (we will explore this option later in the chapter). After clicking **Continue**,
    Xcode will generate an archive of the model and will display this modal:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，请保持**加密模型**复选框未选中，并点击**继续**（我们将在本章后面探索此选项）。点击**继续**后，Xcode将生成模型的存档并显示此模态：
- en: '![Figure 10.8 – The Model Archive Generated dialog'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 10.8 – The Model Archive Generated dialog]'
- en: '](img/Figure_10.08_B14717.jpg)'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 10.08_B14717.jpg]'
- en: Figure 10.8 – The Model Archive Generated dialog
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 10.8 – The Model Archive Generated dialog]'
- en: 'You can click on the blue arrow to the right of the first option in the preceding
    screenshot and it will take you to the exact location where the archive of your
    model is located. You will need to remember this location to upload the archive
    to the Apple servers. You will see a file with the`.mlarchive` extension, as in
    the following screenshot:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以点击上一张截图中的第一个选项右侧的蓝色箭头，这将带您到模型存档的确切位置。您需要记住这个位置以便将存档上传到苹果服务器。您将看到一个扩展名为`.mlarchive`的文件，如下面的截图所示：
- en: '![Figure 10.9 – Location of the archived model'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 10.9 – Location of the archived model]'
- en: '](img/Figure_10.09_B14717.jpg)'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 10.09_B14717.jpg]'
- en: Figure 10.9 – Location of the archived model
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 10.9 – Location of the archived model]'
- en: 'Now click on the blue arrow next to the second option that reads **You can
    upload the Model Archive on the Core ML Model Deployment dashboard**. It will
    open your web browser at the following page:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，点击第二个选项旁边的蓝色箭头，该选项读取为**您可以在Core ML模型部署仪表板上上传模型存档**。它将在以下页面打开您的网络浏览器：
- en: '![Figure 10.10 – Core ML Model Collections page'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: '![图10.10 – Core ML模型集合页面'
- en: '](img/Figure_10.10_B14717.jpg)'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_10.10_B14717.jpg)'
- en: Figure 10.10 – Core ML Model Collections page
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.10 – Core ML模型集合页面
- en: 'This is your dashboard for managing your model collections on the Apple servers.
    What we need to do now is to create a new collection with a reference to our model
    inside, and upload the model archive we just created. Let''s do this; click on
    the blue plus (**+**) icon next to **Model Collections**, and fill in the form
    that appears with the following information:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 这是您在Apple服务器上管理模型集合的仪表板。我们现在需要创建一个新的集合，其中包含我们的模型引用，并上传我们刚刚创建的模型存档。让我们这样做；点击**模型集合**旁边的蓝色加号（**+**）图标，并填写出现的表单，如下所示：
- en: '![Figure 10.11 – Create a Model Collection'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: '![图10.11 – 创建模型集合'
- en: '](img/Figure_10.11_B14717.jpg)'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_10.11_B14717.jpg)'
- en: Figure 10.11 – Create a Model Collection
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.11 – 创建模型集合
- en: 'Let''s review the input fields:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回顾一下输入字段：
- en: '`//1`: `MLModelCollection.beginAccessing(identifier: "SentimentPolarityCollection")`),
    we used the identifier `SentimentPolarityCollection`. Use the same one here (otherwise,
    you will not be able to download the collection).'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`//1`：`MLModelCollection.beginAccessing(identifier: "SentimentPolarityCollection")`），我们使用了标识符`SentimentPolarityCollection`。在这里使用相同的标识符（否则，您将无法下载集合）。'
- en: '**Description**: Use this field to create a description that will help you
    to recognize this collection later on. Take into account that if you work in a
    team, it will need to be useful to the other developers too.'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**描述**：使用此字段创建一个描述，这将帮助您在以后识别此集合。考虑到如果您在一个团队中工作，它还需要对其他开发者有用。'
- en: '`SentimentPolarity` (under comment `//2`: `modelURL = collection.entries["SentimentPolarity"]`).
    Again, these identifiers have to match each other. You have the possibility to
    add more model identifiers by pressing the **Model ID** blue button, but in our
    case, we have just one model inside our collection.'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`SentimentPolarity`（在注释`//2`中：`modelURL = collection.entries["SentimentPolarity"]`）。再次强调，这些标识符必须相互匹配。您可以通过点击**模型ID**蓝色按钮添加更多模型标识符，但在这个例子中，我们的集合中只有一个模型。'
- en: 'Finally, you can click the blue **Create** button, and you will land on the
    following model collection page:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，您可以点击蓝色**创建**按钮，然后您将进入以下模型集合页面：
- en: '![Figure 10.12 – Model collection page'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: '![图10.12 – 模型集合页面'
- en: '](img/Figure_10.12_B14717.jpg)'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_10.12_B14717.jpg)'
- en: Figure 10.12 – Model collection page
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.12 – 模型集合页面
- en: 'From this page, you can finally deploy or archive the model into its reference
    on the cloud. Click on the blue plus (**+**) button next to **Deployments**, and
    fill in the fields as shown here:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个页面，您最终可以将模型部署或存档到云上的引用。点击**部署**旁边的蓝色加号（**+**）按钮，并填写如此处所示的字段：
- en: '![Figure 10.13 – Model deployment properties'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: '![图10.13 – 模型部署属性'
- en: '](img/Figure_10.13_B14717.jpg)'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_10.13_B14717.jpg)'
- en: Figure 10.13 – Model deployment properties
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.13 – 模型部署属性
- en: 'Let''s review the fields:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回顾一下字段：
- en: '**Deployment ID**: You can specify any text here that describes why you are
    deploying this model. It is just a descriptive field; it doesn''t need to match
    anything.'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**部署ID**：您可以在此处指定任何文本来描述您为什么要部署此模型。这只是一个描述字段；它不需要与任何内容匹配。'
- en: '`.mlarchive` file we created before in Xcode when archiving the model.'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`.mlarchive`文件是我们之前在Xcode中存档模型时创建的。'
- en: Notice in the bottom part of the form that we can add **Additional Targeting
    Rules**. This is another new feature of iOS 14 that allows us to target our models
    based on device characteristics. For example, we can download certain models only
    to iPads, or for specific OS versions. To keep this example simple, we are not
    going to add any rules, but you should try it out in your apps!
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 注意到表单的底部部分，我们可以添加**附加目标规则**。这是iOS 14的另一个新功能，允许我们根据设备特性来定位我们的模型。例如，我们可以仅将某些模型下载到iPad上，或者针对特定的操作系统版本。为了使这个例子简单，我们不会添加任何规则，但您应该在您的应用程序中尝试一下！
- en: 'After you upload the `.mlarchive` file, it should display as follows:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 在您上传`.mlarchive`文件后，它应该显示如下：
- en: '![Figure 10.14 – Our first model deployed'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: '![图10.14 – 我们部署的第一个模型'
- en: '](img/Figure_10.14_B14717.jpg)'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_10.14_B14717.jpg)'
- en: Figure 10.14 – Our first model deployed
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.14 – 我们部署的第一个模型
- en: When the status is `analyze` method will give you a verdict.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 当状态为`analyze`方法将给出结论。
- en: In this section, you have learned how to consume the Core ML API to fetch models
    from the cloud to keep your app models up to date. You also learned how to prepare
    your models and how to deploy them to the Apple servers. Now you are going to
    learn how to encrypt those models with a new iOS 14 feature to keep your model's
    data safe on users' devices.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，您学习了如何使用Core ML API从云端获取模型以保持您的应用模型更新。您还学习了如何准备您的模型以及如何将它们部署到Apple服务器。现在您将学习如何使用iOS
    14的新功能对这些模型进行加密，以在用户设备上保护模型数据的安全。
- en: Encrypting Core ML models
  id: totrans-206
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加密Core ML模型
- en: One of the new features of iOS 14 Core ML is the ability to encrypt your machine
    learning models on users' devices. Xcode 12 has a new tool that will help you
    to create a private key that you will deploy to the Apple servers. Your app will
    download that key and store it securely on the users' devices, and will use the
    key to decrypt the local (encrypted) model, load that decrypted version into memory
    (so it is not stored insecurely), and have it ready for use in your app.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: iOS 14 Core ML的新特性之一是能够在用户设备上加密您的机器学习模型。Xcode 12有一个新工具可以帮助您创建一个私有密钥，您将部署到Apple服务器。您的应用将下载该密钥并在用户设备上安全存储，并使用该密钥解密本地（加密）模型，将解密版本加载到内存中（因此它不会以不安全的方式存储），并使其在您的应用中使用时准备就绪。
- en: 'The steps to create the key and deploy it to the Apple servers are very straightforward.
    First, you select your model in the project explorer; in our case, open the `SentimentPolarity.mlmodel`
    file. Then, click on the **Utilities** tab:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 创建密钥并将其部署到Apple服务器的步骤非常简单。首先，在项目资源管理器中选择您的模型；在我们的例子中，打开`SentimentPolarity.mlmodel`文件。然后，点击**实用工具**选项卡：
- en: '![Figure 10.15 – Model encryption'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: '![图10.15 – 模型加密'
- en: '](img/Figure_10.15_B14717.jpg)'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_10.15_B14717.jpg)'
- en: Figure 10.15 – Model encryption
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.15 – 模型加密
- en: 'Now, click on **Create Encryption Key**. In the popup that appears, select
    the proper development account for your app:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，点击**创建加密密钥**。在出现的弹出窗口中，选择您的应用的正确开发账户：
- en: '![Figure 10.16 – Selecting the development team for the encryption key'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: '![图10.16 – 选择加密密钥的开发团队'
- en: '](img/Figure_10.16_B14717.jpg)'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_10.16_B14717.jpg)'
- en: Figure 10.16 – Selecting the development team for the encryption key
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.16 – 选择加密密钥的开发团队
- en: 'This will generate a key and `.mlmodelkey` in your folder:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 这将在您的文件夹中生成一个密钥和`.mlmodelkey`文件：
- en: '![Figure 10.17 – Generating an encryption key'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: '![图10.17 – 生成加密密钥'
- en: '](img/Figure_10.17_B14717.jpg)'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_10.17_B14717.jpg)'
- en: Figure 10.17 – Generating an encryption key
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.17 – 生成加密密钥
- en: Clicking the blue arrow will take you to the specific folder where this key
    is stored. You will need to remember the location if you want to deploy this key
    to the Apple servers later so your team can use it too. Click **OK** and close
    the popup.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 点击蓝色箭头将带您到存储此密钥的特定文件夹。如果您想稍后将其部署到Apple服务器以便您的团队也能使用，则需要记住位置。点击**确定**并关闭弹出窗口。
- en: 'Now if you click on **Create Model Archive**, you will notice that the **Encrypt
    Model** checkbox is active this time:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，如果您点击**创建模型存档**，您会注意到这次**加密模型**复选框是激活的：
- en: '![Figure 10.18 – Generating a model archive with encryption'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: '![图10.18 – 生成带有加密的模型存档'
- en: '](img/Figure_10.18_B14717.jpg)'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_10.18_B14717.jpg)'
- en: Figure 10.18 – Generating a model archive with encryption
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.18 – 生成带有加密的模型存档
- en: When you click **Continue**, Xcode creates an encrypted archive this time. The
    steps that follow are exactly the same as the steps we learned in the *Prepare
    and Deploy the model* section.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 当您点击**继续**时，Xcode这次将创建一个加密存档。接下来的步骤与我们学过的**准备和部署模型**部分中的步骤完全相同。
- en: 'However, you can also tell Xcode to encrypt the bundled model (the local copy).
    To do this, after generating the encryption key (as we just did), you need to
    click on your project, go to **Build Phases**, and open the **Compile Sources**
    section:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，您也可以告诉Xcode加密捆绑的模型（本地副本）。为此，在生成加密密钥（正如我们刚才所做的那样）之后，您需要点击您的项目，转到**构建阶段**，并打开**编译源**部分：
- en: '![Figure 10.19 – The Build Phases tab'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: '![图10.19 – 构建阶段选项卡'
- en: '](img/Figure_10.19_B14717.jpg)'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_10.19_B14717.jpg)'
- en: Figure 10.19 – The Build Phases tab
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.19 – 构建阶段选项卡
- en: 'Now select the **SentimentPolarity.mlmodel** model and on the right side of
    its row, you can double-click to add a flag. Add the route to the encryption key
    in your project folder:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 现在请选择**SentimentPolarity.mlmodel**模型，并在其行右侧双击以添加一个标志。将加密密钥的路由添加到您的项目文件夹中：
- en: '[PRE14]'
  id: totrans-231
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'It should look like this after you have added the flag:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 添加标志后，它应该看起来像这样：
- en: '![Figure 10.20 – Model with the encryption flag'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: '![图10.20 – 带有加密标志的模型'
- en: '](img/Figure_10.20_B14717.jpg)'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.20 – 带有加密标志的模型](img/Figure_10.20_B14717.jpg)'
- en: Figure 10.20 – Model with the encryption flag
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.20 – 带有加密标志的模型
- en: Now if you build the app, Xcode will generate an encrypted version of the model
    inside your app.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，如果你构建应用，Xcode 将在应用内部生成模型的加密版本。
- en: 'You have learned how to encrypt your model locally (and how to encrypt an archive
    for the Apple servers). Let''s see now how you can load that model at runtime.
    There is a new class method in ML Models named `load` that will decrypt the model
    for you, downloading the encryption key from the Apple servers. Check out the
    following example code:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 你已经学习了如何在本地加密模型（以及如何加密用于上传到苹果服务器的存档）。现在让我们看看如何在运行时加载该模型。ML Models 中有一个新的类方法
    `load`，它将为你解密模型，从苹果服务器下载加密密钥。查看以下示例代码：
- en: '[PRE15]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: In the preceding code, the `class func load` will try to download the encryption
    key from the Apple servers and will decrypt the model with it, storing it in memory.
    We assign that decrypted model to our variable model, and it is ready to use.
    We also handle the failure case, displaying an error.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中，`class func load` 方法将尝试从苹果服务器下载加密密钥，并使用它解密模型，将其存储在内存中。我们将解密后的模型分配给我们的变量
    `model`，它现在可以使用了。我们还处理了失败情况，显示错误信息。
- en: In this section, you learned how to generate an encryption key, how to encrypt
    an archived model to upload to the Apple servers and also to encrypt the local
    copy of it, and finally how to load and decrypt the model for the app to use.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，你学习了如何生成加密密钥，如何加密存档模型以便上传到苹果服务器，以及加密其本地副本，最后是如何加载和解密模型以便应用使用。
- en: Summary
  id: totrans-241
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, you have seen how you can make use of the machine learning
    capabilities that iOS provides. You saw that adding a machine learning model to
    your app is extremely simple since you only have to drag it to Xcode and add it
    to your target app. You also learned how you can obtain models, and where to look
    to convert existing models to Core ML models. Creating a machine learning model
    is not simple, so it's great that Apple has made it so simple to implement machine
    learning by embedding trained models in your apps.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你看到了如何利用 iOS 提供的机器学习功能。你了解到，将机器学习模型添加到应用中非常简单，因为你只需将其拖到 Xcode 中并添加到目标应用即可。你还学习了如何获取模型，以及在哪里查找将现有模型转换为
    Core ML 模型的信息。创建机器学习模型并不简单，所以苹果通过在应用中嵌入训练好的模型，使得实现机器学习变得非常简单。
- en: In addition to Core ML, you also learned about the Vision and Natural Language
    frameworks. Vision combines the power of Core ML and smart image analysis to create
    a compelling framework that can perform a massive amount of work on images. Convenient
    requests, such as facial landmark detection, text analysis, and more are available
    out of the box without adding any machine learning models to your app. If you
    do find that you need more power in the form of custom models, you now know how
    to use Create ML to train, export, and use your own custom trained Core ML models.
    You learned that Create ML makes training models simple, but you also learned
    that the quality of your model is drastically impacted by the quality of your
    training data.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 除了 Core ML，你还学习了 Vision 和 Natural Language 框架。Vision 结合了 Core ML 和智能图像分析的力量，创建了一个强大的框架，可以在图像上执行大量工作。如面部特征检测、文本分析等方便的请求，无需添加任何机器学习模型到你的应用中即可直接使用。如果你发现你需要更多以自定义模型形式存在的功能，你现在知道如何使用
    Create ML 来训练、导出和使用你自己的自定义训练好的 Core ML 模型。你了解到 Create ML 使得训练模型变得简单，但你同时也了解到，模型的质量会受到训练数据质量的影响。
- en: Finally, you learned how to deploy your Core ML models in the cloud in order
    to update them without the need to update the app, and how to encrypt and decrypt
    them to store your models safely on the user device.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，你学习了如何在云中部署你的 Core ML 模型，以便在不更新应用的情况下更新它们，以及如何加密和解密它们，以确保在用户设备上安全地存储模型。
- en: In the next chapter, you will learn how you can capture, manipulate, and use
    media files in your apps, including audio, photo, and video elements.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，你将学习如何在应用中捕获、操作和使用媒体文件，包括音频、照片和视频元素。
