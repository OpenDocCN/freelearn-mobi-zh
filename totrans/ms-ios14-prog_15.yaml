- en: '*Chapter 15*: Recognition with Vision Framework'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第 15 章*：使用 Vision 框架进行识别'
- en: 'The Vision framework has been available to developers for a few years now.
    Apple has been introducing better and better features for it, from text recognition
    to image recognition. On iOS 14, Vision comes with more improvements to text recognition
    and other existing functions, but it also allows developers to perform two different
    actions: hand and body pose recognition. The possibilities that these new features
    open up for developers are limitless! Just think about gym apps, yoga apps, health
    apps, and so on.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: Vision 框架已经对开发者开放了几年。苹果公司一直在为其引入更好的功能，从文本识别到图像识别。在 iOS 14 中，Vision 框架带来了对文本识别和其他现有功能的更多改进，但它还允许开发者执行两种不同的操作：手部和身体姿态识别。这些新功能为开发者带来的可能性是无限的！只需想想健身房应用、瑜伽应用、健康应用等等。
- en: 'In this chapter, we are going to learn about the basics of the Vision framework
    and how to use the new advancements in text recognition. We will also learn about
    the new hand landmark recognition, building a demo app that can detect the tips
    of the four fingers and the thumb. The chapter code bundle also provides a similar
    example demonstrating body pose recognition. We will discuss these topics in the
    following sections:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将学习关于 Vision 框架的基础知识以及如何使用文本识别的新进展。我们还将了解新的手部关键点识别，构建一个能够检测四个手指和拇指尖端的演示应用。本章代码包还提供了一个类似的示例，展示了人体姿态识别。以下几节将讨论这些主题：
- en: Introduction to the Vision framework
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Vision 框架简介
- en: Recognizing text in images
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在图像中识别文本
- en: Recognizing hand landmarks in real time
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实时识别手部关键点
- en: By the end of this chapter, you will be able to work with the Vision framework
    with total confidence, being able to apply the techniques explained in this chapter
    to implement any type of recognition that Vision provides, from the recognition
    of text in images to the recognition of hand and body poses in videos.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，你将能够充满信心地使用 Vision 框架，能够将本章中解释的技术应用于实现 Vision 提供的任何类型的识别，从图像中的文本识别到视频中手部和身体姿态的识别。
- en: Technical requirements
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'The code bundle for this chapter includes a starter project called `HandDetection_start`
    and a couple of playground files named `Vision.playground` and `RecognitionPerformance_start.playground`.
    It also contains a completed example for body pose detection named `BodyPoseDetection_completed`.
    You can find them in the code bundle repository:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的代码包包括一个名为 `HandDetection_start` 的入门项目，以及几个名为 `Vision.playground` 和 `RecognitionPerformance_start.playground`
    的游乐场文件。它还包含一个名为 `BodyPoseDetection_completed` 的完成示例。你可以在代码包仓库中找到它们：
- en: https://github.com/PacktPublishing/Mastering-iOS-14-Programming-4th-Edition
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: https://github.com/PacktPublishing/Mastering-iOS-14-Programming-4th-Edition
- en: Introduction to the Vision framework
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Vision 框架简介
- en: Since the beginning of the App Store, there have been many apps that use the
    camera to build great functionalities using image and video recognition. Think
    of the bank apps that can now scan a check or a credit card so that the user doesn't
    need to input all the numbers. There are networking apps that can take a picture
    of a business card and extract the relevant information. Even the Photos app from
    your iPhone can detect faces in your photographs and classify them.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 自 App Store 开始以来，许多应用都利用摄像头通过图像和视频识别构建了出色的功能。想想现在可以扫描支票或信用卡的银行应用，这样用户就不需要输入所有数字。还有可以拍照名片并提取相关信息的网络应用。甚至你
    iPhone 上的照片应用也能检测照片中的面孔并将它们分类。
- en: 'The Vision framework provides developers with a robust set of features to make
    it easier than ever to achieve these functionalities: from text and image recognition
    to barcode detection, face landmarks analysis, and now, with iOS 14, hand and
    body pose recognition.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: Vision 框架为开发者提供了一套强大的功能，使其比以往任何时候都更容易实现这些功能：从文本和图像识别到条形码检测、面部关键点分析，现在，随着 iOS
    14 的推出，还有手部和身体姿态识别。
- en: Vision also allows the use of Core ML models to allow developers to enhance
    object classification and detection in their apps. Vision has been available since
    iOS 11 and macOS 10.13.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: Vision 还允许使用 Core ML 模型，以便开发者能够增强他们应用中的对象分类和检测。Vision 自 iOS 11 和 macOS 10.13
    以来一直可用。
- en: 'There are several concepts in Vision that are common to any type of detection
    (text detection, image detection, barcode detection, and so on), including the
    `VNRequest`, `VNRequestHandler`, and `VNObservation` entities:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: Vision中有几个概念在所有类型的检测中都是通用的（文本检测、图像检测、条形码检测等），包括`VNRequest`、`VNRequestHandler`和`VNObservation`实体：
- en: '`VNRequest` is the task that we want to perform. For example, `VNDetectAnimalRequest`
    would be used to detect animals in a picture.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`VNRequest`是我们想要执行的任务。例如，`VNDetectAnimalRequest`将用于在图片中检测动物。'
- en: '`VNRequestHandler` is how we want to detect. It lets us define a completion
    handler where we can play around with the results and shape them in the way that
    we need.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`VNRequestHandler`是我们想要检测的方式。它允许我们定义一个完成处理程序，在那里我们可以处理结果并按需塑造它们。'
- en: '`VNObservation` encapsulates the results.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`VNObservation`封装了结果。'
- en: 'Let''s look at an example that combines all these concepts and shows how Vision
    can easily help us to detect text inside an image. Open the playground named `Vision.playground`.
    This example code is grabbing an image from a specific URL and trying to extract/detect
    any text on it. The image being used is this one:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看一个结合所有这些概念并展示Vision如何轻松帮助我们检测图像中文字的示例。打开名为`Vision.playground`的沙盒。这个示例代码从一个特定的URL获取图像并尝试从中提取/检测任何文本。所使用的图像是这张：
- en: '![Figure 15.01 – Example image to extract text with Vision'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '![图15.01 – 使用Vision提取文本的示例图像](img/Figure_15.01_B14717.jpg)'
- en: '](img/Figure_15.01_B14717.jpg)'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 15.01 – Example image to extract text with Vision](img/Figure_15.01_B14717.jpg)'
- en: Figure 15.01 – Example image to extract text with Vision
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 图15.01 – 使用Vision提取文本的示例图像
- en: 'If we try to extract text from this image, we should get results such as *Swift
    Data Structure and Algorithms*, or the name of the authors, or the description
    below the title. Let''s review the code in the playground:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们尝试从这张图像中提取文本，我们应该得到像*Swift 数据结构和算法*或作者姓名，或标题下面的描述这样的结果。让我们回顾沙盒中的代码：
- en: '[PRE0]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Let''s go through the numbered comments:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们逐条查看编号的注释：
- en: First, we are creating a `VNImageRequestHandler` instance with a given image
    URL. We instantiate this handler to perform Vision requests on an image. Remember
    that we need to call `perform(_:)` later on to launch the analysis.
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们使用给定的图像URL创建一个`VNImageRequestHandler`实例。我们实例化这个处理程序以在图像上执行Vision请求。记住，我们稍后需要调用`perform(_:)`来启动分析。
- en: Now we create a `request(VNRecognizeTextRequest)` instance that we will perform
    on the `requestHandler` instance instantiated previously. You can perform multiple
    requests on a `requestHandler` instance. We define a block of code to be executed
    when the request finishes. In this block, we are extracting the observations from
    the request results (`VNRecognizedTextObservation` instances). These observations
    will contain potential outcomes for the analyzed text from the image (`VNRecognizedText`
    instances). We print `topCandidate` from each observation, which should be the
    best match according to the Vision parameters.
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们创建一个`request(VNRecognizeTextRequest)`实例，我们将在之前实例化的`requestHandler`实例上执行它。你可以在一个`requestHandler`实例上执行多个请求。我们定义了一块代码，当请求完成时将执行该代码。在这个块中，我们从请求结果中提取观察结果（`VNRecognizedTextObservation`实例）。这些观察结果将包含从图像中分析出的文本的潜在结果（`VNRecognizedText`实例）。我们打印出每个观察结果中的`topCandidate`，根据Vision参数，这应该是最佳匹配。
- en: We can specify the recognition level for the request. In this example, we are
    using `.accurate` (the alternative is `.fast`). We will see later the results
    with `.fast` and when to use one or the other.
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以指定请求的识别级别。在这个例子中，我们使用`.accurate`（另一种选择是`.fast`）。我们将在稍后看到`.fast`的结果以及何时使用其中一个。
- en: Finally, we are performing the request on the `requestHandler` instance to execute
    everything with the `perform(_:)` method.
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们在`requestHandler`实例上执行请求，使用`perform(_:)`方法执行所有操作。
- en: 'If you execute the code, the console in the playground will display the following:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你执行代码，沙盒中的控制台将显示以下内容：
- en: '[PRE1]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Those seem to be great results, right? If you recheck the image, we are extracting
    the correct text from it! The author names, the title (per line), the description,
    and more! Seems to be a great result! But have you noticed that when you execute
    the playground, it takes a while to finish? This is because we are using the `.accurate`
    option. Let''s see what happens if we use `.fast` instead. Change it in the playground
    code:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 这些结果看起来很棒，对吧？如果你重新检查图像，我们会从其中提取正确的文本！作者姓名、标题（每行）、描述等等！看起来是个很棒的结果！但你有没有注意到，当你执行沙盒时，它需要一段时间才能完成？这是因为我们使用了`.accurate`选项。让我们看看如果我们使用`.fast`会发生什么。在沙盒代码中更改它：
- en: '[PRE2]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The output is as follows:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE3]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: This time, the analysis can be done faster, but as you can see, the results
    are far worse for what we wanted (we wanted to detect the text properly!). Why
    should anyone prefer speed over accuracy? Well, for some apps, speed is critical
    and it is fine to sacrifice some accuracy for it. Think of real-time camera-based
    translations or applying real-time filters to take photos. In these scenarios,
    you need fast processing. We will discuss this further later in the chapter.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这次，分析可以做得更快，但正如你所见，对于我们所期望的结果（我们希望正确地检测文本！）来说，结果要差得多。为什么有人会优先考虑速度而不是准确性呢？嗯，对于某些应用来说，速度是关键，为了它牺牲一些准确性是可以接受的。想想基于实时摄像头的翻译或者应用实时滤镜拍照。在这些场景中，你需要快速处理。我们将在本章后面进一步讨论这个问题。
- en: This playground example should help you to have a grasp of the incredible potential
    that Vision contains. Just with a few lines of code, we were able to process and
    extract the text of an image with no issues or complex operations. Vision allows
    developers to do amazing things. Let's dive deeper into it in the following sections,
    starting with a more detailed look at text detection for images.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 这个游乐场示例应该能帮助你了解Vision所包含的惊人潜力。仅仅通过几行代码，我们就能够处理并提取图像中的文本，没有任何问题或复杂的操作。Vision允许开发者做令人惊叹的事情。让我们在接下来的章节中更深入地探讨它，从对图像文本检测的更详细分析开始。
- en: Recognizing text in images
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在图像中识别文本
- en: The Vision framework has been improving its detection of text in images since
    its first iteration. In this section, we are going to learn some state-of-the-art
    techniques to obtain the best results on iOS 14.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 自从Vision框架的第一个迭代以来，它一直在改进图像中检测文本的能力。在本节中，我们将学习一些最先进的技术，以在iOS 14上获得最佳结果。
- en: 'We saw in the previous section that text detection in Vision can happen in
    two different ways, as defined by the value of `recognitionLevel` that we specify
    in the request: `.fast` and `.accurate`. Let''s see the differences:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我们看到了在Vision中，文本检测可以通过两种不同的方式发生，这取决于我们在请求中指定的`recognitionLevel`的值：`.fast`和`.accurate`。让我们看看它们的区别：
- en: '`.accurate`. It doesn''t handle rotated text or different fonts as well as
    the `.accurate` method.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`.accurate`。它处理旋转文本或不同字体的效果不如`.accurate`方法。'
- en: '`.fast` but is more accurate (of course!). It works in the same way that our
    brain recognizes words. If you read the word "m0untain," your brain can extract
    "mountain" from it, and it knows that the 0 (zero) stands for an o. If you use
    `.fast`, which recognizes character by character, the 0 (zero) would still be
    a 0 (zero) in your results, because no context is taken into account.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`.fast`但更准确（当然！）它的工作方式与我们的大脑识别单词的方式相同。如果你读“m0untain”这个词，你的大脑可以从它中提取“mountain”，并且知道0（零）代表一个o。如果你使用`.fast`，它按字符识别，0（零）在你的结果中仍然是0（零），因为没有任何上下文被考虑。'
- en: In both cases, after the initial recognition phase is finished, results are
    passed into a traditional natural language processor for language processing,
    and the outcome of that is the results (observations). This whole process happens
    exclusively on the device.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在两种情况下，在初始识别阶段完成后，结果都会传递到一个传统的自然语言处理器进行语言处理，其结果是观察结果。整个过程仅在设备上发生。
- en: 'So, when should anyone use `.fast`, you might wonder. Well, there are scenarios
    in which it is more convenient than `.accurate`:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，什么时候应该使用`.fast`呢？你可能想知道。嗯，有一些场景中它比`.accurate`更方便：
- en: To read codes or barcodes quickly
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为了快速读取代码或条形码
- en: When user interactivity is a crucial aspect, so you want a fast response from
    the text detection
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当用户交互是一个关键方面，你希望从文本检测中得到快速响应时
- en: 'To demonstrate the differences between the recognition levels, let''s analyze
    the same image using different techniques. You will also learn some useful tricks
    that you can apply to your projects. Follow the steps given here:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 为了展示识别级别的差异，让我们使用不同的技术分析相同的图像。你还将学习一些可以应用到你的项目中的有用技巧。按照这里给出的步骤进行：
- en: Go ahead and open the playground named `RecognitionPerformance_start.playground`.
    The code is roughly the same as what we tried in the previous section.
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 请打开名为`RecognitionPerformance_start.playground`的游乐场。代码与我们之前章节尝试的代码大致相同。
- en: 'The only difference is that the image that we are using now contains a 4-digit
    number that represents the serial number of the book:'
  id: totrans-48
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在我们使用的图像中包含一个4位数，代表书籍的序列号：
- en: '![Figure 15.02 – Book cover with a serial number (1015) below the author names'
  id: totrans-49
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图15.02 – 作者名字下方带有序列号（1015）的书籍封面](img/Figure_15.02_B14717.jpg)'
- en: '](img/Figure_15.02_B14717.jpg)'
  id: totrans-50
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![img/Figure_15.02_B14717.jpg](img/Figure_15.02_B14717.jpg)'
- en: Figure 15.02 – Book cover with a serial number (1015) below the author names
  id: totrans-51
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图15.02 – 作者名字下方的带有序列号（1015）的书籍封面
- en: If you pay close attention to the number font, you will see that it might be
    tricky for a computer to tell whether some digits are numbers or letters. This
    has been done on purpose. In this example, we are going to test the capabilities
    of Vision.
  id: totrans-52
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果你仔细观察数字字体，你会发现对于计算机来说，判断某些数字是数字还是字母可能有些棘手。这是故意为之的。在这个例子中，我们将测试Vision的能力。
- en: 'Go ahead and execute the playground code. The console output should look like
    this:'
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 继续执行playground代码。控制台输出应该如下所示：
- en: '[PRE4]'
  id: totrans-54
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'We have successfully retrieved the serial number of the book: `1015`. The code
    is also taking a measure of how long it takes to finish the text-recognition process.
    In our case, it was **1.93 seconds** (this can differ from computer to computer
    and also between executions). Can we do better than that? Let''s try out some
    techniques that will help us to improve this processing time while keeping the
    same accuracy. We are going to start with the **region of interest**.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经成功检索到书的序列号：`1015`。代码也在测量完成文本识别过程所需的时间。在我们的案例中，它花费了**1.93秒**（这可能会因计算机而异，也可能因执行而异）。我们能做得更好吗？让我们尝试一些可以帮助我们提高处理时间同时保持相同准确性的技术。我们将从**感兴趣区域**开始。
- en: Region of interest
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 感兴趣区域
- en: Sometimes, when we are analyzing an image with Vision, we don't need to process
    the whole image. For example, if we are processing a specific type of form where
    we know in advance that the first name always goes at the top of the document,
    we may want to just process that area. Processing the whole form would only waste
    time and resources if we just need a specific area.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 有时候，当我们使用Vision分析图像时，我们不需要处理整个图像。例如，如果我们处理的是一种特定的表格，我们事先知道名字总是位于文档的顶部，我们可能只想处理那个区域。如果我们只需要特定区域，处理整个表格只会浪费时间和资源。
- en: Let's assume that in the previous example (the book cover), the serial number
    that we want to extract is always in the top-left area. How can we speed up the
    1.93-seconds processing time? We can do so by defining a region of interest. Defining
    a region of interest will tell Vision to only process that area and avoid the
    rest of the image. That will result in a faster processing time.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们假设在之前的例子（书籍封面）中，我们想要提取的序列号总是位于左上角。我们如何加快1.93秒的处理时间？我们可以通过定义感兴趣区域来实现。定义感兴趣区域将告诉Vision只处理该区域，避免处理图像的其余部分。这将导致更快的处理时间。
- en: '`regionOfInterest` is a `CGRect` property of `VNRequest`:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '`regionOfInterest`是`VNRequest`的`CGRect`属性：'
- en: It defines a rectangular area in which the request will be performed.
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它定义了一个矩形区域，请求将在该区域内执行。
- en: The rectangle is normalized to the dimensions of the image, meaning that the
    width and height of the region of interest go from 0 to 1.
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 矩形被归一化到图像的尺寸，这意味着感兴趣区域的宽度和高度从0到1。
- en: The origin of the rectangle is in the bottom-left corner of the image, which
    is (0,0). The top-right corner will be (1,1).
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 矩形的起点在图像的左下角，即(0,0)。右上角将是(1,1)。
- en: 'The default value is `{{0,0},{1,1}}`, which covers everything from the bottom-left
    corner (0,0) to the top-right corner, with width 1 and height 1: the whole image.'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 默认值是`{{0,0},{1,1}}`，它覆盖了从左下角（0,0）到右上角（1,1），宽度为1，高度为1：整个图像。
- en: 'In the following figure, you can see the region of interest that we need to
    define to capture the serial number (**1015**):'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下图中，你可以看到我们需要定义的感兴趣区域来捕获序列号（**1015**）：
- en: '![Figure 15.03 – Region of interest'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '![图15.03 – 感兴趣区域'
- en: '](img/Figure_15.03_B14717.jpg)'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](img/Figure_15.03_B14717.jpg)'
- en: Figure 15.03 – Region of interest
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 图15.03 – 感兴趣区域
- en: 'Let''s add that region to the code from the previous section:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们把那个区域添加到上一节中的代码：
- en: 'In the `ScanPerformance_start.playground` project, add the following code just
    after setting `recoginitionLevel` to `.accurate`:'
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`ScanPerformance_start.playground`项目中，在将`recognitionLevel`设置为`.accurate`之后添加以下代码：
- en: '[PRE5]'
  id: totrans-70
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Now launch the playground and check the result in the console:'
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在启动playground并在控制台中检查结果：
- en: '[PRE6]'
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'There are a couple of differences when comparing these results to the previous
    ones:'
  id: totrans-73
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 与之前的结果相比，有几个不同之处：
- en: We are no longer extracting that much text. Now that we are defining a region
    of interest, we just extract the words/digits that are contained in that area.
  id: totrans-74
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们不再提取那么多文本。现在我们定义了感兴趣区域，我们只提取该区域包含的单词/数字。
- en: We reduced the processing time from 1.93 seconds to 1.23 seconds. That is 36%
    faster.
  id: totrans-75
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们将处理时间从1.93秒减少到1.23秒。这提高了36%。
- en: 'Let''s now try to reduce the region of interest to catch just the serial number.
    Modify the region to the following:'
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们尝试将感兴趣区域缩小，仅捕获序列号。将区域修改为以下：
- en: '[PRE7]'
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Launch the playground. Now the console output is as follows:'
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 启动游乐场。现在控制台输出如下：
- en: '[PRE8]'
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Modify this line to use `.fast`:'
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将此行修改为使用`.fast`：
- en: '[PRE9]'
  id: totrans-81
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Save and execute. Check the console output:'
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 保存并执行。检查控制台输出：
- en: '[PRE10]'
  id: totrans-83
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: You can see how this time, the processing time has been made shorter again,
    but the result is not accurate at all. Instead of detecting `1015`, we have wrongly
    obtained `Iois`.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到这次，处理时间再次缩短，但结果完全不精确。我们检测到的不是`1015`，而是错误地得到了`Iois`。
- en: 'However, there is a common way to fix this situation in scenarios where we
    have domain knowledge. In our case, we know that the processed characters should
    be numbers only. Therefore, we can adjust the output from Vision to improve the
    results and fix misclassifications. For example, see the following adjustments:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在具有领域知识的情况下，有一种常见的解决这种情况的方法。在我们的例子中，我们知道处理后的字符应该是数字。因此，我们可以调整从视觉输出的结果来改进结果并修复误分类。例如，查看以下调整：
- en: The character "I" can be "1."
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 字符“I”可以是“1。”
- en: The character "o" can be "0."
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 字符“o”可以是“0。”
- en: The character "s" can be "5."
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 字符“s”可以是“5。”
- en: 'Let''s implement this in the code:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在代码中实现这个功能：
- en: 'At the very end of the playground file, add the following method:'
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在游乐场文件的最后，添加以下方法：
- en: '[PRE11]'
  id: totrans-91
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: We are extending the `Character` class by adding a new method named `transformToDigit()`.
    This new method is going to help us to improve potential misclassifications. Note
    how in the method itself, we have a table of letter characters that relate to
    a similarly shaped number. What we are doing is just transforming those letters
    into the corresponding digits.
  id: totrans-92
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们通过添加一个名为`transformToDigit()`的新方法来扩展`Character`类。这个新方法将帮助我们改进潜在的误分类。注意在方法本身中，我们有一个与形状相似的字母字符表，这些字母与数字相关。我们所做的是将这些字母转换成相应的数字。
- en: 'Let''s use it now. Below the `print(recognizedStrings)` line, add the following
    code:'
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在让我们使用它。在`print(recognizedStrings)`行下方，添加以下代码：
- en: '[PRE12]'
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: We are getting the result of the Vision process; in our case, it was `"Iois"`,
    and for each character, we are applying to it our new `transformToDigit()` method.
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们正在获取视觉处理的结果；在我们的例子中，它是`"Iois"`，并且对于每个字符，我们对其应用我们新的`transformToDigit()`方法。
- en: 'Execute the code, and you will see the following result in the console:'
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行代码，你将在控制台看到以下结果：
- en: '[PRE13]'
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: That looks great! Note how the `"Iois"` result is now looking much better when
    transformed to `"1" "0" "1" "5"`. Also, note how the processing time didn't increase
    that much; this operation is relatively easy to compute.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来很棒！注意现在将`"Iois"`转换成`"1" "0" "1" "5"`后看起来好多了。同时，注意处理时间并没有增加太多；这个操作相对容易计算。
- en: Now let's summarize what we have done in this section and the improvements we
    made in each step. We started by processing a whole image and using the `.accurate`
    recognition level, and that took us 1.93 seconds. Then, we applied a region of
    interest to just process part of the image that we were interested in, reducing
    the processing time to 1.23 seconds. After that, we changed from `.accurate` to
    `.fast`. This move reduced the processing time to 0.59 seconds, but the results
    were incorrect. Finally, we implemented an easy algorithm to improve the results
    and make them as good as with the `.accurate` level. So, in the end, we got perfect
    results and a processing time of 0.59 seconds rather than 1.93!
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们总结一下本节我们做了什么，以及每一步的改进。我们首先处理了一张整个图像，并使用`.accurate`识别级别，这花费了我们1.93秒。然后，我们应用了感兴趣区域，只处理我们感兴趣的图像部分，将处理时间减少到1.23秒。之后，我们将`.accurate`改为`.fast`。这一改变将处理时间减少到0.59秒，但结果是不正确的。最后，我们实现了一个简单的算法来改进结果，使它们与`.accurate`级别一样好。所以，最终我们得到了完美的结果，处理时间仅为0.59秒，而不是1.93秒！
- en: In the next section, you will learn about one of the new features of iOS14,
    hand detection.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，你将了解iOS14的一个新功能，即手势检测。
- en: Recognizing hand landmarks in real time
  id: totrans-101
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实时识别手势地标
- en: One of the additions to Vision in iOS 14 is hand detection. This new feature
    to detect hands in images and video allows developers to find with great detail
    the positions of the wrist and the individual fingers in a video frame or photo.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: iOS 14中Vision的一个新增功能是手部检测。这个新功能可以检测图像和视频中的手部，允许开发者以很高的精度找到视频帧或照片中手腕和各个手指的位置。
- en: In this section, we are going to explain the basics behind hand detection, and
    we will demonstrate how it works with a sample project. Let's start with the hand
    landmarks that we will be able to recognize.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将解释手部检测背后的基础知识，并通过一个示例项目演示其工作原理。让我们从我们将能够识别的手部特征点开始。
- en: Understanding hand landmarks
  id: totrans-104
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解手部特征点
- en: 'There are 21 landmarks that we will be able to detect in a hand:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将能够在手中检测到21个特征点：
- en: 4 in the thumb
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 拇指4个点
- en: 4 in each finger (16 in total)
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个手指4个点（总共16个点）
- en: 1 in the wrist
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 腕部1个点
- en: 'As you can see, Vision differentiates between finger and thumb. In both the
    finger and thumb, there are 4 points of interest. The following figure shows how
    these landmarks are distributed:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，Vision可以区分手指和拇指。在手指和拇指上，都有4个感兴趣点。以下图示显示了这些特征点的分布情况：
- en: '![Figure 15.04 – Finger and thumb landmarks'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '![图15.04 – 手指和拇指特征点'
- en: '](img/Figure_15.04_B14717.jpg)'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_15.04_B14717.jpg)'
- en: Figure 15.04 – Finger and thumb landmarks
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 图15.04 – 手指和拇指特征点
- en: Note how there is also a landmark in the middle of the wrist.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，在手腕中间也有一个特征点。
- en: 'For the four fingers, we can access each of them individually using the following
    keys:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 对于四个手指，我们可以使用以下键单独访问它们：
- en: '`littleFinger`'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`小指`'
- en: '`middleFinger`'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`中指`'
- en: '`ringFinger`'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`无名指`'
- en: '`indexFinger`'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`indexFinger`'
- en: 'Inside each of them, we can access the four different landmarks:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 在每个手指内部，我们可以访问四个不同的特征点：
- en: '**TIP**'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**指尖**'
- en: '**DIP**'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**DIP**'
- en: '**PIP**'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**PIP**'
- en: '**MCP**'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**MCP**'
- en: Note how for the thumb, these names are slightly different (TIP, IP, PIP, and
    CMC). In the example code that we will build later in this section, we will demonstrate
    how to use these points and each of the fingers plus the thumb.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，对于拇指，这些名称略有不同（TIP、IP、PIP和CMC）。在本节稍后我们将构建的示例代码中，我们将演示如何使用这些点和每个手指以及拇指。
- en: Vision is capable of detecting more than just one hand at a time. We can specify
    the maximum amount of hands that we want to detect. This parameter will have an
    impact on the performance of our detection. Use `maximumHandCount` to set the
    limit.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: Vision能够同时检测不止一个手部。我们可以指定我们想要检测的最大手部数量。此参数将影响检测的性能。使用`maximumHandCount`设置限制。
- en: For performance and accuracy, it is also better if the hand is not near the
    edges of the frame, if the light conditions are good, and if the hands are perpendicular
    to the camera angle (so the whole hand is visible, not just the edge of it). Also,
    take into account that feet can be recognized as hands sometimes, so avoid mixing
    them.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 为了性能和准确性，如果手部不在帧的边缘附近，如果光线条件良好，以及如果手部与摄像头角度垂直（因此整个手部都可见，而不仅仅是边缘），则更好。此外，考虑到有时脚部可能被识别为手部，因此请避免混淆。
- en: That is enough theory; let's jump straight into a code example! We will build
    a demo app that will be able to detect hand landmarks using the front video camera
    of a phone and will display an overlay on the detected points.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 理论就到这里；让我们直接进入代码示例！我们将构建一个演示应用程序，该程序将能够使用手机的正面视频摄像头检测手部特征点，并在检测到的点上显示叠加层。
- en: Implementing hand detection
  id: totrans-128
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实现手部检测
- en: In this section, we are going to implement a demo app that will be able to detect
    hand landmarks using the front video camera of a phone.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将实现一个演示应用程序，该程序将能够使用手机的正面视频摄像头检测手部特征点。
- en: The code bundle of this project contains the initial project and also the final
    result. Go ahead and open the project named `HandDetection_start`.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 该项目的代码包包含初始项目和最终结果。请打开名为`HandDetection_start`的项目。
- en: 'The project contains two main files: A `UIView` instance named `CameraView.swift`
    and a UIViewController instance called `CameraViewController.swift`.'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 该项目包含两个主要文件：一个名为`CameraView.swift`的`UIView`实例和一个名为`CameraViewController.swift`的`UIViewController`实例。
- en: 'The view contains helper methods to draw points on coordinates. It will serve
    as an overlay to draw on top of the camera feed. Just know that the `showPoints(_
    points: [CGPoint], colour: UIColor)` method will allow us to draw an array of
    `CGPoint` structs into the overlay on top of the video camera feed.'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '视图包含辅助方法来在坐标上绘制点。它将作为覆盖层绘制在摄像头视频流之上。只需知道，`showPoints(_ points: [CGPoint], colour:
    UIColor)` 方法将允许我们在视频摄像头流的覆盖层上绘制一个 `CGPoint` 结构体的数组。'
- en: The view controller will be the centerpiece of the example and is where we are
    going to implement the relevant code to perform the hand detection. Go ahead and
    open the `CameraViewController.swift` file. Let's examine the code skeleton that
    we will fill out step by step.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 视图控制器将是示例的核心，我们将在这里实现执行手部检测的相关代码。请打开 `CameraViewController.swift` 文件。让我们检查我们将逐步填充的代码框架。
- en: 'At the top of the file, we are defining four properties:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 在文件顶部，我们定义了四个属性：
- en: '`handPoseRequest: VNDetectHumanHandPoseRequest`. We will apply this request
    at the top of the video stream, to detect hand landmarks in each frame. If we
    detect any, we will display some points in the overlay to show them.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`handPoseRequest: VNDetectHumanHandPoseRequest`。我们将在此视频流的顶部应用此请求，以检测每一帧中的手部关键点。如果我们检测到任何，我们将在覆盖层上显示一些点来显示它们。'
- en: '`videoDataOutputQueue`, `cameraView`, and `cameraFeedSession`.'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`videoDataOutputQueue`, `cameraView`, 和 `cameraFeedSession`。'
- en: With the `viewDidAppear` and `viewWillDisappear` methods, we are starting/creating
    and stopping `AVCaptureSession` for the camera.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `viewDidAppear` 和 `viewWillDisappear` 方法，我们正在启动/创建和停止摄像头的 `AVCaptureSession`。
- en: 'And finally, in the next four methods, we have four TODO comments, which we
    are going to implement one by one to create this app. Let''s summarize the TODO
    tasks that we are going to perform:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在接下来的四个方法中，我们有四个待办事项注释，我们将逐一实现以创建此应用程序。让我们总结一下我们将要执行的待办事项：
- en: '**TODO 1**: Detect one hand only.'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**待办事项 1**: 只检测一只手。'
- en: '**TODO 2**: Create a video session.'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**待办事项 2**: 创建视频会话。'
- en: '**TODO 3**: Perform hand detection on the video session.'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**待办事项 3**: 在视频会话中执行手部检测。'
- en: '**TODO 4**: Process and display detected points.'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**待办事项 4**: 处理并显示检测到的点。'
- en: We are going to implement these four tasks in the following subsections.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在以下小节中实现这四个任务。
- en: Detecting hands
  id: totrans-144
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 检测手部
- en: Vision can do more than detect one hand at a time. The more hands we ask it
    to detect, the more it will impact performance. In our example, we only want to
    detect one hand. By setting `maximumHandCount` to `1` on the request, we will
    improve performance.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 视觉不仅可以一次检测一只手。我们要求它检测的手越多，性能影响就越大。在我们的示例中，我们只想检测一只手。通过在请求中将 `maximumHandCount`
    设置为 `1`，我们将提高性能。
- en: 'Let''s start by adding this code below `// TODO 1`:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从在 `// 待办事项 1` 下方添加以下代码开始：
- en: '[PRE14]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Now, let's create a video session to capture the video stream from the front
    video camera of the device.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们创建一个视频会话来捕获设备前置视频摄像头的视频流。
- en: Creating a video session
  id: totrans-149
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 创建视频会话
- en: 'For the second task, we are going to fill out the code inside the `setupAVSession()`
    method. Go ahead and paste the following code inside the method:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 对于第二个任务，我们将填充 `setupAVSession()` 方法内的代码。请将以下代码粘贴到方法中：
- en: '[PRE15]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'First, we are creating a `videoDevice: AVCaptureDevice` instance by querying
    for the video front camera (if it exists!) with this:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '首先，我们通过以下方式创建 `videoDevice: AVCaptureDevice` 实例，查询视频前置摄像头（如果存在！）：'
- en: '[PRE16]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Then, we use that `videoDevice` to generate a `deviceInput: AVCaptureDeviceInput`
    instance, which will be the video device used for the stream, with the following
    code:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '然后，我们使用那个 `videoDevice` 生成一个 `deviceInput: AVCaptureDeviceInput` 实例，它将是用于流的视频设备，以下代码所示：'
- en: '[PRE17]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Now add this code:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 现在添加以下代码：
- en: '[PRE18]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'After creating the `videoDevice` instance, we are creating a new `session:
    AVCaptureSession` instance. With the session created, we assign `videoDevice`
    as the input and create and configure an output to handle the video stream. We
    assign the class itself as `dataOutput AVCaptureVideoDataOutputSampleBufferDelegate`
    by calling this:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '在创建 `videoDevice` 实例后，我们创建一个新的 `session: AVCaptureSession` 实例。会话创建后，我们将 `videoDevice`
    作为输入，创建并配置一个输出以处理视频流。我们通过调用以下代码将类本身分配为 `dataOutput AVCaptureVideoDataOutputSampleBufferDelegate`：'
- en: '[PRE19]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: This means that when the front video camera captures new frames, our session
    will handle them and send them to our delegate method, which we are going to implement
    in the next step (TODO 3).
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着当前置视频摄像头捕获新的帧时，我们的会话将处理它们并将它们发送到我们的代理方法，我们将在下一步（待办事项 3）中实现。
- en: Performing hand detection in the video session
  id: totrans-161
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在视频会话中执行手部检测
- en: 'Now that we have set up and configured a video session, it is time to handle
    every frame as it comes and tries to detect any hands and their landmarks! We
    need to implement the `captureOutput(_ output: AVCaptureOutput, didOutput sampleBuffer:
    CMSampleBuffer, from connection: AVCaptureConnection)` method.'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '现在我们已经设置并配置了视频会话，是时候处理每一帧了，并尝试检测任何手部和它们的地标！我们需要实现`captureOutput(_ output: AVCaptureOutput,
    didOutput sampleBuffer: CMSampleBuffer, from connection: AVCaptureConnection)`方法。'
- en: 'Under the `// TODO 3: Perform hand detection on the video session` line, add
    this code:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '在`// TODO 3: Perform hand detection on the video session`行下，添加以下代码：'
- en: '[PRE20]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: We want to detect the tip of the four fingers (index, ring, middle, and little)
    and the thumb. So, we are creating five variables of type `CGPoint` to store their
    coordinates, if they are found.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 我们想要检测四个手指（食指、中指、无名指和小指）以及大拇指的指尖。因此，我们创建了五个类型为`CGPoint`的变量来存储它们的坐标，如果找到了的话。
- en: 'Just after these new lines, add the following code:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些新行之后，添加以下代码：
- en: '[PRE21]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: With this code, we are asking Vision to execute `handPoseRequest` over `sampleBuffer`
    (the video stream). Then, we guard (using `guard`) against the case in which we
    don't detect any observations (so that if there is no hand in the video frame,
    we just stop at this point).
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这段代码，我们要求Vision在`sampleBuffer`（视频流）上执行`handPoseRequest`。然后，我们使用`guard`（使用`guard`）来防止没有检测到观察结果的情况（这样如果视频帧中没有手，我们就会在这里停止）。
- en: 'But if the guard doesn''t trigger, it means that we have some hand landmarks
    and we need to process them. Add the following code just after the `// Get observation
    points` line:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 但是如果`guard`没有触发，这意味着我们有一些手部地标需要处理。在`// Get observation points`行之后添加以下代码：
- en: '[PRE22]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Now we are extracting from the observation any instances of `recognizedPoints()`
    that are related to the thumb and the four fingers. Note that we use `try` to
    do this operation because a result is not guaranteed. With the extracted recognized
    points, we later unwrap the TIP point of each finger and thumb with the `guard`
    statement.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们正在从观察结果中提取与拇指和四个手指相关的任何`recognizedPoints()`实例。请注意，我们使用`try`来执行此操作，因为结果并不保证。使用提取出的识别点，我们稍后使用`guard`语句解开每个手指和大拇指的指尖。
- en: At this point, we should have five variables with the coordinates of the TIP
    point of each finger plus the thumb.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个阶段，我们应该有五个变量，分别存储每个手指的指尖坐标以及大拇指的坐标。
- en: 'Although we already have the five coordinates that we are looking for, we still
    need to perform an extra step. Vision coordinates are different from `AVFoundation`
    ones. Let''s transform them; add the following code just after the last `guard`
    statement:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们已经有了我们正在寻找的五个坐标，但我们仍然需要执行一个额外的步骤。Vision坐标与`AVFoundation`坐标不同。让我们转换它们；在最后一个`guard`语句之后添加以下代码：
- en: '[PRE23]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: As you can see, the `x` coordinate is the same in both systems, but the `y`
    coordinate is different. In Vision, the bottom-left corner is the (0,0). So, we
    just need to subtract the `y` coordinate of the Vision point to 1 to get a result
    on the `AVFoundation` system.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，两个系统中的`x`坐标是相同的，但`y`坐标不同。在Vision中，左下角是(0,0)。因此，我们只需要将Vision点的`y`坐标减去1，就可以得到`AVFoundation`系统上的结果。
- en: Great! At this point, we have the hand landmarks detection system up and running,
    with a result in the form of `AVFoundation` CGPoint coordinates. The last step
    is to draw those points!
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 太棒了！在这个阶段，我们已经有了手部地标检测系统，并以`AVFoundation`的`CGPoint`坐标形式得到结果。最后一步是绘制这些点！
- en: 'Add the following code after the `catch` block (outside of it), just at the
    end of the `func captureOutput(…)` method:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 在`catch`块（它外面）之后添加以下代码，正好在`func captureOutput(…)`方法的末尾：
- en: '[PRE24]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: We are calling the `processPoints(…)` method inside the main thread because
    we want it to work on the UI, so we ensure that everything works perfectly by
    dispatching this work into the correct thread. Let's implement the `processPoints(…)`
    method next.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在主线程中调用`processPoints(…)`方法，因为我们希望它在UI上工作，所以我们通过将这项工作调度到正确的线程来确保一切工作完美。接下来，让我们实现`processPoints(…)`方法。
- en: Processing and displaying detected points
  id: totrans-180
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 处理和显示检测到的点
- en: 'After the hand landmarks have been detected inside the `captureOutput(…)` method,
    we now want to draw them into the camera overlay. Replace the empty implementation
    of `processPoints(…)` with this one:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 在`captureOutput(…)`方法内部检测到手部地标后，我们现在想要将它们绘制到相机叠加层中。用以下代码替换`processPoints(…)`的空实现：
- en: '[PRE25]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Remember how we are using `CGPoints` converted to `AVFoundation` coordinates?
    Now we want to convert those points into the `UIKit` preview layer. We are performing
    `map` over them, and finally, we are calling the `cameraView` helper method `showPoints`
    to display them.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 记得我们是如何使用`CGPoints`转换为`AVFoundation`坐标的吗？现在我们想要将这些点转换为`UIKit`预览层。我们正在对它们执行`map`操作，最后，我们调用`cameraView`辅助方法`showPoints`来显示它们。
- en: 'Everything is now in place! It is time to build and run the application. You
    will see the selfie camera triggering, and if you point it at your hand, the tips
    of your fingers and thumb should be overlayed with red dots. Give it a try and
    you should get something like the following:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 一切现在都已就绪！是时候构建并运行应用程序了。你会看到自拍相机被触发，如果你将其对准你的手，你的手指和拇指的尖端应该会被红色圆点覆盖。试一试，你应该会得到以下类似的结果：
- en: '![Figure 15.05 – TIP detection'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: '![图15.05 – TIP检测'
- en: '](img/Figure_15.05_B14717.jpg)'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_15.05_B14717.jpg)'
- en: Figure 15.05 – TIP detection
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 图15.05 – TIP检测
- en: 'However, this approach still has some issues! Try this: let the app detect
    your hand, and then remove the hand from the camera''s view – the red dots are
    still on the overlay! They are not cleaned up when no hand is detected.'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这种方法仍然存在一些问题！试试这个：让应用程序检测你的手，然后从摄像机的视图中移除手部 – 红色圆点仍然在叠加层上！当没有检测到手时，它们没有被清理。
- en: 'This has an easy fix. The reason for it is that inside the `captureOutput(…)`
    method, we are not always executing the `processPoints(…)` method. There are times
    (the `guard` statements) where we return without calling it. The solution is to
    wrap the `processPoints(…)` block into a `defer`, moving it to the beginning of
    the code, just after we define the five properties to store the coordinates of
    each tip. It should look like this:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 这有一个简单的解决方案。原因是，在`captureOutput(…)`方法内部，我们并不总是执行`processPoints(…)`方法。有时（`guard`语句）我们返回而不调用它。解决方案是将`processPoints(…)`块封装到`defer`中，将其移动到代码的开头，就在我们定义存储每个尖端坐标的五个属性之后。它应该看起来像这样：
- en: '[PRE26]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: The highlighted code is the part that we have wrapped into a `defer` (so it
    will always execute before returning the method). Execute the app again, and you
    will notice that when there is no hand on the screen, the red dots will not be
    there either! We are calling `processPoints` with empty values, so nothing is
    being drawn. With this last step, we have a working example of hand landmark detection
    up and running! Congratulations!
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 突出的代码是我们将其封装到`defer`中的部分（因此它将在返回方法之前始终执行）。再次执行应用程序，你会注意到当屏幕上没有手时，红色圆点也不会出现！我们正在使用空值调用`processPoints`，因此没有东西被绘制。通过这一步，我们就有了一个正在运行的手部关键点检测示例！恭喜！
- en: Body pose detection
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 身体姿态检测
- en: Vision also provides body pose detection on iOS 14\. Body pose detection is
    quite similar to hand detection, so we are not going to give a step-by-step demo
    of it. But the code bundle of this book contains an example app similar to the
    one in this section but for body pose detection. You can check out the project
    named `BodyPoseDetection_completed` and see the little differences that it has
    from the hand detection project.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: Vision还为iOS 14提供了身体姿态检测。身体姿态检测与手部检测非常相似，所以我们不会对其进行逐步演示。但本书的代码包中包含了一个类似本节的应用程序示例，但用于身体姿态检测。你可以查看名为`BodyPoseDetection_completed`的项目，并查看它与手部检测项目之间的细微差别。
- en: In this section, we have learned about the new Vision methods to detect hand
    landmarks and how to detect hand landmarks using the video stream of a phone as
    input (instead of just detecting a hand in a static image). We also provided a
    similar demo that can be used for body pose detection. Let's jump into the summary
    to finish the chapter.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们学习了新的Vision方法来检测手部关键点，以及如何使用手机的视频流作为输入来检测手部关键点（而不仅仅是检测静态图像中的手部）。我们还提供了一个类似的演示，可用于身体姿态检测。让我们跳到总结，完成本章。
- en: Summary
  id: totrans-195
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: 'We started this chapter by learning about the basic building blocks of every
    Vision feature: how to use a `VNRequest` instance, its corresponding `VNRequestHandler`
    instances, and the resulting `VNObservation` instances.'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从学习每个Vision功能的基石开始本章：如何使用`VNRequest`实例、其对应的`VNRequestHandler`实例以及产生的`VNObservation`实例。
- en: After learning the basics, we applied them to text recognition. We compared
    different recognition levels by using `.fast` and `.accurate`. We also learned
    about regions of interest and how they can affect the performance of Vision requests.
    Finally, we improved our results in text recognition by applying domain knowledge,
    fixing potential errors and misreads from Vision.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 在学习基础知识之后，我们将它们应用于文本识别。我们通过使用`.fast`和`.accurate`比较了不同的识别级别。我们还了解了感兴趣区域及其如何影响视觉请求的性能。最后，通过应用领域知识、修复潜在的视觉错误和误读，我们在文本识别方面提高了我们的结果。
- en: Finally, we learned about the new hand landmarks recognition capability. But
    this time, we also learned how to apply Vision requests to real-time video streams.
    We were able to detect hand landmarks in a video feed from a device's front camera
    and display an overlay to show the results. This chapter also provided a similar
    example that could be applied to body pose recognition.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们学习了新的手部地标识别功能。但这次，我们还学习了如何将视觉请求应用于实时视频流。我们能够在来自设备前摄像头的视频流中检测到手部地标，并显示叠加层以显示结果。本章还提供了一个类似的示例，该示例可以应用于身体姿态识别。
- en: 'In the next chapter, we will learn about a brand new feature of iOS 14: widgets!'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将学习iOS 14的一个全新功能：小部件！
