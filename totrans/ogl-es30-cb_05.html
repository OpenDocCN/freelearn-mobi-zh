<html><head></head><body><div><div><div><div><h1 class="title"><a id="ch05"/>Chapter 5. Light and Materials</h1></div></div></div><p>In this chapter, we will cover the following recipes:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Implementing the per-vertex ambient light component</li><li class="listitem" style="list-style-type: disc">Implementing the per-vertex diffuse light component</li><li class="listitem" style="list-style-type: disc">Implementing the per-vertex specular light component</li><li class="listitem" style="list-style-type: disc">Optimizing the specular light with the halfway vector</li><li class="listitem" style="list-style-type: disc">Gouraud shading – the per-vertex shading technique</li><li class="listitem" style="list-style-type: disc">Phong shading – the per-fragment shading technique</li><li class="listitem" style="list-style-type: disc">Implementing directional and point light</li><li class="listitem" style="list-style-type: disc">Implementing multiple lights in a scene</li><li class="listitem" style="list-style-type: disc">Implementing two-side shading</li></ul></div><div><div><div><div><h1 class="title"><a id="ch05lvl1sec41"/>Introduction</h1></div></div></div><p>This chapter will introduce the <a id="id360" class="indexterm"/>concepts of light and material in 3D graphics. We will understand the concept of light from the aspect of physics and its dual nature. We will discuss the different types of light components, such as ambient, diffuse and specular, with their <a id="id361" class="indexterm"/>implementation techniques. Later in this chapter, we will cover some important common illumination techniques (such as Phong shading and Gouraud shading). This will help us in implementing realistic-looking lighting models in computer graphics. In addition, you will learn the difference between directional and positional light and see how optimization can be achieved in the specular lighting by using the halfway vector technique. At the end of this chapter, we will demonstrate how to set up multiple lights in a scene and render objects with two-sided shading.</p><p>Light is an electromagnetic radiation; it exists with an enormous range of frequencies or wavelengths. Human eyes can only see a portion of this wavelength of the electromagnetic spectrum and this range of portion is called visible light. Our eye receives these visible wavelengths as colors and the visible light spectrum varies from 400 nm (violet) to 700 nm (red):</p><div><img src="img/5527OT_04_30.jpg" alt="Introduction"/></div><p>Light possesses important properties (such as intensity, direction, color, and location). In 3D graphics, we use these important properties of light to simulate various light models. In this chapter, we will use the OpenGL ES programmable pipeline to program various light models using shaders. This chapter will be helpful in providing an insight into all of the mathematics and physics required for lighting purposes.</p><p>Back in 1600s, colors were believed to be a mixture of light and darkness. In 1672, Sir Issac Newton published a series of experiments and provided us with the modern understanding of light. He successfully refracted that white light consists of a mixture of seven different colors: red, orange, yellow, green, blue, indigo, and violet. He also proposed that light is composed of particles or corpuscles.</p><p>Much later, in 1802, Thomas <a id="id362" class="indexterm"/>Young proved that light behaves as a wave through one of his experiments. He related colors to wavelength and managed to calculate the approximate wavelength of the seven colors discovered by Sir Isaac Newton.</p><p>The final proposition of light was given by Albert Einstein in March, 1905. That year, he published his quantum theory of light, where he proposed light as particles and named these particles <strong>photons</strong>. In June, 1905, he completed his theory of special relativity, which <a id="id363" class="indexterm"/>added a twist to his earlier proposal where light was believed to be a particle. The special theory of relativity sees light as a wave. Such contradiction gave enough proof to Einstein to propose the dual nature of light. According to him, light behaves both as a particle and a wave:</p><div><img src="img/5527OT_04_31.jpg" alt="Introduction"/></div><p>Light has a dual nature; it can behave as a particle and wave at the same time. Let's take a look in more detail:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><strong>Light as a particle</strong>: Light <a id="id364" class="indexterm"/>behaves as particles. These particles are small packets of energy that are not same as the small physical particles of atoms. These packets of energy have a constant velocity and no mass, which exhibit reflection properties that are similar to the billiard balls used in <a id="id365" class="indexterm"/>a pool game. When particles hit each other, they propagate in the direction of the force and are reflected as a result of obstacles. When photon particles hit obstacles, they lose energy in the form of absorption. As a result of continuous reflection, these particles strike and diminish. As a result of collision, the obstacle from these particles gains energy and preserves the law of conservation of energy.</li><li class="listitem" style="list-style-type: disc"><strong>Light as waves</strong>: Light behaves as waves. These are electromagnetic waves with electric and magnetic properties. The electromagnetic waves do not need any medium to travel through space because they are capable of traveling through <a id="id366" class="indexterm"/>vacuum. Each wave looks like a sine wave. The intensity of the wave is measured with amplitude, as shown in the preceding <a id="id367" class="indexterm"/>figure. The length of one complete sine wave is called as <strong>wavelength</strong>. The greater the wavelength, more visible is the color. Treating light as waves in 3D computer graphics opens up many possibilities, which one <a id="id368" class="indexterm"/>cannot achieve with the particle nature of light. For example, the particle exhibits propagation as rays; it cannot simulate diffraction and interference which is an important property of waves.</li></ul></div><p>In a computer graphic simulation, the wave nature of light is represented by wave fronts stored as 2D arrays of complex numbers. The study of light in computer graphics in itself is a vast subject; covering wave-based illuminations is beyond the scope of this chapter. This chapter will help in modeling particle-based local light illumination modeling techniques.</p><p>Light is composed of three <a id="id369" class="indexterm"/>types of components: ambient (<strong>A</strong>), diffuse (<strong>D</strong>), and specular (<strong>S</strong>). They are explained as follows:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><strong>Ambient (A)</strong>: This light component comes from all directions equally and is scattered in all the <a id="id370" class="indexterm"/>directions equally by the objects on which it falls; this makes the objects on the surface appear with constant light intensity.</li><li class="listitem" style="list-style-type: disc"><strong>Diffuse (D)</strong>: This light component comes from a particular direction from the light source. It hits the surface of an object with variable intensity, which depends on the <a id="id371" class="indexterm"/>Lambert law of illumination. In other words, the intensity depends on the direction of light appearing on the face of the object and the direction of object face point to.</li><li class="listitem" style="list-style-type: disc"><strong>Specular (S)</strong>: This light component also comes from a particular direction and reflects the most <a id="id372" class="indexterm"/>in the direction of the camera's view or the observer's eye. It gives an effect of shininess on the model's surface:<div><img src="img/5527OT_04_32.jpg" alt="Introduction"/></div></li></ul></div><p>In computer graphics, light and material are both mathematically treated as colors. The color associated with an object is called material and the color associated with illumination is called light. The color intensity of light and material are specified with RGB (red, blue, green) components. Objects are visible because they reflect the light that falls up on them. For example, when sunlight falls on a green material color ball, the green material absorbs all other wavelengths and reflects the green portion of the light spectrum. As a result, it appears green to the viewer. Mathematically, the reflected or resultant color is the product of light and material color intensities:</p><div><pre class="programlisting"><em>Reflected color                   =           Light intensity      *       Material color</em>
<em>[R1*R2, G1*G2, B1*B2]                         [R1, G1, B1]                 [R2, G2, B2]</em></pre></div><div><img src="img/5527OT_04_33.jpg" alt="Introduction"/></div><p>In modern computer graphics, there are two ways in which light shading equations can be calculated: per-vertex and per-fragment. They are explained as follows:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><strong>Per-vertex light shading</strong>: In this type of shading, the mathematical equations to <a id="id373" class="indexterm"/>calculate light shading colors are formulated in the vertex shader. Each vertex color is calculated within the vertex shader and then passed on to the fragment shader. These vertex colors are then interpolated to the geometry faces to result each fragment or pixel color. As the colors are calculated in the vertex shader, it's called per-vertex shading.</li><li class="listitem" style="list-style-type: disc"><strong>Per-fragment light shading</strong>: This calculates light colors within the fragment shader for <a id="id374" class="indexterm"/>each fragment. The quality of per-fragment shading is considerably better than the vertex shader. The performance of per-fragment shading is slower than per-vertex shading. This is because processing fewer vertices, as compared to thousands of pixels, is quicker. In today's modern graphics, processors are capable of performing several parallel operations at lightning speed; therefore, it may not be very expensive for general purpose application requirements.<div><div><h3 class="title"><a id="note33"/>Note</h3><p>One disadvantage of per-vertex light shading is that it may not be helpful for specular light to generate shading as expected because fragment colors are calculated at each vertex and shared among faces; therefore, instead of generating a smooth oval shining surface, it will generate a flat shining surface.</p></div></div></li></ul></div></div></div>
<div><div><div><div><h1 class="title"><a id="ch05lvl1sec42"/>Implementing the per-vertex ambient light component</h1></div></div></div><p>The ambient <a id="id375" class="indexterm"/>light illuminates the object's surface equally in all directions on which it's applied. All faces receive an equal amount of light; therefore, no change in color can be observed on the complete object. Ambient is basically a mixture of two components: the color intensity of light and material.</p><div><div><h3 class="title"><a id="note34"/>Note</h3><p>Mathematically, this is the product ambient light (L<sub>a</sub>) and ambient material (K<sub>a</sub>).</p><p><em>I<sub>a</sub> = L<sub>a</sub>K<sub>a</sub></em></p></div></div><p>An ambient light plays a vital role in Phong and Gouraud shadings; the diffuse and specular color components of these shadings are computed by using the direction of the light that falls on the object. Therefore, an object may receive less or no light on its side or back faces depending on the direction of light on the object. In such cases, the faces may appear invisible because of the black light that is generated; choosing the correct ambient light and material color will help in making these darkened faces visible.</p><div><div><div><div><h2 class="title"><a id="ch05lvl2sec126"/>Getting ready</h2></div></div></div><p>This chapter will make use of the Wavefront 3D mesh models that we implemented in <a class="link" href="ch04.html" title="Chapter 4. Working with Meshes">Chapter 4</a>, <em>Working with Meshes</em>. We will reuse the ObjLoader recipe from the same chapter to implement new recipes in this chapter.</p></div><div><div><div><div><h2 class="title"><a id="ch05lvl2sec127"/>How to do it...</h2></div></div></div><p>The step-by-step implementation of ambient light is as follows:</p><div><ol class="orderedlist arabic"><li class="listitem">Reuse the ObjLoader recipe from the previous chapter and create a new vertex shader file called <code class="literal">AmbientVertex.glsl</code> and add the following code:<div><pre class="programlisting">// Geometry vertex position
layout(location=0) in vec4 VertexPosition;
uniform mat4 ModelViewProjectionMatrix;  

// Ambient Light and Material information
uniform vec3 MaterialAmbient, LightAmbient;

// Shared calculated ambient from vertex shader
out vec4 FinalColor;
void main(){
   // Calculate the ambient intensity 
   vec3 ambient = MaterialAmbient  * LightAmbient;
   FinalColor   = vec4(ambient, 1.0);
   gl_Position  = ModelViewProjectionMatrix*VertexPosition;
}</pre></div></li><li class="listitem">Similarly, create the <code class="literal">AmbientFragment.glsl</code> fragment shader file as:<div><pre class="programlisting">precision mediump float;
in vec4 FinalColor;
layout(location = 0) out vec4 outColor;
void main() {
outColor = FinalColor; // Apply ambient intensity
}</pre></div></li><li class="listitem">In the <code class="literal">InitModel()</code> of the <code class="literal">ObjLoader</code> class, compile these shaders and set the uniform <a id="id376" class="indexterm"/>variable parameters for the ambient light and material:<div><pre class="programlisting">void ObjLoader::InitModel(){
  // Compile AmbientVertex and AmbientFragment shader.
  Many line skipped here . . . . . 
  // Use the shader program
  glUseProgram( program-&gt;ProgramID ); 
  
  // Query uniforms for light and material 
  MaterialAmbient = GetUniform(program,("MaterialAmbient");
  LightAmbient    = GetUniform(program,"LightAmbient");
  
  // Set Red colored material 
  if (MaterialAmbient &gt;= 0)
  { Uniform3f(MaterialAmbient, 1.0f, 0.0f, 0.0f); }
  
  // Set white light 
  if (LightAmbient &gt;= 0)
  { glUniform3f(LightAmbient, 1.0f, 1.0f, 1.0f); }
  
  // Get Model-View-Projection Matrix location
  MVP = GetUniform(program, "ModelViewProjectionMatrix");
}</pre></div></li><li class="listitem">The <code class="literal">Render()</code> function is the same as before; it uses the VAO to render the Wavefront <code class="literal">OBJ</code> model.</li></ol></div></div><div><div><div><div><h2 class="title"><a id="ch05lvl2sec128"/>How it works...</h2></div></div></div><p>When the <code class="literal">ObjLoader</code> class object is created, it initializes the necessary parameters in the constructor. The <code class="literal">InitModel</code> function compiles the shader program and sets any necessary uniform variables; the vertex shader contains two uniform variables called <code class="literal">MaterialAmbient</code> and <code class="literal">LightAmbient</code>. The former is used to define the ambient color property of the material property of the object and the latter is used to specify the color of the light.</p><p>These variables are sent to the vertex shader and the ambience color shade is calculated as the product of these two variables; the result is stored in a new output variable called <code class="literal">FinalColor</code>. This <a id="id377" class="indexterm"/>variable is sent to the fragment shader and applied as a final color to each fragment. The <code class="literal">gl_position</code> is the clip coordinate value, which is a product of the vertex position and <code class="literal">ModelViewProjectionMatrix</code>. The <code class="literal">ModelViewProjectionMatrix</code> uniform variable is a product of the projection, view, and model matrix.</p><div><img src="img/5527OT_04_34.jpg" alt="How it works..."/></div></div><div><div><div><div><h2 class="title"><a id="ch05lvl2sec129"/>See also</h2></div></div></div><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Refer to the <em>Rendering the wavefront OBJ mesh model</em> recipe in <a class="link" href="ch04.html" title="Chapter 4. Working with Meshes">Chapter 4</a>, <em>Working with Meshes</em></li><li class="listitem" style="list-style-type: disc">Refer to the <em>Managing VBO with Vertex Array Objects</em> recipe in <a class="link" href="ch03.html" title="Chapter 3. New Features of OpenGL ES 3.0">Chapter 3</a>, <em>New Features of OpenGL ES 3.0</em></li><li class="listitem" style="list-style-type: disc">Refer to the <em>Efficient rendering with Vertex Buffer Object</em> recipe in <a class="link" href="ch02.html" title="Chapter 2. OpenGL ES 3.0 Essentials">Chapter 2</a>, <em>OpenGL ES 3.0 Essentials</em></li></ul></div></div></div>
<div><div><div><div><h1 class="title"><a id="ch05lvl1sec43"/>Implementing the per-vertex diffuse light component</h1></div></div></div><p>Diffuse light <a id="id378" class="indexterm"/>comes from a particular direction and is reflected in various directions after collision with the surface of the object. In this section, we model this behavior by using the Phong Reflection Model, which was developed by Bui Tuong Phong in 1973. This model proposed an illumination shading technique that uses a normal surface and the direction of incident light. When light strikes on an object's surface, some of its parts are reflected and the rest is partially absorbed. Therefore, we can calculate either the intensity of light absorbed or reflected, if one of the components is given.</p><div><div><h3 class="title"><a id="note35"/>Note</h3><p>Total light intensity = reflection light intensity + absorption light intensity</p></div></div><p>When 100 percent light intensity falls on a plain surface and 50 percent of it is reflected, it's obvious that 50 percent of light intensity is being absorbed or lost in the surroundings. In 3D graphics, we are only concerned with the reflected light intensity because we see objects as a result of the reflection of light on them. The diffuse and specular components of light basically use the Phong reflection model as a result of light and surface interaction to model illumination techniques.</p><p>The Phong reflection model uses the Lambert cosine law to demonstrate the reflection. The Lambert cosine law uses the direction of incident light and the direction of surface geometry to calculate the intensity of light on the surface of geometry.</p><div><div><h3 class="title"><a id="note36"/>Note</h3><p>The Lambert cosine law states that the intensity of illumination on a diffuse surface is directly proportional to the cosine of the angle made by the surface normal vector and the direction of light.</p></div></div><div><img src="img/5527OT_04_49.jpg" alt="Implementing the per-vertex diffuse light component"/></div><div><div><div><div><h2 class="title"><a id="ch05lvl2sec130"/>Getting ready</h2></div></div></div><p>The general mathematical equation to calculate diffuse light is:</p><p><em>I<sub>d</sub> = L<sub>d</sub>K<sub>d</sub>(N.S)</em></p><p>The <em>L<sub>d</sub></em> and <em>K<sub>d</sub></em> are the diffuse components of the light and material; the (<em>N.S</em>) is the dot product used to calculate the cosine of the angle between the surface normal (<em>N</em>) and the incident light vector (<em>S</em>); both these vectors must be normalized first before calculating the dot product. A normalized vector is a vector whose length is unity; it's also called unit vector. For this recipe, we will reuse our first recipe, that is, ambient and make changes, as described in the next section.</p></div><div><div><div><div><h2 class="title"><a id="ch05lvl2sec131"/>How to do it...</h2></div></div></div><p>Use the following <a id="id379" class="indexterm"/>instructions to implement the diffuse light component:</p><div><ol class="orderedlist arabic"><li class="listitem">Reuse the last recipe for the per-vertex ambient light component (Ambient recipe) and create a new vertex shader file called <code class="literal">DiffuseVertex.glsl</code> in it, as shown in the following code:<div><pre class="programlisting">layout(location = 0) in vec4  VertexPosition;
layout(location = 1) in vec3  Normal;

uniform mat4 ModelViewProjectionMatrix;
uniform mat4 ModelViewMatrix;
uniform mat3 NormalMatrix;

// Diffuse Light and Material information
uniform vec3 MaterialDiffuse, LightDiffuse;

// Position of the light source
uniform vec3 LightPosition;

out vec4 FinalColor; // Output color to frag. shader

void main(){
   // Calculate normal, eye coord and light vector
   vec3 nNormal   = normalize ( NormalMatrix * Normal );
   vec3 eyeCoord  = vec3 (ModelViewMatrix* VertexPosition);
   vec3 nLight    = normalize( LightPosition - eyeCoord );
      
   // Calculate cosine Normal and light vector
   float cosAngle = max( 0.0, dot( nNormal, nLight ));
   vec3 diffuse = MaterialDiffuse  * LightDiffuse;
   FinalColor   = vec4(cosAngle * diffuse, 1);
   gl_Position = ModelViewProjectionMatrix*VertexPosition;
}</pre></div></li><li class="listitem">There is no change in the fragment shader; we can reuse it from the last recipe, except we will rename it as <code class="literal">DiffuseFragment.glsl</code>.</li><li class="listitem">In the <code class="literal">InitModel</code> after the shader are compiled successfully, set the configuration for diffuse light and material color and specify the position of light in world coordinates:<div><pre class="programlisting">  // ObjLoader::InitModel()
  . . . . 
  glUseProgram( program-&gt;ProgramID );
    
  // Query Light and Material uniform for ambient comp.
  MaterialDiffuse  = GetUniform(program, "MaterialDiffuse");
  LightDiffuse     = GetUniform(program, "LightDiffuse");
  LightPosition    = GetUniform(program, "LightPosition");
 
  // Set Red colored diffuse material uniform 
  glm::vec3 color = glm::vec3(1.0, 0.0, 0.0);
  if (MaterialDiffuse &gt;= 0)
      { glUniform3f(MaterialDiffuse,1.0, 0.0, 0.0); }
  
  // Set white diffuse light
  if (LightDiffuse &gt;= 0)
      { glUniform3f(LightDiffuse, 1.0f, 1.0f, 1.0f); }
  
  // Set light position
  glm::vec3 lightPosition(0.0, 0.0, 5.0);
  glUniform3fv(LightPosition,1,(float*)&amp;lightPosition);</pre></div></li><li class="listitem">In the <code class="literal">Render()</code> function, specify the normal matrix, model view matrix, and model <a id="id380" class="indexterm"/>view project matrix, along with the generic vertex attributes:<div><pre class="programlisting">   // ObjLoader::Render()   
   mat3 matrix=*(TransformObj-&gt;TransformGetModelViewMatrix());
   mat3 normalMat = glm::mat3( glm::vec3(matrix[0]),
                 vec3(matrix[1]), glm::vec3(matrix[2]) );
   glUniformMatrix3fv(NormalMatrix,1,GL_FALSE,
                     (float*)&amp;normalMat );
   glUniformMatrix4fv( MV,1,GL_FALSE,(float*)TransformObj-&gt;
                           TransformGetModelViewMatrix() );
   glUniformMatrix4fv( MVP,1,GL_FALSE,(float*)TransformObj-&gt;
   TransformGetModelViewProjectionMatrix());

   // Bind with Vertex Array Object and Render
   glBindVertexArray(OBJ_VAO_Id);    
   glDrawArrays(GL_TRIANGLES, 0, IndexCount );</pre></div></li></ol></div></div><div><div><div><div><h2 class="title"><a id="ch05lvl2sec132"/>How it works...</h2></div></div></div><p>The diffuse light vertex shader uses vertex position, vertex normal, and light position to calculate the light shading using the Phong reflection model; each <code class="literal">VertexPosition</code> is transformed into an eye coordinate by multiplying it with <code class="literal">ModelViewMatrix</code>. Similarly, vertex normal also needs to convert to an eye coordinate so that the transformation is also applied to normal as well. This is achieved by multiplying the <code class="literal">Normal</code> with the <code class="literal">NormalMatrix</code>.</p><div><div><h3 class="title"><a id="note37"/>Note</h3><p>Unlike vertex positions, which are transformed into eye coordinates using the <code class="literal">ModelView</code> matrix, vertex normal are transformed by using the <code class="literal">NormalMatrix</code>. The normal matrix is a submatrix of the model view matrix, but its specialty is that it preserves the normal of the geometry when an affine transformation is applied. <code class="literal">NormalMatrix</code> is the inverse transpose of the upper-left 3 x 3 matrix of the model view matrix.</p></div></div><p>The <code class="literal">nLight</code> light vector is calculated by subtracting eye coordinates of the <code class="literal">eyeCoord</code> vertex position from <code class="literal">LightPosition</code>; the <code class="literal">nLight</code> direction is calculated from the surface to the light <a id="id381" class="indexterm"/>source. The <code class="literal">nLight</code> and <code class="literal">nNormal</code> must be normalized before taking the dot product in order to find the cosine angle between them.</p><p>Light intensity is stored as the cosine angle between the surface normal vector and light vector. The color information of the material and light is specified in two uniform variables, namely, <code class="literal">MaterialDiffuse</code> and <code class="literal">LightDiffuse</code>; the product of these two variables is stored in the new variable called diffuse. The cosine angle is calculated as the dot product of the <code class="literal">nLight</code> and <code class="literal">nNormal</code> and stored in the <code class="literal">cosAngle</code> variable.</p><div><div><h3 class="title"><a id="note38"/>Note</h3><p>The intensity of light and material are basically used in terms of RGB components, which are always non-negative. Each component of R, G, and B is stored as a floating point number in the range between <code class="literal">0.0f</code> and <code class="literal">1.0f</code>. Light intensity is calculated as a cosine function, which can result in a range value between -1 and 1. We do not want negative light intensities because they do not make sense. Therefore, we should only consider light intensity within the range of 0.0 and 1.0; for this reason, the <code class="literal">max()</code> function is used in the resultant light intensity.</p></div></div><div><img src="img/5527OT_04_50.jpg" alt="How it works..."/></div><p>The diffuse color shade is calculated as the product of diffuse and <code class="literal">cosAngle</code> and stored in a new out variable <a id="id382" class="indexterm"/>called <code class="literal">FinalColor</code>. This variable is sent to the fragment shader and applied to each fragment. The last line of the vertex shader helps to calculate clipped coordinates by multiplying the vertex position with the model view projection matrix.</p></div><div><div><div><div><h2 class="title"><a id="ch05lvl2sec133"/>See also</h2></div></div></div><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><em>Implementing the per-vertex ambient light component</em></li></ul></div></div></div>
<div><div><div><div><h1 class="title"><a id="ch05lvl1sec44"/>Implementing the per-vertex specular light component</h1></div></div></div><p>Specular <a id="id383" class="indexterm"/>light is responsible for producing shininess on the surface of an object. Unlike diffuse light, which uses the incident ray and surface normal to find the intensity of light, specular light uses the reflected ray and the direction of the viewer to find the intensity of light.</p><div><div><div><div><h2 class="title"><a id="ch05lvl2sec134"/>Getting ready</h2></div></div></div><p>The following figure illustrates the scenario in which the viewer's position (camera) is brought in to the picture to demonstrate the mathematical calculations for specular light. The angle made by the incident ray of light with the normal of the surface is always equal to an angle of reflection with the same normal. Therefore, both <strong>S</strong> and <strong>R</strong> vectors create a <strong>θ</strong> angle with <strong>N</strong>. The <strong>S</strong> vector is represented by the opposite direction (<strong>-S</strong>); this is because we are interested in calculating the <strong>R</strong> reflection vector:</p><div><img src="img/5527OT_04_36.jpg" alt="Getting ready"/></div><p>This shininess is dependent on the angle made between the viewer and the reflected light; if the angle between the viewer's vector and the reflected vector is small, then the surface is shinier.</p><p>Mathematically, in the Phong reflection model, the specular component's reflection vector (<strong>R</strong>) is calculated as:</p><p><em>R = 2N (N.S) + (-S)</em></p><p>However, in the OpenGL ES shading language, we can use the <code class="literal">reflect()</code> function to calculate vector <code class="literal">R</code>:</p><div><pre class="programlisting">R = reflect( -S, N )</pre></div><p>The <em>α</em> angle between the <em>R</em> and <em>V</em> vectors can be calculated as the dot product between these two vectors. The <em>V</em> vector is in the eye coordinates; the vertices that are closer to the <em>R</em> vector in the same direction will cause shininess on the surface. Given <em>R</em> and <em>V</em>, the specular illumination can be calculated mathematically as:</p><p><em>I<sub>s</sub> = L<sub>s</sub>K<sub>s</sub>( R.V )<sub>G</sub></em></p><p>The <em>G</em> superscript in the preceding formula is used for glossy factor; its practical significance is to produce larger or smaller glossy spot on the surface of an object. Its value ranges between 1 and 200; the larger the value, smaller and brighter and vice versa.</p></div><div><div><div><div><h2 class="title"><a id="ch05lvl2sec135"/>How to do it...</h2></div></div></div><p>Reuse the <a id="id384" class="indexterm"/>previous implemented recipe for diffuse shading and make necessary changes in the shaders and program code, as described in the following steps:</p><div><ol class="orderedlist arabic"><li class="listitem">Create <code class="literal">SpecularVertex.glsl</code> and use the following instruction for the vertex shader; there is no change in the fragment shader. We can reuse the existing code:<div><pre class="programlisting">#version 300 es
layout(location = 0) in vec4  VertexPosition;
layout(location = 1) in vec3  Normal;

uniform mat4    ModelViewProjectionMatrix, ModelViewMatrix;
uniform mat3    NormalMatrix;

// Specular Light and Material information
uniform vec3 MaterialSpecular, LightSpecular,LightPosition;
   uniform float   ShininessFactor;
out vec4        FinalColor;

void main() 
{
      vec3 nNormal = normalize( NormalMatrix * Normal );
      vec3 eyeCoord= vec3( ModelViewMatrix* VertexPosition );
      vec3 nLight  = normalize( LightPosition - eyeCoord);
      vec3 V       = normalize( -eyeCoord);
      vec3 R       = reflect( -nLight, nNormal );
    
      float sIntensity=pow(max(0.0,dot(R,V)),ShininessFactor);
      vec3 specular= MaterialSpecular * LightSpecular;
      FinalColor   = vec4( sIntensity * specular, 1 );

      gl_Position  = ModelViewProjectionMatrix*VertexPosition;
}</pre></div></li><li class="listitem">In the <code class="literal">InitModel,</code> load and compile the specular shader and set the configuration <a id="id385" class="indexterm"/>for specular light and material color. Also, specify the position of light in world coordinates:<div><pre class="programlisting">    // ObjLoader::InitModel()
    . . . . .  
    
    if (MaterialSpecular &gt;= 0)
          { glUniform3f(MaterialSpecular, 1.0, 0.5, 0.5); }
    
    if (LightSpecular &gt;= 0)
          { glUniform3f(LightSpecular, 1.0, 1.0, 1.0); }

    if (ShininessFactor &gt;= 0)
          { glUniform1f(ShininessFactor, 40); }
    
    if (LightPosition &gt;= 0){
       glm::vec3 lightPosition(0.0, 0.0, 10.0);
          glUniform3fv(LightPosition,1,&amp;lightPosition);
    }</pre></div></li></ol></div></div><div><div><div><div><h2 class="title"><a id="ch05lvl2sec136"/>How it works...</h2></div></div></div><p>The specular light vertex shader calculates the <code class="literal">nNormal</code>, <code class="literal">eyeCoord</code>, and <code class="literal">nLight</code> in the same way we computed it in the previous recipe. Calculate the direction of the viewer or the (<em>V</em>) camera by normalizing eye coordinates and the <em>R</em> reflection vector with the help of the reflect() function. The dot product of <em>R</em> and <em>V</em> is clamped by the max function within the range 0.0 and 1.0. This result is used to calculate the power function with <code class="literal">ShininessFactor</code>, which is responsible for producing a glossy spot on the surface; the calculated result is stored in sIntensity. The <code class="literal">FinalColor</code> is calculated as a product of <code class="literal">sIntensity</code>, <code class="literal">MaterialSpecular</code>, and <code class="literal">LightSpecular</code>. This color information is sent to the <a id="id386" class="indexterm"/>fragment shader as an out variable and applied to respective fragments created by primitives formed by vertices:</p><div><img src="img/5527OT_04_37.jpg" alt="How it works..."/></div></div><div><div><div><div><h2 class="title"><a id="ch05lvl2sec137"/>See also</h2></div></div></div><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><em>Implementing the per-vertex ambient light component</em></li><li class="listitem" style="list-style-type: disc"><em>Implementing the per-vertex diffuse light component</em></li></ul></div></div></div>
<div><div><div><div><h1 class="title"><a id="ch05lvl1sec45"/>Optimizing the specular light with the halfway vector</h1></div></div></div><p>The <a id="id387" class="indexterm"/>specular illumination that we have implemented in <a id="id388" class="indexterm"/>the previous recipe uses the reflection vector from the incident light ray to demonstrate the spotty illumination. This reflection vector is calculated by the <code class="literal">reflect()</code> function in the GLSL. This function is slightly expensive to calculate. Therefore, instead of calculating the dot product between the reflection and the (<code class="literal">R.V</code>) camera vector, we can also calculate (<code class="literal">nNormal.H</code>), which is the dot product between our surface normal vector and the halfway vector. The <code class="literal">H</code> halfway vector is the vector between the camera (viewer's) vector and incident light. In the following figure, you can see the resultant of the <code class="literal">V</code> and <code class="literal">S</code> vector (Note: not <code class="literal">-S</code>):</p><div><img src="img/5527OT_04_38.jpg" alt="Optimizing the specular light with the halfway vector"/></div><p>Mathematically, the halfway vector is calculated as:</p><p><em>Halfway vector (H) = incident light vector (S) + camera vector (V)</em></p><p>The equation to calculating the halfway specular light is:</p><p><em>H = S + V</em></p><p><em>I<sub>s</sub> = L<sub>s</sub>K<sub>s</sub> ( N.H )<sub>G</sub></em></p><div><img src="img/5527OT_04_39.jpg" alt="Optimizing the specular light with the halfway vector"/></div><div><div><div><div><h2 class="title"><a id="ch05lvl2sec138"/>How to do it...</h2></div></div></div><p>Use the <a id="id389" class="indexterm"/>previous recipe, <em>Implementing </em><a id="id390" class="indexterm"/>
<em>the per-vertex specular light component</em>, and make the following changes in the <code class="literal">SpecularVertex.glsl</code>. The changes in the following code are marked in bold. There is no change required in the fragment shader:</p><div><pre class="programlisting">// No change in the global variables
. . . . . .
void main() 
{
   vec3 nNormal = normalize( NormalMatrix * Normal );
   vec3 eyeCoord= vec3( ModelViewMatrix * VertexPosition );
   vec3 nLight  = normalize( LightPosition - eyeCoord);
   vec3 V       = normalize( -eyeCoord);
   vec3 H       = normalize (nLight + V);
   float sIntensity = 0.0;
   sIntensity=pow(max(0.0,dot(H,nNormal)),ShininessFactor);

   vec3 specular   = MaterialSpecular * LightSpecular;
   FinalColor      = vec4( sIntensity * specular, 1 );
   gl_Position     = ModelViewProjectionMatrix * VertexPosition;
 }</pre></div></div><div><div><div><div><h2 class="title"><a id="ch05lvl2sec139"/>How it works...</h2></div></div></div><p>In this technique, we use the <code class="literal">nLight</code> incident light vector and the (<code class="literal">V</code>) camera vector to find the (<code class="literal">H</code>) resultant vector by adding them. Both vectors must be in the eye coordinates; the resultant halfway vector must be normalized in order to generate correct results. Calculate the dot product between the (<code class="literal">nNormal</code>) normal surface vector and the (<code class="literal">H</code>) halfway vector and substitute it in the equation mentioned previously to calculate specular illumination:</p><div><pre class="programlisting">sIntensity = pow(max(0.0, dot(H, nNormal)), ShininessFactor)</pre></div><p>The current technique is considered to be more efficient as compared to the prior specular technique <a id="id391" class="indexterm"/>we implemented. The preceding image <a id="id392" class="indexterm"/>shows the difference between the two techniques. There is no doubt that using the halfway vector technique is an approximation and generates less obvious result characteristics in comparison to the original technique. This approximation is very close to reality; therefore, if you are not too bothered about precise quality, you can use the halfway vector to calculate the shininess of the surface.</p><div><div><h3 class="title"><a id="note39"/>Note</h3><p>Remember to always use (<code class="literal">-S</code>) to calculate the reflection vector and use (<code class="literal">S</code>) to calculate the (<code class="literal">H</code>) halfway vector.</p></div></div></div><div><div><div><div><h2 class="title"><a id="ch05lvl2sec140"/>See also</h2></div></div></div><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><em>Implementing the per-vertex specular light component</em></li></ul></div></div></div>
<div><div><div><div><h1 class="title"><a id="ch05lvl1sec46"/>Gouraud shading – the per-vertex shading technique</h1></div></div></div><p>This recipe <a id="id393" class="indexterm"/>implements the Phong reflection model with all the three components of light, that is, ambient (A), diffuse (D), and specular (S), which we looked at in the previous recipes. This illumination technique is also known as ADS or <a id="id394" class="indexterm"/>Gouraud shading. The Gouraud shading technique is per-vertex shading because the fragment's color is calculated in the vertex shader by using each vertex's position information.</p><div><div><div><div><h2 class="title"><a id="ch05lvl2sec141"/>Getting ready</h2></div></div></div><p>This recipe combines the effect of our ambient (A), diffuse (D), and specular (S) illumination, which we have implemented in our previous recipes, using the Phong reflection model technique. Mathematically, it's the summation of ambient, diffuse, and specular fragment colors:</p><p><em>Gouraud shading color = ambient color + diffuse color + specular color</em></p><div><img src="img/5527OT_04_40.jpg" alt="Getting ready"/></div><p>Before implementing the Gouraud shading, it's advisable to understand ambient, diffuse, and specular illumination techniques thoroughly, as mentioned in this chapter.</p></div><div><div><div><div><h2 class="title"><a id="ch05lvl2sec142"/>How to do it...</h2></div></div></div><p>The Gouraud shading recipe implementation will make use of the existing vertex shader files from the ambient, diffuse, and specular recipes in the current vertex shader called <code class="literal">GouraudShadeVertex.glsl</code>. This recipe uses a global function called <code class="literal">GouraudShading()</code> to implement the Gouraud shading technique; the fragment shader can be completely reused as it does not require any change. The following code snippet describes the Gouraud shading vertex shader:</p><div><pre class="programlisting">. . . . // global variables, vertex attribute and matrixes.
vec3 GouraudShading()
{
    nNormal   = normalize ( NormalMatrix * Normal );
    eyeCoord  = vec3 ( ModelViewMatrix * VertexPosition );
    nLight    = normalize( LightPosition - eyeCoord );
    
    // Diffuse Intensity
    cosAngle = max( 0.0, dot( nNormal, nLight ));
    
    // Specular Intensity
    V       = normalize( -eyeCoord );
    R       = reflect( -nLight, nNormal );
    sIntensity=pow( max(0.0, dot(R, V) ), ShininessFactor);
    
    // ADS color as result of Material &amp; Light interaction
    ambient = MaterialAmbient  * LightAmbient;//Ambient light
    diffuse = MaterialDiffuse  * LightDiffuse;//Diffuse light
    specular = MaterialSpecular*LightSpecular;//Specular light
    
    return ambient + (cosAngle*diffuse) + (sIntensity*specular);
}

void main(){
    FinalColor = vec4(GouraudShading(), 1);
    gl_Position = ModelViewProjectionMatrix * VertexPosition;
}</pre></div></div><div><div><div><div><h2 class="title"><a id="ch05lvl2sec143"/>How it works...</h2></div></div></div><p>The <code class="literal">GouraudShading()</code> function calculates the color for each vertex by adding the ambient, diffuse, and specular light colors; the resultant color information is returned to the <code class="literal">main()</code> program. The vertex shader then shares this color information to the fragment shader. The fragment <a id="id395" class="indexterm"/>shader interpolates the entire color for each <a id="id396" class="indexterm"/>fragment by using the color information received from the vertex shader.</p><div><div><h3 class="title"><a id="note40"/>Note</h3><p>The function definitions in OpenGL ES Shading Language is similar to the C language; it can return values and pass arguments by value. These do not support pointers or reference to send the information by address. For more information on <a id="id397" class="indexterm"/>function definition in GL Shading Language 3.0, refer to <a class="ulink" href="http://www.khronos.org/files/opengles_shading_language.pdf">http://www.khronos.org/files/opengles_shading_language.pdf</a>.</p></div></div><p>This recipe is implemented <a id="id398" class="indexterm"/>using point light; the rays from a point light form <a id="id399" class="indexterm"/>different angles with vertex when it falls on the object.</p></div><div><div><div><div><h2 class="title"><a id="ch05lvl2sec144"/>See also</h2></div></div></div><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><em>Implementing directional and point light</em></li></ul></div></div></div>
<div><div><div><div><h1 class="title"><a id="ch05lvl1sec47"/>Phong shading – the per-fragment shading technique</h1></div></div></div><p>This <a id="id400" class="indexterm"/>shading technique is also called as smooth shading. In this recipe, we will implement Phong shading, which is a per-fragment illumination technique. Using the per-fragment technique, light shadings add more realism to the rendering scene in comparison to the per-vertex technique. We will compare Gouraud shading with Phong shading to see the relative difference between the two techniques.</p><p>In Phong shading, color <a id="id401" class="indexterm"/>intensities are directly calculated within the fragment shader with the help of light and material properties. The vertex shader is responsible for calculating the normal and vertex position in the eye coordinates; these variables are then passed on to the fragment shader. The vertex normal and vertex positions are interpolated and normalized for every fragment to produce the resultant fragment colors.</p><div><div><div><div><h2 class="title"><a id="ch05lvl2sec145"/>How to do it...</h2></div></div></div><p>Use the following <a id="id402" class="indexterm"/>steps to implement and see this technique in action:</p><div><ol class="orderedlist arabic"><li class="listitem">Create <code class="literal">PhongShadeVertex.glsl</code> and reuse most of the variables from previous recipes. Refer to the following code. The main difference is <code class="literal">normalCoord</code> and <code class="literal">eyeCoord</code>, which are defined as the out variables. Note: we will not use the properties of light and material in vertex shader; instead, these will be used in fragment shader:<div><pre class="programlisting">#version 300 es
// Vertex information
layout(location = 0) in vec4  VertexPosition;
layout(location = 1) in vec3  Normal;

// Model View Project Normal Matrix
uniform mat4 ModelViewProjectionMatrix, ModelViewMatrix;
uniform mat3 NormalMatrix;

//Out variable shared with Fragment shader
out vec3 normalCoord, eyeCoord;

void main() {
  normalCoord = NormalMatrix * Normal;
  eyeCoord    = vec3(ModelViewMatrix * VertexPosition);
  gl_Position = ModelViewProjectionMatrix * VertexPosition;
}</pre></div></li><li class="listitem">Create the <code class="literal">PhongShadeFragment.glsl</code> fragment shader file and add all the light and material <a id="id403" class="indexterm"/>property variables to the required precision <a id="id404" class="indexterm"/>qualifier. We will use the medium precision qualifier; this precision qualifier precedes the type in the variable declaration:<div><pre class="programlisting">#version 300 es
precision mediump float;

// Material &amp; Light property
uniform vec3 MaterialAmbient,MaterialSpecular,MaterialDiffuse; 
uniform vec3 LightAmbient, LightSpecular, LightDiffuse;
uniform float   ShininessFactor;

uniform vec3 LightPosition;

in vec3    normalCoord;
in vec3    eyeCoord;

layout(location = 0) out vec4 FinalColor;

vec3 normalizeNormal, normalizeEyeCoord, normalizeLightVec, V, R, ambient, diffuse, specular;
float sIntensity, cosAngle;

vec3 PhongShading()
{
  normalizeNormal   = normalize(normalCoord);
  normalizeEyeCoord = normalize(eyeCoord);
  normalizeLightVec = normalize(LightPosition-eyeCoord);
    
  // Diffuse Intensity
  cosAngle = max(0.0,
                dot(normalizeNormal,normalizeLightVec));

  // Specular Intensity
  V = -normalizeEyeCoord; // Viewer's vector
  R = reflect(-normalizeLightVec, normalizeNormal);
  sIntensity = pow(max(0.0,dot(R,V)), ShininessFactor);

  ambient    = MaterialAmbient  * LightAmbient;
  diffuse    = MaterialDiffuse  * LightDiffuse;
  specular   = MaterialSpecular * LightSpecular;

  return ambient+(cosAngle*diffuse)+(sIntensity*specular);
}

void main() {
  FinalColor = vec4(PhongShading(), 1.0);
}</pre></div></li></ol></div></div><div><div><div><div><h2 class="title"><a id="ch05lvl2sec146"/>How it works...</h2></div></div></div><p>In Phong shading, the vertex shader calculates the vertex normal (<code class="literal">normalCoord</code>)  and vertex position in <a id="id405" class="indexterm"/>the eye coordinate system (<code class="literal">eyeCoord</code>) and sends it to the fragment shader. The fragment shader uses these values and interpolates the vertex normal and vertex position for each fragment. The interpolated values must be <a id="id406" class="indexterm"/>normalized in order to produce accurate results. The remaining process to calculate ambient, diffuse, and specular light is the same as discussed in the previous recipes.</p><p>By default, the vertex shader does not require any precision in order to be defined (it's optional). If no precision is defined in the vertex shader, then it's of the highest precision. In the fragment shader, the precision qualifier needs to be defined (it's not optional).</p><p>There are three types of precision qualifier, namely, <code class="literal">lowp</code>, <code class="literal">medium</code>, and <code class="literal">highp</code>. These precision qualifiers could affect the performance of the application; it's therefore advisable to use the correct precision according to the implementation requirement. Lower precision may help to increase the FPS and power efficiency; however, it may reduce the quality of rendering. In our case, we will use the mediump precision for all the variables in the fragment shader.</p><div><img src="img/5527OT_04_41.jpg" alt="How it works..."/></div></div><div><div><div><div><h2 class="title"><a id="ch05lvl2sec147"/>There's more...</h2></div></div></div><p>We have used the Wavefront OBJ mesh to demonstrate the light shading effects on 3D mesh models; you can explore more on meshes in the <a class="link" href="ch04.html" title="Chapter 4. Working with Meshes">Chapter 4</a>, <em>Working with Meshes</em>. The same chapter describes the flat/smooth shading implementation using normal vectors.</p><p>The flat/smooth shading implementation can be enabled by using the <code class="literal">ObjMesh</code> class member function called <code class="literal">ParseObjModel</code>. This <a id="id407" class="indexterm"/>specifies the second argument as Boolean <code class="literal">true</code> (flat shading) or <code class="literal">false</code> (smooth shading). The comparative results for the two shading <a id="id408" class="indexterm"/>types are shown in the following figure:</p><div><img src="img/5527OT_04_42.jpg" alt="There's more..."/></div></div><div><div><div><div><h2 class="title"><a id="ch05lvl2sec148"/>See also</h2></div></div></div><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Refer to <a id="id409" class="indexterm"/>the <em>Rendering the wavefront OBJ </em><a id="id410" class="indexterm"/><em>mesh model</em> recipe in <a class="link" href="ch04.html" title="Chapter 4. Working with Meshes">Chapter 4</a>, <em>Working with Meshes</em></li></ul></div></div></div>
<div><div><div><div><h1 class="title"><a id="ch05lvl1sec48"/>Implementing directional and point light</h1></div></div></div><p>Light can be divided into three types, namely point light, directional light, and spot light. Let's take a look in detail:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><strong>Point light or positional light</strong>: This type of light comes from a fixed position in the <a id="id411" class="indexterm"/>3D space. The position of light and vertices of the object on which it falls is used to calculate the direction of the light. Point light emits light in all directions. Each vertex can have different directions of light, depending on its position from the light source, as shown in the following image.</li><li class="listitem" style="list-style-type: disc"><strong>Directional light</strong>: This <a id="id412" class="indexterm"/>type of light is a special case of the point light. Here, the direction of the light falling on the object is considered as nonvarying. This means that the direction of all the light rays are parallel. In directional light, the light source is considered infinitely far from the model, on which it's supposed to fall. Sometimes, it's better to assume the light direction to be parallel during the 3D scene rendering process. This is the best way to achieve nearly the same effect as point light if the distance between the source point and model is appreciably larger.</li><li class="listitem" style="list-style-type: disc"><strong>Spot light</strong>: This type of light uses the direction of the light and a cutoff angle to form a cone-shaped <a id="id413" class="indexterm"/>imaginary 3D space, as shown in the following figure. The light that falls out of this shape is discarded and the light inside the cone forms the spotlight effect:<div><img src="img/5527OT_04_43.jpg" alt="Implementing directional and point light"/></div></li></ul></div><div><div><div><div><h2 class="title"><a id="ch05lvl2sec149"/>Getting ready</h2></div></div></div><p>Sometimes, the position of the light source is considerably far from the objects. In such cases, it's advisable to implement the light-shading technique using directional lighting. The point light shading technique is a little expensive because the light direction needs to be calculated per-vertex. It's <a id="id414" class="indexterm"/>directly proportional to the number of vertices in the geometry. In contrast, directional light is treated in the constant direction where rays are <a id="id415" class="indexterm"/>assumed to be traveling in parallel directions. Unlike point light, light direction does not consider the vertex position in directional light:</p><div><table border="1"><colgroup><col style="text-align: left"/><col style="text-align: left"/><col style="text-align: left"/></colgroup><thead><tr><th style="text-align: left" valign="bottom">
<p>Light type</p>
</th><th style="text-align: left" valign="bottom">
<p><strong>Mathematical formulation</strong></p>
</th><th style="text-align: left" valign="bottom">
<p><strong>Light direction</strong></p>
</th></tr></thead><tbody><tr><td style="text-align: left" valign="top">
<p>Point</p>
</td><td style="text-align: left" valign="top">
<p>Light direction = light position - eye position</p>
</td><td style="text-align: left" valign="top">
<p>Variable</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>Directional</p>
</td><td style="text-align: left" valign="top">
<p>Light direction = light position</p>
</td><td style="text-align: left" valign="top">
<p>Constant</p>
</td></tr></tbody></table></div></div><div><div><div><div><h2 class="title"><a id="ch05lvl2sec150"/>How to do it...</h2></div></div></div><p>This recipe will demonstrate the difference between point light and directional light; all the previous recipes we have implemented so far used point light. In fact, with the previous section in this recipe, we understood which light to use when. The following instructions in bold are implemented in the fragment shader based on Phong shading; similar changes need to be performed in the vertex shader if Gouraud shading is implemented:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><strong>Point light or positional light</strong>: This <a id="id416" class="indexterm"/>requires one change to implement point light:<div><pre class="programlisting">vec3 PhongShading(){
    normalizeNormal   = normalize( normalCoord );
    normalizeEyeCoord = normalize( eyeCoord );
    // Calculate Point Light Direction
    normalizeLightVec = normalize( LightPosition - eyeCoord );
    . . . . . .
    // Calculate ADS Material &amp; Light
    . . . . . .
    return ambient+(cosAngle*diffuse)+(sIntensity*specular);
}</pre></div></li><li class="listitem" style="list-style-type: disc"><strong>Directional light</strong>: Similarly, change the statement marked in bold for directional <a id="id417" class="indexterm"/>light:<div><pre class="programlisting">vec3 PhongShading(){
    normalizeNormal   = normalize( normalCoord );
    normalizeEyeCoord = normalize( eyeCoord );
    // Calculate Direction Light Direction
    normalizeLightVec = normalize( LightPosition );
    . . . . . .
    // Calculate ADS Material &amp; Light
    . . . . . .
    return ambient+(cosAngle*diffuse)+(sIntensity*specular);
}</pre></div></li></ul></div></div><div><div><div><div><h2 class="title"><a id="ch05lvl2sec151"/>How it works...</h2></div></div></div><p>In point lighting, the light vector is used to calculate the directional vector of light, with respect to each eye coordinate of the vertex; this produces variable directional vectors, which are responsible for different amount of light intensity at each vertex.</p><p>In contrast, directional light assumes all vertexes at origin (0.0, 0.0, and 0.0). Hence, all the direction vector for each vertex are parallel. The following figure compares the point light technique and the directional light technique:</p><div><img src="img/5527OT_04_44.jpg" alt="How it works..."/></div></div></div>
<div><div><div><div><h1 class="title"><a id="ch05lvl1sec49"/>Implementing multiple lights in a scene</h1></div></div></div><p>So far, all of our <a id="id418" class="indexterm"/>recipes are demonstrated using a single light source. This section will help us in implementing multiple lights in a scene. Unlike the fixed pipeline architecture, in which only eight lights can be added to the scene, the programmable pipeline does not impose any upper limit on the number of multiple lights. Adding multiple lights to the scene is very simple. It's similar to the way we added one light position to create one color per-fragment. Now, we add <em>N</em> number of light sources to generate an average of <em>N</em> colors per-fragment:</p><div><img src="img/5527OT_04_45.jpg" alt="Implementing multiple lights in a scene"/></div><p>Mathematically, if light sources such as <strong>L1</strong>, <strong>L2</strong>, and <strong>L3</strong> create <strong>FC1</strong>, <strong>FC2</strong>, and <strong>FC3</strong> fragment colors individually, then the combined effect of these lights will be a single fragment color as a  result of an average weight of all fragment colors.</p><div><div><div><div><h2 class="title"><a id="ch05lvl2sec152"/>Getting ready</h2></div></div></div><p>The vertex shader for this recipe does not require any special changes to the source code. Therefore, we can reuse the same vertex shader (which was implemented in the Phong shading recipe). This recipe requires a few changes to the fragment shader.</p></div><div><div><div><div><h2 class="title"><a id="ch05lvl2sec153"/>How to do it...</h2></div></div></div><p>The steps to <a id="id419" class="indexterm"/>implement multiple light recipes are as follows:</p><div><ol class="orderedlist arabic"><li class="listitem">Create a fragment shader file called <code class="literal">MultiLightFragment.glsl</code> and highlight it, as shown in the following code:<div><pre class="programlisting">// Many line skipped
. . . . . 
// Light uniform array of 4 elements containing light 
// position and diffuse color information.
uniform vec3    LightPositionArray[4];
uniform vec3    LightDiffuseArray[4];
uniform float   ShininessFactor;

vec3 PhongShading( int index )
{
    normalizeNormal   = normalize( normalCoord );
    normalizeEyeCoord = normalize( eyeCoord );
    normalizeLightVec = normalize
    (LightPositionArray[index] - eyeCoord );
    
    cosAngle = max(0.0,dot(normalizeNormal,normalizeLightVec));
    
    V = -normalizeEyeCoord; // Viewer's vector
    R =reflect(-normalizeLightVec,normalizeNormal);//Reflectivity
    sIntensity = pow( max( 0.0, dot( R, V ) ), ShininessFactor );
    
    ambient   = MaterialAmbient * LightAmbient;
    diffuse = MaterialDiffuse * LightDiffuseArray[index];
    specular  = MaterialSpecular * LightSpecular;
    
    return ambient+(cosAngle*diffuse)+(sIntensity*specular);
}

void main() {
   vec4 multipleLightColor = vec4( 0.0 );
   for (int i=0; i&lt;4; i++){
      multipleLightColor += vec4(PhongShading(i),1.0);
   }
   FinalColor = multipleLightColor;
}</pre></div></li><li class="listitem">There is no <a id="id420" class="indexterm"/>change required for the vertex shader; however, the main program specifies four different light positions and four different diffuse color configurations:<div><pre class="programlisting">   // Inside ObjLoader::InitModel()
   // Compile and  use Multiple Light Shade Program
   glUseProgram( program-&gt;ProgramID );
   // Get Material &amp; Light uniform variables from shaders
   float lightpositions[12]={{-10.0,0.0,5.0}, {0.0,10.0,5.0}, {10.0,0.0,5.0},{0.0,-10.0,5.0}};
   glUniform3fv(LightPositionArray,
   sizeof(lightpositions)/sizeof(float), lightpositions);
   
   float lightdiffusecolors[12]={{1.0,0.0,0.0}, {0.0,1.0,0.0},{1.0,0.0,0.0}, {0.0,1.0,0.0} };
   glUniform3fv(LightDiffuseArray, sizeof(lightdiffusecolors)/ 
   sizeof(float), lightdiffusecolors);</pre></div></li></ol></div></div><div><div><div><div><h2 class="title"><a id="ch05lvl2sec154"/>How it works...</h2></div></div></div><p>The current recipe uses four lights to demonstrate multiple-light shading in a scene. These lights are positioned around the object (left, right, top, and bottom). Lights positioned at the left-hand side and the right-hand side use red-diffused light color, whereas lights positioned at the bottom and top are set with green-diffused light color.</p><p>Programmatically, the <a id="id421" class="indexterm"/>position of lights and diffuse light colors are defined as an array in our shader program with <code class="literal">LightPosition</code> and <code class="literal">LightDiffuseArray</code> respectively.</p><div><img src="img/5527OT_04_47.jpg" alt="How it works..."/></div><p>The <code class="literal">GouraudShading()</code> function is modified to accept an argument, which uses an index of the position of the light that needs to be processed. The main program loops to calculate the average fragment color intensity. This fragment color is returned to the main program.</p><p>Light positions that are closer to the surface of the sphere receive more intensity; therefore we can clearly see that the sphere is illuminated with green and red color at the top, bottom, left and right faces. The front part of the sphere is a mixture of green and red color because the intensities received by the sphere at the front face from all four light directions are equal.</p></div></div>
<div><div><div><div><h1 class="title"><a id="ch05lvl1sec50"/>Implementing two-side shading</h1></div></div></div><p>In <a class="link" href="ch02.html" title="Chapter 2. OpenGL ES 3.0 Essentials">Chapter 2</a>, <em>OpenGL ES 3.0 Essentials</em>, we looked at the culling technique, which is a quick way to <a id="id422" class="indexterm"/>improve performance. This technique avoids rendering polygon faces that face backwards; it's not always desirable to clip the back faces (objects that are not completely enclosed are generally rendered with back faces). Sometimes, it makes sense to view these back faces with different colors. This will help the geometry shape to define characteristics that may not be visible with the same color on both sides of the faces (back and front).</p><p>In this recipe, we will render a semi-hollow cylinder with different face colors (inside and outside). The first thing we need to do is to turn off the back culling. We can turn off the back culling with (<code class="literal">glDisable (GL_CULL_FACE)</code>).</p><p>In order to apply different colors on the front and back faces, we need to recognize them first. The OpenGL ES shading language provides a simple global-level variable called <code class="literal">gl_FrontFacing</code> in the fragment shader, which helps us to recognize the fragments belonging to front facings. This API returns Boolean as <code class="literal">true</code> if the face is front facing and vice versa.</p><p>The normal position of the face helps in defining the direction in which it's pointing. The normal position of the front face is always in the opposite direction of the back face; we will use this clue to shade the front face and the back face with different colors.</p><div><div><div><div><h2 class="title"><a id="ch05lvl2sec155"/>Getting ready</h2></div></div></div><p>The multiple lights shading recipe can be reused to implement two-side shading.</p><div><div><h3 class="title"><a id="note41"/>Note</h3><p>Make sure that culling is disabled in the program code; otherwise, two-side shading will not work.</p></div></div></div><div><div><div><div><h2 class="title"><a id="ch05lvl2sec156"/>How to do it...</h2></div></div></div><p>There is no change required in the vertex shader. Create a fragment shader file called <code class="literal">TwoSideShadingFragment.glsl</code> and make the following changes mentioned in bold:</p><div><pre class="programlisting">vec3 GouraudShading( bool frontSide ){
  normalizeNormal   = normalize ( normalCoord );
  normalizeLightVec = normalize ( LightPosition - eyeCoord );
<strong>  if ( frontSide ) // Diffuse Intensity</strong>
<strong>    { cosAngle=max(0.0, dot(normalizeNormal,normalizeLightVec)); }</strong>
<strong>  else</strong>
<strong>    { cosAngle=max(0.0, dot(-normalizeNormal,normalizeLightVec));}</strong>
    
  V = normalize( -eyeCoord );
  R = reflect(-normalizeLightVec, normalizeNormal);
  sIntensity = pow(max(0.0,dot(R,V)), ShininessFactor);
<strong>  ambient    = MaterialAmbient  * LightAmbient; // Net Ambient</strong>
<strong>  specular   = MaterialSpecular * LightSpecular;// Net Specular</strong>
<strong>  if ( frontSide ) // Front and back face net Diffuse color</strong>
<strong>  { diffuse=MaterialDiffuse*LightDiffuse; }</strong>
<strong>  else</strong>
<strong>  { diffuse=MaterialDiffuseBackFace*LightDiffuse; }</strong>

  return ambient + (cosAngle*diffuse) + (sIntensity*specular);
}

void main() {
<strong>    if (gl_FrontFacing)</strong>
<strong>       { FinalColor = vec4(GouraudShading(true), 1.0); }</strong>
<strong>    else</strong>
<strong>       { FinalColor = vec4(GouraudShading(false), 1.0); }</strong>
}</pre></div></div><div><div><div><div><h2 class="title"><a id="ch05lvl2sec157"/>How it works...</h2></div></div></div><p>The working principle <a id="id423" class="indexterm"/>for this recipe is very simple; the ideology behind is to check whether the primitive fragment belongs to the front face or the back face. If it belongs to the front face, assign it with one type of color coding; otherwise, chose another type of color. Within the fragment shader, check the front facing with <code class="literal">gl_FrontFacing</code>. Pass the fragment facing type in the <code class="literal">GouraudShading</code> function as an argument. Depending on the front and back facing Boolean value, this function will generate the color. We will use <code class="literal">MaterialDiffuseBackFace</code> and <code class="literal">LightDiffuse</code> for back facing and front facing diffuse light colors respectively. In order to calculate the Gouraud shading for back surfaces, we must use negative direction normal:</p><div><img src="img/5527OT_04_48.jpg" alt="How it works..."/></div></div><div><div><div><div><h2 class="title"><a id="ch05lvl2sec158"/>See also</h2></div></div></div><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Refer to the <a id="id424" class="indexterm"/><em>Culling in OpenGL ES 3.0</em> recipe in <a class="link" href="ch02.html" title="Chapter 2. OpenGL ES 3.0 Essentials">Chapter 2</a>, <em>OpenGL ES 3.0 Essentials</em></li></ul></div></div></div></body></html>