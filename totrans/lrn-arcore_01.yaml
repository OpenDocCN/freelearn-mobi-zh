- en: Getting Started
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Welcome to the world of immersive computing and augmented reality with Google
    ARCore. In this book, we will start with the basics. First, we will cover the
    basics of **augmented reality** (**AR**) on some important core concepts. From
    there, we will cover the installation and basics of the three development platforms
    (Android, web, and Unity) that we will use throughout the book. Next, we will
    take a more in-depth look at the technical challenges faced by AR developers,
    including various solutions techniques and for solving them. In the final chapters
    of the book, we will expand on those skills by developing three example AR and
    **mixed reality** (**MR**) apps, where we will build a Machine Learning object
    recognizer, an AR Designer app, and an app that transitions from AR to MR.
  prefs: []
  type: TYPE_NORMAL
- en: We decided to omit the Unreal platform from this book, not because it is an
    inferior platform, but quite the opposite. Unreal is a proven and cutting-edge
    game engine that is well suited for experienced graphic and game developers. However,
    Unreal and Unity are essentially on par for development features. Therefore, it
    made more sense to focus on Unity, which is far better suited for learning game
    and graphic development.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will begin by quickly covering the fundamental concepts
    of immersive computing and augmented reality. Then, we will look at the core problems
    ARCore is designed to address (motion tracking, environmental understanding, and
    light estimation). Here''s a quick look at the topics we will cover in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Immersive computing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ARCore and AR
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Motion tracking
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Environmental understanding
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Light estimation
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The road ahead
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This book was written with a beta version of ARCore. If you find something different
    or something that needs to be changed, contact Packt with your errata.
  prefs: []
  type: TYPE_NORMAL
- en: Immersive computing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Immersive computing** is a new term used to describe applications that provide
    an immersive experience for the user. This may come in the form of an augmented
    or virtual reality experience. While our attention in this book will be primarily
    focused on building an augmented reality experience, we will highlight techniques
    that can be used for VR as well. In order to better understand the spectrum of
    immersive computing, let''s take a look at this diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/059704ea-1bb6-4556-96ac-64a34c143408.png)'
  prefs: []
  type: TYPE_IMG
- en: The Immersive Computing Spectrum
  prefs: []
  type: TYPE_NORMAL
- en: The preceding diagram illustrates how the level of immersion affects the user
    experience, with the left-hand side of the diagram representing more traditional
    applications with little or no immersion, and the right representing fully immersive
    virtual reality applications. For us, we will stay in the middle sweet spot and
    work on developing augmented reality applications. In the next section, we will
    be introduced to AR and ARCore in more detail.
  prefs: []
  type: TYPE_NORMAL
- en: AR and ARCore
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Augmented reality applications are unique in that they annotate or augment
    the reality of the user. This is typically done visually by having the AR app
    overlay a view of the real world with computer graphics. ARCore is designed primarily
    for providing this type of visual annotation for the user. An example of a demo
    ARCore application is shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c2377070-82ff-4f3a-8ff2-a300453b1872.png)'
  prefs: []
  type: TYPE_IMG
- en: Google ARCore demo application; the dog is real
  prefs: []
  type: TYPE_NORMAL
- en: The screenshot is even more impressive when you realize that it was rendered
    real time on a mobile device. It isn't the result of painstaking hours of using
    Photoshop or other media effects libraries. What you see in that image is the
    entire superposition of a virtual object, the lion, into the user's reality. More
    impressive still is the quality of immersion. Note the details, such as the lighting
    and shadows on the lion, the shadows on the ground, and the way the object maintains
    position in reality even though it isn't really there. Without those visual enhancements,
    all you would see is a floating lion superimposed on the screen. It is those visual
    details that provide the immersion. Google developed ARCore as a way to help developers
    incorporate those visual enhancements in building AR applications.
  prefs: []
  type: TYPE_NORMAL
- en: Google developed ARCore for Android as a way to compete against Apple's ARKit
    for iOS. The fact that two of the biggest tech giants today are vying for position
    in AR indicates the push to build new and innovative immersive applications.
  prefs: []
  type: TYPE_NORMAL
- en: 'ARCore has its origins in Tango, which is/was a more advanced AR toolkit that
    used special sensors built into the device. In order to make AR more accessible
    and mainstream, Google developed ARCore as an AR toolkit designed for Android
    devices not equipped with any special sensors. Where Tango depended on special
    sensors, ARCore uses software to try and accomplish the same core enhancements.
    For ARCore, Google has identified three core areas to address with this toolkit,
    and they are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Motion tracking
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Environmental understanding
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Light estimation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the next three sections, we will go through each of those core areas in more
    detail and understand how they enhance the user experience.
  prefs: []
  type: TYPE_NORMAL
- en: Motion tracking
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Tracking a user''s motion and ultimately their position in 2D and 3D space
    is fundamental to any AR application. ARCore allows us to track position changes
    by identifying and tracking visual feature points from the device''s camera image.
    An example of how this works is shown in this figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/020d1623-c596-446a-bc77-c536d5ce0b4f.png)'
  prefs: []
  type: TYPE_IMG
- en: Feature point tracking in ARCore
  prefs: []
  type: TYPE_NORMAL
- en: In the figure, we can see how the user's position is tracked in relation to
    the feature points identified on the real couch. Previously, in order to successfully
    track motion (position), we needed to pre-register or pre-train our feature points.
    If you have ever used the Vuforia AR tools, you will be very familiar with having
    to train images or target markers. Now, ARCore does all this automatically for
    us, in real time, without any training. However, this tracking technology is very
    new and has several limitations. In the later part of the book, and specifically
    in [Chapter 5](3bd45362-4747-4f1c-a313-d6ccf5f6b8fc.xhtml), *Real*-*World Motion
    Tracking*, we will add a feature to our AR assistant that allows us to track multiple
    objects' positions from multiple devices in real time using GPS. Then, in [Chapter
    10](6a8f64fb-080f-47a2-9565-4099269831b1.xhtml), *Mixing in Mixed Reality*, we
    will extend our tracking to include augmented maps.
  prefs: []
  type: TYPE_NORMAL
- en: Environmental understanding
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The better an AR application understands the user's reality or the environment
    around them, the more successful the immersion. We already saw how ARCore uses
    feature identification in order to track a user's motion. Yet, tracking motion
    is only the first part. What we need is a way to identify physical objects or
    surfaces in the user's reality. ARCore does this using a technique called **meshing**.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will cover more details about meshing in later chapters, but, for now, take
    a look at the following figure from Google that shows this meshing operation in
    action:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/13b446fd-3c60-4166-83ab-9224b25deb14.png)'
  prefs: []
  type: TYPE_IMG
- en: Google image showing meshing in action
  prefs: []
  type: TYPE_NORMAL
- en: What we see happening in the preceding image is an AR application that has identified
    a real-world surface through meshing. The plane is identified by the white dots.
    In the background, we can see how the user has already placed various virtual
    objects on the surface. Environmental understanding and meshing are essential
    for creating the illusion of blended realities. Where motion tracking uses identified
    features to track the user's position, environmental understanding uses meshing
    to track the virtual objects in the user's reality. In [Chapter 8](2d0f6a3b-90a8-4aa7-afc9-a45d4b15e859.xhtml),
    *Recognizing the Environment*, we will look at how to train our own machine learning
    object identifier, which will allow us to extend our meshing to include automatically
    recognizable objects or areas of an environment.
  prefs: []
  type: TYPE_NORMAL
- en: Light estimation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Magicians work to be masters of trickery and visual illusion. They understand
    that perspective and good lighting are everything in a great illusion, and, with
    developing great AR apps, this is no exception. Take a second and flip back to
    the scene with the virtual lion. Note the lighting and detail in the shadows on
    the lion and ground. Did you note that the lion is casting a shadow on the ground,
    even though it''s not really there? That extra level of lighting detail is only
    made possible by combining the tracking of the user''s position with the environmental
    understanding of the virtual object''s position and a way to read light levels.
    Fortunately, ARCore provides us with a way to read or estimate the light in a
    scene. We can then use this lighting information in order to light and shadow
    virtual AR objects. Here''s an image of an ARCore demo app showing subdued lighting
    on an AR object:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/dbd83535-be6f-4fbb-b0cf-ac41b04803f4.png)'
  prefs: []
  type: TYPE_IMG
- en: Google image of demo ARCore app showing off subdued lighting
  prefs: []
  type: TYPE_NORMAL
- en: The effects of lighting, or lack thereof, will become more obvious as we start
    developing our startup applications. Later, in [Chapter 9](843257a4-843b-4278-99df-fec1e2bd996b.xhtml), *Blending
    Light for Architectural Design*, we will go into far more detail about 3D lighting
    and even build some simple shader effects.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we didn't go into any extensive details; we will get to that
    later, but you should now have a good grasp of the core elements ARCore was developed
    to address. In the next section, we will take a closer look at how best to use
    the material in this book.
  prefs: []
  type: TYPE_NORMAL
- en: The road ahead
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We will take a very hands-on approach for the rest of this book. After all,
    there is no better way to learn than by doing. While the book is meant to be read
    in its entirety, not all readers have the time or a need to do this. Therefore,
    provided in the following table is a quick summary of the platforms, tools, techniques,
    and difficulty level of each chapter left in the book:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Chapter** | **Focus** | **Difficulty** | **Platform** | **Tools and techniques**
    |'
  prefs: []
  type: TYPE_TB
- en: '| [Chapter 2](c5c4b444-3342-457a-b756-266772b70d06.xhtml),*ARCore on Android*
    | Basics of Android | Basic | Android (Java) | Installation of tools and environment
    for Android. |'
  prefs: []
  type: TYPE_TB
- en: '| [Chapter 3](7bf5c94d-55b4-4c07-a626-fde12d15f315.xhtml),*ARCore on Unity*
    | Basics of Unity | Basic | Android/Unity (C#) | Installation, setup, and deployment
    of the Unity sample. |'
  prefs: []
  type: TYPE_TB
- en: '| [Chapter 4](9739deb2-69a5-4756-aa54-946ba15eb405.xhtml),*ARCore on the Web*
    | Building ARCore web apps | Medium | Web (JavaScript) | Installation and setup
    of tools to support web development and hosting. |'
  prefs: []
  type: TYPE_TB
- en: '| [Chapter 5](3bd45362-4747-4f1c-a313-d6ccf5f6b8fc.xhtml), *Real-World Motion
    Tracking* | 3D spatial audio and Firebase | Medium | Web (JavaScript) | Introduce
    motion tracking with a mobile device with audio, integrate with Google Firebase,
    and track multiple objects and/or users in AR. |'
  prefs: []
  type: TYPE_TB
- en: '| [Chapter 6](8390414c-80b0-413c-bcec-cfdad3f7ad5d.xhtml), *Understanding the
    Environment* | Introduction to EU and meshing | Medium | Android (Java) | Learning
    the ARCore API for Java as well as creating a new ARCore Android project, meshing
    an environment, and interacting with objects using OpenGL ES. |'
  prefs: []
  type: TYPE_TB
- en: '| [Chapter 7](edd56812-fcba-4f66-aa3e-e9cf9ee7b637.xhtml),*Light Estimation*
    | Introduction to light estimation and lighting in Unity | Advanced | Unity (C#,
    Cg/HLSL) | Understand the importance of lighting and how it can be used to make
    AR objects appear more realistic. |'
  prefs: []
  type: TYPE_TB
- en: '| [Chapter 8](2d0f6a3b-90a8-4aa7-afc9-a45d4b15e859.xhtml),*Recognizing the
    Environment* | Introduction to **Machine Learning** (**ML**) for AR and how it
    can be used. | Advanced | Android (Java), Unity (C#) | Look at various ML platforms
    in order to better understand how it can be used in AR applications. |'
  prefs: []
  type: TYPE_TB
- en: '| [Chapter 9](843257a4-843b-4278-99df-fec1e2bd996b.xhtml),*Blending Light for
    Architectural Design* | 3D lighting and shaders | Advanced | Unity (C#) | An advanced
    introduction to lighting and shaders in Unity, including writing HLSL/ Cg shader
    code. |'
  prefs: []
  type: TYPE_TB
- en: '| [Chapter 10](6a8f64fb-080f-47a2-9565-4099269831b1.xhtml),*Mixing in Mixed
    Reality* | Combine all elements together. | Advanced+ | Unity (C#), Android (Java)
    | We will extend the ARCore platform by introducing mixed reality and allowing
    the app to transition from AR to MR. |'
  prefs: []
  type: TYPE_TB
- en: '| [Chapter 11](e7c0bdd1-e380-4498-af5a-fe9e627eb6cb.xhtml),*Performance and
    Troubleshooting* | Performance and troubleshooting tips | Basic | All | Provides
    some helpful tips on performance, with a section dedicated to addressing the possible
    issues you may have while working on the samples. |'
  prefs: []
  type: TYPE_TB
- en: Also, [Chapter 10](6a8f64fb-080f-47a2-9565-4099269831b1.xhtml), *Mixing in Mixed
    Reality,* is intended to be used after the reader has reviewed all the previous
    chapters.
  prefs: []
  type: TYPE_NORMAL
- en: While some readers may prefer to only explore a single ARCore platform by sticking
    to those specific chapters, you are strongly encouraged to work through all the
    samples in this book. Given that the ARCore API is so similar across platforms,
    transferring the techniques you learn for one should translate well to another.
    Also, don't be intimidated by a different platform or programming language. If
    you have a good base of knowledge in one C language, learning any other language
    from the rest of the family takes only minimal effort. Developer, programmer,
    software engineer, or whatever you want to call yourself, you can always benefit
    from learning another programming language.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we took a very quick look at what immersive computing and
    AR is all about. We learned that augmented reality covers the middle ground of
    the immersive computing spectrum, that AR is just a careful blend of illusions
    used to trick the user into believing that their reality has been combined with
    a virtual one. After all, Google developed ARCore as a way to provide a better
    set of tools for constructing those illusions and to keep Android competitive
    in the AR market. After that, we learned the core concepts ARCore was designed
    to address and looked at each: motion tracking, environmental understanding, and
    light estimation, in a little more detail. Finally, we finished with a helpful
    roadmap for users looking to get the most out of this book in the shortest amount
    of time.'
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we begin to dive in and get our hands dirty by getting
    the sample Android project set up and tweaked for our needs.
  prefs: []
  type: TYPE_NORMAL
