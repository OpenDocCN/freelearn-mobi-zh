- en: Getting Started
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 入门
- en: Welcome to the world of immersive computing and augmented reality with Google
    ARCore. In this book, we will start with the basics. First, we will cover the
    basics of **augmented reality** (**AR**) on some important core concepts. From
    there, we will cover the installation and basics of the three development platforms
    (Android, web, and Unity) that we will use throughout the book. Next, we will
    take a more in-depth look at the technical challenges faced by AR developers,
    including various solutions techniques and for solving them. In the final chapters
    of the book, we will expand on those skills by developing three example AR and
    **mixed reality** (**MR**) apps, where we will build a Machine Learning object
    recognizer, an AR Designer app, and an app that transitions from AR to MR.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 欢迎来到Google ARCore的沉浸计算和增强现实的世界。在本书中，我们将从基础知识开始。首先，我们将介绍增强现实（**AR**）的一些重要核心概念。从那里，我们将介绍本书中将使用的三个开发平台（Android、Web和Unity）的安装和基础知识。接下来，我们将更深入地探讨AR开发者面临的技术挑战，包括解决这些挑战的各种技术和方法。在本书的最后几章中，我们将通过开发三个示例AR和**混合现实**（**MR**）应用来扩展这些技能，我们将构建一个机器学习物体识别器、一个AR设计应用以及一个从AR过渡到MR的应用。
- en: We decided to omit the Unreal platform from this book, not because it is an
    inferior platform, but quite the opposite. Unreal is a proven and cutting-edge
    game engine that is well suited for experienced graphic and game developers. However,
    Unreal and Unity are essentially on par for development features. Therefore, it
    made more sense to focus on Unity, which is far better suited for learning game
    and graphic development.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 我们决定从本书中省略Unreal平台，并不是因为它是一个低级的平台，恰恰相反。Unreal是一个经过验证且处于前沿的游戏引擎，非常适合经验丰富的图形和游戏开发者。然而，Unreal和Unity在开发功能上基本上是相等的。因此，专注于Unity更有意义，它更适合学习游戏和图形开发。
- en: 'In this chapter, we will begin by quickly covering the fundamental concepts
    of immersive computing and augmented reality. Then, we will look at the core problems
    ARCore is designed to address (motion tracking, environmental understanding, and
    light estimation). Here''s a quick look at the topics we will cover in this chapter:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将首先快速介绍沉浸式计算和增强现实的基本概念。然后，我们将探讨ARCore旨在解决的核心理问题（运动跟踪、环境理解和光估计）。以下是本章我们将涉及的主题快速浏览：
- en: Immersive computing
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 沉浸计算
- en: ARCore and AR
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ARCore和AR
- en: Motion tracking
  id: totrans-6
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运动跟踪
- en: Environmental understanding
  id: totrans-7
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 环境理解
- en: Light estimation
  id: totrans-8
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 光估计
- en: The road ahead
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 前方的道路
- en: This book was written with a beta version of ARCore. If you find something different
    or something that needs to be changed, contact Packt with your errata.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本书是在ARCore的测试版中编写的。如果您发现有任何不同之处或需要更改的内容，请联系Packt并提供勘误表。
- en: Immersive computing
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 沉浸计算
- en: '**Immersive computing** is a new term used to describe applications that provide
    an immersive experience for the user. This may come in the form of an augmented
    or virtual reality experience. While our attention in this book will be primarily
    focused on building an augmented reality experience, we will highlight techniques
    that can be used for VR as well. In order to better understand the spectrum of
    immersive computing, let''s take a look at this diagram:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '**沉浸计算**是一个新术语，用来描述为用户提供沉浸式体验的应用。这可能以增强现实或虚拟现实体验的形式出现。虽然本书的重点将主要集中在构建增强现实体验上，但我们也会突出可用于VR的技术。为了更好地理解沉浸计算的范围，让我们看一下这个图表：'
- en: '![](img/059704ea-1bb6-4556-96ac-64a34c143408.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/059704ea-1bb6-4556-96ac-64a34c143408.png)'
- en: The Immersive Computing Spectrum
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 沉浸计算谱系
- en: The preceding diagram illustrates how the level of immersion affects the user
    experience, with the left-hand side of the diagram representing more traditional
    applications with little or no immersion, and the right representing fully immersive
    virtual reality applications. For us, we will stay in the middle sweet spot and
    work on developing augmented reality applications. In the next section, we will
    be introduced to AR and ARCore in more detail.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 上述图表说明了沉浸程度如何影响用户体验，图表的左侧代表沉浸程度较低或几乎没有的传统应用，而右侧则代表完全沉浸的虚拟现实应用。对我们来说，我们将保持在中间的甜蜜点，致力于开发增强现实应用。在下一节中，我们将更详细地介绍AR和ARCore。
- en: AR and ARCore
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AR和ARCore
- en: 'Augmented reality applications are unique in that they annotate or augment
    the reality of the user. This is typically done visually by having the AR app
    overlay a view of the real world with computer graphics. ARCore is designed primarily
    for providing this type of visual annotation for the user. An example of a demo
    ARCore application is shown here:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 增强现实应用是独特的，因为它们会注释或增强用户的现实。这通常是通过AR应用将计算机图形叠加到现实世界的视图上视觉完成的。ARCore主要是为了为用户提供这种类型的视觉注释而设计的。这里展示了一个ARCore演示应用的例子：
- en: '![](img/c2377070-82ff-4f3a-8ff2-a300453b1872.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/c2377070-82ff-4f3a-8ff2-a300453b1872.png)'
- en: Google ARCore demo application; the dog is real
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 谷歌ARCore演示应用；狗是真的
- en: The screenshot is even more impressive when you realize that it was rendered
    real time on a mobile device. It isn't the result of painstaking hours of using
    Photoshop or other media effects libraries. What you see in that image is the
    entire superposition of a virtual object, the lion, into the user's reality. More
    impressive still is the quality of immersion. Note the details, such as the lighting
    and shadows on the lion, the shadows on the ground, and the way the object maintains
    position in reality even though it isn't really there. Without those visual enhancements,
    all you would see is a floating lion superimposed on the screen. It is those visual
    details that provide the immersion. Google developed ARCore as a way to help developers
    incorporate those visual enhancements in building AR applications.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 当你意识到这个截图是在移动设备上实时渲染的时候，它甚至更加令人印象深刻。这不是使用Photoshop或其他媒体效果库耗时数小时的结果。你在这张图片中看到的是虚拟物体，狮子，在用户现实中的整个叠加。更令人印象深刻的是沉浸感的质量。注意细节，比如狮子上的光照和阴影，地面上的阴影，以及物体在现实中保持位置的方式，尽管它实际上并不在那里。如果没有这些视觉增强，你看到的将只是一个浮现在屏幕上的狮子。正是这些视觉细节提供了沉浸感。谷歌开发了ARCore，作为一种帮助开发者将这种视觉增强融入构建AR应用的方法。
- en: Google developed ARCore for Android as a way to compete against Apple's ARKit
    for iOS. The fact that two of the biggest tech giants today are vying for position
    in AR indicates the push to build new and innovative immersive applications.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 谷歌开发了ARCore用于Android，作为一种与苹果的iOS ARKit竞争的方式。今天，两大科技巨头在AR领域争夺地位的事实表明了构建新的和创新的沉浸式应用的推动力。
- en: 'ARCore has its origins in Tango, which is/was a more advanced AR toolkit that
    used special sensors built into the device. In order to make AR more accessible
    and mainstream, Google developed ARCore as an AR toolkit designed for Android
    devices not equipped with any special sensors. Where Tango depended on special
    sensors, ARCore uses software to try and accomplish the same core enhancements.
    For ARCore, Google has identified three core areas to address with this toolkit,
    and they are as follows:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: ARCore起源于Tango，这是一个更先进的AR工具包，它使用内置在设备中的特殊传感器。为了使AR更加易于访问和主流，谷歌开发了ARCore，这是一个为没有配备任何特殊传感器的Android设备设计的AR工具包。Tango依赖于特殊传感器，而ARCore则使用软件来尝试完成相同的核心增强。对于ARCore，谷歌确定了三个核心领域，通过这个工具包来解决，如下所示：
- en: Motion tracking
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运动追踪
- en: Environmental understanding
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 环境理解
- en: Light estimation
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 光估计
- en: In the next three sections, we will go through each of those core areas in more
    detail and understand how they enhance the user experience.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的三个部分中，我们将更详细地探讨这些核心领域，并了解它们如何增强用户体验。
- en: Motion tracking
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 运动追踪
- en: 'Tracking a user''s motion and ultimately their position in 2D and 3D space
    is fundamental to any AR application. ARCore allows us to track position changes
    by identifying and tracking visual feature points from the device''s camera image.
    An example of how this works is shown in this figure:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 跟踪用户在2D和3D空间中的运动和最终位置是任何AR应用的基础。ARCore允许我们通过识别和跟踪设备摄像头图像中的视觉特征点来跟踪位置变化。这种工作原理的例子如图所示：
- en: '![](img/020d1623-c596-446a-bc77-c536d5ce0b4f.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/020d1623-c596-446a-bc77-c536d5ce0b4f.png)'
- en: Feature point tracking in ARCore
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: ARCore中的特征点跟踪
- en: In the figure, we can see how the user's position is tracked in relation to
    the feature points identified on the real couch. Previously, in order to successfully
    track motion (position), we needed to pre-register or pre-train our feature points.
    If you have ever used the Vuforia AR tools, you will be very familiar with having
    to train images or target markers. Now, ARCore does all this automatically for
    us, in real time, without any training. However, this tracking technology is very
    new and has several limitations. In the later part of the book, and specifically
    in [Chapter 5](3bd45362-4747-4f1c-a313-d6ccf5f6b8fc.xhtml), *Real*-*World Motion
    Tracking*, we will add a feature to our AR assistant that allows us to track multiple
    objects' positions from multiple devices in real time using GPS. Then, in [Chapter
    10](6a8f64fb-080f-47a2-9565-4099269831b1.xhtml), *Mixing in Mixed Reality*, we
    will extend our tracking to include augmented maps.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在图中，我们可以看到用户的位置是如何相对于在真实沙发上识别的特征点进行跟踪的。之前，为了成功跟踪运动（位置），我们需要预先注册或预先训练我们的特征点。如果你曾经使用过Vuforia
    AR工具，你将非常熟悉需要训练图像或目标标记。现在，ARCore为我们自动完成所有这些，实时进行，无需任何训练。然而，这种跟踪技术非常新，存在一些限制。在本书的后期部分，特别是在[第5章](3bd45362-4747-4f1c-a313-d6ccf5f6b8fc.xhtml)，*真实世界运动跟踪*中，我们将为我们的AR助手添加一个功能，允许我们使用GPS实时跟踪来自多个设备的多个对象的位置。然后，在[第10章](6a8f64fb-080f-47a2-9565-4099269831b1.xhtml)，*混合现实中的混合*中，我们将扩展我们的跟踪，包括增强地图。
- en: Environmental understanding
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 环境理解
- en: The better an AR application understands the user's reality or the environment
    around them, the more successful the immersion. We already saw how ARCore uses
    feature identification in order to track a user's motion. Yet, tracking motion
    is only the first part. What we need is a way to identify physical objects or
    surfaces in the user's reality. ARCore does this using a technique called **meshing**.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: AR应用越好地理解用户的现实或他们周围的环境，沉浸感就越强。我们已经看到了ARCore如何使用特征识别来跟踪用户的运动。然而，跟踪运动只是第一步。我们需要的是一种方法来识别用户现实中的物理对象或表面。ARCore通过一种称为**网格化**的技术来实现这一点。
- en: 'We will cover more details about meshing in later chapters, but, for now, take
    a look at the following figure from Google that shows this meshing operation in
    action:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在后面的章节中详细介绍网格化的更多细节，但现在，请看一下谷歌提供的以下图像，它展示了网格化操作的实际应用：
- en: '![](img/13b446fd-3c60-4166-83ab-9224b25deb14.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/13b446fd-3c60-4166-83ab-9224b25deb14.png)'
- en: Google image showing meshing in action
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 展示网格化操作的谷歌图像
- en: What we see happening in the preceding image is an AR application that has identified
    a real-world surface through meshing. The plane is identified by the white dots.
    In the background, we can see how the user has already placed various virtual
    objects on the surface. Environmental understanding and meshing are essential
    for creating the illusion of blended realities. Where motion tracking uses identified
    features to track the user's position, environmental understanding uses meshing
    to track the virtual objects in the user's reality. In [Chapter 8](2d0f6a3b-90a8-4aa7-afc9-a45d4b15e859.xhtml),
    *Recognizing the Environment*, we will look at how to train our own machine learning
    object identifier, which will allow us to extend our meshing to include automatically
    recognizable objects or areas of an environment.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的图像中，我们看到的是一个通过网格化识别了真实世界表面的AR应用。平面通过白色点被识别。在背景中，我们可以看到用户已经在表面上放置了各种虚拟对象。环境理解和网格化对于创建融合现实的幻觉至关重要。运动跟踪使用识别的特征来跟踪用户的位置，而环境理解使用网格化来跟踪用户现实中的虚拟对象。在[第8章](2d0f6a3b-90a8-4aa7-afc9-a45d4b15e859.xhtml)，*识别环境*中，我们将探讨如何训练我们自己的机器学习对象识别器，这将使我们能够将网格化扩展到包括环境中可自动识别的对象或区域。
- en: Light estimation
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 光度估计
- en: 'Magicians work to be masters of trickery and visual illusion. They understand
    that perspective and good lighting are everything in a great illusion, and, with
    developing great AR apps, this is no exception. Take a second and flip back to
    the scene with the virtual lion. Note the lighting and detail in the shadows on
    the lion and ground. Did you note that the lion is casting a shadow on the ground,
    even though it''s not really there? That extra level of lighting detail is only
    made possible by combining the tracking of the user''s position with the environmental
    understanding of the virtual object''s position and a way to read light levels.
    Fortunately, ARCore provides us with a way to read or estimate the light in a
    scene. We can then use this lighting information in order to light and shadow
    virtual AR objects. Here''s an image of an ARCore demo app showing subdued lighting
    on an AR object:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 魔术师努力成为欺诈和视觉错觉的大师。他们明白，在伟大的错觉中，透视和良好的光照是至关重要的，而在开发优秀的AR应用中，这一点也不例外。请花一秒钟时间回到有虚拟狮子的场景。注意狮子和地面上的阴影的照明和细节。你注意到狮子在地面上投下了影子，尽管它实际上并不在那里吗？这种额外的照明细节是通过结合用户位置的追踪、虚拟对象位置的环境理解以及读取光水平的方式才得以实现的。幸运的是，ARCore为我们提供了一种读取或估计场景中光照的方法。然后我们可以使用这些照明信息来照亮和投射虚拟AR对象的阴影。这是一张显示ARCore演示应用上低调照明的图片：
- en: '![](img/dbd83535-be6f-4fbb-b0cf-ac41b04803f4.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](img/dbd83535-be6f-4fbb-b0cf-ac41b04803f4.png)'
- en: Google image of demo ARCore app showing off subdued lighting
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: Google展示低调照明的ARCore演示应用图片
- en: The effects of lighting, or lack thereof, will become more obvious as we start
    developing our startup applications. Later, in [Chapter 9](843257a4-843b-4278-99df-fec1e2bd996b.xhtml), *Blending
    Light for Architectural Design*, we will go into far more detail about 3D lighting
    and even build some simple shader effects.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 随着我们开始开发我们的初创应用程序，光照效果或缺乏光照的影响将变得更加明显。稍后，在第9章 [Blending Light for Architectural
    Design](843257a4-843b-4278-99df-fec1e2bd996b.xhtml) 中，我们将更深入地探讨3D光照，甚至构建一些简单的着色器效果。
- en: In this chapter, we didn't go into any extensive details; we will get to that
    later, but you should now have a good grasp of the core elements ARCore was developed
    to address. In the next section, we will take a closer look at how best to use
    the material in this book.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们没有深入探讨任何详细内容；我们将在稍后进行，但你现在应该已经很好地掌握了ARCore旨在解决的核心理念。在下一节中，我们将更详细地探讨如何最好地使用本书中的材料。
- en: The road ahead
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 前方的道路
- en: 'We will take a very hands-on approach for the rest of this book. After all,
    there is no better way to learn than by doing. While the book is meant to be read
    in its entirety, not all readers have the time or a need to do this. Therefore,
    provided in the following table is a quick summary of the platforms, tools, techniques,
    and difficulty level of each chapter left in the book:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的剩余部分，我们将采取非常实际的方法。毕竟，没有比实践更好的学习方法了。虽然本书旨在整体阅读，但并非所有读者都有时间或需要这样做。因此，以下表格提供了一个关于书中剩余章节的平台、工具、技术和难度级别的快速总结：
- en: '| **Chapter** | **Focus** | **Difficulty** | **Platform** | **Tools and techniques**
    |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
  zh: '| **章节** | **重点** | **难度** | **平台** | **工具和技术** |'
- en: '| [Chapter 2](c5c4b444-3342-457a-b756-266772b70d06.xhtml),*ARCore on Android*
    | Basics of Android | Basic | Android (Java) | Installation of tools and environment
    for Android. |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '| [第2章](c5c4b444-3342-457a-b756-266772b70d06.xhtml)，*Android中的ARCore* | Android基础
    | 基础 | Android (Java) | 安装Android的工具和环境。 |'
- en: '| [Chapter 3](7bf5c94d-55b4-4c07-a626-fde12d15f315.xhtml),*ARCore on Unity*
    | Basics of Unity | Basic | Android/Unity (C#) | Installation, setup, and deployment
    of the Unity sample. |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| [第3章](7bf5c94d-55b4-4c07-a626-fde12d15f315.xhtml)，*Unity中的ARCore* | Unity基础
    | 基础 | Android/Unity (C#) | Unity示例的安装、设置和部署。 |'
- en: '| [Chapter 4](9739deb2-69a5-4756-aa54-946ba15eb405.xhtml),*ARCore on the Web*
    | Building ARCore web apps | Medium | Web (JavaScript) | Installation and setup
    of tools to support web development and hosting. |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '| [第4章](9739deb2-69a5-4756-aa54-946ba15eb405.xhtml)，*Web中的ARCore* | 构建ARCore
    Web应用 | 中等 | Web (JavaScript) | 支持Web开发和托管工具的安装和设置。 |'
- en: '| [Chapter 5](3bd45362-4747-4f1c-a313-d6ccf5f6b8fc.xhtml), *Real-World Motion
    Tracking* | 3D spatial audio and Firebase | Medium | Web (JavaScript) | Introduce
    motion tracking with a mobile device with audio, integrate with Google Firebase,
    and track multiple objects and/or users in AR. |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '| [第5章](3bd45362-4747-4f1c-a313-d6ccf5f6b8fc.xhtml)，*现实世界运动追踪* | 3D空间音频和Firebase
    | 中等 | Web (JavaScript) | 使用带有音频的移动设备进行运动追踪，与Google Firebase集成，并在AR中追踪多个对象和/或用户。
    |'
- en: '| [Chapter 6](8390414c-80b0-413c-bcec-cfdad3f7ad5d.xhtml), *Understanding the
    Environment* | Introduction to EU and meshing | Medium | Android (Java) | Learning
    the ARCore API for Java as well as creating a new ARCore Android project, meshing
    an environment, and interacting with objects using OpenGL ES. |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '| [第6章](8390414c-80b0-413c-bcec-cfdad3f7ad5d.xhtml), *理解环境* | EU和网格化的介绍 | 中级
    | Android (Java) | 学习ARCore API的Java版本，以及创建一个新的ARCore Android项目，对环境进行网格化，并使用OpenGL
    ES与对象交互。 |'
- en: '| [Chapter 7](edd56812-fcba-4f66-aa3e-e9cf9ee7b637.xhtml),*Light Estimation*
    | Introduction to light estimation and lighting in Unity | Advanced | Unity (C#,
    Cg/HLSL) | Understand the importance of lighting and how it can be used to make
    AR objects appear more realistic. |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '| [第7章](edd56812-fcba-4f66-aa3e-e9cf9ee7b637.xhtml),*光估计* | Unity中光估计和光照的介绍
    | 高级 | Unity (C#, Cg/HLSL) | 了解光照的重要性以及如何使用它来使AR对象看起来更真实。 |'
- en: '| [Chapter 8](2d0f6a3b-90a8-4aa7-afc9-a45d4b15e859.xhtml),*Recognizing the
    Environment* | Introduction to **Machine Learning** (**ML**) for AR and how it
    can be used. | Advanced | Android (Java), Unity (C#) | Look at various ML platforms
    in order to better understand how it can be used in AR applications. |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '| [第8章](2d0f6a3b-90a8-4aa7-afc9-a45d4b15e859.xhtml),*识别环境* | AR和机器学习（**ML**）的介绍及其应用
    | 高级 | Android (Java), Unity (C#) | 查看各种机器学习平台，以便更好地理解它们在AR应用中的使用方法。 |'
- en: '| [Chapter 9](843257a4-843b-4278-99df-fec1e2bd996b.xhtml),*Blending Light for
    Architectural Design* | 3D lighting and shaders | Advanced | Unity (C#) | An advanced
    introduction to lighting and shaders in Unity, including writing HLSL/ Cg shader
    code. |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '| [第9章](843257a4-843b-4278-99df-fec1e2bd996b.xhtml),*为建筑设计融合光线* | 3D光照和着色器
    | 高级 | Unity (C#) | Unity中光照和着色器的深入介绍，包括编写HLSL/ Cg着色器代码。 |'
- en: '| [Chapter 10](6a8f64fb-080f-47a2-9565-4099269831b1.xhtml),*Mixing in Mixed
    Reality* | Combine all elements together. | Advanced+ | Unity (C#), Android (Java)
    | We will extend the ARCore platform by introducing mixed reality and allowing
    the app to transition from AR to MR. |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| [第10章](6a8f64fb-080f-47a2-9565-4099269831b1.xhtml),*混合现实中的混合* | 将所有元素结合在一起。
    | 高级+ | Unity (C#), Android (Java) | 我们将通过引入混合现实来扩展ARCore平台，并允许应用从AR过渡到MR。 |'
- en: '| [Chapter 11](e7c0bdd1-e380-4498-af5a-fe9e627eb6cb.xhtml),*Performance and
    Troubleshooting* | Performance and troubleshooting tips | Basic | All | Provides
    some helpful tips on performance, with a section dedicated to addressing the possible
    issues you may have while working on the samples. |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| [第11章](e7c0bdd1-e380-4498-af5a-fe9e627eb6cb.xhtml),*性能和故障排除* | 性能和故障排除技巧
    | 基础 | 所有 | 提供了一些关于性能的有用技巧，并有一个专门的部分来解决你在处理示例时可能遇到的问题。 |'
- en: Also, [Chapter 10](6a8f64fb-080f-47a2-9565-4099269831b1.xhtml), *Mixing in Mixed
    Reality,* is intended to be used after the reader has reviewed all the previous
    chapters.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，[第10章](6a8f64fb-080f-47a2-9565-4099269831b1.xhtml)，*混合现实中的混合*，是在读者回顾了所有前面的章节之后使用的。
- en: While some readers may prefer to only explore a single ARCore platform by sticking
    to those specific chapters, you are strongly encouraged to work through all the
    samples in this book. Given that the ARCore API is so similar across platforms,
    transferring the techniques you learn for one should translate well to another.
    Also, don't be intimidated by a different platform or programming language. If
    you have a good base of knowledge in one C language, learning any other language
    from the rest of the family takes only minimal effort. Developer, programmer,
    software engineer, or whatever you want to call yourself, you can always benefit
    from learning another programming language.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然一些读者可能更喜欢只通过那些特定章节来探索单个ARCore平台，但你被强烈鼓励完成这本书中的所有示例。鉴于ARCore API在各个平台之间如此相似，你学到的技术应该可以很好地转移到另一个平台。另外，不要因为不同的平台或编程语言而感到害怕。如果你在C语言方面有良好的知识基础，学习这个家族中的任何其他语言只需要最小的努力。开发者、程序员、软件工程师，或者你想要称自己为什么，你都可以从学习另一种编程语言中受益。
- en: Summary
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: 'In this chapter, we took a very quick look at what immersive computing and
    AR is all about. We learned that augmented reality covers the middle ground of
    the immersive computing spectrum, that AR is just a careful blend of illusions
    used to trick the user into believing that their reality has been combined with
    a virtual one. After all, Google developed ARCore as a way to provide a better
    set of tools for constructing those illusions and to keep Android competitive
    in the AR market. After that, we learned the core concepts ARCore was designed
    to address and looked at each: motion tracking, environmental understanding, and
    light estimation, in a little more detail. Finally, we finished with a helpful
    roadmap for users looking to get the most out of this book in the shortest amount
    of time.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们简要地探讨了沉浸式计算和增强现实（AR）的基本概念。我们了解到，增强现实覆盖了沉浸式计算光谱的中间地带，AR只是精心混合的幻觉，用来欺骗用户相信他们的现实已经与虚拟现实相结合。毕竟，谷歌开发了ARCore，作为一种提供构建这些幻觉的更好工具的方式，并保持Android在AR市场中的竞争力。之后，我们学习了ARCore旨在解决的核心概念，并逐一进行了更详细的探讨：运动跟踪、环境理解和光估计。最后，我们为那些希望在最短的时间内从本书中获得最大收益的用户提供了一个有用的路线图。
- en: In the next chapter, we begin to dive in and get our hands dirty by getting
    the sample Android project set up and tweaked for our needs.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将开始深入探讨，通过设置和调整满足我们需求的样本Android项目来“动手实践”。
