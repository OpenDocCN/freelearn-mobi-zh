<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Concurrency and Parallel Processing in RxKotlin with Schedulers</h1>
                </header>
            
            <article>
                
<p>So, up until now, you have learned the basics of reactive programming. You learned about Observable, Observers, and Subjects, as well as backpressure, Flowable, processors, and operators. Now, it's time for us to learn some other new topics in reactive programming, probably the most important ones—concurrency and parallel processing.</p>
<p>A popular misconception regarding reactive programming is that reactive programming is multi-threaded by default. The truth is actually that RxKotlin works on a single thread by default, although it provides us with loads of operators to implement multi-threading as per our business logic and requirements with ease.</p>
<p>In this chapter, we will cover the following topics:</p>
<ul>
<li>Introduction to concurrency</li>
<li>The <kbd>subscribeOn()</kbd> and <kbd>observeOn()</kbd> operator</li>
<li>Parallelization</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Introduction to concurrency</h1>
                </header>
            
            <article>
                
<p>The definition of concurrency can be described as follows:</p>
<div class="packt_quote">As a programming paradigm, concurrent computing is a form of modular programming, namely factoring an overall computation into subcomputations that may be executed concurrently.<br/>
                                                                                                                               – Wikipedia</div>
<p>As the definition says, concurrency is all about breaking the entire task into small parts and then executing them concurrently (there's a small difference between concurrent execution and parallel execution, which we will discuss shortly).</p>
<p>So, what does it mean to execute subcomputations concurrently? Let's look at a real-life example. Think of a situation where you're cooking a new dish at your home and you have three chores<span>—</span>bring the spices, cut the vegetables, and also marinate something. Now, if you're doing it all alone, you have to do them one by one, but if you have a family member at your disposal, then you can distribute the tasks between the two of you. You can cut the vegetables while the other person is bringing the spices, and whoever between you two completes early can continue on the third task<span>—</span>marinating the food.</p>
<p>You can think of you and the family member (who helped you) as two threads, or, to be more specific, you're the main thread of the program (here, cooking) as you're the responsible person for the entire job, and you'll be distributing tasks between you and the family member, who is a worker thread. Together, you and your family member form a thread pool.</p>
<p>The entire program will execute faster if there are more threads and the complete task is divided properly among them.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Parallel execution versus concurrency</h1>
                </header>
            
            <article>
                
<p>The concepts of concurrency and parallelization are not only related, but they are deeply connected to each other; you may think of them as identical twin brothers. They look almost the same, but there are differences. Let's try to discover.</p>
<p>In the previous example, we discussed concurrency, but it seemed to execute in parallel. Now, let's take a better example, which will not only help us understand parallelization, but will allow us to understand the differences between concurrency and parallelization as well.</p>
<p>Think of a hotel with 5 customers who ordered 15 dishes. These 15 dishes represent identical tasks, and each of them require to be cooked by a chef. Now, as with the previous example, think of the cooks as threads (in the previous example, you and your family member were playing the role of a cook in your home), but rather than sharing sub-parts of a dish, they will cook each dish at a time (because, obviously, there are 15 orders!).</p>
<p>Now, if you get 15 cooks at your disposal (along with 15 ovens and other resources), then you can get all the dishes to be cooked in one go, but that's not quite economical. You cannot infinitely increase your cooks and resources with the number of orders. The more economical solution would be to hire 5 cooks and make a pool (or you may say a queue) of orders and execute orders one after another. So, each cook has to make three dishes (or iterations of tasks). If there are more orders, then the pool would grow bigger.</p>
<p>Parallelization says to wisely divide tasks in a pool; instead of creating threads for each task, create a pool of tasks, and assign them to an existing thread, and reuse them.</p>
<p>The conclusion is, parallelization is achieved with concurrency, but it is not the same thing; rather, it is about how to use concurrency.</p>
<p>Now, why is it so important? Or rather, why is it required at all? I think you already got the answer, but let's inspect.</p>
<p>Think of a situation where you're working with a large dataset, and also have a long chain of operations to be performed on them before being displayed to the user. If you're an application developer, you'd probably want to perform all the operations in the background and pass the resultant data to the foreground for displaying it to the user. Concurrency is useful for this same scenario.</p>
<p>As I mentioned earlier, RxKotlin doesn't perform actions concurrently, but provides you with loads of options to perform the selected operations concurrently, leaving the choice to you.</p>
<p>You're probably wondering if RxKotlin really is single threaded by default, then how is the subscription handled by it? Should the subscription be concurrent? Let's find the answers before we proceed further with concurrent computing with RxKotlin.</p>
<p>So, whenever you subscribe to an Observable and/or Flowable, the current thread is blocked until all the items are emitted and received by the Observer chain (except for the cases with interval and timer factory methods). Surprising, right? However, it's actually good, because, for an Observable chain, if a separate thread is assigned to each operator (any operator generally subscribes to the source Observable and performs operations on the emissions, the next operator subscribes to the emissions by the current one), then it would be totally messy.</p>
<p>To resolve this scenario, ReactiveX provided us with scheduler and scheduling operators. By using them, thread management becomes easy, as the synchronization is almost automatic and there's no shared data between threads (as a basic property of functional programming, thus functional reactive programming).</p>
<p>Now that we have got some hands on the ideas behind concurrency, we can move forward with implementing concurrency using RxKotlin.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">What is a scheduler?</h1>
                </header>
            
            <article>
                
<p>In ReactiveX, the heart of concurrency lies in schedulers. As I have already mentioned, by default, the Observable and the chain of operators applied to it will do the work on the same thread where subscribe is called, and the thread will be blocked until Observer receives the <kbd>onComplete</kbd> or <kbd>onError</kbd> notification. We can use schedulers to change this behavior.</p>
<p>A scheduler can be thought of as a thread pool, from which ReactiveX can pool a thread and execute its task on it. It's basically an abstraction over multithreading and concurrency, making the implementation of concurrency a lot easier in ReactiveX.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Types of scheduler</h1>
                </header>
            
            <article>
                
<p>As an abstraction layer for thread pool management, the scheduler API provides you with some pre-composed scheduler. It also allows you to create a new user-defined scheduler. Let's take a look at the available scheduler types:</p>
<ul>
<li><kbd>Schedulers.io()</kbd></li>
<li><kbd>Schedulers.computation()</kbd></li>
<li><kbd>Schedulers.newThread()</kbd></li>
<li><kbd>Schedulers.single()</kbd></li>
<li><kbd>Schedulers.trampoline()</kbd></li>
<li><kbd>Schedulers.from()</kbd></li>
</ul>
<p>We will look into their definitions and their prescribed use-cases, but first, let's get started with some code.</p>
<p>We will start with a usual example without a scheduler, and then we will implement a scheduler in the same example to observe the difference, as follows:</p>
<pre>    fun main(args: Array&lt;String&gt;) { 
      Observable.range(1,10) 
        .subscribe { 
           runBlocking { delay(200) } 
           println("Observable1 Item Received $it") 
         } 
 
      Observable.range(21,10) 
        .subscribe { 
           runBlocking { delay(100) } 
           println("Observable2 Item Received $it") 
        } 
    } </pre>
<p>In this program, we used two <kbd>Observable</kbd>; we used delay inside their subscription to simulate long running tasks.</p>
<p>The following output displays the expected result. The Observers run one after another:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img height="340" width="318" src="assets/5c3babe4-c0e1-48dd-a586-a38386fcf3af.jpg"/></div>
<p>The total execution time of this program would be around 3,100 milliseconds (as the delay is performed before printing), while the thread pool was sitting idle in between. Using scheduler, this time can be significantly reduced. Let's get it done:</p>
<pre>    fun main(args: Array&lt;String&gt;) { 
      Observable.range(1, 10) 
       .subscribeOn(Schedulers.computation())//(1) 
       .subscribe { 
          runBlocking { delay(200) } 
          println("Observable1 Item Received $it") 
        } 
 
       Observable.range(21, 10) 
         .subscribeOn(Schedulers.computation())//(2) 
         .subscribe { 
            runBlocking { delay(100) } 
            println("Observable2 Item Received $it") 
          } 
       runBlocking { delay(2100) }//(3) 
    }</pre>
<p>This program contains three new lines as compared to the previous one. On comment <kbd>(1)</kbd> and <kbd>(2)</kbd>, <kbd>subscribeOn(Schedulers.computation())</kbd>, and <kbd>runBlocking { delay(2100) }</kbd> on comment <kbd>(3)</kbd>. We will inspect the significance of those lines after taking a look at the output:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img height="390" width="370" class=" image-border" src="assets/46462863-a4a6-4db2-a7d4-eb39eb80ba97.png"/></div>
<p>As the output shows, <kbd>Observable</kbd> in this example is emitted concurrently. The line of the <kbd>subscribeOn(Schedulers.computation())</kbd> code enabled both downstreams to subscribe to the <kbd>Observable</kbd> in a different (background) thread, which influenced concurrency. You should already be used to it with using it <kbd>runBlocking { delay(2100) }</kbd> on comment <kbd>(3)</kbd>; we use it to keep the program alive. As all the operations are being performed in different threads, we need to block the main thread to keep the program alive. However, notice the time duration of the delay we passed; it's only 2,100 milliseconds, and the output confirms both the subscriptions processed all the emissions. So, it's clear, we saved 1,000 milliseconds right away.</p>
<p>Let's now continue discussions on different types of schedulers available—we will then dive into different ways to use them.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Schedulers.io() - I/O bound scheduler</h1>
                </header>
            
            <article>
                
<p><kbd>Schedulers.io()</kbd> provides us with I/O bound threads. To be more accurate, <kbd>Schedulers.io()</kbd> provides you with <kbd>ThreadPool</kbd>, which can create an unbounded number of worker threads that are meant to be performing I/O bounded tasks.</p>
<p>Now, what exactly does the I/O bounded thread mean? And why are we calling it I/O bounded? Let's inspect.</p>
<p>All the threads in this pool are blocking and are meant to perform more I/O operations than computationally intense tasks, giving less load to CPUs, but may take longer due to waiting for I/O. By I/O operations, we mean interactions with file systems, databases, services, or I/O devices.</p>
<p>We should be cautious about using this scheduler as it can create an infinite number of threads (until the memory lasts) and can cause <kbd>OutOfMemory</kbd> errors.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Schedulers.computation() - CPU bound schedulers</h1>
                </header>
            
            <article>
                
<p>The <kbd>Schedulers.computation()</kbd> is probably the most useful scheduler for programmers. It provides us with a bounded thread-pool, which can contain a number of threads equal to the number of available CPU cores. As the name suggests, this scheduler is meant for CPU intense works.</p>
<p>We should use this scheduler only for CPU—intense tasks and not for any other cause. The reason is that the threads in this scheduler keeps the CPU cores busy, and may slow down the entire application if it is used for I/O bound or any other tasks that involves non-computational tasks.</p>
<p>The main reason why we should consider <kbd>Schedulers.io()</kbd> for I/O bound tasks and <kbd>Schedulers.computation()</kbd> for computational purposes is that <kbd>computation()</kbd> threads utilize the processors better and create no more threads than the available CPU cores, and reuses them. While <kbd>Schedulers.io()</kbd> is unbounded, and if you schedule 10,000 computational tasks on <kbd>io()</kbd> in parallel, then each of those 10,000 tasks each have their own thread and be competing for CPU incurring context switching costs.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Schedulers.newThread()</h1>
                </header>
            
            <article>
                
<p>The <kbd>Schedulers.newThread()</kbd> provides us with a scheduler that creates a new thread for each task provided. While at first glance it may seem similar to <kbd>Schedulers.io()</kbd>, there's actually a huge difference.</p>
<p>The <kbd>Schedulers.io()</kbd> uses a thread pool, and whenever it gets a new unit of work, it first looks into the thread pool to see if any idle thread is available to take up the task; it proceeds to create a new thread if no pre-existing thread is available to take up the work.</p>
<p>However, <kbd>Schedulers.newThread()</kbd> doesn't even use a thread pool; instead, it creates a new thread for every request and forgets them forever.</p>
<p>In most of the cases, when you're not using <kbd>Schedulers.computation()</kbd>, you should consider <kbd>Schedulers.io()</kbd> and should predominantly avoid using <kbd>Schedulers.newThread()</kbd>; threads are very expensive resources, you should try to avoid the creation of new threads as much as possible.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Schedulers.single()</h1>
                </header>
            
            <article>
                
<p>The <kbd>Schedulers.single()</kbd> provides us with a scheduler that contains only one thread and returns the single instance for every call. Confused? Let's make it clear. Think of a situation where you need to execute tasks that are strongly sequential—<kbd>Schedulers.single()</kbd> is the best available option for you here. As it provides you with only one thread, every task that you enqueue here is bound to be executed sequentially.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Schedulers.trampoline()</h1>
                </header>
            
            <article>
                
<p><kbd>Schedulers.single()</kbd> and <kbd>Schedulers.trampoline()</kbd> sound somewhat similar, both the schedulers are for sequential execution. While <kbd>Schedulers.single()</kbd> guarantees that all its task will run sequentially, it may run parallel to the thread it was called upon (if not, that thread is from <kbd>Schedulers.single()</kbd> as well); the <kbd>Schedulers.trampoline()</kbd> is different in that sector.</p>
<p>Unlike maintaining a thread to its disposal like <kbd>Schedulers.single()</kbd>, <kbd>Schedulers.trampoline()</kbd> queues up the task on the thread it was called on.</p>
<p>So, it'll be sequential with the thread it was called upon.</p>
<p>Let's look at some examples of <kbd>Schedulers.single()</kbd> and <kbd>Schedulers.trampoline()</kbd> to understand them better:</p>
<pre>    fun main(args: Array&lt;String&gt;) { 
 
      async(CommonPool) { 
        Observable.range(1, 10) 
          .subscribeOn(Schedulers.single())//(1) 
          .subscribe { 
             runBlocking { delay(200) } 
             println("Observable1 Item Received $it") 
           } 
 
         Observable.range(21, 10) 
           .subscribeOn(Schedulers.single())//(2) 
           .subscribe { 
              runBlocking { delay(100) } 
              println("Observable2 Item Received $it") 
            } 
 
          for (i in 1..10) { 
            delay(100) 
            println("Blocking Thread $i") 
          } 
        } 
 
       runBlocking { delay(6000) } 
    } </pre>
<p>The output is as follows:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img height="539" width="355" src="assets/cfd79afb-d432-441b-8621-cc726d151517.jpg"/></div>
<p>The output clearly shows that despite the fact that both the subscriptions run sequentially, they run in parallel to the calling thread.</p>
<p>Now, let's implement the same code with <kbd>Schedulers.trampoline()</kbd> and observe the difference:</p>
<pre>    fun main(args: Array&lt;String&gt;) { 
 
      async(CommonPool) { 
        Observable.range(1, 10) 
          .subscribeOn(Schedulers.trampoline())//(1) 
          .subscribe { 
              runBlocking { delay(200) } 
              println("Observable1 Item Received $it") 
          } 
 
          Observable.range(21, 10) 
            .subscribeOn(Schedulers.trampoline())//(2) 
            .subscribe { 
               runBlocking { delay(100) } 
               println("Observable2 Item Received $it") 
             } 
 
          for (i in 1..10) { 
            delay(100) 
            println("Blocking Thread $i") 
          } 
       } 
 
       runBlocking { delay(6000) } 
    } </pre>
<p>The following output shows that the scheduler ran sequentially to the calling thread:</p>
<div class="CDPAlignCenter CDPAlign"><img height="495" width="325" src="assets/d045d0b4-1881-49ec-b7a2-784db8c0e416.jpg"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Schedulers.from</h1>
                </header>
            
            <article>
                
<p>So far, we've seen the default/predefined schedulers available within RxKotlin. However, while developing applications, you may need to define your custom scheduler. Keeping that scenario in mind, ReactiveX has provided you with <kbd>Schedulers.from(executor:Executor)</kbd>, which lets you convert any executor into a scheduler.</p>
<p>Let's look at the following example:</p>
<pre>    fun main(args: Array&lt;String&gt;) { 
 
      val executor:Executor = Executors.newFixedThreadPool(2)//(1) 
      val scheduler:Scheduler = Schedulers.from(executor)//(2) 
 
      Observable.range(1, 10) 
        .subscribeOn(scheduler)//(3) 
        .subscribe { 
           runBlocking { delay(200) } 
           println("Observable1 Item Received $it -<br/>           ${Thread.currentThread().name}") 
         } 
 
      Observable.range(21, 10) 
        .subscribeOn(scheduler)//(4) 
        .subscribe { 
            runBlocking { delay(100) } 
            println("Observable2 Item Received $it -<br/>            ${Thread.currentThread().name}") 
         } 
 
       Observable.range(51, 10) 
         .subscribeOn(scheduler)//(5) 
         .subscribe { 
             runBlocking { delay(100) } 
             println("Observable3 Item Received $it - <br/>             ${Thread.currentThread().name}") 
          } 
          runBlocking { delay(10000) }//(6) 
    } </pre>
<p>In this example, we've created a custom <kbd>Scheduler</kbd> from an <kbd>Executor</kbd> (for the sake of simplicity, we've used a standard Thread Pool Executor; you're free to use your own custom executor).</p>
<p>On comment <kbd>(1)</kbd>, we created the executor with the <kbd>Executors.newFixedThreadPool()</kbd> method, on comment <kbd>(2)</kbd>, we created the <kbd>scheduler</kbd> instance with the help of <kbd>Schedulers.from(executor:Executor)</kbd>. We used the <kbd>scheduler</kbd> instance on comment <kbd>(3)</kbd>, comment <kbd>(4)</kbd>, and comment <kbd>(5)</kbd>.</p>
<p>Here is the output:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img height="478" width="312" src="assets/44fd479d-be13-44bf-ad1c-3fc16bd4f185.jpg"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to use schedulers – subscribeOn and observeOn operators</h1>
                </header>
            
            <article>
                
<p>Now that we have gained some grip on what schedulers are, how many types of schedulers are available, and how to create a <kbd>scheduler</kbd> instance, we will focus on how to use schedulers.</p>
<p>There are basically two operators that help us implement schedulers. Up until now, in this chapter, we've used the <kbd>subscribeOn</kbd> operator in all the examples with a scheduler; however, there's another operator—<kbd>observeOn</kbd>. We will now focus on these two operators, learning how they work, and how they differ.</p>
<p>Let's start with the <kbd>subscribeOn</kbd> operator.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Changing thread on subscription – subscribeOn operator</h1>
                </header>
            
            <article>
                
<p>We need to understand how the <kbd>Observable</kbd> works before delving any further in how to use scheduler. Let's take a look at the following graphics:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img height="390" width="365" src="assets/6dd696f1-ad49-4bcf-92a0-13d1d2b4c943.jpg"/></div>
<p>As the preceding image depicts, it's the threads that are responsible for carrying items from the source all the way to the Subscriber through operators. It may be a single thread throughout the subscription, or it may even be different threads at different levels.</p>
<p>By default, the thread in which we perform the subscription is the responsible of bringing all the emissions down to the Subscriber, unless we instruct it otherwise.</p>
<p>Let's take a look at the code example first:</p>
<pre>    fun main(args: Array&lt;String&gt;) { 
      listOf("1","2","3","4","5","6","7","8","9","10") 
        .toObservable() 
        .map { 
           item-&gt; 
           println("Mapping $item ${Thread.currentThread().name}") 
           return@map item.toInt() 
        } 
        .subscribe { 
           item -&gt; println("Received $item <br/>           ${Thread.currentThread().name}") 
        } 
 
    } </pre>
<p>It's a simple RxKotlin code example; we are creating <kbd>Observable</kbd>, mapping it, and then subscribing to it. The only difference here is that I've printed the <kbd>Thread</kbd> name inside both the <kbd>map</kbd> and the <kbd>subscribe</kbd> lambdas.</p>
<p>Let's take a look at the output:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img height="441" width="421" src="assets/baa99960-4bda-454e-be6d-66a998433fd7.jpg"/></div>
<p>From the output, we can determine that the main thread executes the entire subscription.</p>
<p>The <kbd>subscribeOn</kbd> operator, as the name suggests, helps us change the thread of a subscription. Let's modify the program once and take a look:</p>
<pre>    fun main(args: Array&lt;String&gt;) { 
      listOf("1","2","3","4","5","6","7","8","9","10") 
        .toObservable() 
        .map { 
           item-&gt; 
           println("Mapping $item - ${Thread.currentThread().name}") 
           return@map item.toInt() 
         } 
         .subscribeOn(Schedulers.computation())//(1) 
         .subscribe { 
            item -&gt; println("Received $item - <br/>            ${Thread.currentThread().name}") 
         } 
 
         runBlocking { delay(1000) } 
    } </pre>
<p>The entire program remains the same, except that, in between <kbd>map</kbd> and <kbd>subscribe</kbd>, we used the <kbd>subscribeOn</kbd> operator at comment <kbd>(1)</kbd>. Let's check the output:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img height="409" width="386" src="assets/440f9c65-9f1a-4eaf-b124-21e413b55ab2.jpg"/></div>
<p>The <kbd>subscribeOn</kbd> operator changes the thread for the entire subscription; you can use it wherever you want in the subscription flow. It will change the thread once and for all.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Observing on a different thread – observeOn operator</h1>
                </header>
            
            <article>
                
<p>While <kbd>subscribeOn</kbd> looks like an awesome gift from heaven, it may not be suited in some cases. For example, you may want to do computations on the <kbd>computation</kbd> threads and display the results from the <kbd>io</kbd> threads, which actually you should do. The <kbd>subscribeOn</kbd> operator requires a companion for all these things; while it'll specify the thread for the entire subscription, it requires its companion to specify threads for specific operators.</p>
<p>The perfect companion to the <kbd>subscribeOn</kbd> operator is the <kbd>observeOn</kbd> operator. The <kbd>observeOn</kbd> operator specifies the scheduler for all the operators called after it.</p>
<p>Let's modify our program with <kbd>observeOn</kbd> to perform the <kbd>map</kbd> operation in the <kbd>Schedulers.computation()</kbd> and receive the result of the subscription (<kbd>onNext</kbd>) in the <kbd>Schedulers.io()</kbd>:</p>
<pre>    fun main(args: Array&lt;String&gt;) { 
      listOf("1","2","3","4","5","6","7","8","9","10") 
        .toObservable() 
        .observeOn(Schedulers.computation())//(1) 
        .map { 
           item-&gt; 
           println("Mapping $item - ${Thread.currentThread().name}") 
           return@map item.toInt() 
         } 
         .observeOn(Schedulers.io())//(2) 
         .subscribe { 
            item -&gt; println("Received $item - <br/>            ${Thread.currentThread().name}") 
         } 
 
         runBlocking { delay(1000) } 
    } </pre>
<p>The following output clearly shows we're successful in achieving our objective:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img height="408" width="386" src="assets/10acaff9-5525-4572-8318-425df7c4a0de.jpg"/></div>
<p>So, what did we do? We specified the <kbd>computation</kbd> threads for the <kbd>map</kbd> operator by calling <kbd>observeOn(Schedulers.computation())</kbd> just before it, and called <kbd>observeOn(Schedulers.io())</kbd> before subscribe to switch to <kbd>io</kbd> threads to receive the results.</p>
<p>In this program, we did a context switch; we exchanged data with threads and implemented communication in between threads with such an ease, with merely 7-8 lines of code—that's the abstraction schedulers provides us with.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In this chapter, you learned about concurrent execution and parallelism and how to achieve multithreading in RxKotlin. Multithreading is a necessity in today's app driven era, as modern users don't like to wait, or, to be blocked, you need to constantly switch threads to perform computations and UX operations.</p>
<p>In this chapter, you learned how schedulers in RxKotlin can help you, or, rather, how schedulers abstract the complexities of multithreading.</p>
<p>While concurrent execution and parallelism is an essential part of modern application development, testing is probably the most crucial part. We cannot deliver any app without testing it. Agile methodology (though we are not discussing agile here) says we should perform testing repeatedly and with every iteration of our product (application) development.</p>
<p>In the <a href="08299ee7-7cdc-4700-ae32-362b3145d26d.xhtml" target="_blank">Chapter 8</a>, <em>Testing RxKotlin Applications</em>, we will discuss testing. Don't dare miss it out, turn the page right now!</p>


            </article>

            
        </section>
    </body></html>