- en: Chapter 10. Camera and Microphone Support
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover:'
  prefs: []
  type: TYPE_NORMAL
- en: Saving to the camera roll
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reading from the camera roll
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Capturing with the default camera app
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Working with the built-in cameras
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Recording microphone audio
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Playing recorded audio
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The camera and microphone are possibly the two most popular sensors built into
    iOS devices. In fact, iPhone owners rely on the microphone on a daily basis when
    making calls. Those who use Apple's FaceTime depend on both the microphone and
    the camera to keep in touch. And of course, everyone has taken a photo or shot
    a video from time-to-time.
  prefs: []
  type: TYPE_NORMAL
- en: Developers are finding increasingly sophisticated uses for both sensors that
    extend far beyond the functionality provided by Apple's pre-installed applications.
    Image and voice recognition, augmented reality, language translation, and voice
    distortion are just a handful.
  prefs: []
  type: TYPE_NORMAL
- en: Adobe introduced camera and microphone support in AIR 2.6, allowing Flash developers
    to take advantage of both sensors within their apps. While you can work through
    all of this chapter's recipes using Flash Professional CS5.5, those with Flash
    Professional CS5 will be limited to the first recipe, *Saving to the camera roll*.
  prefs: []
  type: TYPE_NORMAL
- en: Saving to the camera roll
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Many iOS applications allow the user to save an image to the camera roll. Drawing
    tools and avatar creators are popular examples, where the user can easily show
    off their creation to friends and family from the device's native photo gallery.
  prefs: []
  type: TYPE_NORMAL
- en: This recipe will show you how to save a snapshot of the stage to the device's
    camera roll.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: From the book's accompanying code bundle, open `chapter10\recipe1\recipe.fla`
    into Flash Professional.
  prefs: []
  type: TYPE_NORMAL
- en: You will find two bitmaps and a movie clip sitting on the stage. The bitmaps
    have been composited to produce a background image, which we will save to the
    camera roll. The movie clip represents a button and will initiate the save when
    pressed.
  prefs: []
  type: TYPE_NORMAL
- en: The button movie clip has an instance name of `saveBtn` and its library symbol
    is linked to a class named `Button`. This class was introduced in the *Handling
    user interaction* recipe from [Chapter 4](ch04.html "Chapter 4. Porting Flash
    Projects to iOS").
  prefs: []
  type: TYPE_NORMAL
- en: Okay, let us write some code.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We will make use of AIR's `CameraRoll` class for this recipe.
  prefs: []
  type: TYPE_NORMAL
- en: Create a document class and name it `Main`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add the following import statements and a member variable of type `CameraRoll:`
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Within the constructor, create a `CameraRoll` object and listen for it dispatching
    `Event.COMPLETE`. Also listen for `MouseEvent.MOUSE_UP` being dispatched from
    the `saveBtn` movie clip:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'When the save button is pressed, we will add a bitmap image of the stage to
    the camera roll. To prevent the button appearing in the captured bitmap image,
    we will hide it from view first. Add a `pressed()` event handler:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Once the bitmap has been successfully added to the camera roll, we will make
    the button visible again. Write a `saved()` event handler for this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Save the class, and when prompted name the file `Main.as`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Move back to your FLA.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Publish the app and deploy it to your device.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Launch the app and press the **SAVE** button. Go to the Photos app where you
    will see your image saved to the camera roll as shown in the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![How to do it...](img/1383_10_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `CameraRoll` class allows access to the device's photo library and belongs
    to the `flash.media` package.
  prefs: []
  type: TYPE_NORMAL
- en: Calling the `CameraRoll.addBitmapData()` method will save a specified bitmap
    to the device. Upon a successful save, `Event.COMPLETE` is dispatched.
  prefs: []
  type: TYPE_NORMAL
- en: For this recipe, we created and passed a `BitmapData` object to the `addBitmapData()`
    method. The `BitmapData` object contained a bitmap representation of the stage,
    which was created by calling the `BitmapData.draw()` method and passing the `stage`
    property to it.
  prefs: []
  type: TYPE_NORMAL
- en: The static `CameraRoll.supportsAddBitmapData` property was also used. It determines
    whether or not saving bitmap data to the device's camera roll is supported for
    your target platform. Although this property returns `true` for all iOS devices,
    it is wise to check if you are writing cross-platform code.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The following information will be of use to you when saving to the camera roll.
  prefs: []
  type: TYPE_NORMAL
- en: Handling a failed save
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Don't assume that a bitmap will always successfully save to the camera roll.
    For example, the device may not have the required storage space available.
  prefs: []
  type: TYPE_NORMAL
- en: When a bitmap cannot be added, the `CameraRoll` object will dispatch `ErrorEvent.ERROR`.
    Querying the `ErrorEvent` object's `text` property retrieves a message associated
    with the error.
  prefs: []
  type: TYPE_NORMAL
- en: Your code should listen for this event and handle any failed attempts at adding
    bitmap data. Perform a search for `flash.media.CameraRoll` within Adobe Community
    Help for a full list of possible errors.
  prefs: []
  type: TYPE_NORMAL
- en: Saving specific display objects
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Although we grabbed the entire stage for this recipe, you can create a bitmap
    image of any display object and add it to the camera roll. Simply create a `BitmapData`
    object and call its `draw()` method, passing your target display object as an
    argument. The `BitmapData` object's dimensions should be made to match that of
    your display object.
  prefs: []
  type: TYPE_NORMAL
- en: Video and the camera roll
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: At present, the AIR SDK does not provide support for adding video content to
    the camera roll.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Reading from the camera roll*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reading from the camera roll
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Depending on the version of the AIR SDK you are using, it is possible to load
    an image from the device's camera roll. AIR for iOS facilitates this by launching
    the native Photos application and allowing the user to select an image. The image
    can then be loaded and added to your display list.
  prefs: []
  type: TYPE_NORMAL
- en: Let us see how to write a simple app that loads an image selected from the camera
    roll.
  prefs: []
  type: TYPE_NORMAL
- en: The steps covered here are applicable only to those using Flash Professional
    CS5.5\. The AIR 2.0 SDK used by Flash Professional CS5 does not feature an API
    for loading images from the camera roll.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: An FLA has been provided as a starting point for this recipe. From the book's
    accompanying code bundle, open `chapter10\recipe2\recipe.fla` into Flash Professional
    CS5.5.
  prefs: []
  type: TYPE_NORMAL
- en: A movie clip with an instance name of `browseBtn` can be found on the stage.
    The clip's library symbol is linked to a class named `Button`, which was introduced
    in the *Handling user interaction* recipe from [Chapter 4](ch04.html "Chapter 4. Porting
    Flash Projects to iOS").
  prefs: []
  type: TYPE_NORMAL
- en: '![Getting ready](img/1383_10_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Let us write some code to let the user browse for, and load an image from the
    camera roll after pressing the `browseBtn` movie clip.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We will make use of several classes, including `CameraRoll, Loader`, and `MediaPromise`.
  prefs: []
  type: TYPE_NORMAL
- en: Create a document class and name it `Main`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Import the required classes and add two member variables—one of type `CameraRoll`
    and the other of type `Loader:`
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Instantiate a `CameraRoll` object and listen for it dispatching `MediaEvent.SELECT`
    and `Event.CANCEL`. Also, listen for the `browseBtn` movie clip being pressed:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'When the `browseBtn` movie clip is pressed, we will hide it from view and also
    launch the native Photos application. Add the following method to handle this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We will make the `browseBtn` movie clip visible again if the user cancels from
    the Photos application:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'If the user makes a selection, then we will create a `Loader` object and start
    loading the photo. Add the `photoSelected()` method to handle this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Finally, write the `photoLoaded()` event handler, which will be called when
    the photo''s image has successfully loaded. This method will re-size and orientate
    the image before adding it to the display list:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Save the class and name the file `Main.as` when prompted.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Also, move back to your FLA and save it too.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Publish the FLA and deploy the resultant `.ipa` file to your device.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Launch the app, tap the **BROWSE** button, and then select an image from the
    camera roll. Your app will load and display the image.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `flash.media.CameraRoll` class allows access to the device's photo library.
  prefs: []
  type: TYPE_NORMAL
- en: Its `browseForImage()` method opens the native Photos application, allowing
    the user to select an image from the device's camera roll. At this point, your
    application will lose focus and will wait in the background.
  prefs: []
  type: TYPE_NORMAL
- en: When a selection is made by the user, your application will regain focus and
    the `CameraRoll` object will dispatch `MediaEvent.SELECT`. If however, the user
    cancels out of the Photos app, then `Event.CANCEL` is dispatched instead.
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, the `browseForImage()` method is called in response to the user
    pressing the **BROWSE** button. However, just before the call is made, the static
    `CameraRoll.supportsBrowseForImage` property is checked. This determines whether
    or not browsing for an image is supported by your target platform. Although the
    property returns `true` for all iOS devices, it is useful when targeting multiple
    platforms.
  prefs: []
  type: TYPE_NORMAL
- en: Once the user has selected an image, the `photoSelected()` event handler is
    called and a `MediaEvent` object is passed to it. From the `MediaEvent` object,
    we retrieve information regarding the selected image by querying its `data` property.
    This returns a `MediaPromise` object, which we pass to a `Loader` object's `loadFilePromise()`
    method to actually load the image. Once complete, the `Loader` object will dispatch
    `Event.COMPLETE`.
  prefs: []
  type: TYPE_NORMAL
- en: The `photoLoaded()` handler captures the `Loader` object's `COMPLETE` event
    and displays the actual image on screen. Images saved to the camera roll can be
    of a much higher resolution than the stage's dimensions and can be either portrait
    or landscape orientation. The `photoLoaded()` method scales the image to fit the
    stage and if it has a landscape aspect ratio, rotates it by 90 degrees.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The `MediaPromise` class also provides a `file` property, which can be used
    to obtain a URL to the selected camera roll image. While this property will be
    valid for certain platforms, such as Android, it will always return `null` on
    iOS. When writing cross-platform code, use `Loader.loadFilePromise()` rather than
    attempting to obtain and pass a URL to `Loader.load()`.
  prefs: []
  type: TYPE_NORMAL
- en: You can obtain more information regarding `flash.media.CameraRoll` and `flash.media.MediaPromise`
    from Adobe Community Help.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When saving photos to a device, iOS embeds additional metadata with the image.
    Depending on the application you are writing, the following information may be
    useful.
  prefs: []
  type: TYPE_NORMAL
- en: Parsing Exif data
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Photos taken on iOS devices adhere to the **Exchangeable image file (Exif)**
    format and can contain thumbnail data and tags of additional information. These
    tags can describe anything ranging from the GPS coordinates associated with the
    image to its orientation.
  prefs: []
  type: TYPE_NORMAL
- en: Although the AIR SDK does not directly provide support for these tags, there
    are some third-party parsers available. Take a look at [http://code.shichiseki.jp/as3/ExifInfo](http://code.shichiseki.jp/as3/ExifInfo)
    and [www.mxml.it/index.php/2010/01/04/reading-exif-data-with-actionscript-30](http://www.mxml.it/index.php/2010/01/04/reading-exif-data-with-actionscript-30).
    Additionally, the Exif specification can be found at [www.exif.org/exif2-2.pdf](http://www.exif.org/exif2-2.pdf).
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Saving to the camera roll*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Capturing with the default camera app
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Most iOS devices have a built-in camera. More recent models have two—one mounted
    on the rear and another on the front. Users can capture photos and shoot video
    using the camera app that comes pre-installed. Third-party applications can also
    utilize the camera with many applications simply launching the default camera
    app for this purpose. Once the user has finished with the camera, the third-party
    app is able to access the photo or video that was taken.
  prefs: []
  type: TYPE_NORMAL
- en: AIR 2.6 and above provides the `CameraUI` class, making it possible to launch
    and use the default camera app. This recipe will show you how to do this from
    Flash Professional CS5.5\. AIR 2.0 and Flash CS5 do not provide camera support.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You will need a device that features a camera. The fourth-generation iPod touch,
    iPad 2, and all models of iPhone have cameras.
  prefs: []
  type: TYPE_NORMAL
- en: From the book's accompanying code bundle, open `chapter10\recipe3\recipe.fla`
    into Flash Professional CS5.5.
  prefs: []
  type: TYPE_NORMAL
- en: You will find a movie clip named `captureBtn` and a dynamic text field named
    `output` positioned on the stage. The button clip's library symbol is linked to
    a class named `Button`, which was introduced in the *Handling user interaction*
    recipe from [Chapter 4](ch04.html "Chapter 4. Porting Flash Projects to iOS").
  prefs: []
  type: TYPE_NORMAL
- en: We will create a simple app that launches the default camera app when the button
    is pressed, allowing the user to capture a photo.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let us write the ActionScript required to do this.
  prefs: []
  type: TYPE_NORMAL
- en: Create a document class and name it `Main`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Import the various classes required for this recipe and create a member variable
    of type `CameraUI:`
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Within the constructor, instantiate a `CameraUI` object and listen for it dispatching
    `MediaEvent.COMPLETE` and `Event.CANCEL`. Also, listen for the user pressing the
    `captureBtn` movie clip:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'When the button is pressed, we will launch the camera app allowing the user
    to take a photo. Add a `pressed()` event handler for this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'When the user returns from the camera app, we will check that the photo was
    successfully obtained and write confirmation to the `output` text field. Handle
    this by adding a `captured()` method to your class:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The user can cancel from the default camera app, discarding any photo that
    they may have taken. Add an event handler for this, stating within the `output`
    text field that the operation was cancelled:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Save the class and name the file `Main.as` when prompted.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Move back to your FLA and save it too.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Publish the app and launch it once you have deployed the IPA to your device.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Tap the **CAPTURE** button to launch the default camera app. Take a photo and
    press the **Use** button. A message will be displayed confirming that the photo
    was successfully captured and is now accessible by your app.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `flash.media.CameraUI` class allows access to the default camera app. Calling
    its `launch()` method will open the camera app and allow the user to capture either
    an image or video. At this point, your application will lose focus and will wait
    in the background. Once the user has finished, your application will regain focus
    and the `CameraUI` object will dispatch `MediaEvent.COMPLETE`. If the user cancels
    out of the camera app, then `Event.CANCEL` will be dispatched instead.
  prefs: []
  type: TYPE_NORMAL
- en: When calling `launch()`, you must pass a constant defined by `flash.media.MediaType`,
    specifying whether you wish to take a photo or shoot video. For this recipe, we
    passed `MediaType.IMAGE`.
  prefs: []
  type: TYPE_NORMAL
- en: The captured media is accessed using the `data` property of the `COMPLETE` event's
    `MediaEvent` object. This property is an instance of the `MediaPromise` class
    and can be used to load the image or even access its data.
  prefs: []
  type: TYPE_NORMAL
- en: Notice the use of the static `isSupported` property within the `pressed()` event
    handler. It determines whether or not access to the default camera app is supported
    by the device that is currently running your app.
  prefs: []
  type: TYPE_NORMAL
- en: You can obtain more information regarding `flash.media.CameraUI` and `flash.media.MediaPromise`
    from Adobe Community Help.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The following information will help complete your understanding.
  prefs: []
  type: TYPE_NORMAL
- en: Handling errors
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A `CameraUI` object will dispatch an error if the default camera app is already
    in use. You can capture this event by listening for `flash.events.ErrorEvent.ERROR`.
    Query the `ErrorEvent` object's `errorID` and `text` properties to discover more
    about the error.
  prefs: []
  type: TYPE_NORMAL
- en: Displaying the captured image
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We didn't go so far as to actually load and display the photo that was taken
    with the default camera app. This can be achieved by creating a `Loader` object
    and passing the photo's `MediaPromise` object to the loader's `loadFilePromise()`
    method. Refer to the previous recipe, *Reading from the camera roll*, for more
    detail.
  prefs: []
  type: TYPE_NORMAL
- en: Saving the captured image to the camera roll
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Unlike some other mobile operating systems, the captured photo isn't actually
    stored by iOS in the camera roll. If you want the photo to appear in the camera
    roll, you will need to manually add it yourself. This is done by using a `Loader`
    object to load your `MediaPromise` object's binary data, then writing its bitmap
    data to the camera roll using a `CameraRoll` instance.
  prefs: []
  type: TYPE_NORMAL
- en: Refer to the *Reading from the camera roll* and the *Saving to the camera roll*
    recipes from earlier in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Capturing video
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'While we captured a photo using the default camera app, a simple code change
    is all that is required to shoot video instead. You can see this in the following
    code snippet where `MediaType.VIDEO` is passed to the `CameraUI` object''s `launch()`
    method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: It is not possible for the user to change between photo and camera mode while
    using the default camera app launched from AIR. You can only use the camera app
    for capturing a single media type at any one time.
  prefs: []
  type: TYPE_NORMAL
- en: Take a look at the *Playing local H.264 video* recipe from [Chapter 12](ch12.html
    "Chapter 12. Working with Video and Audio") to see how to playback your captured
    video.
  prefs: []
  type: TYPE_NORMAL
- en: Reading the captured data
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: It is also possible to directly access the binary data that represents the image
    or video captured from the camera. This is useful for applications that perhaps
    need to write the media directly to the device's file system, upload the data
    to a server, or to simply parse or alter the data in some way. The `MediaPromise`
    object provides an `open()` method that can be used to access the data. You can
    then read it into a `ByteArray` object.
  prefs: []
  type: TYPE_NORMAL
- en: 'To do this within this recipe''s example, add the following member variables:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Add the following code snippet at the end of the `captured()` event handler:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Now write an event handler to copy the data into a `ByteArray` object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Also include the following import statements:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: You will now have access to the media's binary data within the `dataCaptured()`
    method.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Saving to the camera roll*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Reading from the camera roll*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Working with the built-in cameras*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Working with the built-in cameras
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: While launching and using the default camera app provides the user with the
    native camera experience that they are familiar with, it may not be appropriate
    for all types of applications. In addition to `CameraUI`, AIR also provides the
    `Camera` class, which receives the video data captured by the device's on-board
    camera, allowing it to be directly displayed within your app.
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, you will learn how to receive a video stream from the camera
    and display it within your app using Flash Professional CS5.5\. The `Camera` class
    is not supported by Flash CS5 and AIR 2.0 for iOS.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You will need a device that features a camera. The fourth generation iPod touch,
    iPad 2, and all models of iPhone have cameras.
  prefs: []
  type: TYPE_NORMAL
- en: From the book's accompanying code bundle, open `chapter10\recipe4\recipe.fla`
    into Flash Professional CS5.5.
  prefs: []
  type: TYPE_NORMAL
- en: A landscape aspect ratio has been set for the stage and this has also been reflected
    within the FLA's AIR for iOS settings.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Follow these steps to receive video from the camera and display it on the stage:'
  prefs: []
  type: TYPE_NORMAL
- en: Create a document class and name it `Main`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Declare two member variables—one of type `Camera` and the other of type `Video:`
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Within the constructor, obtain a reference to the device''s default camera
    and attach it to a `Video` object. Also, add the `Video` object to the stage allowing
    the video data to be viewed by the user:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Save the class as `Main.as`. Also move back to your FLA and save it too.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Publish the FLA and test it on your device.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Hold the device in landscape orientation. Video from the rear-facing camera
    will be rendered to the screen.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `flash.media.Camera` class is a singleton, meaning only one instance of
    it can exist. To guarantee this, the class has no public constructor. Instead,
    access to the camera is obtained by calling the `Camera` class' `getCamera()`
    static method, which returns the `Camera` instance for you to work with.
  prefs: []
  type: TYPE_NORMAL
- en: Once the `Camera` instance is obtained, the capture mode to be used by the camera
    can be specified. This is done by calling `setMode()` and passing to it a width,
    height, and target frame rate. For this recipe, we passed the stage's dimensions
    and frame rate. If the specified requirements cannot be met by the camera, then
    it will use a mode which is the closest match.
  prefs: []
  type: TYPE_NORMAL
- en: In order to display the live video being streamed from the camera, it must be
    attached to a `Video` object. The `flash.media.Video` class inherits `DisplayObject`
    allowing any `Video` object to be added to the display list. First the `Video`
    object is created and a width and height for it are passed to its constructor—we
    set its dimensions to match those used by the camera. Then a call to `attachCamera()`
    is made, providing the `Video` object with access to the `Camera` object's video
    stream. Finally, the `Video` object is added to the display list by calling `addChild()`.
  prefs: []
  type: TYPE_NORMAL
- en: Before attempting to connect to a camera, you should first check that one is
    available. The `Camera.names` static property returns an array of available cameras.
    We checked at the beginning of the document class' constructor that the array's
    length was greater than `0` before proceeding. Alternatively, check for `null`
    being returned by `Camera.getCamera()`.
  prefs: []
  type: TYPE_NORMAL
- en: For more information regarding camera support, perform a search for `flash.media.Camera`
    and `flash.media.Video` within Adobe Community Help.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let us look at some additional options when capturing live video from the camera.
  prefs: []
  type: TYPE_NORMAL
- en: Portrait mode
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'On iOS, a `Camera` object captures video in landscape orientation. If your
    application uses a portrait aspect ratio, then you will need to swap the camera''s
    capture dimensions and also rotate and re-position the `Video` object. To do this,
    make the following changes to this recipe''s constructor:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Remember to change the stage's dimensions and update the AIR for iOS settings
    to use a portrait aspect ratio. There is a performance hit when capturing portrait
    video due to the rotation applied to the `Video` object. Where possible, try to
    use landscape for applications that use the camera.
  prefs: []
  type: TYPE_NORMAL
- en: Selecting a camera
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `Camera.getCamera()` static method connects to the rear-facing camera by
    default. For devices that support more than one, you can specify a camera by passing
    a string representing the zero-based index position within the array specified
    by `Camera.names`. For example, the following code uses the iPhone 4/4S''s front-facing
    camera:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: It is important that you pass a string rather than an integer when making this
    call.
  prefs: []
  type: TYPE_NORMAL
- en: Only one camera can be active at any one time on iOS. If you connect to a second
    camera, then the previous camera's connection will be dropped.
  prefs: []
  type: TYPE_NORMAL
- en: Grabbing a bitmap image
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'It is possible to capture a bitmap image from the camera''s live video stream.
    The following code extracts the bitmap data from the video''s current frame and
    stores it within a `Bitmap` object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, the `BitmapData` object's dimensions are made to match those
    of the video. The current frame is then drawn into the `BitmapData` object, which
    is used to create the actual bitmap.
  prefs: []
  type: TYPE_NORMAL
- en: Live streaming
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: For this recipe, we simply used the camera's video stream locally on the device.
    However, by using the `NetConnection` and `NetStream` classes, it is possible
    to transmit the video stream to a Flash Media Server, where it can be broadcast
    to other clients. This is ideal for live video chat applications or other collaborative
    projects.
  prefs: []
  type: TYPE_NORMAL
- en: Both classes belong to the `flash.net` package. More detail is available from
    Adobe Community Help.
  prefs: []
  type: TYPE_NORMAL
- en: Using the stage
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: It is also possible to place and size a `Video` object on the stage using the
    Flash IDE rather than ActionScript. Simply right-click on the **Library** panel
    and select **New Video** from the context menu. From the **Video Properties**
    panel that appears, click on the **Video (ActionScript-controlled)** radio button
    before clicking on **OK**. A video clip will appear in the library, which you
    can drag to the stage and assign an instance name to.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Saving to the camera roll*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Capturing with the default camera app*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Recording microphone audio
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: AIR provides an API that enables an application to connect to the built-in microphone.
    The microphone's raw data can be obtained, recorded for later use, processed as
    it is received, or routed to the device's speakers.
  prefs: []
  type: TYPE_NORMAL
- en: This recipe will show you how to use the `Microphone` and `ByteArray` classes
    to capture and record audio. You will need Flash Professional CS5.5 as microphone
    access for iOS is not supported by CS5 and AIR 2.0.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: While all recent models from the iOS family contain a built-in microphone, previous
    generations of the iPod touch don't. The second and third-generation devices do,
    however, provide support for an external microphone, which can be used for this
    recipe.
  prefs: []
  type: TYPE_NORMAL
- en: From the book's accompanying code bundle, open `chapter10\recipe5\recipe.fla`
    into Flash Professional CS5.5.
  prefs: []
  type: TYPE_NORMAL
- en: Sitting on the stage you will find a dynamic text field with an instance name
    of `output` and three movie clips. Two of the movie clips represent buttons and
    are named `recordBtn` and `stopBtn` respectively. The `stopBtn` clip is positioned
    directly behind the `recordBtn` clip but sits on its own timeline layer for easy
    access. The third movie clip is named `micStatus` and covers the entire background.
    It is used to indicate when recording is taking place.
  prefs: []
  type: TYPE_NORMAL
- en: The library symbols for `recordBtn` and `stopBtn` are linked to a base class
    named `Button`. This class was introduced in the *Handling user interaction* recipe
    from [Chapter 4](ch04.html "Chapter 4. Porting Flash Projects to iOS").
  prefs: []
  type: TYPE_NORMAL
- en: We will add ActionScript to start recording data from the microphone when the
    user taps the `recordBtn` movie clip. Audio capture will end when `stopBtn` is
    pressed. To give feedback to the user that recording is taking place, we will
    move the `micStatus` movie clip's `playhead` to frame `2`. The text field will
    be used to output confirmation that audio was successfully recorded.
  prefs: []
  type: TYPE_NORMAL
- en: This recipe will concentrate on the recording of microphone audio. We will cover
    playback of the audio in the next recipe.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now let us write the ActionScript for this. Follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Create a document class and name it `Main`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Import the various classes required for this recipe and create two member variables—one
    to reference the device''s microphone and another to store data captured from
    it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Within the constructor, set up the movie clips and create a connection to the
    device''s microphone:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Add a handler for each button being pressed:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next add a method that sets up the microphone and starts listening for live
    audio data. We will also instantiate a `ByteArray` object named `soundData`, which
    will be used to store the captured data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Add an event handler that gets called every time audio data is available from
    the microphone. We will write a maximum of 2 MB of this audio data to our `ByteArray`
    object for later use:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Finally add a method that stops listening for live audio data from the microphone.
    The total number of bytes recorded will be written to the `output` text field:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Save the class and name its file `Main.as`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Move back to your FLA and save it.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Publish the FLA and deploy the resultant `.ipa` file to your device.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Launch the app, tap the **RECORD** button and start speaking into the microphone.
    When you are finished, tap the **STOP** button.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The amount of audio data (in bytes) that was recorded will be written to the
    screen.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Microphone support is provided by the `flash.media.Microphone` class. To connect
    to the device's microphone, make a call to the static `Microphone.getMicrophone()`
    method, which will return a new `Microphone` instance. If a microphone can't be
    found, then `null` will be returned instead.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code snippet is the call being made from within our document
    class'' constructor:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: Once you have a `Microphone` object, you can adjust the audio data that will
    be received. We did this within the `startRecording()` method by setting the `Microphone`
    object's gain and sample rate.
  prefs: []
  type: TYPE_NORMAL
- en: The gain is used to boost the microphone's signal and is set using the `gain`
    property. A value of `100` was used to maximize its loudness.
  prefs: []
  type: TYPE_NORMAL
- en: The sample rate dictates the quality of the audio that is captured and is specified
    by the `rate` property. Higher sample rates produce clearer audio but demand more
    from the CPU and require increased space to store. We set the `rate` property
    to `44`, specifying an actual sample frequency of 44 kHz. In other words, we will
    capture sound from the microphone 44,100 times per second! This is the highest
    permitted sample rate and records the clearest sound.
  prefs: []
  type: TYPE_NORMAL
- en: 'To actually start capturing audio from the microphone, add a `SampleDataEvent.SAMPLE_DATA`
    listener to the `Microphone` object. The `SAMPLE_DATA` event is continually dispatched
    as the microphone''s audio buffer fills. We added the `SAMPLE_DATA` event listener
    within the `startRecording()` method immediately after setting the gain and sample
    rate:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'Each `SampleDataEvent` object has a `data` property, which is a `ByteArray`
    containing the current audio sampled from the microphone. Recording the audio
    is a simple case of copying this temporary data into a more permanent `ByteArray`
    object. You can see the code for this within the `SampleData()` event handler,
    where a loop is used to extract the sampled data and write it to the `soundData`
    member variable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: Each sample is represented by a floating point value. The loop, therefore, reads
    a float from the audio buffer and writes it to the `soundData` member variable.
    This process continues until the data stored within the `SampleDataEvent` object
    is empty.
  prefs: []
  type: TYPE_NORMAL
- en: To prevent the app from completely exhausting the device's memory, the `sampleData()`
    handler checks the size of the `soundData` member variable. If it exceeds 2 MB
    (2,097,152 bytes) in size, then recording is stopped and the number of recorded
    bytes is written to the `output` text field.
  prefs: []
  type: TYPE_NORMAL
- en: Audio capture is stopped by removing the `SAMPLE_DATA` event listener from the
    `Microphone` object. Take a look at the `stopRecording()` method to see this.
  prefs: []
  type: TYPE_NORMAL
- en: For more information regarding audio capture, perform a search for `flash.media.Microphone,
    flash.events.SampleDataEvent`, and `flash.utils.ByteArray` within Adobe Community
    Help.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Following are some additional options open to you when recording from the microphone.
  prefs: []
  type: TYPE_NORMAL
- en: Microphone activity
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: You can determine the amount of sound that the microphone is detecting by querying
    the `Microphone` object's `activityLevel` property. This will return a value ranging
    from `0` to `100`, with `0` being returned when no sound is detected.
  prefs: []
  type: TYPE_NORMAL
- en: It is also possible using the `setSilenceLevel()` method to specify an activity
    level threshold that must be met before audio is accepted by the microphone. The
    higher the activity level that is passed as a parameter, the louder an audio source
    must be before it is detected. This method also accepts an optional second parameter,
    which specifies the number of milliseconds of inactivity that must pass before
    sound is considered to have stopped.
  prefs: []
  type: TYPE_NORMAL
- en: 'As an example, add the following to your `startRecording()` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'Now add the following event handler:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, add the following import statement:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: Test these changes on your device. Your app won't dispatch `SAMPLE_DATA` events
    until the microphone's silence level is exceeded. Also, once activated, the microphone
    will deactivate again if silence occurs for more than two seconds.
  prefs: []
  type: TYPE_NORMAL
- en: Live streaming
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The microphone's audio data was simply used locally in this recipe. However,
    it is possible, using the `NetConnection` and `NetStream` classes, to transmit
    the data to a Flash Media Server for broadcast to other clients. Additional detail
    can be found on Adobe Community Help by searching for both classes, which belong
    to the `flash.net` package.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Playing recorded audio*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Playing recorded audio
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: After capturing the microphone's raw audio data, you will need a means of playing
    it back. This recipe will show you how to send the data to your device's speaker.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If you have completed the *Recording microphone audio* recipe, then you can
    work from the code you wrote for it. Alternatively, from the book's accompanying
    code bundle, open `chapter10\recipe6\recipe.fla` and use it as a starting point.
  prefs: []
  type: TYPE_NORMAL
- en: Currently the FLA will record audio from the microphone and store it within
    a member variable of type `ByteArray` named `soundData`. We will add code that
    plays back the audio once the user has finished recording it.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The following changes are required to read and playback the recorded audio:'
  prefs: []
  type: TYPE_NORMAL
- en: Open `Main.as`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Import the following three classes:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Also add a `Sound` and `SoundChannel` member variable:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The `stopRecording()` method will need to make an additional call to initiate
    playback of the recorded audio. Add the following line at the end of the method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now write the `playRecording()` method, which will initiate playback of the
    audio:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Add a method that periodically pulls data from the `soundData` object for playback:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Finally, reset the button movie clips once audio playback is complete:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Save your changes to the class.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Publish the FLA and test it on your device.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Start recording some audio and when you are finished, tap the **STOP** button.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The recorded audio will be played back through your device's speaker. If you
    don't hear anything then increase your speaker's volume and try again.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Both the `Sound` and `SoundChannel` classes are used for audio playback.
  prefs: []
  type: TYPE_NORMAL
- en: 'We create a `Sound` object and add a `SAMPLE_DATA` event listener to it. This
    event is dispatched when there is no more audio data for the `Sound` object to
    play:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'A call is also made to the object''s `play()` method, which returns a `SoundChannel`
    instance allowing playback to be monitored. We listen for the `SoundChannel` object
    dispatching `SOUND_COMPLETE` to determine when audio playback has ended:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: Initially the `Sound` object doesn't contain any audio data. The data from the
    entire recording is instead held by the `soundData` member variable, which is
    a `ByteArray`. As the `Sound` object has no audio data to play, it immediately
    dispatches a `SAMPLE_DATA` event, which is captured by the `playSampleData()`
    handler.
  prefs: []
  type: TYPE_NORMAL
- en: Within `playSampleData()`, we extract some audio data from the `soundData` member
    variable and feed it to the `Sound` object. This provides the `Sound` object with
    enough data to start playing audio. Each time its buffer runs low, it will dispatch
    another `SAMPLE_DATA` event and we will feed it more data. This process continues
    until the entire recording has been played.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is the code from the `playSampleData()` handler that is responsible
    for writing data to the `Sound` object''s buffer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: The `Sound` object's buffer is accessed through the `SampleDataEvent` parameter's
    `data` property. We, therefore, take a sample from the `soundData` member variable
    and write it to the `data` property's `ByteArray`. The `readFloat()` method is
    used to read a sample from `soundData`, while `writeFloat()` is used to write
    the same sample into the `Sound` object's buffer—each sample is represented by
    a floating point value.
  prefs: []
  type: TYPE_NORMAL
- en: However, we don't just write a single sample to the buffer—it would instantly
    empty again. Instead, we take the opportunity to write 8192 stereo samples, providing
    the object with 64 KB of audio data. Typically you can write between 2048 and
    8192 stereo samples at a time. However, a runtime exception will be thrown if
    you attempt to write more than 64 KB of data to the buffer.
  prefs: []
  type: TYPE_NORMAL
- en: 'To create a stereo sample, we write each recorded sample to the `Sound` object
    twice:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: While the microphone records monophonic data, your device is capable of stereo
    output. Therefore, when writing audio data to a `Sound` object, you need to write
    the sample to both the left and right channels. The first call to `writeFloat()`
    sends the sample to the left channel, while the second call sends it to the right.
  prefs: []
  type: TYPE_NORMAL
- en: For more information, perform a search for `flash.media.Sound` and `flash.media.SoundChannel`
    within Adobe Community Help.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There are a few final pieces of information related to microphone audio playback.
  prefs: []
  type: TYPE_NORMAL
- en: Working with lower sample rates
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The `Sound` class uses a sample rate of 44 kHz. If audio from the microphone
    was captured at an alternative frequency, then you will need to upscale it from
    the lower rate to 44 kHz before feeding it to the `Sound` object.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, if the `Microphone` object''s `rate` property was set to a frequency
    of 22 kHz when recording, you would need to adjust the playback loop within `playSampleData()`
    to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: Essentially the same sample is written to each channel twice, which up-scales
    the 22 kHz recording to 44 kHz. Notice that 4096 iterations of the loop are performed
    compared to 8192 previously. This is to ensure that no more than 64 KB of audio
    data is written to the `Sound` object's buffer, which is its upper limit.
  prefs: []
  type: TYPE_NORMAL
- en: The example provided here is somewhat simplistic and not recommended for the
    majority of the sample rates. A more thorough approach is to generate the missing
    data by interpolating between existing samples. In most cases, it is likely that
    you will want to avoid re-sampling your audio in realtime as doing so can be computationally
    expensive.
  prefs: []
  type: TYPE_NORMAL
- en: 'Additional detail regarding sample rate conversion can be found on Wikipedia:
    [http://en.wikipedia.org/wiki/Sample_rate_conversion](http://en.wikipedia.org/wiki/Sample_rate_conversion).
    Also, take a look at the SoundTouch AS3 library, which allows real time audio
    processing using ActionScript 3.0: [https://github.com/also/soundtouch-as3](http://https://github.com/also/soundtouch-as3).'
  prefs: []
  type: TYPE_NORMAL
- en: Saving captured data
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This and the previous recipe have simply held the recorded audio data in memory.
    Your application, however, may require recordings to be persistent. Using the
    classes provided in the `flash.filesystem` package, you can write binary data
    to your device and read it back later.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code snippet saves our recorded audio to the device:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'Retrieving the data is just as easy:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: Data written to the file system can only be accessed by the app that placed
    it there. When the app is uninstalled, any data belonging to it is deleted.
  prefs: []
  type: TYPE_NORMAL
- en: Exporting as WAV or MP3
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: For this and the previous recipe, we have simply worked with the raw PCM data
    captured from the microphone. However, you may want to save your data in common
    audio formats such as MP3 and WAV. Unfortunately, AIR does not provide APIs for
    exporting in either of these formats. Instead, you will need to rely on third-party
    libraries.
  prefs: []
  type: TYPE_NORMAL
- en: 'WAV encoding is provided by the `WAVWriter` class, which is available at: [http://code.google.com/p/ghostcat/source/browse/trunk/ghostcatfp10/src/ghostcat/media/WAVWriter.as?spec=svn424&r=424](http://code.google.com/p/ghostcat/source/browse/trunk/ghostcatfp10/src/ghostcat/media/WAVWriter.as?spec=svn424&r=424).'
  prefs: []
  type: TYPE_NORMAL
- en: 'MP3 encoding can be achieved using the Shine library: [https://github.com/kikko/Shine-MP3-Encoder-on-AS3-Alchemy](http://https://github.com/kikko/Shine-MP3-Encoder-on-AS3-Alchemy).'
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Recording microphone audio*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Controlling audio playback, [Chapter 12](ch12.html "Chapter 12. Working with
    Video and Audio")*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Referencing an app''s common directories, [Chapter 13](ch13.html "Chapter 13. Connectivity,
    Persistence, and URI Schemes")*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Writing files, [Chapter 13](ch13.html "Chapter 13. Connectivity, Persistence,
    and URI Schemes")*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
