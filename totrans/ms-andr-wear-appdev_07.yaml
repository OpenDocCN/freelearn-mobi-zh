- en: Chapter 7.  Voice Interactions, Sensors, and Tracking
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '|   | *"All I have is a voice."* |   |'
  prefs: []
  type: TYPE_TB
- en: '|   | --*W. H. Auden* |'
  prefs: []
  type: TYPE_TB
- en: In this chapter, we cover the voice capabilities offered by the Wear API and
    define voice actions interfacing with our `Today` app from the previous chapter.
    We also introduce device sensors and discuss how they can be used to track data.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The code accompanying this chapter is available for reference on GitHub ([https://github.com/siddii/mastering-android-wear/tree/master/Chapter_7](https://github.com/siddii/mastering-android-wear/tree/master/Chapter_7)).
    For the sake of brevity, only code snippets are included as needed. The reader
    is encouraged to download the referenced code from GitHub and follow along as
    they progress through the chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Voice capabilities
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'If you lived your adolescence through the eighties, chances are you got all
    your knowledge of wearable device voice interactions from this guy:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Voice capabilities](img/image00194.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Three decades on, here you are, itching to find out whether the `Wear` API offers
    a system-provided voice action that enables you to summon your car. I'm afraid,
    not yet. The complete list of system-provided voice actions is presented in the
    subsection that follows.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: You can visit the Android's developer site ([https://developer.android.com/training/wearables/apps/voice.html](https://developer.android.com/training/wearables/apps/voice.html))
    for more insight on the voice capabilities for your wearable app.
  prefs: []
  type: TYPE_NORMAL
- en: By system-provided voice actions, we mean the voice actions that are built into
    the Wear platform, that is, provided out of the box for developer use.
  prefs: []
  type: TYPE_NORMAL
- en: In contrast, the term app-provided voice actions refer to those that are specific
    to your app.
  prefs: []
  type: TYPE_NORMAL
- en: System-provided voice actions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: System-provided voice actions must be filtered according to the specific activity
    you want to start when the phrase corresponding to the voice action is spoken.
    For instance, note to self.
  prefs: []
  type: TYPE_NORMAL
- en: 'The Wear platform supports the following voice intents:'
  prefs: []
  type: TYPE_NORMAL
- en: Take a note
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Call a car/taxi
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Set alarm
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Set timer
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Start/stop a run
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Start/stop a bike ride
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Start stopwatch
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Start/stop a run
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Start/stop a workout
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Show step count
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Show heart rate
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: App-provided voice actions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Depending on your needs, the system-provided voice actions may not be enough.
    In that case, you can choose to register a start action for your app the same
    way you register a launcher icon on a handheld.
  prefs: []
  type: TYPE_NORMAL
- en: 'To start `TodayActivity` using a voice action, specify a label attribute with
    a text value set to whatever you say after the `Start` keyword. In this sample
    code, we use our app name as the label attribute. The existence of an intent-filter
    tag recognizes the voice action `Start Today` and launches the `TodayActivity`
    activity:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: New feature - adding to-do items through voice commands
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's get ready to write some code. In the last chapter, we augmented our `Today`
    app to allow us to add to-do items through a paired handheld app. The wearable
    then surfaced notifications based on configured contexts.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let's spice that up by adding voice interactions to the mix. We'll use
    the wearable app to take to-do notes through voice commands. This will involve
    extending the context-aware notifications feature we implemented with the ability
    to add to-do items using voice inputs. Furthermore, we will supply the context
    along with the to-do item.
  prefs: []
  type: TYPE_NORMAL
- en: For example, if we were to say "home make dinner", our wearable app will create
    a to-do item named *Make dinner* and associate it with the `Home` context. In
    the same way, if we were to say "work set up monthly review meeting", the app
    will create a to-do item named *Set up monthly review meeting* and associate it
    with the `Work` context.
  prefs: []
  type: TYPE_NORMAL
- en: 'A few things to keep in mind before we step through the code:'
  prefs: []
  type: TYPE_NORMAL
- en: At the time of this writing, Android Wear emulators do not support voice inputs.
    So we opted to use a physical wear device.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now, if you recall, we had mentioned previously that we don't really need a
    physical device to build Android Wear apps. While that is true for the most part,
    there are cases where the emulators cannot emulate physical device behaviors such
    as voice inputs, motion sensing, and so on. In these cases, we really have no
    option besides getting hold of a physical device for a fuller Android wear development
    experience. Besides, if you're serious about Android Wear development, you might
    as well consider getting a physical device because it really helps speed up your
    development.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is important to note that while voice interactions are not presently supported
    in Android Wear emulators, Google might up their support for voice interactions
    in the future. We'll be keeping an eye on that.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Add to-do Item - a new action in the wearable app
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let''s get started. One of the first things we will do is add an `Add Todo
    Item` action to our `arrays.xml` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'This newly configured action is now displayed on our screen, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Add to-do Item - a new action in the wearable app](img/image00195.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: The AddTodoItem activity in the wearable app
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We wire in the handler for the selection of the `AddTodoItem` activity:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Clicking on the **Add Todo Item** action has the following effect:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The AddTodoItem activity in the wearable app](img/image00196.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Handling speech inputs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The `onActivityResult` method callback fires when the speech recognizer returns
    with the voice input intent. Note how we extract the spoken text and then call
    the `GoogleApiClient` API if the voice command begins with one of our predefined
    contexts, namely `home` or `work`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Android Wear parses the speech input and presents the spoken text as a confirmation,
    as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Handling speech inputs](img/image00197.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Once `GoogleClient` is connected, that is, the `onConnected` handler fires,
    we extract the `todoItem` text after excluding the context (`home` or `work`)
    and send the to-do item as a message to the handheld app using the `Wearable Data`
    API:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Handheld app
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Over on the handheld app, we implement the `onMessageReceived` handler to process
    the message received from the wearable. Remember, the handheld app is where we
    do the heavy-lifting work. In this case, it is the creation of a to-do item:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'The added to-do item is displayed in the to-do list on our handheld''s `Today
    - Todos` app, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Handheld app](img/image00198.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Motion sensors
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Motion sensors let us monitor the motion of a device through space, such as
    a rotation, swing, shake, or tilt. The movement may be relative to its immediate
    environment as is the case when you mimic a steering wheel in a car simulation.
    In this case, we monitor its motion relative to its own frame of reference or
    that of the application running on it.
  prefs: []
  type: TYPE_NORMAL
- en: However, the movement may also be relative to the environment surrounding the
    device, namely the world. An example of the latter is determining absolute speed
    from inside a moving vehicle. The device may be stationary inside the vehicle,
    but it is moving with respect to the earth at the same speed as the vehicle itself.
  prefs: []
  type: TYPE_NORMAL
- en: The Android platform lets us monitor the motion of a device using a broad array
    of sensors—some are hardware-based, such as the gyroscope and accelerometer. Others
    are software-based or they may be hardware-based but dependent on other hardware
    sensors. Examples are the rotation vector sensor, the gravity sensor, the significant
    motion sensor, the step counter sensor and the step detector sensor. You can read
    all about these on the developers site ([https://developer.android.com/guide/topics/sensors/sensors_motion.html](https://developer.android.com/guide/topics/sensors/sensors_motion.html)).
  prefs: []
  type: TYPE_NORMAL
- en: Our concern in this section is to provide a very brief treatment of two hardware
    sensors that are at the very heart of all motion sensing the gyroscope and the
    accelerometer. Understanding the principles underlying these sensors will give
    us an appreciation for the physics that pervades the behavior of all motion sensors
    and will leave us with an intuitive sense of how to go about solving our application
    problems through the indirect use of these sensors via the API available to us.
  prefs: []
  type: TYPE_NORMAL
- en: Gyroscope
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A gyroscope is, at its most basic level, a device consisting of a wheel or disk
    mounted so that it can spin freely about an axis without being influenced by the
    orientation of the mount that encloses it.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following image helps us better visualize the construction:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Gyroscope](img/image00199.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: For the purposes of gaining an intuitive understanding, we just need to digest
    the fact that the properties of a gyroscope are only manifested while the rotor
    (disk) is rotating about its axis. When the disk is not rotating, the device does
    not exhibit any useful properties. But when rotating, the orientation of this
    axis is unaffected by the tilting or rotation of the mounting. This is in accordance
    with the conservation of angular momentum, and in essence, this is what makes
    a gyroscope useful for measuring or maintaining orientation.
  prefs: []
  type: TYPE_NORMAL
- en: Accelerometer
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: An accelerometer is an instrument for measuring acceleration, typically that
    of an automobile, ship, aircraft, or spacecraft, or that involved in the vibration
    of a machine, building, or other structure.
  prefs: []
  type: TYPE_NORMAL
- en: Accelerometers find application in many fields of science and industry. For
    example, accelerometers are used to detect and monitor vibrations in rotating
    machinery. They are also used in tablets and digital cameras to ensure that images
    are always displayed upright on screen.
  prefs: []
  type: TYPE_NORMAL
- en: In the domain of wear devices, an acceleration sensor measures the acceleration
    applied to the device, which includes the forces of gravity. In general, the accelerometer
    is typically a good choice if you are monitoring device motion. It is available
    in almost every Android-powered handheld and tablet. It consumes significantly
    less power than the other motion sensors.
  prefs: []
  type: TYPE_NORMAL
- en: New feature - tracking our steps
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Everyone loves step counters. How about we build one for our wearable device?
    Not much to talk about here, so let's dive into the code.
  prefs: []
  type: TYPE_NORMAL
- en: Add to-do item - a new action in the wearable app
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The first thing we will do here is to add a menu `item` to the wearable app.
    Let''s call it `Step Count`. Our changes to `arrays.xml` file would be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'This action should now show up on the wearable app, as shown in the following
    figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Add to-do item - a new action in the wearable app](img/image00200.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Click on the `Step Count` menu item to launch the corresponding `StepCounterActivity`
    activity. The code for that class is given here. Note how the activity implements
    the `SensorEventListener` class. We hook up the correct sensor type using the
    `SensorManager` class in the `onCreate` handler for this activity. Take note of
    the other handlers you would expect this activity to be associated with owing
    to its implementation of the `SensorEventListener` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'This is how our new activity appears on the wearable device:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Add to-do item - a new action in the wearable app](img/image00201.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: As shown in the preceding code, the type of sensor we use here is denoted by
    the `TYPE_STEP_COUNTER` constant of the `Sensor` class. This type of sensor gets
    the number of steps that the user has taken since the last reboot of the wearable
    device. The important thing to remember about this sensor type is that applications
    need to stay registered because the step counter does not track steps if it is
    not activated.
  prefs: []
  type: TYPE_NORMAL
- en: We chose this basic type of sensor because our focus was on using the API. Feel
    free to explore the `Sensor` API class here to study the other sensors available
    to you. In particular, take a look at the `TYPE_STEP_DETECTOR` sensor type. This
    one triggers an event every time the user takes a step. Unlike the step counter,
    which tracks steps taken over a period of time, the step detector is ideal for
    detecting a step at the very moment it is taken.
  prefs: []
  type: TYPE_NORMAL
- en: You can also think about how you would go about implementing a step counter
    for a given day—an exercise left to the interested reader who wants to make the
    most of our `Today` app.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we demonstrated the creation of app-provided voice actions
    using the `Wear` API to launch our `Today Todo` app. We also introduced motion
    sensor concepts and examined the API classes that let us avail of these sensors.
    We then applied these concepts to augment our sample `Today` application with
    a simple activity that tracks the number of steps a user has taken.
  prefs: []
  type: TYPE_NORMAL
