<html><head></head><body><div><div><div><div><h1 class="title"><a id="ch04"/>Chapter 4. Trackables and Tracking</h1></div></div></div><p>Trackables are an integral part of an AR experience. It is the foundation on which the whole world we are building <a id="id137" class="indexterm"/>literally rests. We can have the best AR content in the world, but if the trackable is not suitable, the experience will degrade considerably. In this chapter we will try to understand the details of how to create and use suitable trackables. We will also explore how to modify a trackable to increase its trackability in the app.</p><div><div><div><div><h1 class="title"><a id="ch04lvl1sec23"/>What are trackables for image targets?</h1></div></div></div><p>Trackables are a<a id="id138" class="indexterm"/> collection of features that the AR app can track. This can be anything from the traditional QR code, where a collection of black and white binary code determines the object detected, to the image targets we experienced in the previous chapter where the trackable is just an image.</p><p>For image targets<a id="id139" class="indexterm"/>, only the natural features of the image itself is used as a way of detecting the image in the real, and its perspective to calculate where the AR camera should be. Natural features are analyzed, stored in a database, and then used to compare with the camera input feed. This naturally makes how effectively the image can be tracked, based on its features.</p></div></div>
<div><div><div><div><h1 class="title"><a id="ch04lvl1sec24"/>Creating image targets</h1></div></div></div><p>The process is made simple <a id="id140" class="indexterm"/>using Vuforia's <a id="id141" class="indexterm"/>
<strong>Target Manager</strong>. The target manager is an online tool provided by Qualcomm that automatically analyzes and creates image target databases to be deployed in apps. It can also manage multiple datasets with multiple targets.</p><p>To reach this target manager, simply go to the following URL: <a class="ulink" href="https://developer.vuforia.com/target-manager">https://developer.vuforia.com/target-manager</a>.</p><p>The following screenshot shows <strong>Target Manager</strong>:</p><div><img src="img/0032_4_1.jpg" alt="Creating image targets"/></div><p>You should be greeted with a view similar to the one above. This is the target manager—the tool that we will use to create all of our targets and maintain them. The target manager<a id="id142" class="indexterm"/> can be used for both local target datasets and cloud-based ones. In this book, we will focus on <a id="id143" class="indexterm"/>
<strong>Device Databases</strong>.</p><p>To start, let's create a database that we will use to see how the process of creating targets works. Click on the <strong>Create Database</strong> button and name the database Chapter 4. The following image shows a created dataset in <strong>Target Manager</strong>:</p><div><img src="img/0032_4_2.jpg" alt="Creating image targets"/></div><p>Now we have a dataset. Currently our dataset is empty, but we can add multiple image targets to a dataset for the AR app to track all of them. We can even create multiple datasets in this view, each with its own set of targets.</p><p>Now what we need to do is to create our first image target. First, we will use the stones image from Vuforia's sample project we did earlier. It will give us an idea of how the image targets for the sample project were created.</p><p>Click on the<a id="id144" class="indexterm"/> database to open it. We will find an add a target button on the right; click on it. The following image shows target creation:</p><div><img src="img/0032_4_3.jpg" alt="Creating image targets"/></div><p>The parameters for creating a target are very simple. For the name, we will pick Stones, like it was in the sample app. For target type, we will leave it at Single Image. The other two types are used for MultiTarget prefab in Vuforia for detecting 3D objects in the world.</p><p>The last parameter, Target Dimension, is an important parameter. This number is the representation of the image target in the scene. It governs how objects that appear on top of it are scaled, and how much space it occupies of the virtual space in the scene. That said, it is a value easily ignorable in Unity 3D environment. This is due to the scaling property that is easily editable in Unity. This value is very important in OpenGL environment however. For now, we can leave it at 5 units. This is a 5 units distance in the Unity 3D scene.</p><p>Click on the <strong>Add</strong> button, <a id="id145" class="indexterm"/>and let the image be uploaded. The target will have processing tag on it; processing takes a few minutes to happen. Give it some time, and then click on the target to see its details window. The following image shows Stones target details window:</p><div><img src="img/0032_4_4.jpg" alt="Creating image targets"/></div><p>This is the details window of the target we just added to the database. To the right, we will find all the details about the target. It starts with a unique ID of the target across all databases, <a id="id146" class="indexterm"/>cloud-based and local. This is useful for global identification of the target.</p><p>Below the <strong>Target ID</strong>, we will find the augmentable score. This is the most important feature of the target. It demonstrates how well the target can be tracked in the app. This target has 5 stars out of 5; this is because the features in image are great for tracking.</p></div>
<div><div><div><div><h1 class="title"><a id="ch04lvl1sec25"/>Trackable score</h1></div></div></div><p>Several factors affect the trackable score, but first we need to understand how the score affects the trackability for the image.</p><p>The augmentable score is based on 5 stars. It represents augmentability as follows:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><strong>Between 4 to 5 stars</strong>: The trackable is very suitable for AR apps. It can handle part of the image to be occluded, and still the app will be able to track it. It can also be tracked<a id="id147" class="indexterm"/> in low light and other environment noise.</li><li class="listitem" style="list-style-type: disc"><strong>Between 2 to 3 stars</strong>: The trackable is augmentable. It will work fine under ideal conditions. It may not be very good with part of the images occluded. This is the least score to aim for that will not affect the user's experience.</li><li class="listitem" style="list-style-type: disc"><strong>1 star</strong>: This is the bare minimum score for trackability. It means that the image will be recognizable by the app, but the experience will be affected. Avoid attaining this score at all costs.</li><li class="listitem" style="list-style-type: disc"><strong>0 stars</strong>: The image is not suitable for trackability at all; there are not enough recognizable features in the image for the app to recognize. This image will not be recognized at all by the app.</li></ul></div><p>In situations where the content of the trackable is restricted, and we know that the usage conditions will be idle in good lighting with no occlusion, we can aim for 2 to 3 stars. Otherwise, it is <a id="id148" class="indexterm"/>preferable to get 4 to 5 stars for optimal usage by the user. Anything below 2 stars should be avoided completely.</p></div>
<div><div><div><div><h1 class="title"><a id="ch04lvl1sec26"/>What decides trackable score?</h1></div></div></div><p>Trackables are the foundation of the AR experience using Vuforia. It is paramount to understand and <a id="id149" class="indexterm"/>create a suitable trackable for the experience to be robust and useful. The score attributed to the trackable in the target manager is our indication of how robust the target image is going to perform, but what decides that score?</p><p>The best way of understanding this, is by understanding how Vuforia tracks the images. The idea is simple; it looks for position of contrasting edges in clusters all around the image. Those edges are tracked, and based on the map of positions that are stored in the dataset, Vuforia can tell the relative position of the trackable in the real world, and accordingly render the 3D content on top of it. This particularly means that tracking the image is not a function of its color or what really is in it, as much as how many contrasting edges are there in the image, and how well they are distributed on the image.</p><p>To better understand this, we can look on the current edges that are recognizable in the image we have just uploaded. To do that, simply click on the <strong>Show Features</strong> link on the top left of the webpage. The following image shows features in image target stones:</p><div><img src="img/0032_4_5.jpg" alt="What decides trackable score?"/></div><p>Once the <strong>Show Features</strong> link has been clicked, the image target manager layers over the target image an overlay of where it detects a recognizable edge that it can track in a Vuforia image target. Notice that it is only tracking the dark edges between the <code class="literal">Stones</code> and nothing else in the image. It is even tracking only the high contrast edges between the <code class="literal">Stones</code>, while ignoring some of the lighter ones.</p><p>Also notice that<a id="id150" class="indexterm"/> the number of edges found in the image is large, and evenly distributed all around the image. This is a great factor in what made this image suitable for tracking.</p><p>To contrast this image's result, lets try an image that will yield a 1-star score when tried on the target manager. The following image shows landscape image added to target image:</p><div><img src="img/0032_4_6.jpg" alt="What decides trackable score?"/></div><p>Before adding this image, intuitively, we might think that this image is suitable for tracking. It certainly has a lot of details of a wide-angle landscape. But this image yielded a shocking 1-star result when added to the <strong>Target Manager</strong>.</p><p>The main reason for the low score for this image is the fact that the entire image is a shade of green. This greatly diminishes contrasting edges in the image.</p><p>If we are to click on the <a id="id151" class="indexterm"/>
<strong>Show Features</strong> link on the top, we will be able to see what the target manager detected from the image. The following image shows features in the mountain landscape image:</p><div><img src="img/0032_4_7.jpg" alt="What decides trackable score?"/></div><p>Immediately,<a id="id152" class="indexterm"/> we notice the considerably lower number of features detected in the image compared to the stones one. It only detected the edges created by the shadows of the objects in the image, which is clearly not enough to award it any score above 1 star.</p><div><div><div><div><h2 class="title"><a id="ch04lvl2sec12"/>Features definition</h2></div></div></div><p>To help us get a higher score, we must understand what are the features that the target manager is looking for. <a id="id153" class="indexterm"/>We do know now that the main thing that the target manager is looking for in an image is edges, but what kind of edges specifically? To understand that, we need the definition of features.</p><p>A feature is a sharp and spiked detail in the image, like the corner of an edge. Features must be very contrasting to be found and it has to be distributed evenly across the image and in a random manner. The following image shows shapes and features recognized in them:</p><div><img src="img/0032_4_8.jpg" alt="Features definition"/></div><p>In the shapes illustrated above, we can see the yellow crosses representation of the features recognizable in the shape. The representation is as follows:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><strong>Shape 1</strong>: It is a perfect circle without any corners at all, and as such, no features are recognizable in it.</li><li class="listitem" style="list-style-type: disc"><strong>Shape 2</strong>: It has an<a id="id154" class="indexterm"/> edge to the left with two recognizable corners. That yields two features recognizable in the shape.</li><li class="listitem" style="list-style-type: disc"><strong>Shape 3</strong>: It is a square with four edges and four corners. This yields four recognizable features in the shape.</li></ul></div><p>This means that any curved object yields little to none features at all. Primarily, humans and animals make very poor trackables due to their curved nature.</p></div><div><div><div><div><h2 class="title"><a id="ch04lvl2sec13"/>Enhancing score by enhancing contrast</h2></div></div></div><p>One of the easiest ways of enhancing an image's score is by simply enhancing the image's contrast. Feature detection<a id="id155" class="indexterm"/> looks for sharp edges like above; it is very hard to do so when the image's contrast is low. Like the landscape image we used before, the main reason the image resulted in a low score was because of the low contrast in the image. Then what happens when we increase the image's contrast and light levels in a photo editing application like Photoshop or Gimp? The following image shows the figure with enhanced contrast in landscape image:</p><div><img src="img/0032_4_9.jpg" alt="Enhancing score by enhancing contrast"/></div><p>The score makes a giant leap from 1-star score to 4-star score. As you can see, if you compare the image used now to the one we used earlier, the image's contrast is greatly enhanced, and the target manager easily detects such shadows and edges now. Lets look at the features detected by the target manager. The following image shows features in the high contrast image:</p><div><img src="img/0032_4_10.jpg" alt="Enhancing score by enhancing contrast"/></div><p>The features detected in the image are way more than what the target manager found in the previous image. Mostly, the features are located around the mountain and tree shadows. Notice<a id="id156" class="indexterm"/> how the green field is still yielding little features, but the features from the mountain and trees are enough to yield a high score of 4 stars.</p><p>It is highly recommend to enhance the contrast in all targets used for AR apps. It is greatly beneficial for the experience to have the best trackable possible.</p></div><div><div><div><div><h2 class="title"><a id="ch04lvl2sec14"/>Feature distribution on image targets</h2></div></div></div><p>Having recognizable features on the image is important, but how they are distributed is also very important. We can <a id="id157" class="indexterm"/>have all the features recognized on only one part of the image and nothing on another. This kind of imbalance lowers the score greatly, because it hinders the detection of the relative position of the image in the world for the AR app. For example, examine the image target below. The following image shows the lake target:</p><div><img src="img/0032_4_11.jpg" alt="Feature distribution on image targets"/></div><p>This is a lake image target that was added to the image target manager. It has a fair bit of details, but the <a id="id158" class="indexterm"/>left side of the image is mostly empty but for the lake. This image yielded 2 stars, and that is after enhancing the image's contrast.</p><p>To understand the reason for the low score, lets look at the features detected. The following image shows features in the lake house target:</p><div><img src="img/0032_4_12.jpg" alt="Feature distribution on image targets"/></div><p>As expected, all the features detected are on the right side of the image, leaving the left side completely empty. This is very bad for occlusion management and relative position detection by the AR app. It will track, but it will be a very poor target.</p></div><div><div><div><div><h2 class="title"><a id="ch04lvl2sec15"/>How to enhance distribution of features</h2></div></div></div><p>Enhancing distribution of features can be done by the obvious method, which is adding objects to the empty space of the image. If we are to add textured objects to the empty side of the image above, it will<a id="id159" class="indexterm"/> naturally enhance its score after the new object yields new detectable features. But changing the target's composition might not always be a viable option in practice if there is a restriction on what the target can be. For example, if the target is part of a magazine or a brochure, and we do not have control on what we can add to the image. However, we will always have control on what we can subtract from the target.</p><p>If we manage to subtract the empty space from the image target and take a subset of the target that is rich in details and well-distributed features, we can circumvent the problem. The interesting part is that the AR app will trigger on the large image just fine, even if we only give data of the subset. For example, examine this subset target of the lake target we added earlier. The following figure shows a subset of the lake image target:</p><div><img src="img/0032_4_13.jpg" alt="How to enhance distribution of features"/></div><p>As we can see, the above image is only a subset of the lake image, with just the lake house visible in it. Immediately, more features are recognizable now that target manager can focus on a smaller area. It also enhanced the feature distribution on the image. This enhanced the score to 3 stars for this trackable.</p><p>The AR app will trigger to this image, regardless if it's in this subset form, or if it was subjected to the original image before cropping the lake house from it. This is a very useful feature to keep in mind when trying to achieve a higher score for a target.</p><p>The position of the AR content will need to be adjusted according to appear relative the original lake image and not the subset. This can be achieved easily with an offset to the position applied<a id="id160" class="indexterm"/> to the AR content in Unity.</p></div><div><div><div><div><h2 class="title"><a id="ch04lvl2sec16"/>Patterns in image targets</h2></div></div></div><p>We now understand the need for a good distribution of features on the image, but there is one thing to <a id="id161" class="indexterm"/>keep in mind: having repeated patterns on the image is only counted once, meaning if we have a repeated pattern all across the image target, the score will be very bad. Examine the following image target. The following figure shows a snowflake pattern image target:</p><div><img src="img/0032_4_14.jpg" alt="Patterns in image targets"/></div><p>The above image when used yields a staggering 0 star. This image is mainly a repeated pattern of a snowflake. If we examine the features detected, we will see something like the following image. The following figure shows features in snowflake pattern:</p><div><img src="img/0032_4_15.jpg" alt="Patterns in image targets"/></div><p>As we can see, there are enough features detected in the image to effectively be augmentable, but yet the target manager gives it a 0 star. It will not be detectable at all from the app's perspective.</p><p>To understand why that happens, we need to ask ourselves the following question: if we take a subset of the image at the center, would it be distinguishable from the larger image? The answer <a id="id162" class="indexterm"/>is no, the pattern repeats itself symmetrically around the image. The app will not be able to find the relative position of the target in the real world if it compares the features detected with that in the dataset.</p></div></div>
<div><div><div><div><h1 class="title"><a id="ch04lvl1sec27"/>Exporting datasets to Unity</h1></div></div></div><p>Now that we know how to select and create <a id="id163" class="indexterm"/>our trackables, exporting them to Unity is a much easier task. The following figure shows highlighted targets to be exported:</p><div><img src="img/0032_4_16.jpg" alt="Exporting datasets to Unity"/></div><p>From the dataset's view, we can select what targets we want to export. Simply select any number of targets for deployment. <a id="id164" class="indexterm"/>Once the targets are selected, we can click on <strong>Download Selected Targets</strong> on the top left. The following image shows <strong>Download Selected Targets</strong>:</p><div><img src="img/0032_4_17.jpg" alt="Exporting datasets to Unity"/></div><p>From the list of development option, select <a id="id165" class="indexterm"/>
<strong>Unity Editor</strong> as the option. It is recommended to leave the database name the same name in the target manager. This makes it easier to update the dataset later. This will download a Unity package file that we can import easily into a project like we did in the sample project.</p><p>As we have seen, the create <a id="id166" class="indexterm"/>of a dataset in the target manager is quite easy, and makes creating a project more fluid.</p></div>
<div><div><div><div><h1 class="title"><a id="ch04lvl1sec28"/>Summary</h1></div></div></div><p>In this chapter, we understood the process of creating our own trackables and datasets using the target manager from Qualcomm. We also explored how to design and use a trackable that will yield the best trackability in our apps. We have seen what makes a trackable bad, such as patterns and feature distribution, and what makes it good, such as contrast, and edges. We learned a couple of tricks to enhance the trackability score of our trackable, such as taking a subset of the original image or by increasing the contrast in Photoshop or apps like it. With this knowledge, we easily optimize the most important foundation of AR, which is our trackable.</p><p>In the next chapter, we will create a project from the scratch that will be an AR game. Techniques and code will be of a higher level than previously explored in the book so far, and will get us closer to the full potential of Unity and Vuforia.</p></div></body></html>