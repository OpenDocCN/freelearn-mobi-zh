- en: Recognizing the Environment
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 环境识别
- en: Throughout this book, we have looked at the numerous ways of how our device,
    with the help of ARCore, can track the user, understand the user's world, and
    render an alternate reality. ARCore uses the device's sensors and camera as inputs
    to constantly update what it perceives as the user's real world. However, what
    if we wanted to do more for the user; perhaps identify a certain object, sign,
    or landmark? That would require a much more advanced set of tools. Even just 5
    years ago, this would seem like an incredibly daunting task. With the advent of
    OpenAI, thanks to Mr. Musk, many other companies have started to open source and
    make their tools available. This has led to phenomenal explosive growth in these
    technologies, colloquially referred to as **Machine Learning** (**ML**), and broadened
    their accessibility to everyone. Fortunately, for those interested in developing
    AR apps, this is a good thing. We want all the help we can get when it comes to
    recognizing and understanding the user's environment.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在整本书中，我们探讨了我们的设备如何借助ARCore的多种方式来跟踪用户、理解用户的世界，并渲染一个替代现实。ARCore使用设备的传感器和摄像头作为输入，不断更新它感知到的用户真实世界。然而，如果我们想为用户提供更多功能；比如识别某个物体、标志或地标？这将需要一套更高级的工具。即使是在5年前，这也会被视为一项极其艰巨的任务。随着OpenAI的出现，多亏了马斯克先生，许多其他公司也开始开源并使他们的工具可用。这导致了这些技术（俗称为**机器学习**（**ML**））的爆炸性增长，并使它们对每个人更加易于访问。幸运的是，对于那些对开发AR应用感兴趣的人来说，这是一个好事。当我们需要识别和理解用户的环境时，我们希望得到所有可能的帮助。
- en: 'For this chapter, we will introduce ML and explore how we can use it to create
    better AR apps for our users. In this chapter, we will cover the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将介绍机器学习，并探讨我们如何利用它为我们的用户提供更好的AR应用。在本章中，我们将涵盖以下主题：
- en: Introduction to ML
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习简介
- en: Deep reinforcement learning
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 深度强化学习
- en: Programming a neural network
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 编程神经网络
- en: Training a neural network
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练神经网络
- en: TensorFlow
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TensorFlow
- en: Machine Learning is a very advanced subject that can take years of study in
    order to master. However, for our purposes, we will learn some basic techniques,
    which the reader can extend on later, either through more learning or implementing
    their own solution.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习是一个非常高级的主题，要掌握它可能需要多年的学习。然而，为了我们的目的，我们将学习一些基本技术，读者可以在以后通过更多的学习或实现自己的解决方案来扩展。
- en: If you already have an in-depth understanding of neural networks, convolutional
    neural networks, and TensorFlow, feel free to breeze over this chapter.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你已经对神经网络、卷积神经网络和TensorFlow有深入的了解，你可以自由地跳过这一章。
- en: Introduction to ML
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习简介
- en: Machine Learning is a term widely used to refer to artificial intelligence and
    related computer predictive analytical models. The name Machine Learning, while
    perhaps overly generalized, fits better than the term AI. However, Machine Learning
    is itself such a broad term that it perhaps needs some further explanation and
    clarification. A machine obviously refers to a computer, or other device and learning
    tends to denote an algorithm or model that will evolve or learn over time. However,
    this is often not the case in many Machine Learning models. Therefore, for our
    purposes, we will use the broader term of Machine Learning to refer to any tool
    or algorithm that can be trained to recognize the environment or parts of the
    environment in AR, thus allowing us, the developers, to better augment our user's
    world.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习是一个广泛使用的术语，用来指代人工智能和相关计算机预测分析模型。虽然“机器学习”这个名字可能过于笼统，但它比“人工智能”这个术语更合适。然而，机器学习本身是一个非常广泛的术语，可能需要进一步的解释和澄清。机器显然指的是计算机或其他设备，而学习通常表示一个随着时间的推移会演变或学习的算法或模型。然而，在许多机器学习模型中，情况往往并非如此。因此，为了我们的目的，我们将使用更广泛的“机器学习”这个术语来指代任何可以训练以识别AR中的环境或环境部分的工具或算法，从而让我们，开发者，更好地增强用户的世界。
- en: Data science and Machine Learning go hand in hand. Data science is all about
    making sense of data, extracting patterns, and making predictions. In essence,
    when you start writing Machine Learning models in order to recognize objects or
    the environment, you are really just analyzing data, which means you can also,
    very loosely, call yourself a data scientist.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学和机器学习密不可分。数据科学是关于理解数据、提取模式和做出预测的。本质上，当你开始编写机器学习模型以识别物体或环境时，你实际上只是在分析数据，这意味着你也可以非常松散地称自己为数据科学家。
- en: 'Machine Learning is a big area and is only getting bigger every day, so let''s
    break down the specific problems we would like ML to help us with:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习是一个很大的领域，并且每天都在不断扩大，所以让我们具体分析一下我们希望机器学习帮助我们解决的问题：
- en: '**Target detection**: Targets have been used in AR for some time. It has been
    the primary tracking and reference point for many AR apps previous to ARCore.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**目标检测**：目标在AR中已经使用了一段时间。它曾是许多AR应用在ARCore之前的跟踪和参考点。'
- en: '**Image recognition**: This spawns into a whole set of sub-applications, all
    of which we will deal with in detail later.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**图像识别**：这衍生出一系列子应用，我们将在后面详细讨论。'
- en: '**Object detection**: Being able to detect an object in 3D from point cloud
    data is no easy feat, but it has been done and is getting better.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**物体检测**：从点云数据中检测3D物体并非易事，但这已经实现，并且正在变得更好。'
- en: '**Face detection**: Detecting a person''s face in an image has been around
    for years and has been used to great effect in many apps.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**人脸检测**：在图像中检测人脸已经存在多年，并在许多应用中得到了很好的应用。'
- en: '**Person detection**: Detecting people or motion has great possibilities. Think
    Kinect comes to AR.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**人员检测**：检测人或动作具有很大的可能性。想想看，Kinect 进入 AR。'
- en: '**Hand**/**Gesture detection**: Not to be confused with touch gestures. This
    is where we detect a user''s hand motions or gestures in front of a device''s
    camera.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**手**/**手势检测**：不要与触摸手势混淆。这是我们检测用户在设备摄像头前手的动作或手势的地方。'
- en: '**Pose detection on object**: Related to object detection, but now we also
    detect the position and orientation of the object.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**物体姿态检测**：与物体检测相关，但现在我们还在检测物体的位置和方向。'
- en: '**Light source detection**: Being able to place realistic lights in a scene
    to make virtual object rendering more realistic. We already looked at the importance
    of lighting in [Chapter 7](edd56812-fcba-4f66-aa3e-e9cf9ee7b637.xhtml), *Light
    Estimation*.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**光源检测**：能够在场景中放置逼真的光源，使虚拟对象渲染更加逼真。我们已经在[第7章](edd56812-fcba-4f66-aa3e-e9cf9ee7b637.xhtml)中探讨了光照的重要性，*光照估计*。'
- en: '**Environment detection**: Recognizing the environment a user has moved into
    has great application in mapping buildings or other locations where GPS is unavailable,
    which applies to most internal spaces.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**环境检测**：识别用户移动到的环境在地图制作或GPS不可用的建筑或其他位置有很好的应用，这适用于大多数内部空间。'
- en: Each of those problems may require different tools and techniques to solve those
    issues. In ML, it's not always about using the tool but the final answer and what
    works. Think about this as you build any ML you need for your app. Try a variety
    of ML tools and techniques; differences in size and performance of ML models can
    be critical, and it's something you need to consider.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 每个问题可能需要不同的工具和技术来解决这些问题。在机器学习中，不仅仅关于使用工具，而是最终的答案和什么有效。在构建您应用所需的任何机器学习时，请考虑这一点。尝试各种机器学习工具和技术；机器学习模型的大小和性能差异可能至关重要，这是您需要考虑的。
- en: A Machine Learning algorithm walks into a restaurant.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 一位机器学习算法走进了一家餐厅。
- en: The waiter asks, "What will you have?
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 服务员问道：“您要点什么？”
- en: The algorithm says, "What's everyone else having?"
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 算法说：“其他人都在吃什么？”
- en: '- Unknown'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '- 未知'
- en: 'In the following table is a summary of the current major ML providers and the
    types of AR problems they can be used to solve:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在下表中总结了当前主要机器学习提供商及其可以解决的AR问题类型：
- en: '| **Toolset** | **Pros/Cons** | **Machine Learning task** |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '| **工具集** | **优点/缺点** | **机器学习任务** |'
- en: '| **Targets/Image** | **Object/Pose** | **Face** | **Person** | **Hand** |
    **Light** | **Environment** |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '| **目标/图像** | **物体/姿态** | **人脸** | **人员** | **手** | **光源** | **环境** |'
- en: '| Vuforia | Mature and easy to use. Requires internet connectivity. | Yes |
    Yes/Paid |  |  |  |  |  |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| Vuforia | 成熟且易于使用。需要互联网连接。 | 是 | 是/付费 |  |  |  |  | '
- en: '| XZIMG | Face and image/target tracking supported for Unity and other platforms.
    | Yes |  | Yes |  |  |  |  |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| XZIMG | 支持Unity和其他平台的人脸和图像/目标跟踪。 | 是 |  | 是 |  |  |  | '
- en: '| ARToolkit | Mature OpenSource platform for image tacking and feature detection.
    | Yes |  |  |  |  |  |  |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| ARToolkit | 成熟的开源平台，用于图像跟踪和特征检测。 | 是 |  |  |  |  |  | '
- en: '| EasyAR | Pro license gets object and feature tracking. | Yes | Yes/Paid |  |  |  |  |  |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| EasyAR | 专业许可证获得对象和特征跟踪。 | 是 | 是/付费 |  |  |  |  | '
- en: '| Google Face Detection API | Low level Android API. |  |  | Yes |  |  |  |  |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| Google Face Detection API | 低级 Android API。 |  |  | 是 |  |  |  | '
- en: '| OpenCV | A mature low-level API for Android, commercial version ported to
    Unity. Still requires low level knowledge. | Yes | Yes | Yes | Yes | Yes | Coming
    | Coming |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| OpenCV | Android的一个成熟的底层API，商业版本已移植到Unity。仍需要底层知识。 | 是 | 是 | 是 | 是 | 是 |
    即将推出 | 即将推出 |'
- en: '| Google TensorFlow | Still in its infancy but quickly becoming the platform
    standard for CNN. Low level and advanced ML knowledge required. | Yes | Yes |
    Yes | Yes | Yes | coming | coming |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '| Google TensorFlow | 尚处于起步阶段，但迅速成为CNN的平台标准。需要底层和高级机器学习知识。 | 是 | 是 | 是 | 是
    | 是 | 即将推出 | 即将推出 |'
- en: '| Google ARCore | Currently, identifies planes, feature points, and light.
    |  |  |  |  | Yes | Yes |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| Google ARCore | 目前识别平面、特征点和光线。 |  |  |  |  | 是 | 是 |'
- en: We only included the main players who have built an AR platform for a mobile
    ARCore-supported device. Web technologies were omitted from this due to their
    limitations, although many of the mentioned technologies require internet connectivity
    and support web platforms as well. If you quickly review the table, you can also
    clearly see two main contenders that have the potential to dominate the entire
    space; that's because these are both low-level technologies that often back larger
    platforms such as Vuforia. Both of these platforms now support mobile pretrained
    networks for fast recognition on mobile devices. This may not seem like a big
    deal yet, but after we get into training our own models, you will see why.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我们只包括为支持移动ARCore设备的AR平台构建了主要平台的参与者。由于这些技术的局限性，我们排除了Web技术，尽管许多提到的技术需要互联网连接并支持Web平台。如果你快速浏览一下表格，你也可以清楚地看到两个有潜力主导整个空间的主要竞争者；这是因为这些技术都是底层技术，通常支持像Vuforia这样的更大平台。这两个平台现在都支持移动预训练网络，以便在移动设备上进行快速识别。这现在可能看起来不是什么大事，但当我们开始训练自己的模型时，你就会明白为什么。
- en: Linear regression explained
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 线性回归解释
- en: 'Let''s discuss the basic premise behind what Machine Learning is and what it
    attempts to accomplish. Take a look at the following chart that shows some fictional
    sales data for your next app:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们讨论一下机器学习的基本原理以及它试图实现的目标。看看以下图表，它显示了为你下一个应用程序的一些虚构的销售数据：
- en: '![](img/a6bb518b-0fb4-485f-8be4-390fc27184bd.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![图表](img/a6bb518b-0fb4-485f-8be4-390fc27184bd.png)'
- en: Chart of fictional sales data
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 虚构的销售数据图表
- en: Now, just looking at the chart, you can see that as the *x* values increase
    (perhaps days on sale), it appears that our sales also increase: *y* value (sales).
    By just eyeing the chart, we ourselves can make predictions by following the trend
    of the points. Try it; how many sales are for an *x* value (bottom axis) of 25?
    Give it a guess, and write it down. With your guess secured, we will use a technique
    called **linear regression** to find a good answer.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，只需看一下图表，你就可以看到，随着*x*值（可能是销售天数）的增加，我们的销售额似乎也在增加：*y*值（销售额）。仅凭观察图表，我们自己就可以通过跟随点的趋势来做出预测。试试看；当*x*值（底部轴）为25时，销售额是多少？给出你的猜测，并写下它。在你确定了猜测之后，我们将使用一种称为**线性回归**的技术来找到一个好的答案。
- en: 'Linear regression has been around for years and is considered as the base for
    many statistical data analysis methods. It is the basis for many other Machine
    Learning algorithms used in data science and predictive analysis today. This technique
    works by finding a solution (a line, curve, or whatever) that best fits the points.
    From that solution, we can determine the future or previous events or occurrences.
    Since this method is so well established, you can just open up Excel and let it
    draw the linear regression solution right on the graph. The following is an example
    of the linear regression with a trend line and equation added to the chart:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 线性回归已经存在多年，被认为是许多统计数据分析方法的基础。它是今天在数据科学和预测分析中使用的许多其他机器学习算法的基础。这种技术通过找到一个最佳拟合点（一条线、曲线或任何其他形状）的解决方案来实现。从这个解决方案中，我们可以确定未来的或过去的事件或发生。由于这种方法已经非常成熟，你只需打开Excel，就可以让它直接在图表上绘制线性回归解决方案。以下是一个带有趋势线和方程的线性回归图表的示例：
- en: '![](img/fb098124-343b-45ba-abe6-e30e4c25ec4b.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![图表](img/fb098124-343b-45ba-abe6-e30e4c25ec4b.png)'
- en: Chart with linear regression trend line
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 带有线性回归趋势线的图表
- en: Keep in mind that this example uses 2D points, but the same concepts equally
    apply to 3D as well. You just need to account for the extra dimension, which is
    not always a trivial thing but doable nonetheless.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，这个例子使用的是二维点，但同样的概念也适用于三维，你只需要考虑额外的维度，这虽然不是一件 trivial 的事情，但仍然可行。
- en: Without getting into the nitty-gritty details of the math, just understand that
    the line is drawn in order to minimize the error between the line and the points,
    which is often referred to as the line of best fit or one that minimizes the error,
    which in this case, is expressed as an R squared value (**R²**). **R²** ranges
    in value from 1.0, a best possible fit, to 0.0, or shooting blanks in the dark.
    You can see that our **R²** is not perfect, but it is **0.9125 ** out of 1 or
    91.25% correct; it's not perfect but perhaps good enough.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 不深入数学的细节，只需理解，这条线是为了最小化线与点之间的误差，这通常被称为最佳拟合线或最小误差线，在这种情况下，它被表示为R平方值（**R²**）。**R²**的值从1.0（最佳拟合）到0.0（在黑暗中射击）不等。你可以看到我们的**R²**并不完美，但它是1或91.25%的正确率；它并不完美，但可能足够好了。
- en: Probability and statistics play heavily into Machine Learning of all forms.
    If you don't have a good statistics background, you can still get the statistics
    by choosing a third-party provider. The only exception is if you have issues with
    that technology; then, it helps to have some background on your side, which is
    probably not something you wanted to hear if you're already trying to catch up
    on your 3D math skills.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 概率和统计学在所有形式的机器学习中都起着重要作用。如果你没有良好的统计学背景，你仍然可以通过选择第三方提供商来获取统计数据。唯一的例外是如果你有关于该技术的难题；那么，拥有一些你自己的背景知识会有所帮助，如果你已经在努力追赶你的3D数学技能，这可能不是你想要听到的。
- en: Take the example we just looked at and now think about the problem in 3D, and
    it's not a line but a 3D object we want to recognize or predict. Obviously, things
    can get complicated quite fast and computationally expensive using statistical
    models. Fortunately, there is a better way to do this using a technique that uses
    **supervised learning** that models the human brain, called **neural networks**
    (**NN**).
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 以我们刚才看到的例子为例，现在考虑在3D空间中的问题，它不是一个线，而是一个我们想要识别或预测的3D对象。显然，使用统计模型，事情可以很快变得复杂，计算成本也很高。幸运的是，有一种更好的方法来做这件事，使用一种使用**监督学习**来模拟人脑的技术，称为**神经网络**（**NN**）。
- en: In the next section, we will go under the covers into supervised learning and
    explore some techniques that we can use to analyze data using **deep learning**
    (**DL**) with neural networks.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将深入了解监督学习，并探讨我们可以使用神经网络进行数据分析和使用**深度学习**（**DL**）的一些技术。
- en: Deep learning
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深度学习
- en: As we discussed, the more traditional predictive models such as linear regression
    don't scale well, because they always need to calculate the whole solution using
    all the available points or data. These types of techniques or models have no
    ability to remember, learn, and improve, and they are generally classified as
    supervised models. This has led to the evolution of more advanced learning models
    known as **reinforcement learning** (**RL**) techniques for solving ML problems.
    In fact, deep learning and deep reinforcement learning techniques now outclass
    statistical methods in performance and accuracy by several orders of magnitude.
    However, that wasn't always the case, and statistical methods are also improving
    just as dramatically everyday. It really is an exciting time to be getting into
    Machine Learning.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们讨论的那样，更传统的预测模型，如线性回归，扩展性不好，因为它们总是需要使用所有可用的点或数据来计算整个解决方案。这些类型的技巧或模型没有记忆、学习和改进的能力，它们通常被归类为监督模型。这导致了更高级的学习模型的演变，称为**强化学习**（**RL**）技术，用于解决机器学习问题。实际上，深度学习和深度强化学习技术在性能和准确性上已经超越了统计方法几个数量级。然而，情况并非总是如此，统计方法也在每天以同样的速度显著改进。这确实是一个进入机器学习的激动人心的时刻。
- en: 'The following diagram demonstrates the reinforcement learning process:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的图示展示了强化学习过程：
- en: '![](img/40c72b92-4041-4106-add0-16b98161e8f8.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/40c72b92-4041-4106-add0-16b98161e8f8.png)'
- en: Reinforcement learning process
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 强化学习过程
- en: In the diagram, you can see that there is an **Agent** (assume computer) and
    the **Environment** (game or real world). The **Agent** acts on **Observations**
    from the **Environment**, and those actions may or may not be based on **Rewards**.
    An RL system using rewards is known as reinforcement learning. The learning method
    we will use in this chapter is called supervised learning since we are labeling
    or training to a specific output class. Unsupervised learning is a class of training
    that doesn't label data but just uses techniques to classify or group data.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在图中，你可以看到有一个**代理**（假设为计算机）和**环境**（游戏或现实世界）。**代理**根据**环境**的**观察**采取行动，这些行动可能基于或可能不基于**奖励**。使用奖励的RL系统被称为强化学习。我们在本章中使用的学习方法被称为监督学习，因为我们正在对特定输出类别进行标记或训练。无监督学习是一种不标记数据但仅使用技术进行分类或分组的数据训练方法。
- en: 'There are three classes of training we typically identify: unsupervised learning,
    supervised learning, and reinforcement learning. Reinforcement learning uses a
    rewards-based system on top of supervised or unsupervised systems as an enhancement
    to learning. RL systems can learn this way with essentially no initial training.
    AlphaGo Zero, which uses a deep RL model, is currently making the news after being
    able to beat a trained version of itself from scratch, with no human intervention.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通常识别出三类训练：无监督学习、监督学习和强化学习。强化学习在监督或无监督系统之上使用基于奖励的系统作为学习增强。RL系统可以以这种方式学习，基本上不需要初始训练。使用深度RL模型的AlphaGo
    Zero在能够从头开始击败经过训练的版本，且没有人类干预后，目前正成为新闻焦点。
- en: Part of the problem in defining all these ML concepts is that they often get
    woven together, where one learning algorithm or technique is layered on top of
    another, perhaps using RL with or without supervision. It is quite common, as
    we will see, to use multiple different layers of techniques to produce an accurate
    answer. This layering also has the benefit of being able to try multiple different
    approaches quickly or swap a technique out for something better later.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 定义所有这些ML概念的问题之一是它们经常交织在一起，其中一种学习算法或技术可能被层叠在另一种之上，可能使用带有或不带有监督的RL。正如我们将看到的，使用多个不同的技术层来产生准确的答案是很常见的。这种层叠的好处是能够快速尝试多种不同的方法，或者稍后用更好的技术替换。
- en: Deep learning is the term we use to describe this layering process. DL can be
    trained using any of the training methods we talked about. In any case, we need
    to stop talking in generalities and actually look at the DL process.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习是我们用来描述这种层叠过程的术语。DL可以使用我们讨论过的任何训练方法进行训练。在任何情况下，我们需要停止泛泛而谈，真正地看看DL的过程。
- en: Deep reinforcement learning has become quite popular as of late with plenty
    of success from playing Atari games to beating earlier supervised trained versions
    of itself quickly. If this area of training interests you, ensure that you search
    for AlphaGo Zero.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 深度强化学习近年来变得非常流行，从玩Atari游戏到快速击败早期监督训练版本的成功案例有很多。如果你对这个领域的训练感兴趣，确保你搜索AlphaGo Zero。
- en: Neural networks – the foundation of deep learning
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 神经网络——深度学习的基础
- en: 'When we speak of DL, we generally think of one ML technique called neural networks.
    Neural networks were conceptualized by trying to model the human brain. At the
    core of a neural network is the neuron, called so because it represents a single
    human brain cell. The following is an image of a human and computer neuron:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们谈论DL时，我们通常想到的是一种称为神经网络的ML技术。神经网络是通过尝试模拟人脑而构思的。神经网络的核心是神经元，之所以称为神经元，是因为它代表了一个单一的人类脑细胞。以下是人类和计算机神经元的图像：
- en: '![](img/1ebe7ce1-750f-484d-bf5e-b567a5515012.jpg)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1ebe7ce1-750f-484d-bf5e-b567a5515012.jpg)'
- en: Human and computer neuron
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 人类和计算机神经元
- en: 'Just like the brain, where billions of neurons are connected in layers, we
    connect neurons in layers in a similar way. Each neuron is connected to all the
    other neurons'' inputs and outputs in layers, where the first layer takes our
    input and the last layer or perhaps single neuron spits out our answer. The following
    is an example of what this typically looks like:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 就像大脑中数十亿个神经元在层中连接一样，我们以类似的方式在层中连接神经元。每个神经元都与层中其他所有神经元的输入和输出相连，其中第一层接收我们的输入，而最后一层或单个神经元输出我们的答案。以下是一个典型的例子：
- en: '![](img/3a6b9b74-f880-4efd-a7a9-ff00ee7db3a3.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3a6b9b74-f880-4efd-a7a9-ff00ee7db3a3.png)'
- en: Neural network with layers
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 带有层的神经网络
- en: One thing we should clarify before going any further is that the layers we talk
    about in deep learning don't correspond to the layers in a neural network. Think
    of a neural network as being in one layer of the DL system.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们继续之前，我们应该澄清一点，我们讨论的深度学习中的层并不对应于神经网络中的层。将神经网络想象为DL系统中的一个层。
- en: Here, each circle in the diagram represents a single neuron. Each neuron fires
    when the sum of all its inputs passes some threshold or activation function. This
    process continues for all the neurons, and the final layer outputs the answer.
    Of course, this is a very simple example, but it is difficult to see the power
    of neural networks until you start programming with them. Therefore, in the next
    section, we will write a neural network, which we plan to use to recognize objects
    in the environment.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，图中的每个圆圈代表一个单独的神经元。每个神经元在其所有输入的总和超过某个阈值或激活函数时都会触发。这个过程会持续对所有神经元进行，最终层输出答案。当然，这是一个非常简单的例子，但直到你开始用它们编程，你很难看到神经网络的威力。因此，在下一节中，我们将编写一个神经网络，我们计划用它来识别环境中的物体。
- en: When you encounter neural networks for the first time, the assumption is that
    this can't possibly work. After all, how could a self-driving car recognize a
    person using just a bunch of interconnected neurons? The answer to that is how
    indeed. We are really only starting to understand how the neural networks do what
    they do and, often, what we find is that we need to go back to the drawing board.
    In this case, the drawing board is the human brain and some of the more recent
    advances in neural networks were results of further brain research.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 当你第一次遇到神经网络时，你可能会认为这不可能工作。毕竟，自动驾驶汽车怎么可能只使用一串相互连接的神经元来识别人呢？答案确实如此。我们实际上才开始理解神经网络是如何工作的，而且，我们经常发现我们需要回到起点。在这种情况下，起点是人的大脑，而神经网络的一些最新进展是进一步大脑研究的结果。
- en: Programming a neural network
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 编程神经网络
- en: The best way to learn something is to do it, so in this section, we will write
    a simple neural network that we'll then train to perform various tasks. This network
    will have a set number of layers—input, hidden, and output—but we will allow for
    a number of neurons to be set in each layer. We will write this code in Unity
    so that we can use it in [Chapter 10](6a8f64fb-080f-47a2-9565-4099269831b1.xhtml), *Mixing
    in Mixed Reality*.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 学习某事物的最佳方式是去实践，因此在本节中，我们将编写一个简单的神经网络，然后对其进行训练以执行各种任务。这个网络将具有固定数量的层——输入层、隐藏层和输出层——但我们将在每一层中允许设置一定数量的神经元。我们将使用Unity编写此代码，以便在[第10章](6a8f64fb-080f-47a2-9565-4099269831b1.xhtml)，*混合现实*中使用。
- en: Writing a neural network is an advanced example, which will require a discussion
    with math to properly explain. If you feel overwhelmed at any time, you can always
    open up the finished project and check the final results. Of course, if you have
    written a neural network earlier, then you may also want to skip this section.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 编写神经网络是一个高级示例，需要与数学讨论才能正确解释。如果你在任何时候感到不知所措，你总是可以打开完成的项目并检查最终结果。当然，如果你之前已经编写过神经网络，那么你可能也想跳过这一部分。
- en: 'For this example, we will create a new project from the source Unity template,
    so let''s get started by opening Command Prompt:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个例子，我们将从源Unity模板创建一个新的项目，所以让我们开始通过打开命令提示符来开始：
- en: 'Create a new folder called `ARCore` off the root (`C:\` on Windows) folder
    using the following commands:'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令在根文件夹（Windows上的`C:\`）下创建一个名为`ARCore`的新文件夹：
- en: '[PRE0]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: This set of commands creates a new folder and then navigates to it.
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这组命令创建了一个新文件夹，然后导航到它。
- en: 'Execute the following command:'
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行以下命令：
- en: '[PRE1]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: This pulls the Unity ARCore template from GitHub into a new folder called `ARCoreML`.
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这将Unity ARCore模板从GitHub拖入一个名为`ARCoreML`的新文件夹中。
- en: Open a new instance of Unity and click on Open on the Project page. This will
    open the select project folder dialog. Select the new folder you just pulled the
    template into, `ARCoreML`,to open the project. Wait as the project opens in the
    Unity editor.
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开Unity的新实例，并在项目页面点击“打开”。这将打开选择项目文件夹对话框。选择您刚刚将模板拖入的新文件夹，`ARCoreML`，以打开项目。等待项目在Unity编辑器中打开。
- en: Right-click on (*Ctrl* + Click on Mac) the `Assets` folder in the Project window.
    Select Create | Folder from the context menu. Name the new folder `Scripts`.
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在项目窗口中，右键单击（在Mac上按*Ctrl* + 点击）`Assets`文件夹。从上下文菜单中选择创建 | 文件夹。将新文件夹命名为`Scripts`。
- en: Open the `HelloAR` scene from the `Assets/GoogleARCore/Examples/HelloAR` folder
    by double-clicking on it in the Project window.
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过在项目窗口中双击它，从`Assets/GoogleARCore/Examples/HelloAR`文件夹打开`HelloAR`场景。
- en: From the menu, select **File** | Build Settings. Ensure that Android is set
    for the target platform and the `HelloAR` scene is set as scene `0` in the build.
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从菜单中选择**文件** | **构建设置**。确保Android设置为目标平台，并将`HelloAR`场景设置为构建中的场景`0`。
- en: Connect your device and build and run. Just ensure that the example runs as
    you expected on your device.
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 连接您的设备并构建运行。只需确保示例在您的设备上按预期运行。
- en: Scripting the neural network
  id: totrans-88
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 编写神经网络脚本
- en: 'With the new project set up, we can now start writing our scripts to build
    a neural network. Go back to Unity and perform the following steps:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在新项目设置完成后，我们现在可以开始编写脚本以构建神经网络。回到Unity并执行以下步骤：
- en: Open the `ARCoreML/Scripts` folder and then from the menu, select Assets | Create
    | C# Script. Name the script as `Neuron` and double-click to open it in your editor
    of choice.
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开`ARCoreML/Scripts`文件夹，然后从菜单中选择Assets | Create | C# Script。将脚本命名为`Neuron`，双击以在您选择的编辑器中打开它。
- en: The code for this example was originally sourced from [https://github.com/Blueteak/Unity-Neural-Network.git](https://github.com/Blueteak/Unity-Neural-Network.git),
    which shows an excellent example of a simple and concise neural network with training
    explicitly developed for Unity. We will modify the original code for our needs,
    but feel free to check out and contribute to the original source if you are interested.
    This code is great for learning, but certainly, it's not something you may want
    to use in production. We will look at options for production-ready neural networks
    in the section on TensorFlow.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 这个示例的代码最初来源于[https://github.com/Blueteak/Unity-Neural-Network.git](https://github.com/Blueteak/Unity-Neural-Network.git)，它展示了为Unity开发的一个简单且简洁的神经网络示例，并明确进行了训练。我们将根据我们的需求修改原始代码，但如果您感兴趣，请随意查看并贡献原始源代码。这段代码非常适合学习，但当然，这并不是您可能希望在生产中使用的东西。我们将在TensorFlow部分查看生产就绪神经网络的选项。
- en: 'Delete all the code, leave the `using` statements, and then add the following:'
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 删除所有代码，留下`using`语句，然后添加以下内容：
- en: '[PRE2]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Note how this class does not inherit `MonoBehaviour` and thus will not be a
    game object, which means we will load this class in another script. Then, we create
    a placeholder for `Random`; we do this because we are using `System.Random` rather
    than `Unity.Random`. `Unity.Random` only supports generating a random `float`,
    but we need the precision of a `double`. The rest are just properties that we
    will discuss as we get to the relevant code sections.
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 注意这个类没有继承`MonoBehaviour`，因此不会是一个游戏对象，这意味着我们将在这个脚本中加载这个类。然后，我们为`Random`创建一个占位符；我们这样做是因为我们使用的是`System.Random`而不是`Unity.Random`。`Unity.Random`仅支持生成随机`float`，但我们需要`double`的精度。其余的都是我们将随着相关代码部分的出现而讨论的属性。
- en: 'Enter the following after the last property declaration but before the class''s
    ending brace:'
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在最后一个属性声明之后但在类的结束花括号之前输入以下内容：
- en: '[PRE3]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: We create this `static` helper method in order to generate `double` random numbers
    from `-1.0` to `1.0`. This allows for greater precision and assures that our values
    are always getting generated around `0`. Keeping values close to `0` avoids rounding
    errors and just generally makes things easier to calculate.
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们创建这个`static`辅助方法是为了生成从`-1.0`到`1.0`的`double`随机数。这允许有更高的精度，并确保我们的值总是围绕`0`生成。将值保持在`0`附近可以避免舍入错误，并且通常使计算变得更简单。
- en: 'Next, enter the following code after the `static` method:'
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，在`static`方法之后输入以下代码：
- en: '[PRE4]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Here, we set up a base and single parameter constructors. The base constructor
    creates a `List<Synapse>` for the input and output connections to the neuron.
    A `Synapse` represents a connection. The other constructor calls the base (`this`)
    and takes an `IEnumerable<Neuron>` of neurons that it then connects back to. This
    way, networks can be built bottom up; we will see how this works when we get to
    the `NeuralNet` class.
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这里，我们设置了基类构造函数和单个参数构造函数。基类构造函数为神经元的输入和输出连接创建了一个`List<Synapse>`。`Synapse`代表一个连接。另一个构造函数调用基类（`this`）并接受一个`IEnumerable<Neuron>`的神经元，然后将其连接回。这样，网络可以自下而上构建；当我们到达`NeuralNet`类时，我们将看到这是如何工作的。
- en: 'Next, we will add the rest of the methods for the `Neuron` class:'
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将添加`Neuron`类的其余方法：
- en: '[PRE5]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: We added four methods here: `CalculateValue`, `CalculateError`, `CalculateGradient`,
    and `UpdateWeights`. `CalculateValue` is used to determine the neuron's output
    based on the activation function we defined in `Sigmoid`. We will get to `Sigmoid`
    shortly. The other methods are used to train the neuron. Training a neuron is
    something we will cover in the next section.
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们在这里添加了四个方法：`CalculateValue`、`CalculateError`、`CalculateGradient` 和 `UpdateWeights`。`CalculateValue`
    用于根据我们在 `Sigmoid` 中定义的激活函数确定神经元的输出。我们将在稍后介绍 `Sigmoid`。其他方法用于训练神经元。训练神经元是我们将在下一节中介绍的内容。
- en: 'Stay in the same file, and add the following three new helper classes outside
    the `Neuron` class:'
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 保持在同一文件中，并在 `Neuron` 类外部添加以下三个新的辅助类：
- en: '[PRE6]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The first class `Synapse`, as we already know, defines a connection between
    neurons. Next comes `Sigmoid`, which, conveniently enough, is just a wrapper class
    for the sigmoid activation function we use. Note that the values are getting capped
    at `-45.0` and `+45.0`. This limits the size of our network, but we can manually
    change that later. Then comes `DataSet`, which is just a holder for our training
    data.
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第一个类 `Synapse`，正如我们已知的，定义了神经元之间的连接。接下来是 `Sigmoid`，它恰好是一个用于我们使用的 sigmoid 激活函数的包装类。注意，值被限制在
    `-45.0` 和 `+45.0`。这限制了我们的网络大小，但我们可以手动更改它。然后是 `DataSet`，它只是我们训练数据的持有者。
- en: 'That completes the `Neuron` class. Create another script in Unity, and this
    time, call it `NeuralNet`; open it up in your editor of choice and perform the
    following steps:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 这样就完成了 `Neuron` 类。在 Unity 中创建另一个脚本，这次命名为 `NeuralNet`；在您选择的编辑器中打开它并执行以下步骤：
- en: 'Delete the starter code again, but leave the `using`''s statements, and enter
    the following:'
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 再次删除起始代码，但保留 `using` 语句，并输入以下内容：
- en: '[PRE7]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Again, this is another set of public properties that define the `LearnRate`
    network and `Momentum`. Then, three `List<Neuron>` to hold the collection of neurons
    in the input, hidden (middle), and output layers. In this example, we use a single
    hidden layer, but more sophisticated networks often support several more layers.
    You guessed it, `LearnRate` and `Momentum` will be covered in the section on training.
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 再次，这是一组定义 `LearnRate` 网络和 `Momentum` 的公共属性。然后是三个 `List<Neuron>`，用于存储输入、隐藏（中间）和输出层中的神经元集合。在这个例子中，我们使用单个隐藏层，但更复杂的网络通常支持更多层。你可以猜到，`LearnRate`
    和 `Momentum` 将在训练部分进行介绍。
- en: We generally prefer not to use properties with getters and setters in Unity.
    Why? Primarily because the Unity editor just plays better with public fields.
    Secondarily, game programming is all about performance, and it only makes sense
    to avoid the overhead of getters and setters where possible. Using a list is also
    a no-no, but it makes the code easier to understand in this case.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通常在 Unity 中不倾向于使用带有获取器和设置器的属性。为什么？主要是因为 Unity 编辑器与公共字段配合得更好。其次，游戏编程完全是关于性能的，尽可能避免获取器和设置器的开销是有意义的。使用列表也是不允许的，但在这个情况下，它使得代码更容易理解。
- en: 'Next, let''s add a constructor for our `NeuralNet`:'
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，让我们为我们的 `NeuralNet` 添加一个构造函数：
- en: '[PRE8]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: This constructor expects several inputs, including the number of neurons in
    the input, hidden, and output layers, in addition to a value for the `learnRate`
    and `momentum`. Inside the constructor, the properties are initialized based on
    the input values. Note how the first layer uses the default `Neuron` constructor,
    and the successive layers use the single parameter constructor with the previous
    layer as input. Remember from building the `Neuron` class that this is where all
    the synapse connections between the neuron layers are added.
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 此构造函数期望几个输入，包括输入、隐藏和输出层中的神经元数量，以及 `learnRate` 和 `momentum` 的值。在构造函数内部，属性根据输入值进行初始化。注意，第一层使用默认的
    `Neuron` 构造函数，而后续层使用带有前一层作为输入的单参数构造函数。记得从构建 `Neuron` 类中，这是添加神经元层之间所有突触连接的地方。
- en: 'Next, we will add a couple of methods for training:'
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将添加一些用于训练的方法：
- en: '[PRE9]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Then, we will add methods to propagate the network forward and backward:'
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们将添加方法来正向和反向传播网络：
- en: '[PRE10]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Finally, add the following methods to compute the whole network and to calculate
    errors:'
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，添加以下方法来计算整个网络和计算错误：
- en: '[PRE11]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: That completes the neural network code. We left a number of areas for discussion
    in the next section on training the neural network.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 这样就完成了神经网络代码。我们在下一节关于训练神经网络的训练部分留下了许多讨论区域。
- en: Training a neural network
  id: totrans-122
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练神经网络
- en: 'As you may have already summarized, a neural network is essentially useless
    until it is trained. Before we get into training, we should talk some more on
    how a neuron is activated. Open up the `Neuron` class again and take a look at
    the `CalculateValue` function. This method calculates the output based on its
    internal set of weights and is described by the following:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 如您可能已经总结的那样，神经网络在训练之前基本上是无用的。在我们开始训练之前，我们应该更多地讨论一下神经元是如何被激活的。再次打开 `Neuron` 类，并查看
    `CalculateValue` 函数。此方法根据其内部设置的权重计算输出，如下所述：
- en: '![](img/5bd05beb-4c40-411f-996d-e4c0c396ef43.png)![](img/d0fefff0-1227-4e2b-b7ae-b3529be79bb6.png)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5bd05beb-4c40-411f-996d-e4c0c396ef43.png)![](img/d0fefff0-1227-4e2b-b7ae-b3529be79bb6.png)'
- en: 'Here:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 这里：
- en: '![](img/bbd0e139-c191-48c1-b1fb-32e5193d399a.png)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![](img/bbd0e139-c191-48c1-b1fb-32e5193d399a.png)'
- en: 'Also, keep the following in mind:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 同时，请注意以下几点：
- en: '*n* = total number of neurons connected as inputs'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '*n* = 作为输入连接的总神经元数'
- en: '*I* = signaled input to the `Neuron` class'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '*I* = 传递给 `Neuron` 类的信号输入'
- en: '*O* = calculated output'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '*O* = 计算的输出'
- en: '*S* = the `sigmoid` function with a graph:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '*S* = 具有如下图的 `sigmoid` 函数：'
- en: '![](img/3cad5108-6d20-4609-81e8-6643e2a262ad.png)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3cad5108-6d20-4609-81e8-6643e2a262ad.png)'
- en: Sigmoid function
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: Sigmoid 函数
- en: '**Sigmoid Function** essentially distributes the weighted sum of values between
    0 and 1 based on a curve (function) similar to the one shown in the preceding
    graph. We do this in order to evenly weigh the outputs of each of the neurons.
    Likewise, when we look to input data into a network, we also like to normalize
    the values between 0 and 1\. If we didn''t do this, one single neuron or input
    could bias our entire network. This is like hitting your thumb with a hammer and
    only being able to feel pain in your thumb for the next several seconds, Except
    that we don''t want our network to respond to wild inputs like that. Instead,
    we want to mellow our network out with the `sigmoid` function.'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '**Sigmoid 函数**基本上根据类似于前述图表的曲线（函数）在 0 和 1 之间分配值的加权总和。我们这样做是为了使每个神经元的输出均匀加权。同样，当我们考虑将输入数据输入到网络中时，我们也希望将值规范化到
    0 和 1 之间。如果我们不这样做，单个神经元或输入可能会偏置我们的整个网络。这就像用锤子敲你的大拇指，接下来的几秒钟内只能感觉到大拇指的疼痛，但我们不希望我们的网络对这种野外的输入做出反应。相反，我们希望用
    `sigmoid` 函数来平缓我们的网络。'
- en: Activating the warning
  id: totrans-135
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 激活警告
- en: 'Let''s delay our discussion of training a bit further and put together a simple
    example to see how this works. Open up Unity again and perform the following steps:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们进一步推迟对训练的讨论，并准备一个简单的例子来看看它是如何工作的。再次打开 Unity 并执行以下步骤：
- en: Create a new C# script called `EnvironmentScanner` in the `Assets/ARCoreML/Scripts`
    folder. Then, open the script in your editor.
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `Assets/ARCoreML/Scripts` 文件夹中创建一个新的 C# 脚本，名为 `EnvironmentScanner`。然后，在您的编辑器中打开该脚本。
- en: 'Add the code, as shown, to the class definition:'
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将如下所示的代码添加到类定义中：
- en: '[PRE12]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '`RequireComponent` is a custom Unity attribute that forces a `GameObject` to
    require a specific class before this component can be added. In this example,
    we require an `AudioSource` component.'
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`RequireComponent` 是一个自定义的 Unity 属性，它强制一个 `GameObject` 在添加此组件之前需要特定的类。在这个例子中，我们需要一个
    `AudioSource` 组件。'
- en: 'Enter the following new properties/fields and method to the class; don''t delete
    anything:'
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将以下新的属性/字段和方法添加到类中；不要删除任何内容：
- en: '[PRE13]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: The `Awake` method is special in Unity in that it gets called when the object
    first wakes up or becomes active. `Awake` varies from `Start` in that it is called
    upon initialization of the object, whereas `Start` is called before the first
    frame an object is rendered. The difference is subtle and is typically only relevant
    when you are worried about object load time.
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 Unity 中，`Awake` 方法是特殊的，因为它在对象首次唤醒或变为活动状态时被调用。`Awake` 与 `Start` 的不同之处在于它在对象的初始化时被调用，而
    `Start` 在对象渲染第一帧之前被调用。这种差异很微妙，通常只有在您担心对象加载时间时才相关。
- en: Next, we create a number of temporary input variables for setting the number
    of **input**, **hidden**, and **output** neurons. For this example, we will use
    one input, four hidden, and one output. These inputs are used to create `NeuralNet`
    in the next line, which is followed by the initialization of the `dataSets` list.
  id: totrans-144
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 接下来，我们创建了一些临时输入变量来设置 **输入**、**隐藏**和**输出**神经元的数量。在这个例子中，我们将使用一个输入、四个隐藏和一个输出。这些输入用于在下一行创建
    `NeuralNet`，随后初始化 `dataSets` 列表。
- en: 'Next, let''s modify the `Start` method to resemble the following:'
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，让我们修改 `Start` 方法，使其类似于以下内容：
- en: '[PRE14]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The first line inside `Start` creates a very simple `DataSet` with inputs and
    outputs. Since we are using a single input and output neuron, these inputs and
    outputs map 1 to 1 and thus produce the following chart:'
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`Start`内部的第一行创建了一个非常简单的`DataSet`，具有输入和输出。由于我们使用单个输入和输出神经元，这些输入和输出映射1到1，因此产生以下图表：'
- en: '![](img/ce4f1a06-3c30-4222-9461-9d280c01cb5f.png)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/ce4f1a06-3c30-4222-9461-9d280c01cb5f.png)'
- en: Chart of training inputs
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 训练输入图表
- en: Then, `net.Train` trains the neural network with a minimum error of `.001`.
    After that, it gets the required `AudioSource`, remembers the `RequireComponent`
    attribute, and sets it to a private `audioSource` field. We will use sound in
    order to warn the user when they get too close. Think about what it is that those
    points are describing as a function.
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，`net.Train`使用最小误差`.001`训练神经网络。之后，它获取所需的`AudioSource`，记住`RequireComponent`属性，并将其设置为私有的`audioSource`字段。我们将使用声音来警告用户当他们太靠近时。考虑一下这些点作为函数描述的是什么。
- en: 'Finally, modify the `Update` method to include the following:'
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，修改`Update`方法以包含以下内容：
- en: '[PRE15]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: There is a lot going on here, so let's break it down. We first check whether
    the `warning` is `true`. If it is, we play a sound, otherwise we stop playing;
    `warning` will be our flag to indicate when our NN is signalling. Next, we ensure
    that the `Frame` is tracking, with the same code as we saw earlier. Then, we reset
    `min` and get the current point cloud from the `Frame`.
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这里有很多事情在进行中，所以让我们分解一下。我们首先检查`warning`是否为`true`。如果是，我们播放声音，否则我们停止播放；`warning`将是我们表示神经网络发出信号的标志。接下来，我们确保`Frame`正在跟踪，使用与之前看到的相同的代码。然后，我们重置`min`并从`Frame`获取当前点云。
- en: After that, we ensure that `pointCloud` has points, and it is the most recent.
    This is checked by testing the timestamp. Then, inside the `if` block, we calculate
    the current min by looping through all points. We then push this through our NN
    with `net.Compute`, the value of `min` (minimum point); this returns our signal
    or neuron output. In this particular case, we are testing for `.001` to determine
    whether the neuron is signalling an activation. This sets the warning to `true`
    or `false`.
  id: totrans-154
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 之后，我们确保`pointCloud`有点，并且是最新的。这是通过测试时间戳来检查的。然后，在`if`块内部，我们通过遍历所有点来计算当前的`min`。然后，我们通过`net.Compute`将这个值（最小点）推送到我们的神经网络中，这返回我们的信号或神经元输出。在这种情况下，我们正在测试`.001`以确定神经元是否发出激活信号。这会将警告设置为`true`或`false`。
- en: Save the code and return to Unity; ensure that you see no compiler errors.
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 保存代码并返回Unity；确保您没有看到编译错误。
- en: Adding the environmental scanner
  id: totrans-156
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 添加环境扫描器
- en: 'Now that we have a script that uses the component, let''s add it to our scene
    as a new object. Return to the editor where we last left off and continue as follows:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有一个使用该组件的脚本，让我们将其添加到场景中作为一个新对象。返回到我们上次离开的编辑器，并继续以下步骤：
- en: Open the `HelloAR` scene. From the menu, select File | Save as and save the
    scene as `Main` in the `Assets/ARCoreML` folder.
  id: totrans-158
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开`HelloAR`场景。从菜单中选择文件 | 保存为，并将场景保存为`Main`在`Assets/ARCoreML`文件夹中。
- en: Find and select First Person Camera in the Hierarchy window. Remember that you
    can use the search panel.
  id: totrans-159
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在层次结构窗口中找到并选择第一人称摄像机。请记住，您可以使用搜索面板。
- en: Right-click (*Ctrl* + Click on Mac) on the First Person Camera and from the
    context menu, select Create Empty. Name the object as `Environmental Scanner`.
  id: totrans-160
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 右键单击（*Ctrl* + 点击Mac）第一人称摄像机，并从上下文菜单中选择创建空对象。将对象命名为`Environmental Scanner`。
- en: Select the new object and in the Inspector window, add a new `AudioSource` component.
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择新对象，在`Inspector`窗口中添加一个新的`AudioSource`组件。
- en: Create a new folder called `Audio` in the `Assets/ARCoreML` path in the Project
    window.
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在项目窗口中，在`Assets/ARCoreML`路径下创建一个新的文件夹，命名为`Audio`。
- en: Open the `Resources` folder from the downloaded code folder and copy the `tone-beep.wav`
    file to the new `Assets/ARCoreML/Audio` folder you just created.
  id: totrans-163
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从下载的代码文件夹中打开`Resources`文件夹，并将`tone-beep.wav`文件复制到您刚刚创建的`Assets/ARCoreML/Audio`文件夹中。
- en: 'Open up the `Environmental Scanner` object in the Inspector window and set
    the AudioSource properties, as shown in the following screenshot:'
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`Inspector`窗口中打开`Environmental Scanner`对象，并设置`AudioSource`属性，如图所示：
- en: '![](img/2e7a3aca-4c32-4a9f-a92d-4b3fd67d0d5c.png)'
  id: totrans-165
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/2e7a3aca-4c32-4a9f-a92d-4b3fd67d0d5c.png)'
- en: Setting the AudioSource properties in the Inspector
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 在`Inspector`中设置`AudioSource`属性
- en: With `Environmental Scanner` still selected, click on the Add Component button
    in the I**nspector** window. Add the `Environmental Scanner` script we wrote earlier.
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`Inspector`窗口中选中`Environmental Scanner`，然后点击添加组件按钮。添加我们之前编写的`Environmental
    Scanner`脚本。
- en: Open the Build Settings dialog and ensure that you add the current scene (`Main`)
    to the build. Ensure that you remove any other scenes from the build.
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开构建设置对话框，确保将当前场景（`Main`）添加到构建中。确保从构建中删除任何其他场景。
- en: Connect, build, and run. Move around the room. Now what happens when you get
    too close to objects? At what distance?
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 连接、构建和运行。在房间内移动。那么，当您接近物体时会发生什么？在什么距离？
- en: Great, so we have effectively made a backup or warning beeper to let you know
    when you are getting too close to an object. Obviously, we could have just as
    easily written a simple threshold test ourselves to test when `min` is getting
    too close. However, this simple example gives us a good basis for understanding
    how training works.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 很好，所以我们已经有效地创建了一个备份或警告蜂鸣器，以便在您接近物体时通知您。显然，我们也可以简单地编写一个简单的阈值测试来测试当`min`接近时的情况。然而，这个简单的例子为我们理解训练工作提供了一个良好的基础。
- en: Backward propagation explained
  id: totrans-171
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 反向传播解释
- en: In this example, we are pretraining our model (supervised learning) to a simple
    function described by a set of inputs (1.0, 0.1, 0) and expected outputs of (0,
    1.0, 1.0), which is represented by the graph/chart we saw earlier. In essence,
    we want our neural net to learn the function defined by those points and be able
    to output those results. We do this by calling `net.Train`, passing in `datasets`
    and the minimum expected error. This trains the network by backward propagating
    the error through each neuron of the network until a minimum error can be reached.
    Then, the training stops and the network declares itself ready.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们正在对模型（监督学习）进行预训练，使其执行一个简单的函数，该函数由一系列输入（1.0, 0.1, 0）和预期的输出（0, 1.0, 1.0）描述，这在我们之前看到的图表/图中表示。本质上，我们希望我们的神经网络能够学习由这些点定义的函数，并能够输出这些结果。我们通过调用`net.Train`，传入`datasets`和最小预期误差来实现这一点。这样，网络通过反向传播错误通过网络中的每个神经元来训练，直到达到最小误差。然后，训练停止，网络声明自己已准备好。
- en: 'Backward propagation works using a simple iterative optimization algorithm
    called **gradient descent**, which uses the minimum error to minimize each of
    the neuron input weights so that the global minimum error can be reached. To fully
    understand this, we will need to go into some differential calculus and derivatives.
    Instead, we will take a shortcut and just look at what the code is doing in the
    `Train` method of the `NeuralNet` class:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 反向传播使用一个简单的迭代优化算法，称为**梯度下降**，它使用最小误差来最小化每个神经元的输入权重，以便达到全局最小误差。为了完全理解这一点，我们需要进入一些微分学和导数的知识。相反，我们将走捷径，只看看`NeuralNet`类的`Train`方法中的代码在做什么：
- en: '[PRE16]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The code here is relatively straightforward. We set an `error` and `numEpochs`.
    Then, we start a `while` loop that ends when the `error` is greater than the `minimumError`
    (global) and the `numEpochs` is less than the maximum `int` value. Inside the
    loop, we then loop through each `dataSet` in `dataSets`. First, `ForwardPropagate` is
    used on the inputs of the dataset values to determine output. Then, `BackPropagate`
    is used on the dataset target value to adjust the weights on each of the neurons
    using gradient descent. Let''s take a look inside the `BackPropagate` method:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的代码相对简单。我们设置了一个`error`和`numEpochs`。然后，我们启动一个`while`循环，该循环在`error`大于`minimumError`（全局）并且`numEpochs`小于最大`int`值时结束。在循环内部，我们遍历`dataSets`中的每个`dataSet`。首先，使用`ForwardPropagate`对数据集值的输入进行操作以确定输出。然后，使用`BackPropagate`对数据集的目标值进行调整，使用梯度下降法调整每个神经元的权重。让我们看看`BackPropagate`方法内部的情况：
- en: '[PRE17]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'This method just elegantly loops through each layer of neurons using `ForEach`
    from `System.Linq`. First, it calculates the gradient in the output and hidden
    layers and then it adjusts the weights in reverse order: first the hidden and
    then the output. Next, we will dissect the `CalculateGradient` method:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 这个方法优雅地使用`System.Linq`中的`ForEach`遍历每个神经元层。首先，它计算输出和隐藏层的梯度，然后以相反的顺序调整权重：首先是隐藏层，然后是输出层。接下来，我们将剖析`CalculateGradient`方法：
- en: '[PRE18]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: We can see that the `CalculateGradient` method takes a nullable `double` called
    `target`. If `target` is `null`, the `Gradient` is calculated by summing the previous
    gradient multiplied by the input weights. Otherwise, the `Gradient` is calculated
    by multiplying the error by the derivative of the `Sigmoid`. Remember that, sigmoid
    was our activation function, which is essentially what we are trying to minimize.
    If you recall from calculus, we can take the derivative of a function in order
    to determine its minimum or maximum value. In fact, in order to use the gradient
    descent method for backward propagation, your activation function has to be differentiable.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到`CalculateGradient`方法接受一个名为`target`的可空`double`。如果`target`为`null`，则通过将先前梯度乘以输入权重来计算`Gradient`。否则，`Gradient`通过将误差乘以`Sigmoid`的导数来计算。记住，sigmoid是我们的激活函数，这基本上是我们试图最小化的。如果你从微积分中回忆起来，我们可以通过对函数求导来确定其最小值或最大值。实际上，为了使用梯度下降法进行反向传播，你的激活函数必须是可导的。
- en: Gradient descent explained
  id: totrans-180
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 梯度下降法解释
- en: 'Gradient descent uses the partial derivative of the loss or error function
    in order to propagate the updates back to the neuron weights. Our cost function
    in this example is the sigmoid function, which relates back to our activation
    function. In order to find the gradient for the output neuron, we need to derive
    the partial derivative of the sigmoid function. The following graph shows how
    the gradient descent method walks down the derivative in order to find the minimum:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 梯度下降法使用损失或误差函数的偏导数来将更新传播回神经元权重。在这个例子中，我们的成本函数是Sigmoid函数，这与我们的激活函数相关。为了找到输出神经元的梯度，我们需要对Sigmoid函数求偏导数。以下图表显示了梯度下降法如何沿着导数下降以找到最小值：
- en: '![](img/f3899ca3-835e-4d3e-8e7f-fd1c5a9044fb.png)'
  id: totrans-182
  prefs: []
  type: TYPE_IMG
  zh: '![图表](img/f3899ca3-835e-4d3e-8e7f-fd1c5a9044fb.png)'
- en: Gradient descent algorithm visualized
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 梯度下降算法可视化
- en: If you plan to spend anymore time studying neural networks, deep learning, or
    machine learning, you will certainly study the mathematics of gradient descent
    and backward propagation in more depth. However, it is unlikely that you will
    get further exposure to the basic concepts of programming a neural network, so
    this chapter will be a good future reference.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你计划花更多时间学习神经网络、深度学习或机器学习，你肯定会更深入地学习梯度下降和反向传播的数学。然而，你不太可能进一步接触到编程神经网络的基礎概念，因此这一章将是一个很好的未来参考。
- en: 'Let''s take a look at the `CalculateError` function, which simply subtracts
    the neuron''s output value from what its value should have been:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看`CalculateError`函数，它简单地从神经元的输出值中减去其应有的值：
- en: '[PRE19]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Then, scroll to the `UpdateWeights` method, as shown in the following code:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，滚动到以下代码中的`UpdateWeights`方法：
- en: '[PRE20]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '`UpdateWeights` then adjusts each of the neurons'' weights based on `learnRate`
    and `momentum`; `learnRate` and `momentum` set the speed at which the NN will
    learn. We often want to control the learning rate of the algorithm to prevent
    overfitting and falling into a local minimum or maximum. After that, the code
    is relatively straightforward, with it looping through the synapse connections
    and updating the weights with a new value. The `Bias` is used to control the intercept
    of the sigmoid activation function, thus allowing the neuron to adjust its initial
    activation function. We can see how the `Bias` can alter the activation function
    in the following graph:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: '`UpdateWeights`随后根据`learnRate`和`momentum`调整每个神经元的权重；`learnRate`和`momentum`设置了神经网络学习的速度。我们通常希望控制算法的学习率，以防止过拟合和陷入局部最小值或最大值。之后，代码相对简单，它通过循环突触连接并使用新值更新权重。`Bias`用于控制Sigmoid激活函数的截距，从而允许神经元调整其初始激活函数。我们可以在以下图表中看到`Bias`如何改变激活函数：'
- en: '![](img/0380b555-7ffa-4da2-89cc-f0ab40f7a22a.png)'
  id: totrans-190
  prefs: []
  type: TYPE_IMG
  zh: '![图表](img/0380b555-7ffa-4da2-89cc-f0ab40f7a22a.png)'
- en: Effect of Bias on the sigmoid activation function
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 偏置对Sigmoid激活函数的影响
- en: Adjusting the `Bias` allows for the neuron to start firing or activating at
    a value other than 0, as indicated in the preceding graph. Thus, if the value
    of `Bias` is 2, then the neuron will start activating at -2, as shown in the graph.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 调整`Bias`允许神经元在除了0以外的值开始放电或激活，如前图所示。因此，如果`Bias`的值为2，那么神经元将在-2处开始激活，如图所示。
- en: Defining the network architecture
  id: totrans-193
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义网络架构
- en: 'We just learned how to write and use a simple neural network to warn a user
    when they are getting too close to an object. As you look through the code, appreciate
    that most of these values are internally adjusted as part of training. When using
    a neural network, it is important to understand these basic principals:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 我们刚刚学习了如何编写和使用一个简单的神经网络来警告用户当他们离物体太近时。当你查看代码时，请注意，这些值中的大多数都是在训练过程中内部调整的。在使用神经网络时，理解这些基本原理非常重要：
- en: '**Activation function**: If you are not using sigmoid, then you will also need
    to find the partial derivative of your activation function in order to use gradient
    descent with backward propagation.'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**激活函数**: 如果你没有使用sigmoid函数，那么你还需要找到你的激活函数的偏导数，以便在使用反向传播时使用梯度下降。'
- en: '**# Input neurons**: This will not only set the complexity of the network,
    but it will also determine the number of hidden or middle layer of neurons.'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**# 输入神经元**: 这不仅会设置网络的复杂性，还会确定隐藏或中间层的神经元数量。'
- en: '**# Output neurons**: How many outputs or ways do you need your network to
    classify?'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**# 输出神经元**: 你需要你的网络有多少个输出或分类方式？'
- en: '**# Hidden layers/neurons**: As a good rule of thumb, you want to use the average
    of the input and output neurons, or just *input+output/2*. We will apply this
    rule in our next example.'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**# 隐藏层/神经元**: 作为一条好的经验法则，你希望使用输入和输出神经元的平均值，或者就是 *输入+输出/2*。我们将在下一个示例中应用这个规则。'
- en: '**Training method**: Our neural network supports two methods of training: minimum
    error or by epoch or number of iterations. Our preference will be to use minimum
    error, as this quantifies our model better.'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**训练方法**: 我们的神经网络支持两种训练方法：最小误差或按epoch或迭代次数。我们更倾向于使用最小误差，因为这能更好地量化我们的模型。'
- en: 'Included in the source code download for this chapter is a working example
    in an asset package of our simple neural network being used as an environment
    or object recognizer. Jump back to Unity and perform the following steps to set
    up this example:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 本章源代码下载中包含了一个工作示例，在资产包中展示了我们的简单神经网络被用作环境或对象识别器。回到Unity，执行以下步骤来设置此示例：
- en: Ensure that you save your existing project or download a new ARCore template
    before beginning. The asset import will overwrite your existing files, so you
    should make a backup before continuing if you want to keep any of your earlier
    work.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始之前，请确保保存你的现有项目或下载一个新的ARCore模板。资产导入将覆盖你的现有文件，所以如果你想在继续之前保留任何早期工作，你应该先进行备份。
- en: From the menu, select Assets | Import Package | Custom Package. Use the file
    dialog to navigate to the `Code/Chapter_8` folder of the book's downloaded source
    code and import `Chapter_8_Final.unitypackage`.
  id: totrans-202
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从菜单中选择“Assets | 导入包 | 自定义包”。使用文件对话框导航到书籍下载源代码的“Code/Chapter_8”文件夹，并导入“Chapter_8_Final.unitypackage”。
- en: Open the Main scene from the `Assets/ARCoreML` folder.
  id: totrans-203
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从“Assets/ARCoreML”文件夹中打开主场景。
- en: Open the Build Settings dialog and ensure that the Main scene is added to the
    build and is active.
  id: totrans-204
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开构建设置对话框，确保主场景被添加到构建中并且是激活的。
- en: 'Connect, build, and run. Now when you run the app, you will see two buttons
    at the top of the interface: one that says Train 0 and one that says Train 1.'
  id: totrans-205
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 连接、构建和运行。现在当你运行应用时，你将在界面顶部看到两个按钮：一个写着“训练0”，另一个写着“训练1”。
- en: Face your device on an area you want the NN to recognize. Ensure that ARCore
    is identifying plenty of blue points on the screen, and then press the Train 1
    button; this will signal to the network that you want it to identify this feature
    set.
  id: totrans-206
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将你的设备对准你希望神经网络识别的区域。确保ARCore正在屏幕上识别大量的蓝色点，然后按下“训练1”按钮；这将向网络发出信号，表明你希望它识别这个特征集。
- en: Face the device on an area that you don't want the NN to recognize and press
    the Train 0 button; this will reinforce to the network that you do not want it
    to recognize this area.
  id: totrans-207
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将设备对准你不想神经网络识别的区域，并按下“训练0”按钮；这将向网络强化你不想它识别这个区域。
- en: While staying in place, continue this process. Point your device at the same
    area you want recognized repeatedly and press Train 1\. Likewise, do this for
    areas you don't want recognized, but ensure that you press the Train 0 button.
    After you train 10 or so times, you should start hearing the warning beep, identifying
    when the NN has recognized your area.
  id: totrans-208
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在原地保持不动，继续这个过程。将你的设备对准你希望重复识别的区域，并按下“训练1”按钮。同样，对于你不想识别的区域，也这样做，但确保按下“训练0”按钮。训练大约10次后，你应该开始听到警告蜂鸣声，这表明神经网络已经识别了你的区域。
- en: If you start hearing the warning tones, that will be an indicator that your
    NN is starting to learn. Continue to spin around in the place, training the network,
    making sure to correct the network by pressing the appropriate button. You will
    likely have to do this several times (perhaps 20 to 50 times or so) before you
    note that the NN recognizes the area you want.
  id: totrans-209
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你开始听到警告音，那将是一个指标，表明你的神经网络（NN）开始学习。继续在那个地方旋转，训练网络，确保通过按下适当的按钮来纠正网络。你可能需要做几次（可能是20到50次左右）才能注意到NN识别了你想要区域。
- en: Ensure that when you are training the network, you can see plenty of blue points.
    If you don't see any points, you will essentially be training with null data.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 确保在训练网络时，你能看到很多蓝色点。如果你看不到任何点，你实际上就是在用空数据训练。
- en: Finally, when your network is fully trained, you should be able to spin slowly
    around the room and hear when your device recognizes your region of choice.
  id: totrans-211
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，当你的网络完全训练完成后，你应该能够慢慢地绕着房间转一圈，并听到当你的设备识别到你选择区域时。
- en: 'Using our simple NN, we were able to build an object/feature recognizer that
    we could train to recognize specific features, places, or objects. This example
    is quite simple and not very robust or accurate. However, considering the limited
    training dataset, it does a good job of being able to recognize features on the
    fly. Open up the `Environmental Scanner` script, and we will take a look at how
    the network is configured:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 使用我们简单的神经网络（NN），我们能够构建一个对象/特征识别器，可以训练它识别特定的特征、地点或对象。这个例子相当简单，并不非常稳健或准确。然而，考虑到有限的训练数据集，它能够很好地在实时识别特征。打开`环境扫描器`脚本，我们将看看网络是如何配置的：
- en: 'Scroll down to the `Awake` method and take a look at how the network is created:'
  id: totrans-213
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 滚动到`唤醒`方法，看看网络是如何创建的：
- en: '[PRE21]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Note that this time we are creating an input layer of `25` neurons and output
    of `1`. If we stick to the general rule for our hidden layer being the average
    of the input and output, that equates to `13` [(`25`+`1`)/2=`13`].
  id: totrans-215
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 注意这次我们创建了一个包含`25`个神经元的输入层和`1`个输出。如果我们坚持我们的隐藏层是输入和输出的平均值的通用规则，那么这就等于`13`个神经元（`（25+1）/2=13`）。
- en: 'We removed the initial NN setup and training from `Start` and moved it to the
    bottom in a new method called `Train`:'
  id: totrans-216
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们从`Start`方法中移除了初始的NN设置和训练，并将其移动到新的`Train`方法底部：
- en: '[PRE22]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: This time, we are using a different form of training called **epoch**. We use
    this form of training when we are not actually sure what the expected error is
    or it needs to change, as in this case. Think about this—when we start training
    our network with a very limited dataset, our error rates will be high due to our
    lack of data. This will mean that we will never be able to train our network to
    a minimum error. It, therefore, makes more sense to just run our training algorithm
    for a set number of iterations or epochs for every training cycle.
  id: totrans-218
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这次，我们使用了一种不同的训练形式，称为**时代**。当我们不确定预期的误差是什么，或者它需要改变，就像在这个例子中一样，我们会使用这种训练形式。想想看——当我们用一个非常有限的数据集开始训练我们的网络时，由于我们的数据不足，我们的错误率会很高。这意味着我们永远无法将我们的网络训练到最小误差。因此，对于每个训练周期，只运行我们的训练算法一定数量的迭代或时代似乎更有意义。
- en: 'Just preceding `Train` is `TrainNetwork`, and it''s shown as follows:'
  id: totrans-219
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`Train`方法之前是`TrainNetwork`，如下所示：
- en: '[PRE23]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '`TrainNetwork` is a public method that we use to signal to the `Environmental
    Scanner` to initiate a training cycle with the expected outcome. This allows us
    to wire up event handlers on the UI buttons to call this method with an expected
    value. When you press Train 0, `TrainNetwork` is passed `0.0`, and after the Train
    1 button is pressed, `1.0` is passed.'
  id: totrans-221
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`TrainNetwork`是一个公共方法，我们用它来向`环境扫描器`发出信号，以启动一个具有预期结果的训练周期。这允许我们在UI按钮上设置事件处理器，以调用此方法并传递预期值。当你按下“训练0”按钮时，`TrainNetwork`会传递`0.0`，而在按下“训练1”按钮后，会传递`1.0`。'
- en: 'Scroll up to the `Update` method and look at the following section of code:'
  id: totrans-222
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 滚动到`更新`方法，看看以下代码段：
- en: '[PRE24]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: This is the block of code that checks the `training` flag. If it is set, it
    collects the normalized inputs and adds them to `dataSets` with the expected outcome.
    We then turn the flag off and call `Train`.
  id: totrans-224
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这是检查`训练`标志的代码块。如果它被设置，它会收集归一化的输入并将它们添加到`dataSets`中，并带有预期的结果。然后我们关闭标志并调用`Train`。
- en: 'Scroll up to the following block of code, and you can see how we are normalizing
    the training `inputs`:'
  id: totrans-225
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 滚动到上面的代码块，你可以看到我们是如何对训练`输入`进行归一化的：
- en: '[PRE25]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Here, we are normalizing the `inputs`. An `input` represents the distance or
    magnitude between an identified point and the camera (user). Normalizing is scaling
    or converting your data to values in the range `0` to `1`. We do this, in this
    case, by finding the maximum distance of each point and then using that to divide
    into all the other inputs. The test in the loop to check whether `i` is less than
    the `PointCount` is to ensure that we always set a value for each input neuron.
  id: totrans-227
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这里，我们正在归一化`inputs`。一个`input`代表一个识别点与相机（用户）之间的距离或大小。归一化是将您的数据缩放到`0`到`1`范围内的值。在这种情况下，我们通过找到每个点的最大距离，然后使用它来除以所有其他输入来实现这一点。循环中的测试是为了确保我们始终为每个输入神经元设置一个值。
- en: The rest of the code is similar to what we wrote earlier and not worth going
    over again.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 其余的代码与我们之前写的类似，不值得再次讨论。
- en: The network view of the world
  id: totrans-229
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 网络视图的世界
- en: 'So what exactly is going on here, what is it that the network is identifying?
    Essentially, we are flattening our 3D view of the world into a 2D line or curve.
    A typical example of how this line may look normalized is as follows:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，这里到底发生了什么，网络到底在识别什么？本质上，我们正在将我们对世界的3D视图展平成2D线或曲线。以下是如何看起来归一化的典型示例：
- en: '![](img/5d6fd76d-b118-432a-b113-c6c2248e895a.png)'
  id: totrans-231
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/5d6fd76d-b118-432a-b113-c6c2248e895a.png)'
- en: Normalized input points
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 归一化输入点
- en: Those inputs represent the normalized view the neural network is training for,
    or perhaps, against. If you trained the network to recognize that line, then the
    warning sound should go off when it detects the said line. Of course, the more
    points you add, the better your recognizer may or may not work. We will leave
    it up to you to further test the network on your own.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 这些输入代表了神经网络正在训练或可能对抗的归一化视图。如果您训练网络识别那条线，那么当它检测到那条线时，警告声音应该响起。当然，您添加的点越多，您的识别器可能工作得越好，也可能不会。我们将把它留给您自己进一步测试网络。
- en: Neural networks were quite popular with game and graphic developers in the late
    1990s and early 2000s. NNs showed some success in various AI scenarios, driving
    games especially, but at the end, other purpose-built techniques won out, that
    is, until quite recently with the advent of new techniques such as convolutional
    NNs. These new successes have led to massive surges in deep learning techniques
    and platforms.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络在1990年代末和2000年代初非常受游戏和图形开发者的欢迎。神经网络在各种AI场景中取得了一些成功，尤其是在驱动游戏方面，但最终，其他专门设计的技巧胜出，即直到最近，随着卷积神经网络等新技术的出现。这些新的成功导致了深度学习技术和平台的大幅增长。
- en: This simple NN can be extended to recognize other simple functions or patterns
    you wanted. However, it will work poorly if we try to use it for any of the other
    recognition tasks we identified earlier as critical for AR. Therefore, in the
    next section, we will look at how ML solves our recognition problems with a new
    platform developed by Google, called TensorFlow.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 这个简单的神经网络可以扩展以识别您想要的其他简单函数或模式。然而，如果我们尝试将其用于我们之前确定为AR关键的其他任何识别任务，它将表现得很差。因此，在下一节中，我们将探讨如何使用谷歌开发的新平台TensorFlow来解决我们的识别问题。
- en: Exercises
  id: totrans-236
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 练习
- en: 'Work through the following exercises on your own:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 独立完成以下练习：
- en: Explain the difference between unsupervised learning, supervised learning, and
    reinforcement learning. This is more of a thought exercise, but it will be beneficial
    to really understand the difference.
  id: totrans-238
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 解释无监督学习、监督学习和强化学习之间的区别。这更多的是一种思维练习，但真正理解这些区别将是有益的。
- en: Modify the original NN example to warn you when objects are detected past a
    certain distance.
  id: totrans-239
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 修改原始神经网络示例，当检测到超过一定距离的物体时发出警告。
- en: What happens in the second example if you order the inputs by length? Does it
    still work?
  id: totrans-240
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在第二个示例中，如果您按长度对输入进行排序会发生什么？它仍然有效吗？
- en: Add an additional output neuron to the network in the second example. You will
    also need a new training button and will need to modify the `TrainNetwork` function
    to take two `inputs`.
  id: totrans-241
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在第二个示例中，向网络添加一个额外的输出神经元。您还需要一个新的训练按钮，并需要修改`TrainNetwork`函数以接受两个`inputs`。
- en: TensorFlow
  id: totrans-242
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: TensorFlow
- en: There is a new kid on the block called **TensorFlow**, also developed by Google,
    that is making impressive waves in ML. TensorFlow is a full ML platform that is
    actually more than just an execution engine with a bunch of built-in tools. What
    is even more impressive is that you can train advanced neural nets, convolutional
    neural networks, capsule networks, or whatever else you need on massive datasets
    offline. Then, you take those trained networks and put them on a mobile device
    in what is called a **MobileNet** to quickly recognize and classify complex objects.
    We will take a break from ARCore in this section and look at the upcoming power
    of TensorFlow.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习领域，有一个新出现的名字叫做 **TensorFlow**，它也是由 Google 开发的，正在掀起一股令人印象深刻的浪潮。TensorFlow
    是一个完整的机器学习平台，实际上它不仅仅是一个带有大量内置工具的执行引擎。更令人印象深刻的是，你可以在离线状态下使用大规模数据集训练高级神经网络、卷积神经网络、胶囊网络或你需要的一切。然后，你将这些训练好的网络放在一个称为
    **MobileNet** 的移动设备上，以便快速识别和分类复杂对象。在本节中，我们将暂时放下 ARCore，来看看即将到来的 TensorFlow 的强大功能。
- en: TensorFlow is an advanced ML resource and toolkit that will be worth your time,
    learning more about whether you need to do any advanced recognition tasks. Keep
    in mind, though, that this tool requires advanced knowledge in math and a working
    knowledge of Python.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow 是一个高级的机器学习资源库和工具包，值得你花时间去学习，了解你是否需要进行任何高级的识别任务。然而，请记住，这个工具需要你在数学方面有高级知识，并且对
    Python 有实际的操作经验。
- en: 'We will run the TensorFlow example for Android, not just to get a grasp of
    the power of the tool but also to understand what is possible. With Google building
    TensorFlow and ARCore though, we can only assume that new integrated tools will
    be built in the future. For now, though, let''s open Command Prompt or shell and
    get started:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将运行 TensorFlow 的 Android 示例，不仅是为了了解工具的强大功能，也是为了理解可能实现的内容。尽管 Google 正在构建 TensorFlow
    和 ARCore，但我们只能假设未来将构建新的集成工具。然而，目前，让我们打开命令提示符或 shell 并开始吧：
- en: 'Run the following command from your user folder or root:'
  id: totrans-246
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从你的用户文件夹或根目录运行以下命令：
- en: '[PRE26]'
  id: totrans-247
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Create the `TensorFlow` directory and navigate to it. Then, type the following
    command:'
  id: totrans-248
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建 `TensorFlow` 目录并导航到它。然后，输入以下命令：
- en: '[PRE27]'
  id: totrans-249
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Open Android Studio. From the Welcome screen, select Open an existing Android
    Studio project.
  id: totrans-250
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开 Android Studio。从欢迎界面，选择“打开现有的 Android Studio 项目”。
- en: Use the dialog and navigate to, select the `TensorFlow/tensorflow/examples/android`
    folder, and click on OK.
  id: totrans-251
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用对话框导航到，选择 `TensorFlow/tensorflow/examples/android` 文件夹，然后点击“确定”。
- en: If it asks you to do a Gradle Sync, click on OK.
  id: totrans-252
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果提示你进行 Gradle 同步，请点击“确定”。
- en: 'Open the `build.gradle` file from the Project side panel under the Gradle Scripts
    and set the `nativeBuildSystem` variable to `none`, as shown here:'
  id: totrans-253
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从项目侧面板下的 Gradle 脚本中打开 `build.gradle` 文件，并将 `nativeBuildSystem` 变量设置为 `none`，如图所示：
- en: '[PRE28]'
  id: totrans-254
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Connect your device and click on the Run button, the green arrow icon on top.
    Follow any necessary build steps and let the apps push to your device.
  id: totrans-255
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 连接你的设备并点击运行按钮，顶部的绿色箭头图标。遵循任何必要的构建步骤，并让应用推送到你的设备。
- en: 'When the build is completed, Studio will have pushed four apps to your device:
    **TFClassify**, **TFDetect**, **TFSpeech**, and **TFStylize**. Play around with
    each of these examples and observe the power of some networks running on your
    device.'
  id: totrans-256
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构建完成后，Studio 将推送四个应用到你的设备：**TFClassify**、**TFDetect**、**TFSpeech** 和 **TFStylize**。尝试每个示例，并观察一些在设备上运行的网络的强大功能。
- en: 'The following is an example of the TFDetect app running and correctly classifying
    a dog and person with very high accuracy:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个 TFDetect 应用运行并非常准确地分类狗和人的示例：
- en: '![](img/ad019856-28a7-4f43-84eb-82a4379fe961.png)'
  id: totrans-258
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/ad019856-28a7-4f43-84eb-82a4379fe961.png)'
- en: TFDetect correctly classifying a dog and person
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: TFDetect 正确分类狗和人的功能
- en: Unfortunately, the components needed to run TensorFlow with ARCore are not quite
    ready yet, so at the time of writing, we couldn't complete a full example. However,
    the future of ML for AR apps will most certainly be with TensorFlow or some other
    third-party solution, piggybacking on top of TensorFlow. Google has years of experience
    in AI/ML, from developing self-driving cars to the Google Home. It has put those
    years of knowledge into TensorFlow and made it accessible to the world. You would
    have to be a fool not to spend any time learning TensorFlow if you plan to build
    your own ML for object/feature recognition.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 很遗憾，运行 TensorFlow 与 ARCore 需要的组件尚未完全准备好，因此在撰写本文时，我们无法完成一个完整的示例。然而，AR 应用程序的机器学习未来无疑将与
    TensorFlow 或其他第三方解决方案相结合，在 TensorFlow 的基础上进行。谷歌在人工智能/机器学习领域拥有多年的经验，从开发自动驾驶汽车到
    Google Home。它将这些年的知识融入 TensorFlow，使其对全世界开放。如果你计划构建自己的机器学习对象/特征识别，不花时间学习 TensorFlow
    算是愚蠢之举。
- en: We had planned to build an example with a trained MobileNet running in ARCore.
    Unfortunately, the pieces were not quite ready yet, and it made for a far too
    complicated example. Right around the time that this book is published, we will
    likely see more tools developed to make integrating TensorFlow into ARCore easier.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 我们计划构建一个在 ARCore 中运行的经过训练的 MobileNet 的示例。遗憾的是，组件尚未完全准备好，这导致了一个过于复杂的示例。大约在本书出版时，我们可能会看到更多工具的开发，以使将
    TensorFlow 集成到 ARCore 中变得更加容易。
- en: Summary
  id: totrans-262
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we took a proverbial dive into the deep end—or the deep learning
    end—of the pool. We started by talking about the importance of ML and what applications
    we can use it for in AR. Then, we looked at how ML can use various methods of
    learning from unsupervised, supervised, and reinforcement learning in order to
    teach an ML agent to learn. We then looked at a specific example of learning ML
    algorithms, called neural networks and often referred to as deep learning. This
    led us to build a simple neural network that you can also use to learn the intricacies
    of neural networks on your own. NNs are very complex and not very intuitive, and
    it is helpful to understand their basic structure well. We then trained this network
    on a very simple dataset to notify the user if they get too close to an object.
    This led to a further discussion of how NNs train with back propagation using
    the gradient descent algorithm. After that, we looked at an enhanced example that
    allows you to train the network to recognize an area or object. Finally, we looked
    at the current king of ML, TensorFlow, and looked at a quick example of what is
    possible and what is coming soon.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们深入探讨了机器学习的深层次——或者说深度学习的深层次——领域。我们首先讨论了机器学习的重要性以及我们可以在 AR 中使用它的应用。然后，我们探讨了机器学习如何通过无监督学习、监督学习和强化学习等不同学习方法来教授机器学习代理进行学习。接着，我们查看了一个特定的学习机器学习算法的例子，称为神经网络，通常被称为深度学习。这引导我们构建了一个简单的神经网络，你也可以用它来自己学习神经网络的复杂性。神经网络非常复杂，不太直观，因此了解它们的基本结构非常重要。然后，我们在一个非常简单的数据集上训练了这个网络，以通知用户他们是否离物体太近。这进一步讨论了神经网络如何使用梯度下降算法进行反向传播训练。之后，我们查看了一个增强的例子，它允许你训练网络来识别区域或对象。最后，我们探讨了当前机器学习的王者
    TensorFlow，并查看了一个快速示例，展示了可能性和即将到来的是什么。
- en: In the next chapter, we get back to building a practical example with ARCore.
    We will build a simple design app that lets the user virtually decorate their
    living space.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将回到使用 ARCore 构建实际示例。我们将构建一个简单的设计应用程序，让用户能够虚拟装饰他们的生活空间。
