- en: Recognizing the Environment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Throughout this book, we have looked at the numerous ways of how our device,
    with the help of ARCore, can track the user, understand the user's world, and
    render an alternate reality. ARCore uses the device's sensors and camera as inputs
    to constantly update what it perceives as the user's real world. However, what
    if we wanted to do more for the user; perhaps identify a certain object, sign,
    or landmark? That would require a much more advanced set of tools. Even just 5
    years ago, this would seem like an incredibly daunting task. With the advent of
    OpenAI, thanks to Mr. Musk, many other companies have started to open source and
    make their tools available. This has led to phenomenal explosive growth in these
    technologies, colloquially referred to as **Machine Learning** (**ML**), and broadened
    their accessibility to everyone. Fortunately, for those interested in developing
    AR apps, this is a good thing. We want all the help we can get when it comes to
    recognizing and understanding the user's environment.
  prefs: []
  type: TYPE_NORMAL
- en: 'For this chapter, we will introduce ML and explore how we can use it to create
    better AR apps for our users. In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to ML
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deep reinforcement learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Programming a neural network
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Training a neural network
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: TensorFlow
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Machine Learning is a very advanced subject that can take years of study in
    order to master. However, for our purposes, we will learn some basic techniques,
    which the reader can extend on later, either through more learning or implementing
    their own solution.
  prefs: []
  type: TYPE_NORMAL
- en: If you already have an in-depth understanding of neural networks, convolutional
    neural networks, and TensorFlow, feel free to breeze over this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to ML
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Machine Learning is a term widely used to refer to artificial intelligence and
    related computer predictive analytical models. The name Machine Learning, while
    perhaps overly generalized, fits better than the term AI. However, Machine Learning
    is itself such a broad term that it perhaps needs some further explanation and
    clarification. A machine obviously refers to a computer, or other device and learning
    tends to denote an algorithm or model that will evolve or learn over time. However,
    this is often not the case in many Machine Learning models. Therefore, for our
    purposes, we will use the broader term of Machine Learning to refer to any tool
    or algorithm that can be trained to recognize the environment or parts of the
    environment in AR, thus allowing us, the developers, to better augment our user's
    world.
  prefs: []
  type: TYPE_NORMAL
- en: Data science and Machine Learning go hand in hand. Data science is all about
    making sense of data, extracting patterns, and making predictions. In essence,
    when you start writing Machine Learning models in order to recognize objects or
    the environment, you are really just analyzing data, which means you can also,
    very loosely, call yourself a data scientist.
  prefs: []
  type: TYPE_NORMAL
- en: 'Machine Learning is a big area and is only getting bigger every day, so let''s
    break down the specific problems we would like ML to help us with:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Target detection**: Targets have been used in AR for some time. It has been
    the primary tracking and reference point for many AR apps previous to ARCore.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Image recognition**: This spawns into a whole set of sub-applications, all
    of which we will deal with in detail later.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Object detection**: Being able to detect an object in 3D from point cloud
    data is no easy feat, but it has been done and is getting better.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Face detection**: Detecting a person''s face in an image has been around
    for years and has been used to great effect in many apps.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Person detection**: Detecting people or motion has great possibilities. Think
    Kinect comes to AR.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Hand**/**Gesture detection**: Not to be confused with touch gestures. This
    is where we detect a user''s hand motions or gestures in front of a device''s
    camera.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Pose detection on object**: Related to object detection, but now we also
    detect the position and orientation of the object.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Light source detection**: Being able to place realistic lights in a scene
    to make virtual object rendering more realistic. We already looked at the importance
    of lighting in [Chapter 7](edd56812-fcba-4f66-aa3e-e9cf9ee7b637.xhtml), *Light
    Estimation*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Environment detection**: Recognizing the environment a user has moved into
    has great application in mapping buildings or other locations where GPS is unavailable,
    which applies to most internal spaces.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each of those problems may require different tools and techniques to solve those
    issues. In ML, it's not always about using the tool but the final answer and what
    works. Think about this as you build any ML you need for your app. Try a variety
    of ML tools and techniques; differences in size and performance of ML models can
    be critical, and it's something you need to consider.
  prefs: []
  type: TYPE_NORMAL
- en: A Machine Learning algorithm walks into a restaurant.
  prefs: []
  type: TYPE_NORMAL
- en: The waiter asks, "What will you have?
  prefs: []
  type: TYPE_NORMAL
- en: The algorithm says, "What's everyone else having?"
  prefs: []
  type: TYPE_NORMAL
- en: '- Unknown'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following table is a summary of the current major ML providers and the
    types of AR problems they can be used to solve:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Toolset** | **Pros/Cons** | **Machine Learning task** |'
  prefs: []
  type: TYPE_TB
- en: '| **Targets/Image** | **Object/Pose** | **Face** | **Person** | **Hand** |
    **Light** | **Environment** |'
  prefs: []
  type: TYPE_TB
- en: '| Vuforia | Mature and easy to use. Requires internet connectivity. | Yes |
    Yes/Paid |  |  |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| XZIMG | Face and image/target tracking supported for Unity and other platforms.
    | Yes |  | Yes |  |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| ARToolkit | Mature OpenSource platform for image tacking and feature detection.
    | Yes |  |  |  |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| EasyAR | Pro license gets object and feature tracking. | Yes | Yes/Paid |  |  |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| Google Face Detection API | Low level Android API. |  |  | Yes |  |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| OpenCV | A mature low-level API for Android, commercial version ported to
    Unity. Still requires low level knowledge. | Yes | Yes | Yes | Yes | Yes | Coming
    | Coming |'
  prefs: []
  type: TYPE_TB
- en: '| Google TensorFlow | Still in its infancy but quickly becoming the platform
    standard for CNN. Low level and advanced ML knowledge required. | Yes | Yes |
    Yes | Yes | Yes | coming | coming |'
  prefs: []
  type: TYPE_TB
- en: '| Google ARCore | Currently, identifies planes, feature points, and light.
    |  |  |  |  | Yes | Yes |'
  prefs: []
  type: TYPE_TB
- en: We only included the main players who have built an AR platform for a mobile
    ARCore-supported device. Web technologies were omitted from this due to their
    limitations, although many of the mentioned technologies require internet connectivity
    and support web platforms as well. If you quickly review the table, you can also
    clearly see two main contenders that have the potential to dominate the entire
    space; that's because these are both low-level technologies that often back larger
    platforms such as Vuforia. Both of these platforms now support mobile pretrained
    networks for fast recognition on mobile devices. This may not seem like a big
    deal yet, but after we get into training our own models, you will see why.
  prefs: []
  type: TYPE_NORMAL
- en: Linear regression explained
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s discuss the basic premise behind what Machine Learning is and what it
    attempts to accomplish. Take a look at the following chart that shows some fictional
    sales data for your next app:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a6bb518b-0fb4-485f-8be4-390fc27184bd.png)'
  prefs: []
  type: TYPE_IMG
- en: Chart of fictional sales data
  prefs: []
  type: TYPE_NORMAL
- en: Now, just looking at the chart, you can see that as the *x* values increase
    (perhaps days on sale), it appears that our sales also increase: *y* value (sales).
    By just eyeing the chart, we ourselves can make predictions by following the trend
    of the points. Try it; how many sales are for an *x* value (bottom axis) of 25?
    Give it a guess, and write it down. With your guess secured, we will use a technique
    called **linear regression** to find a good answer.
  prefs: []
  type: TYPE_NORMAL
- en: 'Linear regression has been around for years and is considered as the base for
    many statistical data analysis methods. It is the basis for many other Machine
    Learning algorithms used in data science and predictive analysis today. This technique
    works by finding a solution (a line, curve, or whatever) that best fits the points.
    From that solution, we can determine the future or previous events or occurrences.
    Since this method is so well established, you can just open up Excel and let it
    draw the linear regression solution right on the graph. The following is an example
    of the linear regression with a trend line and equation added to the chart:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/fb098124-343b-45ba-abe6-e30e4c25ec4b.png)'
  prefs: []
  type: TYPE_IMG
- en: Chart with linear regression trend line
  prefs: []
  type: TYPE_NORMAL
- en: Keep in mind that this example uses 2D points, but the same concepts equally
    apply to 3D as well. You just need to account for the extra dimension, which is
    not always a trivial thing but doable nonetheless.
  prefs: []
  type: TYPE_NORMAL
- en: Without getting into the nitty-gritty details of the math, just understand that
    the line is drawn in order to minimize the error between the line and the points,
    which is often referred to as the line of best fit or one that minimizes the error,
    which in this case, is expressed as an R squared value (**R²**). **R²** ranges
    in value from 1.0, a best possible fit, to 0.0, or shooting blanks in the dark.
    You can see that our **R²** is not perfect, but it is **0.9125 ** out of 1 or
    91.25% correct; it's not perfect but perhaps good enough.
  prefs: []
  type: TYPE_NORMAL
- en: Probability and statistics play heavily into Machine Learning of all forms.
    If you don't have a good statistics background, you can still get the statistics
    by choosing a third-party provider. The only exception is if you have issues with
    that technology; then, it helps to have some background on your side, which is
    probably not something you wanted to hear if you're already trying to catch up
    on your 3D math skills.
  prefs: []
  type: TYPE_NORMAL
- en: Take the example we just looked at and now think about the problem in 3D, and
    it's not a line but a 3D object we want to recognize or predict. Obviously, things
    can get complicated quite fast and computationally expensive using statistical
    models. Fortunately, there is a better way to do this using a technique that uses
    **supervised learning** that models the human brain, called **neural networks**
    (**NN**).
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will go under the covers into supervised learning and
    explore some techniques that we can use to analyze data using **deep learning**
    (**DL**) with neural networks.
  prefs: []
  type: TYPE_NORMAL
- en: Deep learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we discussed, the more traditional predictive models such as linear regression
    don't scale well, because they always need to calculate the whole solution using
    all the available points or data. These types of techniques or models have no
    ability to remember, learn, and improve, and they are generally classified as
    supervised models. This has led to the evolution of more advanced learning models
    known as **reinforcement learning** (**RL**) techniques for solving ML problems.
    In fact, deep learning and deep reinforcement learning techniques now outclass
    statistical methods in performance and accuracy by several orders of magnitude.
    However, that wasn't always the case, and statistical methods are also improving
    just as dramatically everyday. It really is an exciting time to be getting into
    Machine Learning.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following diagram demonstrates the reinforcement learning process:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/40c72b92-4041-4106-add0-16b98161e8f8.png)'
  prefs: []
  type: TYPE_IMG
- en: Reinforcement learning process
  prefs: []
  type: TYPE_NORMAL
- en: In the diagram, you can see that there is an **Agent** (assume computer) and
    the **Environment** (game or real world). The **Agent** acts on **Observations**
    from the **Environment**, and those actions may or may not be based on **Rewards**.
    An RL system using rewards is known as reinforcement learning. The learning method
    we will use in this chapter is called supervised learning since we are labeling
    or training to a specific output class. Unsupervised learning is a class of training
    that doesn't label data but just uses techniques to classify or group data.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are three classes of training we typically identify: unsupervised learning,
    supervised learning, and reinforcement learning. Reinforcement learning uses a
    rewards-based system on top of supervised or unsupervised systems as an enhancement
    to learning. RL systems can learn this way with essentially no initial training.
    AlphaGo Zero, which uses a deep RL model, is currently making the news after being
    able to beat a trained version of itself from scratch, with no human intervention.'
  prefs: []
  type: TYPE_NORMAL
- en: Part of the problem in defining all these ML concepts is that they often get
    woven together, where one learning algorithm or technique is layered on top of
    another, perhaps using RL with or without supervision. It is quite common, as
    we will see, to use multiple different layers of techniques to produce an accurate
    answer. This layering also has the benefit of being able to try multiple different
    approaches quickly or swap a technique out for something better later.
  prefs: []
  type: TYPE_NORMAL
- en: Deep learning is the term we use to describe this layering process. DL can be
    trained using any of the training methods we talked about. In any case, we need
    to stop talking in generalities and actually look at the DL process.
  prefs: []
  type: TYPE_NORMAL
- en: Deep reinforcement learning has become quite popular as of late with plenty
    of success from playing Atari games to beating earlier supervised trained versions
    of itself quickly. If this area of training interests you, ensure that you search
    for AlphaGo Zero.
  prefs: []
  type: TYPE_NORMAL
- en: Neural networks – the foundation of deep learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'When we speak of DL, we generally think of one ML technique called neural networks.
    Neural networks were conceptualized by trying to model the human brain. At the
    core of a neural network is the neuron, called so because it represents a single
    human brain cell. The following is an image of a human and computer neuron:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1ebe7ce1-750f-484d-bf5e-b567a5515012.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Human and computer neuron
  prefs: []
  type: TYPE_NORMAL
- en: 'Just like the brain, where billions of neurons are connected in layers, we
    connect neurons in layers in a similar way. Each neuron is connected to all the
    other neurons'' inputs and outputs in layers, where the first layer takes our
    input and the last layer or perhaps single neuron spits out our answer. The following
    is an example of what this typically looks like:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3a6b9b74-f880-4efd-a7a9-ff00ee7db3a3.png)'
  prefs: []
  type: TYPE_IMG
- en: Neural network with layers
  prefs: []
  type: TYPE_NORMAL
- en: One thing we should clarify before going any further is that the layers we talk
    about in deep learning don't correspond to the layers in a neural network. Think
    of a neural network as being in one layer of the DL system.
  prefs: []
  type: TYPE_NORMAL
- en: Here, each circle in the diagram represents a single neuron. Each neuron fires
    when the sum of all its inputs passes some threshold or activation function. This
    process continues for all the neurons, and the final layer outputs the answer.
    Of course, this is a very simple example, but it is difficult to see the power
    of neural networks until you start programming with them. Therefore, in the next
    section, we will write a neural network, which we plan to use to recognize objects
    in the environment.
  prefs: []
  type: TYPE_NORMAL
- en: When you encounter neural networks for the first time, the assumption is that
    this can't possibly work. After all, how could a self-driving car recognize a
    person using just a bunch of interconnected neurons? The answer to that is how
    indeed. We are really only starting to understand how the neural networks do what
    they do and, often, what we find is that we need to go back to the drawing board.
    In this case, the drawing board is the human brain and some of the more recent
    advances in neural networks were results of further brain research.
  prefs: []
  type: TYPE_NORMAL
- en: Programming a neural network
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The best way to learn something is to do it, so in this section, we will write
    a simple neural network that we'll then train to perform various tasks. This network
    will have a set number of layers—input, hidden, and output—but we will allow for
    a number of neurons to be set in each layer. We will write this code in Unity
    so that we can use it in [Chapter 10](6a8f64fb-080f-47a2-9565-4099269831b1.xhtml), *Mixing
    in Mixed Reality*.
  prefs: []
  type: TYPE_NORMAL
- en: Writing a neural network is an advanced example, which will require a discussion
    with math to properly explain. If you feel overwhelmed at any time, you can always
    open up the finished project and check the final results. Of course, if you have
    written a neural network earlier, then you may also want to skip this section.
  prefs: []
  type: TYPE_NORMAL
- en: 'For this example, we will create a new project from the source Unity template,
    so let''s get started by opening Command Prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a new folder called `ARCore` off the root (`C:\` on Windows) folder
    using the following commands:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: This set of commands creates a new folder and then navigates to it.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Execute the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: This pulls the Unity ARCore template from GitHub into a new folder called `ARCoreML`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Open a new instance of Unity and click on Open on the Project page. This will
    open the select project folder dialog. Select the new folder you just pulled the
    template into, `ARCoreML`,to open the project. Wait as the project opens in the
    Unity editor.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Right-click on (*Ctrl* + Click on Mac) the `Assets` folder in the Project window.
    Select Create | Folder from the context menu. Name the new folder `Scripts`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Open the `HelloAR` scene from the `Assets/GoogleARCore/Examples/HelloAR` folder
    by double-clicking on it in the Project window.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: From the menu, select **File** | Build Settings. Ensure that Android is set
    for the target platform and the `HelloAR` scene is set as scene `0` in the build.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Connect your device and build and run. Just ensure that the example runs as
    you expected on your device.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Scripting the neural network
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'With the new project set up, we can now start writing our scripts to build
    a neural network. Go back to Unity and perform the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Open the `ARCoreML/Scripts` folder and then from the menu, select Assets | Create
    | C# Script. Name the script as `Neuron` and double-click to open it in your editor
    of choice.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The code for this example was originally sourced from [https://github.com/Blueteak/Unity-Neural-Network.git](https://github.com/Blueteak/Unity-Neural-Network.git),
    which shows an excellent example of a simple and concise neural network with training
    explicitly developed for Unity. We will modify the original code for our needs,
    but feel free to check out and contribute to the original source if you are interested.
    This code is great for learning, but certainly, it's not something you may want
    to use in production. We will look at options for production-ready neural networks
    in the section on TensorFlow.
  prefs: []
  type: TYPE_NORMAL
- en: 'Delete all the code, leave the `using` statements, and then add the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Note how this class does not inherit `MonoBehaviour` and thus will not be a
    game object, which means we will load this class in another script. Then, we create
    a placeholder for `Random`; we do this because we are using `System.Random` rather
    than `Unity.Random`. `Unity.Random` only supports generating a random `float`,
    but we need the precision of a `double`. The rest are just properties that we
    will discuss as we get to the relevant code sections.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Enter the following after the last property declaration but before the class''s
    ending brace:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: We create this `static` helper method in order to generate `double` random numbers
    from `-1.0` to `1.0`. This allows for greater precision and assures that our values
    are always getting generated around `0`. Keeping values close to `0` avoids rounding
    errors and just generally makes things easier to calculate.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Next, enter the following code after the `static` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Here, we set up a base and single parameter constructors. The base constructor
    creates a `List<Synapse>` for the input and output connections to the neuron.
    A `Synapse` represents a connection. The other constructor calls the base (`this`)
    and takes an `IEnumerable<Neuron>` of neurons that it then connects back to. This
    way, networks can be built bottom up; we will see how this works when we get to
    the `NeuralNet` class.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Next, we will add the rest of the methods for the `Neuron` class:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: We added four methods here: `CalculateValue`, `CalculateError`, `CalculateGradient`,
    and `UpdateWeights`. `CalculateValue` is used to determine the neuron's output
    based on the activation function we defined in `Sigmoid`. We will get to `Sigmoid`
    shortly. The other methods are used to train the neuron. Training a neuron is
    something we will cover in the next section.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Stay in the same file, and add the following three new helper classes outside
    the `Neuron` class:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: The first class `Synapse`, as we already know, defines a connection between
    neurons. Next comes `Sigmoid`, which, conveniently enough, is just a wrapper class
    for the sigmoid activation function we use. Note that the values are getting capped
    at `-45.0` and `+45.0`. This limits the size of our network, but we can manually
    change that later. Then comes `DataSet`, which is just a holder for our training
    data.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'That completes the `Neuron` class. Create another script in Unity, and this
    time, call it `NeuralNet`; open it up in your editor of choice and perform the
    following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Delete the starter code again, but leave the `using`''s statements, and enter
    the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Again, this is another set of public properties that define the `LearnRate`
    network and `Momentum`. Then, three `List<Neuron>` to hold the collection of neurons
    in the input, hidden (middle), and output layers. In this example, we use a single
    hidden layer, but more sophisticated networks often support several more layers.
    You guessed it, `LearnRate` and `Momentum` will be covered in the section on training.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We generally prefer not to use properties with getters and setters in Unity.
    Why? Primarily because the Unity editor just plays better with public fields.
    Secondarily, game programming is all about performance, and it only makes sense
    to avoid the overhead of getters and setters where possible. Using a list is also
    a no-no, but it makes the code easier to understand in this case.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, let''s add a constructor for our `NeuralNet`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: This constructor expects several inputs, including the number of neurons in
    the input, hidden, and output layers, in addition to a value for the `learnRate`
    and `momentum`. Inside the constructor, the properties are initialized based on
    the input values. Note how the first layer uses the default `Neuron` constructor,
    and the successive layers use the single parameter constructor with the previous
    layer as input. Remember from building the `Neuron` class that this is where all
    the synapse connections between the neuron layers are added.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Next, we will add a couple of methods for training:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we will add methods to propagate the network forward and backward:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, add the following methods to compute the whole network and to calculate
    errors:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: That completes the neural network code. We left a number of areas for discussion
    in the next section on training the neural network.
  prefs: []
  type: TYPE_NORMAL
- en: Training a neural network
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As you may have already summarized, a neural network is essentially useless
    until it is trained. Before we get into training, we should talk some more on
    how a neuron is activated. Open up the `Neuron` class again and take a look at
    the `CalculateValue` function. This method calculates the output based on its
    internal set of weights and is described by the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5bd05beb-4c40-411f-996d-e4c0c396ef43.png)![](img/d0fefff0-1227-4e2b-b7ae-b3529be79bb6.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/bbd0e139-c191-48c1-b1fb-32e5193d399a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Also, keep the following in mind:'
  prefs: []
  type: TYPE_NORMAL
- en: '*n* = total number of neurons connected as inputs'
  prefs: []
  type: TYPE_NORMAL
- en: '*I* = signaled input to the `Neuron` class'
  prefs: []
  type: TYPE_NORMAL
- en: '*O* = calculated output'
  prefs: []
  type: TYPE_NORMAL
- en: '*S* = the `sigmoid` function with a graph:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3cad5108-6d20-4609-81e8-6643e2a262ad.png)'
  prefs: []
  type: TYPE_IMG
- en: Sigmoid function
  prefs: []
  type: TYPE_NORMAL
- en: '**Sigmoid Function** essentially distributes the weighted sum of values between
    0 and 1 based on a curve (function) similar to the one shown in the preceding
    graph. We do this in order to evenly weigh the outputs of each of the neurons.
    Likewise, when we look to input data into a network, we also like to normalize
    the values between 0 and 1\. If we didn''t do this, one single neuron or input
    could bias our entire network. This is like hitting your thumb with a hammer and
    only being able to feel pain in your thumb for the next several seconds, Except
    that we don''t want our network to respond to wild inputs like that. Instead,
    we want to mellow our network out with the `sigmoid` function.'
  prefs: []
  type: TYPE_NORMAL
- en: Activating the warning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s delay our discussion of training a bit further and put together a simple
    example to see how this works. Open up Unity again and perform the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Create a new C# script called `EnvironmentScanner` in the `Assets/ARCoreML/Scripts`
    folder. Then, open the script in your editor.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Add the code, as shown, to the class definition:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '`RequireComponent` is a custom Unity attribute that forces a `GameObject` to
    require a specific class before this component can be added. In this example,
    we require an `AudioSource` component.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Enter the following new properties/fields and method to the class; don''t delete
    anything:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: The `Awake` method is special in Unity in that it gets called when the object
    first wakes up or becomes active. `Awake` varies from `Start` in that it is called
    upon initialization of the object, whereas `Start` is called before the first
    frame an object is rendered. The difference is subtle and is typically only relevant
    when you are worried about object load time.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Next, we create a number of temporary input variables for setting the number
    of **input**, **hidden**, and **output** neurons. For this example, we will use
    one input, four hidden, and one output. These inputs are used to create `NeuralNet`
    in the next line, which is followed by the initialization of the `dataSets` list.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Next, let''s modify the `Start` method to resemble the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'The first line inside `Start` creates a very simple `DataSet` with inputs and
    outputs. Since we are using a single input and output neuron, these inputs and
    outputs map 1 to 1 and thus produce the following chart:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/ce4f1a06-3c30-4222-9461-9d280c01cb5f.png)'
  prefs: []
  type: TYPE_IMG
- en: Chart of training inputs
  prefs: []
  type: TYPE_NORMAL
- en: Then, `net.Train` trains the neural network with a minimum error of `.001`.
    After that, it gets the required `AudioSource`, remembers the `RequireComponent`
    attribute, and sets it to a private `audioSource` field. We will use sound in
    order to warn the user when they get too close. Think about what it is that those
    points are describing as a function.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Finally, modify the `Update` method to include the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: There is a lot going on here, so let's break it down. We first check whether
    the `warning` is `true`. If it is, we play a sound, otherwise we stop playing;
    `warning` will be our flag to indicate when our NN is signalling. Next, we ensure
    that the `Frame` is tracking, with the same code as we saw earlier. Then, we reset
    `min` and get the current point cloud from the `Frame`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: After that, we ensure that `pointCloud` has points, and it is the most recent.
    This is checked by testing the timestamp. Then, inside the `if` block, we calculate
    the current min by looping through all points. We then push this through our NN
    with `net.Compute`, the value of `min` (minimum point); this returns our signal
    or neuron output. In this particular case, we are testing for `.001` to determine
    whether the neuron is signalling an activation. This sets the warning to `true`
    or `false`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Save the code and return to Unity; ensure that you see no compiler errors.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Adding the environmental scanner
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that we have a script that uses the component, let''s add it to our scene
    as a new object. Return to the editor where we last left off and continue as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Open the `HelloAR` scene. From the menu, select File | Save as and save the
    scene as `Main` in the `Assets/ARCoreML` folder.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Find and select First Person Camera in the Hierarchy window. Remember that you
    can use the search panel.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Right-click (*Ctrl* + Click on Mac) on the First Person Camera and from the
    context menu, select Create Empty. Name the object as `Environmental Scanner`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select the new object and in the Inspector window, add a new `AudioSource` component.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a new folder called `Audio` in the `Assets/ARCoreML` path in the Project
    window.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Open the `Resources` folder from the downloaded code folder and copy the `tone-beep.wav`
    file to the new `Assets/ARCoreML/Audio` folder you just created.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Open up the `Environmental Scanner` object in the Inspector window and set
    the AudioSource properties, as shown in the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/2e7a3aca-4c32-4a9f-a92d-4b3fd67d0d5c.png)'
  prefs: []
  type: TYPE_IMG
- en: Setting the AudioSource properties in the Inspector
  prefs: []
  type: TYPE_NORMAL
- en: With `Environmental Scanner` still selected, click on the Add Component button
    in the I**nspector** window. Add the `Environmental Scanner` script we wrote earlier.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Open the Build Settings dialog and ensure that you add the current scene (`Main`)
    to the build. Ensure that you remove any other scenes from the build.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Connect, build, and run. Move around the room. Now what happens when you get
    too close to objects? At what distance?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Great, so we have effectively made a backup or warning beeper to let you know
    when you are getting too close to an object. Obviously, we could have just as
    easily written a simple threshold test ourselves to test when `min` is getting
    too close. However, this simple example gives us a good basis for understanding
    how training works.
  prefs: []
  type: TYPE_NORMAL
- en: Backward propagation explained
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this example, we are pretraining our model (supervised learning) to a simple
    function described by a set of inputs (1.0, 0.1, 0) and expected outputs of (0,
    1.0, 1.0), which is represented by the graph/chart we saw earlier. In essence,
    we want our neural net to learn the function defined by those points and be able
    to output those results. We do this by calling `net.Train`, passing in `datasets`
    and the minimum expected error. This trains the network by backward propagating
    the error through each neuron of the network until a minimum error can be reached.
    Then, the training stops and the network declares itself ready.
  prefs: []
  type: TYPE_NORMAL
- en: 'Backward propagation works using a simple iterative optimization algorithm
    called **gradient descent**, which uses the minimum error to minimize each of
    the neuron input weights so that the global minimum error can be reached. To fully
    understand this, we will need to go into some differential calculus and derivatives.
    Instead, we will take a shortcut and just look at what the code is doing in the
    `Train` method of the `NeuralNet` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'The code here is relatively straightforward. We set an `error` and `numEpochs`.
    Then, we start a `while` loop that ends when the `error` is greater than the `minimumError`
    (global) and the `numEpochs` is less than the maximum `int` value. Inside the
    loop, we then loop through each `dataSet` in `dataSets`. First, `ForwardPropagate` is
    used on the inputs of the dataset values to determine output. Then, `BackPropagate`
    is used on the dataset target value to adjust the weights on each of the neurons
    using gradient descent. Let''s take a look inside the `BackPropagate` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'This method just elegantly loops through each layer of neurons using `ForEach`
    from `System.Linq`. First, it calculates the gradient in the output and hidden
    layers and then it adjusts the weights in reverse order: first the hidden and
    then the output. Next, we will dissect the `CalculateGradient` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: We can see that the `CalculateGradient` method takes a nullable `double` called
    `target`. If `target` is `null`, the `Gradient` is calculated by summing the previous
    gradient multiplied by the input weights. Otherwise, the `Gradient` is calculated
    by multiplying the error by the derivative of the `Sigmoid`. Remember that, sigmoid
    was our activation function, which is essentially what we are trying to minimize.
    If you recall from calculus, we can take the derivative of a function in order
    to determine its minimum or maximum value. In fact, in order to use the gradient
    descent method for backward propagation, your activation function has to be differentiable.
  prefs: []
  type: TYPE_NORMAL
- en: Gradient descent explained
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Gradient descent uses the partial derivative of the loss or error function
    in order to propagate the updates back to the neuron weights. Our cost function
    in this example is the sigmoid function, which relates back to our activation
    function. In order to find the gradient for the output neuron, we need to derive
    the partial derivative of the sigmoid function. The following graph shows how
    the gradient descent method walks down the derivative in order to find the minimum:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f3899ca3-835e-4d3e-8e7f-fd1c5a9044fb.png)'
  prefs: []
  type: TYPE_IMG
- en: Gradient descent algorithm visualized
  prefs: []
  type: TYPE_NORMAL
- en: If you plan to spend anymore time studying neural networks, deep learning, or
    machine learning, you will certainly study the mathematics of gradient descent
    and backward propagation in more depth. However, it is unlikely that you will
    get further exposure to the basic concepts of programming a neural network, so
    this chapter will be a good future reference.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take a look at the `CalculateError` function, which simply subtracts
    the neuron''s output value from what its value should have been:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, scroll to the `UpdateWeights` method, as shown in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: '`UpdateWeights` then adjusts each of the neurons'' weights based on `learnRate`
    and `momentum`; `learnRate` and `momentum` set the speed at which the NN will
    learn. We often want to control the learning rate of the algorithm to prevent
    overfitting and falling into a local minimum or maximum. After that, the code
    is relatively straightforward, with it looping through the synapse connections
    and updating the weights with a new value. The `Bias` is used to control the intercept
    of the sigmoid activation function, thus allowing the neuron to adjust its initial
    activation function. We can see how the `Bias` can alter the activation function
    in the following graph:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0380b555-7ffa-4da2-89cc-f0ab40f7a22a.png)'
  prefs: []
  type: TYPE_IMG
- en: Effect of Bias on the sigmoid activation function
  prefs: []
  type: TYPE_NORMAL
- en: Adjusting the `Bias` allows for the neuron to start firing or activating at
    a value other than 0, as indicated in the preceding graph. Thus, if the value
    of `Bias` is 2, then the neuron will start activating at -2, as shown in the graph.
  prefs: []
  type: TYPE_NORMAL
- en: Defining the network architecture
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We just learned how to write and use a simple neural network to warn a user
    when they are getting too close to an object. As you look through the code, appreciate
    that most of these values are internally adjusted as part of training. When using
    a neural network, it is important to understand these basic principals:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Activation function**: If you are not using sigmoid, then you will also need
    to find the partial derivative of your activation function in order to use gradient
    descent with backward propagation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**# Input neurons**: This will not only set the complexity of the network,
    but it will also determine the number of hidden or middle layer of neurons.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**# Output neurons**: How many outputs or ways do you need your network to
    classify?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**# Hidden layers/neurons**: As a good rule of thumb, you want to use the average
    of the input and output neurons, or just *input+output/2*. We will apply this
    rule in our next example.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Training method**: Our neural network supports two methods of training: minimum
    error or by epoch or number of iterations. Our preference will be to use minimum
    error, as this quantifies our model better.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Included in the source code download for this chapter is a working example
    in an asset package of our simple neural network being used as an environment
    or object recognizer. Jump back to Unity and perform the following steps to set
    up this example:'
  prefs: []
  type: TYPE_NORMAL
- en: Ensure that you save your existing project or download a new ARCore template
    before beginning. The asset import will overwrite your existing files, so you
    should make a backup before continuing if you want to keep any of your earlier
    work.
  prefs: []
  type: TYPE_NORMAL
- en: From the menu, select Assets | Import Package | Custom Package. Use the file
    dialog to navigate to the `Code/Chapter_8` folder of the book's downloaded source
    code and import `Chapter_8_Final.unitypackage`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Open the Main scene from the `Assets/ARCoreML` folder.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Open the Build Settings dialog and ensure that the Main scene is added to the
    build and is active.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Connect, build, and run. Now when you run the app, you will see two buttons
    at the top of the interface: one that says Train 0 and one that says Train 1.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Face your device on an area you want the NN to recognize. Ensure that ARCore
    is identifying plenty of blue points on the screen, and then press the Train 1
    button; this will signal to the network that you want it to identify this feature
    set.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Face the device on an area that you don't want the NN to recognize and press
    the Train 0 button; this will reinforce to the network that you do not want it
    to recognize this area.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: While staying in place, continue this process. Point your device at the same
    area you want recognized repeatedly and press Train 1\. Likewise, do this for
    areas you don't want recognized, but ensure that you press the Train 0 button.
    After you train 10 or so times, you should start hearing the warning beep, identifying
    when the NN has recognized your area.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If you start hearing the warning tones, that will be an indicator that your
    NN is starting to learn. Continue to spin around in the place, training the network,
    making sure to correct the network by pressing the appropriate button. You will
    likely have to do this several times (perhaps 20 to 50 times or so) before you
    note that the NN recognizes the area you want.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Ensure that when you are training the network, you can see plenty of blue points.
    If you don't see any points, you will essentially be training with null data.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, when your network is fully trained, you should be able to spin slowly
    around the room and hear when your device recognizes your region of choice.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Using our simple NN, we were able to build an object/feature recognizer that
    we could train to recognize specific features, places, or objects. This example
    is quite simple and not very robust or accurate. However, considering the limited
    training dataset, it does a good job of being able to recognize features on the
    fly. Open up the `Environmental Scanner` script, and we will take a look at how
    the network is configured:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Scroll down to the `Awake` method and take a look at how the network is created:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Note that this time we are creating an input layer of `25` neurons and output
    of `1`. If we stick to the general rule for our hidden layer being the average
    of the input and output, that equates to `13` [(`25`+`1`)/2=`13`].
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We removed the initial NN setup and training from `Start` and moved it to the
    bottom in a new method called `Train`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: This time, we are using a different form of training called **epoch**. We use
    this form of training when we are not actually sure what the expected error is
    or it needs to change, as in this case. Think about this—when we start training
    our network with a very limited dataset, our error rates will be high due to our
    lack of data. This will mean that we will never be able to train our network to
    a minimum error. It, therefore, makes more sense to just run our training algorithm
    for a set number of iterations or epochs for every training cycle.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Just preceding `Train` is `TrainNetwork`, and it''s shown as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: '`TrainNetwork` is a public method that we use to signal to the `Environmental
    Scanner` to initiate a training cycle with the expected outcome. This allows us
    to wire up event handlers on the UI buttons to call this method with an expected
    value. When you press Train 0, `TrainNetwork` is passed `0.0`, and after the Train
    1 button is pressed, `1.0` is passed.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Scroll up to the `Update` method and look at the following section of code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: This is the block of code that checks the `training` flag. If it is set, it
    collects the normalized inputs and adds them to `dataSets` with the expected outcome.
    We then turn the flag off and call `Train`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Scroll up to the following block of code, and you can see how we are normalizing
    the training `inputs`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: Here, we are normalizing the `inputs`. An `input` represents the distance or
    magnitude between an identified point and the camera (user). Normalizing is scaling
    or converting your data to values in the range `0` to `1`. We do this, in this
    case, by finding the maximum distance of each point and then using that to divide
    into all the other inputs. The test in the loop to check whether `i` is less than
    the `PointCount` is to ensure that we always set a value for each input neuron.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The rest of the code is similar to what we wrote earlier and not worth going
    over again.
  prefs: []
  type: TYPE_NORMAL
- en: The network view of the world
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'So what exactly is going on here, what is it that the network is identifying?
    Essentially, we are flattening our 3D view of the world into a 2D line or curve.
    A typical example of how this line may look normalized is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5d6fd76d-b118-432a-b113-c6c2248e895a.png)'
  prefs: []
  type: TYPE_IMG
- en: Normalized input points
  prefs: []
  type: TYPE_NORMAL
- en: Those inputs represent the normalized view the neural network is training for,
    or perhaps, against. If you trained the network to recognize that line, then the
    warning sound should go off when it detects the said line. Of course, the more
    points you add, the better your recognizer may or may not work. We will leave
    it up to you to further test the network on your own.
  prefs: []
  type: TYPE_NORMAL
- en: Neural networks were quite popular with game and graphic developers in the late
    1990s and early 2000s. NNs showed some success in various AI scenarios, driving
    games especially, but at the end, other purpose-built techniques won out, that
    is, until quite recently with the advent of new techniques such as convolutional
    NNs. These new successes have led to massive surges in deep learning techniques
    and platforms.
  prefs: []
  type: TYPE_NORMAL
- en: This simple NN can be extended to recognize other simple functions or patterns
    you wanted. However, it will work poorly if we try to use it for any of the other
    recognition tasks we identified earlier as critical for AR. Therefore, in the
    next section, we will look at how ML solves our recognition problems with a new
    platform developed by Google, called TensorFlow.
  prefs: []
  type: TYPE_NORMAL
- en: Exercises
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Work through the following exercises on your own:'
  prefs: []
  type: TYPE_NORMAL
- en: Explain the difference between unsupervised learning, supervised learning, and
    reinforcement learning. This is more of a thought exercise, but it will be beneficial
    to really understand the difference.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Modify the original NN example to warn you when objects are detected past a
    certain distance.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What happens in the second example if you order the inputs by length? Does it
    still work?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add an additional output neuron to the network in the second example. You will
    also need a new training button and will need to modify the `TrainNetwork` function
    to take two `inputs`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: TensorFlow
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There is a new kid on the block called **TensorFlow**, also developed by Google,
    that is making impressive waves in ML. TensorFlow is a full ML platform that is
    actually more than just an execution engine with a bunch of built-in tools. What
    is even more impressive is that you can train advanced neural nets, convolutional
    neural networks, capsule networks, or whatever else you need on massive datasets
    offline. Then, you take those trained networks and put them on a mobile device
    in what is called a **MobileNet** to quickly recognize and classify complex objects.
    We will take a break from ARCore in this section and look at the upcoming power
    of TensorFlow.
  prefs: []
  type: TYPE_NORMAL
- en: TensorFlow is an advanced ML resource and toolkit that will be worth your time,
    learning more about whether you need to do any advanced recognition tasks. Keep
    in mind, though, that this tool requires advanced knowledge in math and a working
    knowledge of Python.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will run the TensorFlow example for Android, not just to get a grasp of
    the power of the tool but also to understand what is possible. With Google building
    TensorFlow and ARCore though, we can only assume that new integrated tools will
    be built in the future. For now, though, let''s open Command Prompt or shell and
    get started:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Run the following command from your user folder or root:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Create the `TensorFlow` directory and navigate to it. Then, type the following
    command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: Open Android Studio. From the Welcome screen, select Open an existing Android
    Studio project.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use the dialog and navigate to, select the `TensorFlow/tensorflow/examples/android`
    folder, and click on OK.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If it asks you to do a Gradle Sync, click on OK.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Open the `build.gradle` file from the Project side panel under the Gradle Scripts
    and set the `nativeBuildSystem` variable to `none`, as shown here:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: Connect your device and click on the Run button, the green arrow icon on top.
    Follow any necessary build steps and let the apps push to your device.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'When the build is completed, Studio will have pushed four apps to your device:
    **TFClassify**, **TFDetect**, **TFSpeech**, and **TFStylize**. Play around with
    each of these examples and observe the power of some networks running on your
    device.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The following is an example of the TFDetect app running and correctly classifying
    a dog and person with very high accuracy:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ad019856-28a7-4f43-84eb-82a4379fe961.png)'
  prefs: []
  type: TYPE_IMG
- en: TFDetect correctly classifying a dog and person
  prefs: []
  type: TYPE_NORMAL
- en: Unfortunately, the components needed to run TensorFlow with ARCore are not quite
    ready yet, so at the time of writing, we couldn't complete a full example. However,
    the future of ML for AR apps will most certainly be with TensorFlow or some other
    third-party solution, piggybacking on top of TensorFlow. Google has years of experience
    in AI/ML, from developing self-driving cars to the Google Home. It has put those
    years of knowledge into TensorFlow and made it accessible to the world. You would
    have to be a fool not to spend any time learning TensorFlow if you plan to build
    your own ML for object/feature recognition.
  prefs: []
  type: TYPE_NORMAL
- en: We had planned to build an example with a trained MobileNet running in ARCore.
    Unfortunately, the pieces were not quite ready yet, and it made for a far too
    complicated example. Right around the time that this book is published, we will
    likely see more tools developed to make integrating TensorFlow into ARCore easier.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we took a proverbial dive into the deep end—or the deep learning
    end—of the pool. We started by talking about the importance of ML and what applications
    we can use it for in AR. Then, we looked at how ML can use various methods of
    learning from unsupervised, supervised, and reinforcement learning in order to
    teach an ML agent to learn. We then looked at a specific example of learning ML
    algorithms, called neural networks and often referred to as deep learning. This
    led us to build a simple neural network that you can also use to learn the intricacies
    of neural networks on your own. NNs are very complex and not very intuitive, and
    it is helpful to understand their basic structure well. We then trained this network
    on a very simple dataset to notify the user if they get too close to an object.
    This led to a further discussion of how NNs train with back propagation using
    the gradient descent algorithm. After that, we looked at an enhanced example that
    allows you to train the network to recognize an area or object. Finally, we looked
    at the current king of ML, TensorFlow, and looked at a quick example of what is
    possible and what is coming soon.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we get back to building a practical example with ARCore.
    We will build a simple design app that lets the user virtually decorate their
    living space.
  prefs: []
  type: TYPE_NORMAL
