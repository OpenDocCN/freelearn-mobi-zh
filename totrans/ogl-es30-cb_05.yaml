- en: Chapter 5. Light and Materials
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following recipes:'
  prefs: []
  type: TYPE_NORMAL
- en: Implementing the per-vertex ambient light component
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing the per-vertex diffuse light component
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing the per-vertex specular light component
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Optimizing the specular light with the halfway vector
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gouraud shading – the per-vertex shading technique
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Phong shading – the per-fragment shading technique
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing directional and point light
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing multiple lights in a scene
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing two-side shading
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter will introduce the concepts of light and material in 3D graphics.
    We will understand the concept of light from the aspect of physics and its dual
    nature. We will discuss the different types of light components, such as ambient,
    diffuse and specular, with their implementation techniques. Later in this chapter,
    we will cover some important common illumination techniques (such as Phong shading
    and Gouraud shading). This will help us in implementing realistic-looking lighting
    models in computer graphics. In addition, you will learn the difference between
    directional and positional light and see how optimization can be achieved in the
    specular lighting by using the halfway vector technique. At the end of this chapter,
    we will demonstrate how to set up multiple lights in a scene and render objects
    with two-sided shading.
  prefs: []
  type: TYPE_NORMAL
- en: 'Light is an electromagnetic radiation; it exists with an enormous range of
    frequencies or wavelengths. Human eyes can only see a portion of this wavelength
    of the electromagnetic spectrum and this range of portion is called visible light.
    Our eye receives these visible wavelengths as colors and the visible light spectrum
    varies from 400 nm (violet) to 700 nm (red):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Introduction](img/5527OT_04_30.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Light possesses important properties (such as intensity, direction, color, and
    location). In 3D graphics, we use these important properties of light to simulate
    various light models. In this chapter, we will use the OpenGL ES programmable
    pipeline to program various light models using shaders. This chapter will be helpful
    in providing an insight into all of the mathematics and physics required for lighting
    purposes.
  prefs: []
  type: TYPE_NORMAL
- en: 'Back in 1600s, colors were believed to be a mixture of light and darkness.
    In 1672, Sir Issac Newton published a series of experiments and provided us with
    the modern understanding of light. He successfully refracted that white light
    consists of a mixture of seven different colors: red, orange, yellow, green, blue,
    indigo, and violet. He also proposed that light is composed of particles or corpuscles.'
  prefs: []
  type: TYPE_NORMAL
- en: Much later, in 1802, Thomas Young proved that light behaves as a wave through
    one of his experiments. He related colors to wavelength and managed to calculate
    the approximate wavelength of the seven colors discovered by Sir Isaac Newton.
  prefs: []
  type: TYPE_NORMAL
- en: 'The final proposition of light was given by Albert Einstein in March, 1905\.
    That year, he published his quantum theory of light, where he proposed light as
    particles and named these particles **photons**. In June, 1905, he completed his
    theory of special relativity, which added a twist to his earlier proposal where
    light was believed to be a particle. The special theory of relativity sees light
    as a wave. Such contradiction gave enough proof to Einstein to propose the dual
    nature of light. According to him, light behaves both as a particle and a wave:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Introduction](img/5527OT_04_31.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Light has a dual nature; it can behave as a particle and wave at the same time.
    Let''s take a look in more detail:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Light as a particle**: Light behaves as particles. These particles are small
    packets of energy that are not same as the small physical particles of atoms.
    These packets of energy have a constant velocity and no mass, which exhibit reflection
    properties that are similar to the billiard balls used in a pool game. When particles
    hit each other, they propagate in the direction of the force and are reflected
    as a result of obstacles. When photon particles hit obstacles, they lose energy
    in the form of absorption. As a result of continuous reflection, these particles
    strike and diminish. As a result of collision, the obstacle from these particles
    gains energy and preserves the law of conservation of energy.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Light as waves**: Light behaves as waves. These are electromagnetic waves
    with electric and magnetic properties. The electromagnetic waves do not need any
    medium to travel through space because they are capable of traveling through vacuum.
    Each wave looks like a sine wave. The intensity of the wave is measured with amplitude,
    as shown in the preceding figure. The length of one complete sine wave is called
    as **wavelength**. The greater the wavelength, more visible is the color. Treating
    light as waves in 3D computer graphics opens up many possibilities, which one
    cannot achieve with the particle nature of light. For example, the particle exhibits
    propagation as rays; it cannot simulate diffraction and interference which is
    an important property of waves.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In a computer graphic simulation, the wave nature of light is represented by
    wave fronts stored as 2D arrays of complex numbers. The study of light in computer
    graphics in itself is a vast subject; covering wave-based illuminations is beyond
    the scope of this chapter. This chapter will help in modeling particle-based local
    light illumination modeling techniques.
  prefs: []
  type: TYPE_NORMAL
- en: 'Light is composed of three types of components: ambient (**A**), diffuse (**D**),
    and specular (**S**). They are explained as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Ambient (A)**: This light component comes from all directions equally and
    is scattered in all the directions equally by the objects on which it falls; this
    makes the objects on the surface appear with constant light intensity.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Diffuse (D)**: This light component comes from a particular direction from
    the light source. It hits the surface of an object with variable intensity, which
    depends on the Lambert law of illumination. In other words, the intensity depends
    on the direction of light appearing on the face of the object and the direction
    of object face point to.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Specular (S)**: This light component also comes from a particular direction
    and reflects the most in the direction of the camera''s view or the observer''s
    eye. It gives an effect of shininess on the model''s surface:![Introduction](img/5527OT_04_32.jpg)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In computer graphics, light and material are both mathematically treated as
    colors. The color associated with an object is called material and the color associated
    with illumination is called light. The color intensity of light and material are
    specified with RGB (red, blue, green) components. Objects are visible because
    they reflect the light that falls up on them. For example, when sunlight falls
    on a green material color ball, the green material absorbs all other wavelengths
    and reflects the green portion of the light spectrum. As a result, it appears
    green to the viewer. Mathematically, the reflected or resultant color is the product
    of light and material color intensities:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '![Introduction](img/5527OT_04_33.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'In modern computer graphics, there are two ways in which light shading equations
    can be calculated: per-vertex and per-fragment. They are explained as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Per-vertex light shading**: In this type of shading, the mathematical equations
    to calculate light shading colors are formulated in the vertex shader. Each vertex
    color is calculated within the vertex shader and then passed on to the fragment
    shader. These vertex colors are then interpolated to the geometry faces to result
    each fragment or pixel color. As the colors are calculated in the vertex shader,
    it''s called per-vertex shading.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Per-fragment light shading**: This calculates light colors within the fragment
    shader for each fragment. The quality of per-fragment shading is considerably
    better than the vertex shader. The performance of per-fragment shading is slower
    than per-vertex shading. This is because processing fewer vertices, as compared
    to thousands of pixels, is quicker. In today''s modern graphics, processors are
    capable of performing several parallel operations at lightning speed; therefore,
    it may not be very expensive for general purpose application requirements.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
- en: One disadvantage of per-vertex light shading is that it may not be helpful for
    specular light to generate shading as expected because fragment colors are calculated
    at each vertex and shared among faces; therefore, instead of generating a smooth
    oval shining surface, it will generate a flat shining surface.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Implementing the per-vertex ambient light component
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The ambient light illuminates the object''s surface equally in all directions
    on which it''s applied. All faces receive an equal amount of light; therefore,
    no change in color can be observed on the complete object. Ambient is basically
    a mixture of two components: the color intensity of light and material.'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Mathematically, this is the product ambient light (L[a]) and ambient material
    (K[a]).
  prefs: []
  type: TYPE_NORMAL
- en: '*I[a] = L[a]K[a]*'
  prefs: []
  type: TYPE_NORMAL
- en: An ambient light plays a vital role in Phong and Gouraud shadings; the diffuse
    and specular color components of these shadings are computed by using the direction
    of the light that falls on the object. Therefore, an object may receive less or
    no light on its side or back faces depending on the direction of light on the
    object. In such cases, the faces may appear invisible because of the black light
    that is generated; choosing the correct ambient light and material color will
    help in making these darkened faces visible.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This chapter will make use of the Wavefront 3D mesh models that we implemented
    in [Chapter 4](ch04.html "Chapter 4. Working with Meshes"), *Working with Meshes*.
    We will reuse the ObjLoader recipe from the same chapter to implement new recipes
    in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The step-by-step implementation of ambient light is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Reuse the ObjLoader recipe from the previous chapter and create a new vertex
    shader file called `AmbientVertex.glsl` and add the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Similarly, create the `AmbientFragment.glsl` fragment shader file as:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'In the `InitModel()` of the `ObjLoader` class, compile these shaders and set
    the uniform variable parameters for the ambient light and material:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The `Render()` function is the same as before; it uses the VAO to render the
    Wavefront `OBJ` model.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When the `ObjLoader` class object is created, it initializes the necessary parameters
    in the constructor. The `InitModel` function compiles the shader program and sets
    any necessary uniform variables; the vertex shader contains two uniform variables
    called `MaterialAmbient` and `LightAmbient`. The former is used to define the
    ambient color property of the material property of the object and the latter is
    used to specify the color of the light.
  prefs: []
  type: TYPE_NORMAL
- en: These variables are sent to the vertex shader and the ambience color shade is
    calculated as the product of these two variables; the result is stored in a new
    output variable called `FinalColor`. This variable is sent to the fragment shader
    and applied as a final color to each fragment. The `gl_position` is the clip coordinate
    value, which is a product of the vertex position and `ModelViewProjectionMatrix`.
    The `ModelViewProjectionMatrix` uniform variable is a product of the projection,
    view, and model matrix.
  prefs: []
  type: TYPE_NORMAL
- en: '![How it works...](img/5527OT_04_34.jpg)'
  prefs: []
  type: TYPE_IMG
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Refer to the *Rendering the wavefront OBJ mesh model* recipe in [Chapter 4](ch04.html
    "Chapter 4. Working with Meshes"), *Working with Meshes*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Refer to the *Managing VBO with Vertex Array Objects* recipe in [Chapter 3](ch03.html
    "Chapter 3. New Features of OpenGL ES 3.0"), *New Features of OpenGL ES 3.0*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Refer to the *Efficient rendering with Vertex Buffer Object* recipe in [Chapter
    2](ch02.html "Chapter 2. OpenGL ES 3.0 Essentials"), *OpenGL ES 3.0 Essentials*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing the per-vertex diffuse light component
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Diffuse light comes from a particular direction and is reflected in various
    directions after collision with the surface of the object. In this section, we
    model this behavior by using the Phong Reflection Model, which was developed by
    Bui Tuong Phong in 1973\. This model proposed an illumination shading technique
    that uses a normal surface and the direction of incident light. When light strikes
    on an object's surface, some of its parts are reflected and the rest is partially
    absorbed. Therefore, we can calculate either the intensity of light absorbed or
    reflected, if one of the components is given.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Total light intensity = reflection light intensity + absorption light intensity
  prefs: []
  type: TYPE_NORMAL
- en: When 100 percent light intensity falls on a plain surface and 50 percent of
    it is reflected, it's obvious that 50 percent of light intensity is being absorbed
    or lost in the surroundings. In 3D graphics, we are only concerned with the reflected
    light intensity because we see objects as a result of the reflection of light
    on them. The diffuse and specular components of light basically use the Phong
    reflection model as a result of light and surface interaction to model illumination
    techniques.
  prefs: []
  type: TYPE_NORMAL
- en: The Phong reflection model uses the Lambert cosine law to demonstrate the reflection.
    The Lambert cosine law uses the direction of incident light and the direction
    of surface geometry to calculate the intensity of light on the surface of geometry.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The Lambert cosine law states that the intensity of illumination on a diffuse
    surface is directly proportional to the cosine of the angle made by the surface
    normal vector and the direction of light.
  prefs: []
  type: TYPE_NORMAL
- en: '![Implementing the per-vertex diffuse light component](img/5527OT_04_49.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The general mathematical equation to calculate diffuse light is:'
  prefs: []
  type: TYPE_NORMAL
- en: '*I[d] = L[d]K[d](N.S)*'
  prefs: []
  type: TYPE_NORMAL
- en: The *L[d]* and *K[d]* are the diffuse components of the light and material;
    the (*N.S*) is the dot product used to calculate the cosine of the angle between
    the surface normal (*N*) and the incident light vector (*S*); both these vectors
    must be normalized first before calculating the dot product. A normalized vector
    is a vector whose length is unity; it's also called unit vector. For this recipe,
    we will reuse our first recipe, that is, ambient and make changes, as described
    in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Use the following instructions to implement the diffuse light component:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Reuse the last recipe for the per-vertex ambient light component (Ambient recipe)
    and create a new vertex shader file called `DiffuseVertex.glsl` in it, as shown
    in the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: There is no change in the fragment shader; we can reuse it from the last recipe,
    except we will rename it as `DiffuseFragment.glsl`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In the `InitModel` after the shader are compiled successfully, set the configuration
    for diffuse light and material color and specify the position of light in world
    coordinates:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'In the `Render()` function, specify the normal matrix, model view matrix, and
    model view project matrix, along with the generic vertex attributes:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The diffuse light vertex shader uses vertex position, vertex normal, and light
    position to calculate the light shading using the Phong reflection model; each
    `VertexPosition` is transformed into an eye coordinate by multiplying it with
    `ModelViewMatrix`. Similarly, vertex normal also needs to convert to an eye coordinate
    so that the transformation is also applied to normal as well. This is achieved
    by multiplying the `Normal` with the `NormalMatrix`.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Unlike vertex positions, which are transformed into eye coordinates using the
    `ModelView` matrix, vertex normal are transformed by using the `NormalMatrix`.
    The normal matrix is a submatrix of the model view matrix, but its specialty is
    that it preserves the normal of the geometry when an affine transformation is
    applied. `NormalMatrix` is the inverse transpose of the upper-left 3 x 3 matrix
    of the model view matrix.
  prefs: []
  type: TYPE_NORMAL
- en: The `nLight` light vector is calculated by subtracting eye coordinates of the
    `eyeCoord` vertex position from `LightPosition`; the `nLight` direction is calculated
    from the surface to the light source. The `nLight` and `nNormal` must be normalized
    before taking the dot product in order to find the cosine angle between them.
  prefs: []
  type: TYPE_NORMAL
- en: Light intensity is stored as the cosine angle between the surface normal vector
    and light vector. The color information of the material and light is specified
    in two uniform variables, namely, `MaterialDiffuse` and `LightDiffuse`; the product
    of these two variables is stored in the new variable called diffuse. The cosine
    angle is calculated as the dot product of the `nLight` and `nNormal` and stored
    in the `cosAngle` variable.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The intensity of light and material are basically used in terms of RGB components,
    which are always non-negative. Each component of R, G, and B is stored as a floating
    point number in the range between `0.0f` and `1.0f`. Light intensity is calculated
    as a cosine function, which can result in a range value between -1 and 1\. We
    do not want negative light intensities because they do not make sense. Therefore,
    we should only consider light intensity within the range of 0.0 and 1.0; for this
    reason, the `max()` function is used in the resultant light intensity.
  prefs: []
  type: TYPE_NORMAL
- en: '![How it works...](img/5527OT_04_50.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The diffuse color shade is calculated as the product of diffuse and `cosAngle`
    and stored in a new out variable called `FinalColor`. This variable is sent to
    the fragment shader and applied to each fragment. The last line of the vertex
    shader helps to calculate clipped coordinates by multiplying the vertex position
    with the model view projection matrix.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Implementing the per-vertex ambient light component*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing the per-vertex specular light component
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Specular light is responsible for producing shininess on the surface of an object.
    Unlike diffuse light, which uses the incident ray and surface normal to find the
    intensity of light, specular light uses the reflected ray and the direction of
    the viewer to find the intensity of light.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The following figure illustrates the scenario in which the viewer''s position
    (camera) is brought in to the picture to demonstrate the mathematical calculations
    for specular light. The angle made by the incident ray of light with the normal
    of the surface is always equal to an angle of reflection with the same normal.
    Therefore, both **S** and **R** vectors create a **θ** angle with **N**. The **S**
    vector is represented by the opposite direction (**-S**); this is because we are
    interested in calculating the **R** reflection vector:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Getting ready](img/5527OT_04_36.jpg)'
  prefs: []
  type: TYPE_IMG
- en: This shininess is dependent on the angle made between the viewer and the reflected
    light; if the angle between the viewer's vector and the reflected vector is small,
    then the surface is shinier.
  prefs: []
  type: TYPE_NORMAL
- en: 'Mathematically, in the Phong reflection model, the specular component''s reflection
    vector (**R**) is calculated as:'
  prefs: []
  type: TYPE_NORMAL
- en: '*R = 2N (N.S) + (-S)*'
  prefs: []
  type: TYPE_NORMAL
- en: 'However, in the OpenGL ES shading language, we can use the `reflect()` function
    to calculate vector `R`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'The *α* angle between the *R* and *V* vectors can be calculated as the dot
    product between these two vectors. The *V* vector is in the eye coordinates; the
    vertices that are closer to the *R* vector in the same direction will cause shininess
    on the surface. Given *R* and *V*, the specular illumination can be calculated
    mathematically as:'
  prefs: []
  type: TYPE_NORMAL
- en: '*I[s] = L[s]K[s]( R.V )[G]*'
  prefs: []
  type: TYPE_NORMAL
- en: The *G* superscript in the preceding formula is used for glossy factor; its
    practical significance is to produce larger or smaller glossy spot on the surface
    of an object. Its value ranges between 1 and 200; the larger the value, smaller
    and brighter and vice versa.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Reuse the previous implemented recipe for diffuse shading and make necessary
    changes in the shaders and program code, as described in the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create `SpecularVertex.glsl` and use the following instruction for the vertex
    shader; there is no change in the fragment shader. We can reuse the existing code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'In the `InitModel,` load and compile the specular shader and set the configuration
    for specular light and material color. Also, specify the position of light in
    world coordinates:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The specular light vertex shader calculates the `nNormal`, `eyeCoord`, and
    `nLight` in the same way we computed it in the previous recipe. Calculate the
    direction of the viewer or the (*V*) camera by normalizing eye coordinates and
    the *R* reflection vector with the help of the reflect() function. The dot product
    of *R* and *V* is clamped by the max function within the range 0.0 and 1.0\. This
    result is used to calculate the power function with `ShininessFactor`, which is
    responsible for producing a glossy spot on the surface; the calculated result
    is stored in sIntensity. The `FinalColor` is calculated as a product of `sIntensity`,
    `MaterialSpecular`, and `LightSpecular`. This color information is sent to the
    fragment shader as an out variable and applied to respective fragments created
    by primitives formed by vertices:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How it works...](img/5527OT_04_37.jpg)'
  prefs: []
  type: TYPE_IMG
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Implementing the per-vertex ambient light component*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Implementing the per-vertex diffuse light component*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Optimizing the specular light with the halfway vector
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The specular illumination that we have implemented in the previous recipe uses
    the reflection vector from the incident light ray to demonstrate the spotty illumination.
    This reflection vector is calculated by the `reflect()` function in the GLSL.
    This function is slightly expensive to calculate. Therefore, instead of calculating
    the dot product between the reflection and the (`R.V`) camera vector, we can also
    calculate (`nNormal.H`), which is the dot product between our surface normal vector
    and the halfway vector. The `H` halfway vector is the vector between the camera
    (viewer''s) vector and incident light. In the following figure, you can see the
    resultant of the `V` and `S` vector (Note: not `-S`):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Optimizing the specular light with the halfway vector](img/5527OT_04_38.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Mathematically, the halfway vector is calculated as:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Halfway vector (H) = incident light vector (S) + camera vector (V)*'
  prefs: []
  type: TYPE_NORMAL
- en: 'The equation to calculating the halfway specular light is:'
  prefs: []
  type: TYPE_NORMAL
- en: '*H = S + V*'
  prefs: []
  type: TYPE_NORMAL
- en: '*I[s] = L[s]K[s] ( N.H )[G]*'
  prefs: []
  type: TYPE_NORMAL
- en: '![Optimizing the specular light with the halfway vector](img/5527OT_04_39.jpg)'
  prefs: []
  type: TYPE_IMG
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Use the previous recipe, *Implementing* *the per-vertex specular light component*,
    and make the following changes in the `SpecularVertex.glsl`. The changes in the
    following code are marked in bold. There is no change required in the fragment
    shader:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this technique, we use the `nLight` incident light vector and the (`V`)
    camera vector to find the (`H`) resultant vector by adding them. Both vectors
    must be in the eye coordinates; the resultant halfway vector must be normalized
    in order to generate correct results. Calculate the dot product between the (`nNormal`)
    normal surface vector and the (`H`) halfway vector and substitute it in the equation
    mentioned previously to calculate specular illumination:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: The current technique is considered to be more efficient as compared to the
    prior specular technique we implemented. The preceding image shows the difference
    between the two techniques. There is no doubt that using the halfway vector technique
    is an approximation and generates less obvious result characteristics in comparison
    to the original technique. This approximation is very close to reality; therefore,
    if you are not too bothered about precise quality, you can use the halfway vector
    to calculate the shininess of the surface.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Remember to always use (`-S`) to calculate the reflection vector and use (`S`)
    to calculate the (`H`) halfway vector.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Implementing the per-vertex specular light component*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gouraud shading – the per-vertex shading technique
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This recipe implements the Phong reflection model with all the three components
    of light, that is, ambient (A), diffuse (D), and specular (S), which we looked
    at in the previous recipes. This illumination technique is also known as ADS or
    Gouraud shading. The Gouraud shading technique is per-vertex shading because the
    fragment's color is calculated in the vertex shader by using each vertex's position
    information.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This recipe combines the effect of our ambient (A), diffuse (D), and specular
    (S) illumination, which we have implemented in our previous recipes, using the
    Phong reflection model technique. Mathematically, it''s the summation of ambient,
    diffuse, and specular fragment colors:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Gouraud shading color = ambient color + diffuse color + specular color*'
  prefs: []
  type: TYPE_NORMAL
- en: '![Getting ready](img/5527OT_04_40.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Before implementing the Gouraud shading, it's advisable to understand ambient,
    diffuse, and specular illumination techniques thoroughly, as mentioned in this
    chapter.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The Gouraud shading recipe implementation will make use of the existing vertex
    shader files from the ambient, diffuse, and specular recipes in the current vertex
    shader called `GouraudShadeVertex.glsl`. This recipe uses a global function called
    `GouraudShading()` to implement the Gouraud shading technique; the fragment shader
    can be completely reused as it does not require any change. The following code
    snippet describes the Gouraud shading vertex shader:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `GouraudShading()` function calculates the color for each vertex by adding
    the ambient, diffuse, and specular light colors; the resultant color information
    is returned to the `main()` program. The vertex shader then shares this color
    information to the fragment shader. The fragment shader interpolates the entire
    color for each fragment by using the color information received from the vertex
    shader.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The function definitions in OpenGL ES Shading Language is similar to the C language;
    it can return values and pass arguments by value. These do not support pointers
    or reference to send the information by address. For more information on function
    definition in GL Shading Language 3.0, refer to [http://www.khronos.org/files/opengles_shading_language.pdf](http://www.khronos.org/files/opengles_shading_language.pdf).
  prefs: []
  type: TYPE_NORMAL
- en: This recipe is implemented using point light; the rays from a point light form
    different angles with vertex when it falls on the object.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Implementing directional and point light*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Phong shading – the per-fragment shading technique
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This shading technique is also called as smooth shading. In this recipe, we
    will implement Phong shading, which is a per-fragment illumination technique.
    Using the per-fragment technique, light shadings add more realism to the rendering
    scene in comparison to the per-vertex technique. We will compare Gouraud shading
    with Phong shading to see the relative difference between the two techniques.
  prefs: []
  type: TYPE_NORMAL
- en: In Phong shading, color intensities are directly calculated within the fragment
    shader with the help of light and material properties. The vertex shader is responsible
    for calculating the normal and vertex position in the eye coordinates; these variables
    are then passed on to the fragment shader. The vertex normal and vertex positions
    are interpolated and normalized for every fragment to produce the resultant fragment
    colors.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Use the following steps to implement and see this technique in action:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create `PhongShadeVertex.glsl` and reuse most of the variables from previous
    recipes. Refer to the following code. The main difference is `normalCoord` and
    `eyeCoord`, which are defined as the out variables. Note: we will not use the
    properties of light and material in vertex shader; instead, these will be used
    in fragment shader:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create the `PhongShadeFragment.glsl` fragment shader file and add all the light
    and material property variables to the required precision qualifier. We will use
    the medium precision qualifier; this precision qualifier precedes the type in
    the variable declaration:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In Phong shading, the vertex shader calculates the vertex normal (`normalCoord`)
    and vertex position in the eye coordinate system (`eyeCoord`) and sends it to
    the fragment shader. The fragment shader uses these values and interpolates the
    vertex normal and vertex position for each fragment. The interpolated values must
    be normalized in order to produce accurate results. The remaining process to calculate
    ambient, diffuse, and specular light is the same as discussed in the previous
    recipes.
  prefs: []
  type: TYPE_NORMAL
- en: By default, the vertex shader does not require any precision in order to be
    defined (it's optional). If no precision is defined in the vertex shader, then
    it's of the highest precision. In the fragment shader, the precision qualifier
    needs to be defined (it's not optional).
  prefs: []
  type: TYPE_NORMAL
- en: There are three types of precision qualifier, namely, `lowp`, `medium`, and
    `highp`. These precision qualifiers could affect the performance of the application;
    it's therefore advisable to use the correct precision according to the implementation
    requirement. Lower precision may help to increase the FPS and power efficiency;
    however, it may reduce the quality of rendering. In our case, we will use the
    mediump precision for all the variables in the fragment shader.
  prefs: []
  type: TYPE_NORMAL
- en: '![How it works...](img/5527OT_04_41.jpg)'
  prefs: []
  type: TYPE_IMG
- en: There's more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We have used the Wavefront OBJ mesh to demonstrate the light shading effects
    on 3D mesh models; you can explore more on meshes in the [Chapter 4](ch04.html
    "Chapter 4. Working with Meshes"), *Working with Meshes*. The same chapter describes
    the flat/smooth shading implementation using normal vectors.
  prefs: []
  type: TYPE_NORMAL
- en: 'The flat/smooth shading implementation can be enabled by using the `ObjMesh`
    class member function called `ParseObjModel`. This specifies the second argument
    as Boolean `true` (flat shading) or `false` (smooth shading). The comparative
    results for the two shading types are shown in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![There''s more...](img/5527OT_04_42.jpg)'
  prefs: []
  type: TYPE_IMG
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Refer to the *Rendering the wavefront OBJ* *mesh model* recipe in [Chapter 4](ch04.html
    "Chapter 4. Working with Meshes"), *Working with Meshes*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing directional and point light
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Light can be divided into three types, namely point light, directional light,
    and spot light. Let''s take a look in detail:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Point light or positional light**: This type of light comes from a fixed
    position in the 3D space. The position of light and vertices of the object on
    which it falls is used to calculate the direction of the light. Point light emits
    light in all directions. Each vertex can have different directions of light, depending
    on its position from the light source, as shown in the following image.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Directional light**: This type of light is a special case of the point light.
    Here, the direction of the light falling on the object is considered as nonvarying.
    This means that the direction of all the light rays are parallel. In directional
    light, the light source is considered infinitely far from the model, on which
    it''s supposed to fall. Sometimes, it''s better to assume the light direction
    to be parallel during the 3D scene rendering process. This is the best way to
    achieve nearly the same effect as point light if the distance between the source
    point and model is appreciably larger.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Spot light**: This type of light uses the direction of the light and a cutoff
    angle to form a cone-shaped imaginary 3D space, as shown in the following figure.
    The light that falls out of this shape is discarded and the light inside the cone
    forms the spotlight effect:![Implementing directional and point light](img/5527OT_04_43.jpg)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Sometimes, the position of the light source is considerably far from the objects.
    In such cases, it''s advisable to implement the light-shading technique using
    directional lighting. The point light shading technique is a little expensive
    because the light direction needs to be calculated per-vertex. It''s directly
    proportional to the number of vertices in the geometry. In contrast, directional
    light is treated in the constant direction where rays are assumed to be traveling
    in parallel directions. Unlike point light, light direction does not consider
    the vertex position in directional light:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Light type | **Mathematical formulation** | **Light direction** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Point | Light direction = light position - eye position | Variable |'
  prefs: []
  type: TYPE_TB
- en: '| Directional | Light direction = light position | Constant |'
  prefs: []
  type: TYPE_TB
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This recipe will demonstrate the difference between point light and directional
    light; all the previous recipes we have implemented so far used point light. In
    fact, with the previous section in this recipe, we understood which light to use
    when. The following instructions in bold are implemented in the fragment shader
    based on Phong shading; similar changes need to be performed in the vertex shader
    if Gouraud shading is implemented:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Point light or positional light**: This requires one change to implement
    point light:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '**Directional light**: Similarly, change the statement marked in bold for directional
    light:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In point lighting, the light vector is used to calculate the directional vector
    of light, with respect to each eye coordinate of the vertex; this produces variable
    directional vectors, which are responsible for different amount of light intensity
    at each vertex.
  prefs: []
  type: TYPE_NORMAL
- en: 'In contrast, directional light assumes all vertexes at origin (0.0, 0.0, and
    0.0). Hence, all the direction vector for each vertex are parallel. The following
    figure compares the point light technique and the directional light technique:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How it works...](img/5527OT_04_44.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Implementing multiple lights in a scene
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'So far, all of our recipes are demonstrated using a single light source. This
    section will help us in implementing multiple lights in a scene. Unlike the fixed
    pipeline architecture, in which only eight lights can be added to the scene, the
    programmable pipeline does not impose any upper limit on the number of multiple
    lights. Adding multiple lights to the scene is very simple. It''s similar to the
    way we added one light position to create one color per-fragment. Now, we add
    *N* number of light sources to generate an average of *N* colors per-fragment:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Implementing multiple lights in a scene](img/5527OT_04_45.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Mathematically, if light sources such as **L1**, **L2**, and **L3** create **FC1**,
    **FC2**, and **FC3** fragment colors individually, then the combined effect of
    these lights will be a single fragment color as a result of an average weight
    of all fragment colors.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The vertex shader for this recipe does not require any special changes to the
    source code. Therefore, we can reuse the same vertex shader (which was implemented
    in the Phong shading recipe). This recipe requires a few changes to the fragment
    shader.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The steps to implement multiple light recipes are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a fragment shader file called `MultiLightFragment.glsl` and highlight
    it, as shown in the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'There is no change required for the vertex shader; however, the main program
    specifies four different light positions and four different diffuse color configurations:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The current recipe uses four lights to demonstrate multiple-light shading in
    a scene. These lights are positioned around the object (left, right, top, and
    bottom). Lights positioned at the left-hand side and the right-hand side use red-diffused
    light color, whereas lights positioned at the bottom and top are set with green-diffused
    light color.
  prefs: []
  type: TYPE_NORMAL
- en: Programmatically, the position of lights and diffuse light colors are defined
    as an array in our shader program with `LightPosition` and `LightDiffuseArray`
    respectively.
  prefs: []
  type: TYPE_NORMAL
- en: '![How it works...](img/5527OT_04_47.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The `GouraudShading()` function is modified to accept an argument, which uses
    an index of the position of the light that needs to be processed. The main program
    loops to calculate the average fragment color intensity. This fragment color is
    returned to the main program.
  prefs: []
  type: TYPE_NORMAL
- en: Light positions that are closer to the surface of the sphere receive more intensity;
    therefore we can clearly see that the sphere is illuminated with green and red
    color at the top, bottom, left and right faces. The front part of the sphere is
    a mixture of green and red color because the intensities received by the sphere
    at the front face from all four light directions are equal.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing two-side shading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In [Chapter 2](ch02.html "Chapter 2. OpenGL ES 3.0 Essentials"), *OpenGL ES
    3.0 Essentials*, we looked at the culling technique, which is a quick way to improve
    performance. This technique avoids rendering polygon faces that face backwards;
    it's not always desirable to clip the back faces (objects that are not completely
    enclosed are generally rendered with back faces). Sometimes, it makes sense to
    view these back faces with different colors. This will help the geometry shape
    to define characteristics that may not be visible with the same color on both
    sides of the faces (back and front).
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we will render a semi-hollow cylinder with different face colors
    (inside and outside). The first thing we need to do is to turn off the back culling.
    We can turn off the back culling with (`glDisable (GL_CULL_FACE)`).
  prefs: []
  type: TYPE_NORMAL
- en: In order to apply different colors on the front and back faces, we need to recognize
    them first. The OpenGL ES shading language provides a simple global-level variable
    called `gl_FrontFacing` in the fragment shader, which helps us to recognize the
    fragments belonging to front facings. This API returns Boolean as `true` if the
    face is front facing and vice versa.
  prefs: []
  type: TYPE_NORMAL
- en: The normal position of the face helps in defining the direction in which it's
    pointing. The normal position of the front face is always in the opposite direction
    of the back face; we will use this clue to shade the front face and the back face
    with different colors.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The multiple lights shading recipe can be reused to implement two-side shading.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Make sure that culling is disabled in the program code; otherwise, two-side
    shading will not work.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There is no change required in the vertex shader. Create a fragment shader
    file called `TwoSideShadingFragment.glsl` and make the following changes mentioned
    in bold:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The working principle for this recipe is very simple; the ideology behind is
    to check whether the primitive fragment belongs to the front face or the back
    face. If it belongs to the front face, assign it with one type of color coding;
    otherwise, chose another type of color. Within the fragment shader, check the
    front facing with `gl_FrontFacing`. Pass the fragment facing type in the `GouraudShading`
    function as an argument. Depending on the front and back facing Boolean value,
    this function will generate the color. We will use `MaterialDiffuseBackFace` and
    `LightDiffuse` for back facing and front facing diffuse light colors respectively.
    In order to calculate the Gouraud shading for back surfaces, we must use negative
    direction normal:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How it works...](img/5527OT_04_48.jpg)'
  prefs: []
  type: TYPE_IMG
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Refer to the *Culling in OpenGL ES 3.0* recipe in [Chapter 2](ch02.html "Chapter 2. OpenGL
    ES 3.0 Essentials"), *OpenGL ES 3.0 Essentials*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
